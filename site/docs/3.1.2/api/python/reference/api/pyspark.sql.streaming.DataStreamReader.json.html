
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>pyspark.sql.streaming.DataStreamReader.json &#8212; PySpark 3.1.2 documentation</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="pyspark.sql.streaming.DataStreamReader.load" href="pyspark.sql.streaming.DataStreamReader.load.html" />
    <link rel="prev" title="pyspark.sql.streaming.DataStreamReader.format" href="pyspark.sql.streaming.DataStreamReader.format.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../index.html">
    
      <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../user_guide/index.html">User Guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../development/index.html">Development</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../migration_guide/index.html">Migration Guide</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="../pyspark.sql.html">Spark SQL</a>
                </li>
            
          
            
                <li class="active">
                    <a href="../pyspark.ss.html">Structured Streaming</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.ml.html">MLlib (DataFrame-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.streaming.html">Spark Streaming</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.mllib.html">MLlib (RDD-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.html">Spark Core</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.resource.html">Resource Management</a>
                </li>
            
          
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="pyspark-sql-streaming-datastreamreader-json">
<h1>pyspark.sql.streaming.DataStreamReader.json<a class="headerlink" href="#pyspark-sql-streaming-datastreamreader-json" title="Permalink to this headline">Â¶</a></h1>
<dl class="py method">
<dt id="pyspark.sql.streaming.DataStreamReader.json">
<code class="sig-prename descclassname">DataStreamReader.</code><code class="sig-name descname">json</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span></em>, <em class="sig-param"><span class="n">schema</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">primitivesAsString</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">prefersDecimal</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowComments</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowUnquotedFieldNames</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowSingleQuotes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowNumericLeadingZero</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowBackslashEscapingAnyCharacter</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">mode</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">columnNameOfCorruptRecord</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dateFormat</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">timestampFormat</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">multiLine</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowUnquotedControlChars</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">lineSep</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">locale</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dropFieldIfAllNull</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">encoding</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">pathGlobFilter</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">recursiveFileLookup</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allowNonNumericNumbers</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/sql/streaming.html#DataStreamReader.json"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.sql.streaming.DataStreamReader.json" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Loads a JSON file stream and returns the results as a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p>
<p><a class="reference external" href="http://jsonlines.org/">JSON Lines</a> (newline-delimited JSON) is supported by default.
For JSON (one record per file), set the <code class="docutils literal notranslate"><span class="pre">multiLine</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">schema</span></code> parameter is not specified, this function goes
through the input once to determine the input schema.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.0.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>path</strong><span class="classifier">str</span></dt><dd><p>string represents path to the JSON dataset,
or RDD of Strings storing JSON objects.</p>
</dd>
<dt><strong>schema</strong><span class="classifier"><a class="reference internal" href="pyspark.sql.types.StructType.html#pyspark.sql.types.StructType" title="pyspark.sql.types.StructType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.StructType</span></code></a> or str, optional</span></dt><dd><p>an optional <a class="reference internal" href="pyspark.sql.types.StructType.html#pyspark.sql.types.StructType" title="pyspark.sql.types.StructType"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.types.StructType</span></code></a> for the input schema
or a DDL-formatted string (For example <code class="docutils literal notranslate"><span class="pre">col0</span> <span class="pre">INT,</span> <span class="pre">col1</span> <span class="pre">DOUBLE</span></code>).</p>
</dd>
<dt><strong>primitivesAsString</strong><span class="classifier">str or bool, optional</span></dt><dd><p>infers all primitive values as a string type. If None is set,
it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>prefersDecimal</strong><span class="classifier">str or bool, optional</span></dt><dd><p>infers all floating-point values as a decimal type. If the values
do not fit in decimal, then it infers them as doubles. If None is
set, it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>allowComments</strong><span class="classifier">str or bool, optional</span></dt><dd><p>ignores Java/C++ style comment in JSON records. If None is set,
it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>allowUnquotedFieldNames</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows unquoted JSON field names. If None is set,
it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>allowSingleQuotes</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows single quotes in addition to double quotes. If None is
set, it uses the default value, <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
</dd>
<dt><strong>allowNumericLeadingZero</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows leading zeros in numbers (e.g. 00012). If None is
set, it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>allowBackslashEscapingAnyCharacter</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows accepting quoting of all character
using backslash quoting mechanism. If None is
set, it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str, optional</span></dt><dd><p>allows a mode for dealing with corrupt records during parsing. If None is
set, it uses the default value, <code class="docutils literal notranslate"><span class="pre">PERMISSIVE</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PERMISSIVE</span></code>: when it meets a corrupted record, puts the malformed string               into a field configured by <code class="docutils literal notranslate"><span class="pre">columnNameOfCorruptRecord</span></code>, and sets malformed               fields to <code class="docutils literal notranslate"><span class="pre">null</span></code>. To keep corrupt records, an user can set a string type               field named <code class="docutils literal notranslate"><span class="pre">columnNameOfCorruptRecord</span></code> in an user-defined schema. If a               schema does not have the field, it drops corrupt records during parsing.               When inferring a schema, it implicitly adds a <code class="docutils literal notranslate"><span class="pre">columnNameOfCorruptRecord</span></code>               field in an output schema.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DROPMALFORMED</span></code>: ignores the whole corrupted records.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FAILFAST</span></code>: throws an exception when it meets corrupted records.</p></li>
</ul>
</dd>
<dt><strong>columnNameOfCorruptRecord</strong><span class="classifier">str, optional</span></dt><dd><p>allows renaming the new field having malformed string
created by <code class="docutils literal notranslate"><span class="pre">PERMISSIVE</span></code> mode. This overrides
<code class="docutils literal notranslate"><span class="pre">spark.sql.columnNameOfCorruptRecord</span></code>. If None is set,
it uses the value specified in
<code class="docutils literal notranslate"><span class="pre">spark.sql.columnNameOfCorruptRecord</span></code>.</p>
</dd>
<dt><strong>dateFormat</strong><span class="classifier">str, optional</span></dt><dd><p>sets the string that indicates a date format. Custom date formats
follow the formats at
<a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html">datetime pattern</a>.  # noqa
This applies to date type. If None is set, it uses the
default value, <code class="docutils literal notranslate"><span class="pre">yyyy-MM-dd</span></code>.</p>
</dd>
<dt><strong>timestampFormat</strong><span class="classifier">str, optional</span></dt><dd><p>sets the string that indicates a timestamp format.
Custom date formats follow the formats at
<a class="reference external" href="https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html">datetime pattern</a>.  # noqa
This applies to timestamp type. If None is set, it uses the
default value, <code class="docutils literal notranslate"><span class="pre">yyyy-MM-dd'T'HH:mm:ss[.SSS][XXX]</span></code>.</p>
</dd>
<dt><strong>multiLine</strong><span class="classifier">str or bool, optional</span></dt><dd><p>parse one record, which may span multiple lines, per file. If None is
set, it uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>allowUnquotedControlChars</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows JSON Strings to contain unquoted control
characters (ASCII characters with value less than 32,
including tab and line feed characters) or not.</p>
</dd>
<dt><strong>lineSep</strong><span class="classifier">str, optional</span></dt><dd><p>defines the line separator that should be used for parsing. If None is
set, it covers all <code class="docutils literal notranslate"><span class="pre">\r</span></code>, <code class="docutils literal notranslate"><span class="pre">\r\n</span></code> and <code class="docutils literal notranslate"><span class="pre">\n</span></code>.</p>
</dd>
<dt><strong>locale</strong><span class="classifier">str, optional</span></dt><dd><p>sets a locale as language tag in IETF BCP 47 format. If None is set,
it uses the default value, <code class="docutils literal notranslate"><span class="pre">en-US</span></code>. For instance, <code class="docutils literal notranslate"><span class="pre">locale</span></code> is used while
parsing dates and timestamps.</p>
</dd>
<dt><strong>dropFieldIfAllNull</strong><span class="classifier">str or bool, optional</span></dt><dd><p>whether to ignore column of all null values or empty
array/struct during schema inference. If None is set, it
uses the default value, <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</dd>
<dt><strong>encoding</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows to forcibly set one of standard basic or extended encoding for
the JSON files. For example UTF-16BE, UTF-32LE. If None is set,
the encoding of input JSON will be detected automatically
when the multiLine option is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
</dd>
<dt><strong>pathGlobFilter</strong><span class="classifier">str or bool, optional</span></dt><dd><p>an optional glob pattern to only include files with paths matching
the pattern. The syntax follows <cite>org.apache.hadoop.fs.GlobFilter</cite>.
It does not change the behavior of
<a class="reference external" href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#partition-discovery">partition discovery</a>.  # noqa</p>
</dd>
<dt><strong>recursiveFileLookup</strong><span class="classifier">str or bool, optional</span></dt><dd><p>recursively scan a directory for files. Using this option
disables
<a class="reference external" href="https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#partition-discovery">partition discovery</a>.  # noqa</p>
</dd>
<dt><strong>allowNonNumericNumbers</strong><span class="classifier">str or bool, optional</span></dt><dd><p>allows JSON parser to recognize set of âNot-a-Numberâ (NaN)
tokens as legal floating number values. If None is set,
it uses the default value, <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">+INF</span></code>: for positive infinity, as well as alias of</dt><dd><p><code class="docutils literal notranslate"><span class="pre">+Infinity</span></code> and <code class="docutils literal notranslate"><span class="pre">Infinity</span></code>.</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">-INF</span></code>: for negative infinity, alias <code class="docutils literal notranslate"><span class="pre">-Infinity</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NaN</span></code>: for other not-a-numbers, like result of division by zero.</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This API is evolving.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">json_sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">(),</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">sdf_schema</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">json_sdf</span><span class="o">.</span><span class="n">isStreaming</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">json_sdf</span><span class="o">.</span><span class="n">schema</span> <span class="o">==</span> <span class="n">sdf_schema</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="pyspark.sql.streaming.DataStreamReader.format.html" title="previous page">pyspark.sql.streaming.DataStreamReader.format</a>
    <a class='right-next' id="next-link" href="pyspark.sql.streaming.DataStreamReader.load.html" title="next page">pyspark.sql.streaming.DataStreamReader.load</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright .<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>