
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>RegexTokenizer &#8212; PySpark 3.1.2 documentation</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="RFormula" href="pyspark.ml.feature.RFormula.html" />
    <link rel="prev" title="RobustScalerModel" href="pyspark.ml.feature.RobustScalerModel.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../index.html">
    
      <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../user_guide/index.html">User Guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../development/index.html">Development</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../migration_guide/index.html">Migration Guide</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="../pyspark.sql.html">Spark SQL</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.ss.html">Structured Streaming</a>
                </li>
            
          
            
                <li class="active">
                    <a href="../pyspark.ml.html">MLlib (DataFrame-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.streaming.html">Spark Streaming</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.mllib.html">MLlib (RDD-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.html">Spark Core</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.resource.html">Resource Management</a>
                </li>
            
          
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="regextokenizer">
<h1>RegexTokenizer<a class="headerlink" href="#regextokenizer" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="pyspark.ml.feature.RegexTokenizer">
<em class="property">class </em><code class="sig-prename descclassname">pyspark.ml.feature.</code><code class="sig-name descname">RegexTokenizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">minTokenLength</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">gaps</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">pattern</span><span class="o">=</span><span class="default_value">'\\s+'</span></em>, <em class="sig-param"><span class="n">inputCol</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">outputCol</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">toLowercase</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A regex based tokenizer that extracts tokens either by using the
provided regex pattern (in Java dialect) to split the text
(default) or repeatedly matching the regex (if gaps is false).
Optional parameters also allow filtering tokens using a minimal
length.
It returns an array of strings that can be empty.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="s2">&quot;A B  c&quot;</span><span class="p">,)],</span> <span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
<span class="go">RegexTokenizer...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>
<span class="go">RegexTokenizer...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="go">Row(text=&#39;A B  c&#39;, words=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Change a parameter.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;tokens&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="go">Row(text=&#39;A B  c&#39;, tokens=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Temporarily modify a parameter.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">{</span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">outputCol</span><span class="p">:</span> <span class="s2">&quot;words&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="go">Row(text=&#39;A B  c&#39;, words=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="go">Row(text=&#39;A B  c&#39;, tokens=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Must use keyword arguments to specify params.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">TypeError</span>: <span class="n">Method setParams forces keyword arguments.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regexTokenizerPath</span> <span class="o">=</span> <span class="n">temp_path</span> <span class="o">+</span> <span class="s2">&quot;/regex-tokenizer&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reTokenizer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">regexTokenizerPath</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loadedReTokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">regexTokenizerPath</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loadedReTokenizer</span><span class="o">.</span><span class="n">getMinTokenLength</span><span class="p">()</span> <span class="o">==</span> <span class="n">reTokenizer</span><span class="o">.</span><span class="n">getMinTokenLength</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loadedReTokenizer</span><span class="o">.</span><span class="n">getGaps</span><span class="p">()</span> <span class="o">==</span> <span class="n">reTokenizer</span><span class="o">.</span><span class="n">getGaps</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loadedReTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">reTokenizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.clear" title="pyspark.ml.feature.RegexTokenizer.clear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clear</span></code></a>(param)</p></td>
<td><p>Clears a param from the param map if it has been explicitly set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.copy" title="pyspark.ml.feature.RegexTokenizer.copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">copy</span></code></a>([extra])</p></td>
<td><p>Creates a copy of this instance with the same uid and some extra params.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.explainParam" title="pyspark.ml.feature.RegexTokenizer.explainParam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explainParam</span></code></a>(param)</p></td>
<td><p>Explains a single param and returns its name, doc, and optional default value and user-supplied value in a string.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.explainParams" title="pyspark.ml.feature.RegexTokenizer.explainParams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explainParams</span></code></a>()</p></td>
<td><p>Returns the documentation of all params with their optionally default values and user-supplied values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.extractParamMap" title="pyspark.ml.feature.RegexTokenizer.extractParamMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extractParamMap</span></code></a>([extra])</p></td>
<td><p>Extracts the embedded default param values and user-supplied values, and then merges them with extra values from input into a flat param map, where the latter value is used if there exist conflicts, i.e., with ordering: default param values &lt; user-supplied values &lt; extra.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getGaps" title="pyspark.ml.feature.RegexTokenizer.getGaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getGaps</span></code></a>()</p></td>
<td><p>Gets the value of gaps or its default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getInputCol" title="pyspark.ml.feature.RegexTokenizer.getInputCol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getInputCol</span></code></a>()</p></td>
<td><p>Gets the value of inputCol or its default value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getMinTokenLength" title="pyspark.ml.feature.RegexTokenizer.getMinTokenLength"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getMinTokenLength</span></code></a>()</p></td>
<td><p>Gets the value of minTokenLength or its default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getOrDefault" title="pyspark.ml.feature.RegexTokenizer.getOrDefault"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getOrDefault</span></code></a>(param)</p></td>
<td><p>Gets the value of a param in the user-supplied param map or its default value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getOutputCol" title="pyspark.ml.feature.RegexTokenizer.getOutputCol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getOutputCol</span></code></a>()</p></td>
<td><p>Gets the value of outputCol or its default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getParam" title="pyspark.ml.feature.RegexTokenizer.getParam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getParam</span></code></a>(paramName)</p></td>
<td><p>Gets a param by its name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getPattern" title="pyspark.ml.feature.RegexTokenizer.getPattern"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getPattern</span></code></a>()</p></td>
<td><p>Gets the value of pattern or its default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.getToLowercase" title="pyspark.ml.feature.RegexTokenizer.getToLowercase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getToLowercase</span></code></a>()</p></td>
<td><p>Gets the value of toLowercase or its default value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.hasDefault" title="pyspark.ml.feature.RegexTokenizer.hasDefault"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hasDefault</span></code></a>(param)</p></td>
<td><p>Checks whether a param has a default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.hasParam" title="pyspark.ml.feature.RegexTokenizer.hasParam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hasParam</span></code></a>(paramName)</p></td>
<td><p>Tests whether this instance contains a param with a given (string) name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.isDefined" title="pyspark.ml.feature.RegexTokenizer.isDefined"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isDefined</span></code></a>(param)</p></td>
<td><p>Checks whether a param is explicitly set by user or has a default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.isSet" title="pyspark.ml.feature.RegexTokenizer.isSet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isSet</span></code></a>(param)</p></td>
<td><p>Checks whether a param is explicitly set by user.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.load" title="pyspark.ml.feature.RegexTokenizer.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(path)</p></td>
<td><p>Reads an ML instance from the input path, a shortcut of <cite>read().load(path)</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.read" title="pyspark.ml.feature.RegexTokenizer.read"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read</span></code></a>()</p></td>
<td><p>Returns an MLReader instance for this class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.save" title="pyspark.ml.feature.RegexTokenizer.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(path)</p></td>
<td><p>Save this ML instance to the given path, a shortcut of ‘write().save(path)’.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.set" title="pyspark.ml.feature.RegexTokenizer.set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set</span></code></a>(param, value)</p></td>
<td><p>Sets a parameter in the embedded param map.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setGaps" title="pyspark.ml.feature.RegexTokenizer.setGaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setGaps</span></code></a>(value)</p></td>
<td><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.gaps" title="pyspark.ml.feature.RegexTokenizer.gaps"><code class="xref py py-attr docutils literal notranslate"><span class="pre">gaps</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setInputCol" title="pyspark.ml.feature.RegexTokenizer.setInputCol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setInputCol</span></code></a>(value)</p></td>
<td><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.inputCol" title="pyspark.ml.feature.RegexTokenizer.inputCol"><code class="xref py py-attr docutils literal notranslate"><span class="pre">inputCol</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setMinTokenLength" title="pyspark.ml.feature.RegexTokenizer.setMinTokenLength"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setMinTokenLength</span></code></a>(value)</p></td>
<td><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.minTokenLength" title="pyspark.ml.feature.RegexTokenizer.minTokenLength"><code class="xref py py-attr docutils literal notranslate"><span class="pre">minTokenLength</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setOutputCol" title="pyspark.ml.feature.RegexTokenizer.setOutputCol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setOutputCol</span></code></a>(value)</p></td>
<td><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.outputCol" title="pyspark.ml.feature.RegexTokenizer.outputCol"><code class="xref py py-attr docutils literal notranslate"><span class="pre">outputCol</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setParams" title="pyspark.ml.feature.RegexTokenizer.setParams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setParams</span></code></a>(self, \*[, minTokenLength, gaps, …])</p></td>
<td><p>Sets params for this RegexTokenizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setPattern" title="pyspark.ml.feature.RegexTokenizer.setPattern"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setPattern</span></code></a>(value)</p></td>
<td><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.pattern" title="pyspark.ml.feature.RegexTokenizer.pattern"><code class="xref py py-attr docutils literal notranslate"><span class="pre">pattern</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.setToLowercase" title="pyspark.ml.feature.RegexTokenizer.setToLowercase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setToLowercase</span></code></a>(value)</p></td>
<td><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.toLowercase" title="pyspark.ml.feature.RegexTokenizer.toLowercase"><code class="xref py py-attr docutils literal notranslate"><span class="pre">toLowercase</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.transform" title="pyspark.ml.feature.RegexTokenizer.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(dataset[, params])</p></td>
<td><p>Transforms the input dataset with optional parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.write" title="pyspark.ml.feature.RegexTokenizer.write"><code class="xref py py-obj docutils literal notranslate"><span class="pre">write</span></code></a>()</p></td>
<td><p>Returns an MLWriter instance for this ML instance.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.gaps" title="pyspark.ml.feature.RegexTokenizer.gaps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gaps</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.inputCol" title="pyspark.ml.feature.RegexTokenizer.inputCol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inputCol</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.minTokenLength" title="pyspark.ml.feature.RegexTokenizer.minTokenLength"><code class="xref py py-obj docutils literal notranslate"><span class="pre">minTokenLength</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.outputCol" title="pyspark.ml.feature.RegexTokenizer.outputCol"><code class="xref py py-obj docutils literal notranslate"><span class="pre">outputCol</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.params" title="pyspark.ml.feature.RegexTokenizer.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns all params ordered by name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.pattern" title="pyspark.ml.feature.RegexTokenizer.pattern"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pattern</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.toLowercase" title="pyspark.ml.feature.RegexTokenizer.toLowercase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">toLowercase</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods Documentation</p>
<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.clear">
<code class="sig-name descname">clear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears a param from the param map if it has been explicitly set.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">extra</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a copy of this instance with the same uid and some
extra params. This implementation first calls Params.copy and
then make a copy of the companion Java pipeline component with
extra params. So both the Python wrapper and the Java pipeline
component get copied.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>extra</strong><span class="classifier">dict, optional</span></dt><dd><p>Extra parameters to copy to the new instance</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">JavaParams</span></code></dt><dd><p>Copy of this instance</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.explainParam">
<code class="sig-name descname">explainParam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.explainParam" title="Permalink to this definition">¶</a></dt>
<dd><p>Explains a single param and returns its name, doc, and optional
default value and user-supplied value in a string.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.explainParams">
<code class="sig-name descname">explainParams</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.explainParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the documentation of all params with their optionally
default values and user-supplied values.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.extractParamMap">
<code class="sig-name descname">extractParamMap</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">extra</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.extractParamMap" title="Permalink to this definition">¶</a></dt>
<dd><p>Extracts the embedded default param values and user-supplied
values, and then merges them with extra values from input into
a flat param map, where the latter value is used if there exist
conflicts, i.e., with ordering: default param values &lt;
user-supplied values &lt; extra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>extra</strong><span class="classifier">dict, optional</span></dt><dd><p>extra param values</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>merged param map</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getGaps">
<code class="sig-name descname">getGaps</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.getGaps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getGaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of gaps or its default value.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getInputCol">
<code class="sig-name descname">getInputCol</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getInputCol" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of inputCol or its default value.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getMinTokenLength">
<code class="sig-name descname">getMinTokenLength</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.getMinTokenLength"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getMinTokenLength" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of minTokenLength or its default value.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getOrDefault">
<code class="sig-name descname">getOrDefault</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getOrDefault" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of a param in the user-supplied param map or its
default value. Raises an error if neither is set.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getOutputCol">
<code class="sig-name descname">getOutputCol</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getOutputCol" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of outputCol or its default value.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getParam">
<code class="sig-name descname">getParam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">paramName</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getParam" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a param by its name.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getPattern">
<code class="sig-name descname">getPattern</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.getPattern"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getPattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of pattern or its default value.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.getToLowercase">
<code class="sig-name descname">getToLowercase</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.getToLowercase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.getToLowercase" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of toLowercase or its default value.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.0.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.hasDefault">
<code class="sig-name descname">hasDefault</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.hasDefault" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether a param has a default value.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.hasParam">
<code class="sig-name descname">hasParam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">paramName</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.hasParam" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests whether this instance contains a param with a given
(string) name.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.isDefined">
<code class="sig-name descname">isDefined</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.isDefined" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether a param is explicitly set by user or has
a default value.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.isSet">
<code class="sig-name descname">isSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.isSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether a param is explicitly set by user.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.load">
<em class="property">classmethod </em><code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads an ML instance from the input path, a shortcut of <cite>read().load(path)</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.read">
<em class="property">classmethod </em><code class="sig-name descname">read</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.read" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an MLReader instance for this class.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save this ML instance to the given path, a shortcut of ‘write().save(path)’.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.set">
<code class="sig-name descname">set</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.set" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets a parameter in the embedded param map.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setGaps">
<code class="sig-name descname">setGaps</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setGaps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setGaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.gaps" title="pyspark.ml.feature.RegexTokenizer.gaps"><code class="xref py py-attr docutils literal notranslate"><span class="pre">gaps</span></code></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setInputCol">
<code class="sig-name descname">setInputCol</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setInputCol"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setInputCol" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.inputCol" title="pyspark.ml.feature.RegexTokenizer.inputCol"><code class="xref py py-attr docutils literal notranslate"><span class="pre">inputCol</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setMinTokenLength">
<code class="sig-name descname">setMinTokenLength</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setMinTokenLength"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setMinTokenLength" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.minTokenLength" title="pyspark.ml.feature.RegexTokenizer.minTokenLength"><code class="xref py py-attr docutils literal notranslate"><span class="pre">minTokenLength</span></code></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setOutputCol">
<code class="sig-name descname">setOutputCol</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setOutputCol"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setOutputCol" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.outputCol" title="pyspark.ml.feature.RegexTokenizer.outputCol"><code class="xref py py-attr docutils literal notranslate"><span class="pre">outputCol</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setParams">
<code class="sig-name descname">setParams</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">\*</em>, <em class="sig-param">minTokenLength=1</em>, <em class="sig-param">gaps=True</em>, <em class="sig-param">pattern=&quot;\s+&quot;</em>, <em class="sig-param">inputCol=None</em>, <em class="sig-param">outputCol=None</em>, <em class="sig-param">toLowercase=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setParams"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets params for this RegexTokenizer.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setPattern">
<code class="sig-name descname">setPattern</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setPattern"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setPattern" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.pattern" title="pyspark.ml.feature.RegexTokenizer.pattern"><code class="xref py py-attr docutils literal notranslate"><span class="pre">pattern</span></code></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.setToLowercase">
<code class="sig-name descname">setToLowercase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/feature.html#RegexTokenizer.setToLowercase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.setToLowercase" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#pyspark.ml.feature.RegexTokenizer.toLowercase" title="pyspark.ml.feature.RegexTokenizer.toLowercase"><code class="xref py py-attr docutils literal notranslate"><span class="pre">toLowercase</span></code></a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.0.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">params</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transforms the input dataset with optional parameters.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>dataset</strong><span class="classifier"><a class="reference internal" href="pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.DataFrame</span></code></a></span></dt><dd><p>input dataset</p>
</dd>
<dt><strong>params</strong><span class="classifier">dict, optional</span></dt><dd><p>an optional param map that overrides embedded params.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.DataFrame</span></code></a></dt><dd><p>transformed dataset</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.feature.RegexTokenizer.write">
<code class="sig-name descname">write</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.write" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an MLWriter instance for this ML instance.</p>
</dd></dl>

<p class="rubric">Attributes Documentation</p>
<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.gaps">
<code class="sig-name descname">gaps</code><em class="property"> = Param(parent='undefined', name='gaps', doc='whether regex splits on gaps (True) or matches tokens (False)')</em><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.gaps" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.inputCol">
<code class="sig-name descname">inputCol</code><em class="property"> = Param(parent='undefined', name='inputCol', doc='input column name.')</em><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.inputCol" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.minTokenLength">
<code class="sig-name descname">minTokenLength</code><em class="property"> = Param(parent='undefined', name='minTokenLength', doc='minimum token length (&gt;= 0)')</em><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.minTokenLength" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.outputCol">
<code class="sig-name descname">outputCol</code><em class="property"> = Param(parent='undefined', name='outputCol', doc='output column name.')</em><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.outputCol" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.params">
<code class="sig-name descname">params</code><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns all params ordered by name. The default implementation
uses <code class="xref py py-func docutils literal notranslate"><span class="pre">dir()</span></code> to get all attributes of type
<code class="xref py py-class docutils literal notranslate"><span class="pre">Param</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.pattern">
<code class="sig-name descname">pattern</code><em class="property"> = Param(parent='undefined', name='pattern', doc='regex pattern (Java dialect) used for tokenizing')</em><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.pattern" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.feature.RegexTokenizer.toLowercase">
<code class="sig-name descname">toLowercase</code><em class="property"> = Param(parent='undefined', name='toLowercase', doc='whether to convert all characters to lowercase before tokenizing')</em><a class="headerlink" href="#pyspark.ml.feature.RegexTokenizer.toLowercase" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="pyspark.ml.feature.RobustScalerModel.html" title="previous page">RobustScalerModel</a>
    <a class='right-next' id="next-link" href="pyspark.ml.feature.RFormula.html" title="next page">RFormula</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright .<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>