<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Factorization Machines Classification Model</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for spark.fmClassifier {SparkR}"><tr><td>spark.fmClassifier {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Factorization Machines Classification Model</h2>

<h3>Description</h3>

<p><code>spark.fmClassifier</code> fits a factorization classification model against a SparkDataFrame.
Users can call <code>summary</code> to print a summary of the fitted model, <code>predict</code> to make
predictions on new data, and <code>write.ml</code>/<code>read.ml</code> to save/load fitted models.
Only categorical data is supported.
</p>


<h3>Usage</h3>

<pre>
spark.fmClassifier(data, formula, ...)

## S4 method for signature 'SparkDataFrame,formula'
spark.fmClassifier(
  data,
  formula,
  factorSize = 8,
  fitLinear = TRUE,
  regParam = 0,
  miniBatchFraction = 1,
  initStd = 0.01,
  maxIter = 100,
  stepSize = 1,
  tol = 1e-06,
  solver = c("adamW", "gd"),
  thresholds = NULL,
  seed = NULL,
  handleInvalid = c("error", "keep", "skip")
)

## S4 method for signature 'FMClassificationModel'
summary(object)

## S4 method for signature 'FMClassificationModel'
predict(object, newData)

## S4 method for signature 'FMClassificationModel,character'
write.ml(object, path, overwrite = FALSE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>data</code></td>
<td>
<p>a <code>SparkDataFrame</code> of observations and labels for model fitting.</p>
</td></tr>
<tr valign="top"><td><code>formula</code></td>
<td>
<p>a symbolic description of the model to be fitted. Currently only a few formula
operators are supported, including '~', '.', ':', '+', and '-'.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>additional arguments passed to the method.</p>
</td></tr>
<tr valign="top"><td><code>factorSize</code></td>
<td>
<p>dimensionality of the factors.</p>
</td></tr>
<tr valign="top"><td><code>fitLinear</code></td>
<td>
<p>whether to fit linear term.  # TODO Can we express this with formula?</p>
</td></tr>
<tr valign="top"><td><code>regParam</code></td>
<td>
<p>the regularization parameter.</p>
</td></tr>
<tr valign="top"><td><code>miniBatchFraction</code></td>
<td>
<p>the mini-batch fraction parameter.</p>
</td></tr>
<tr valign="top"><td><code>initStd</code></td>
<td>
<p>the standard deviation of initial coefficients.</p>
</td></tr>
<tr valign="top"><td><code>maxIter</code></td>
<td>
<p>maximum iteration number.</p>
</td></tr>
<tr valign="top"><td><code>stepSize</code></td>
<td>
<p>stepSize parameter.</p>
</td></tr>
<tr valign="top"><td><code>tol</code></td>
<td>
<p>convergence tolerance of iterations.</p>
</td></tr>
<tr valign="top"><td><code>solver</code></td>
<td>
<p>solver parameter, supported options: &quot;gd&quot; (minibatch gradient descent) or &quot;adamW&quot;.</p>
</td></tr>
<tr valign="top"><td><code>thresholds</code></td>
<td>
<p>in binary classification, in range [0, 1]. If the estimated probability of
class label 1 is &gt; threshold, then predict 1, else 0. A high threshold
encourages the model to predict 0 more often; a low threshold encourages the
model to predict 1 more often. Note: Setting this with threshold p is
equivalent to setting thresholds c(1-p, p).</p>
</td></tr>
<tr valign="top"><td><code>seed</code></td>
<td>
<p>seed parameter for weights initialization.</p>
</td></tr>
<tr valign="top"><td><code>handleInvalid</code></td>
<td>
<p>How to handle invalid data (unseen labels or NULL values) in features and
label column of string type.
Supported options: &quot;skip&quot; (filter out rows with invalid data),
&quot;error&quot; (throw an error), &quot;keep&quot; (put invalid data in
a special additional bucket, at index numLabels). Default
is &quot;error&quot;.</p>
</td></tr>
<tr valign="top"><td><code>object</code></td>
<td>
<p>a FM Classification model fitted by <code>spark.fmClassifier</code>.</p>
</td></tr>
<tr valign="top"><td><code>newData</code></td>
<td>
<p>a SparkDataFrame for testing.</p>
</td></tr>
<tr valign="top"><td><code>path</code></td>
<td>
<p>The directory where the model is saved.</p>
</td></tr>
<tr valign="top"><td><code>overwrite</code></td>
<td>
<p>Overwrites or not if the output path already exists. Default is FALSE
which means throw exception if the output path exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>spark.fmClassifier</code> returns a fitted Factorization Machines Classification Model.
</p>
<p><code>summary</code> returns summary information of the fitted model, which is a list.
</p>
<p><code>predict</code> returns the predicted values based on a FM Classification model.
</p>


<h3>Note</h3>

<p>spark.fmClassifier since 3.1.0
</p>
<p>summary(FMClassificationModel) since 3.1.0
</p>
<p>predict(FMClassificationModel) since 3.1.0
</p>
<p>write.ml(FMClassificationModel, character) since 3.1.0
</p>


<h3>See Also</h3>

<p><a href="../../SparkR/help/read.ml.html">read.ml</a>
</p>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D df &lt;- read.df(&quot;data/mllib/sample_binary_classification_data.txt&quot;, source = &quot;libsvm&quot;)
##D 
##D # fit Factorization Machines Classification Model
##D model &lt;- spark.fmClassifier(
##D            df, label ~ features,
##D            regParam = 0.01, maxIter = 10, fitLinear = TRUE
##D          )
##D 
##D # get the summary of the model
##D summary(model)
##D 
##D # make predictions
##D predictions &lt;- predict(model, df)
##D 
##D # save and load the model
##D path &lt;- &quot;path/to/model&quot;
##D write.ml(model, path)
##D savedModel &lt;- read.ml(path)
##D summary(savedModel)
## End(Not run)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 3.1.2 <a href="00Index.html">Index</a>]</div>
</body></html>
