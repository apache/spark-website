
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Options and settings &#8212; PySpark 3.2.1 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/css/blank.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/options.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="From/to pandas and PySpark DataFrames" href="pandas_pyspark.html" />
    <link rel="prev" title="Pandas API on Spark" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../development/index.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../migration_guide/index.html">
  Migration Guide
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../python_packaging.html">
   Python Package Management
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../sql/index.html">
   Spark SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../sql/arrow_pandas.html">
     Apache Arrow in PySpark
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Pandas API on Spark
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Options and settings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pandas_pyspark.html">
     From/to pandas and PySpark DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transform_apply.html">
     Transform and apply a function
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="types.html">
     Type Support in Pandas API on Spark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="typehints.html">
     Type Hints in Pandas API on Spark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="from_to_dbms.html">
     From/to other DBMSes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="best_practices.html">
     Best Practices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="faq.html">
     FAQ
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-and-setting-options">
   Getting and setting options
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#operations-on-different-dataframes">
   Operations on different DataFrames
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#default-index-type">
   Default Index type
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#available-options">
   Available options
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="options-and-settings">
<h1>Options and settings<a class="headerlink" href="#options-and-settings" title="Permalink to this headline">¶</a></h1>
<p>Pandas API on Spark has an options system that lets you customize some aspects of its behaviour,
display-related options being those the user is most likely to adjust.</p>
<p>Options have a full “dotted-style”, case-insensitive name (e.g. <code class="docutils literal notranslate"><span class="pre">display.max_rows</span></code>).
You can get/set options directly as attributes of the top-level <code class="docutils literal notranslate"><span class="pre">options</span></code> attribute:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span>
<span class="go">10</span>
</pre></div>
</div>
<p>The API is composed of 3 relevant functions, available directly from the <code class="docutils literal notranslate"><span class="pre">pandas_on_spark</span></code>
namespace:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.get_option.html#pyspark.pandas.get_option" title="pyspark.pandas.get_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_option()</span></code></a> / <a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.set_option.html#pyspark.pandas.set_option" title="pyspark.pandas.set_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_option()</span></code></a> - get/set the value of a single option.</p></li>
<li><p><a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.reset_option.html#pyspark.pandas.reset_option" title="pyspark.pandas.reset_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">reset_option()</span></code></a> - reset one or more options to their default value.</p></li>
</ul>
<p><strong>Note:</strong> Developers can check out <a class="reference external" href="https://github.com/apache/spark/blob/master/python/pyspark/pandas/config.py">pyspark.pandas/config.py</a> for more information.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">101</span>
</pre></div>
</div>
<section id="getting-and-setting-options">
<h2>Getting and setting options<a class="headerlink" href="#getting-and-setting-options" title="Permalink to this headline">¶</a></h2>
<p>As described above, <a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.get_option.html#pyspark.pandas.get_option" title="pyspark.pandas.get_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_option()</span></code></a> and <a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.set_option.html#pyspark.pandas.set_option" title="pyspark.pandas.set_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_option()</span></code></a>
are available from the <code class="docutils literal notranslate"><span class="pre">pandas_on_spark</span></code> namespace.  To change an option, call
<code class="docutils literal notranslate"><span class="pre">set_option('option</span> <span class="pre">name',</span> <span class="pre">new_value)</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s1">&#39;compute.max_rows&#39;</span><span class="p">)</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.max_rows&#39;</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s1">&#39;compute.max_rows&#39;</span><span class="p">)</span>
<span class="go">2000</span>
</pre></div>
</div>
<p>All options also have a default value, and you can use <code class="docutils literal notranslate"><span class="pre">reset_option</span></code> to do just that:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">999</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">999</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">1000</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">option_context</span></code> context manager has been exposed through
the top-level API, allowing you to execute code with given option values. Option values
are restored automatically when you exit the <cite>with</cite> block:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">ps</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;compute.max_rows&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">))</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;compute.max_rows&quot;</span><span class="p">))</span>
<span class="go">10</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;compute.max_rows&quot;</span><span class="p">))</span>
<span class="go">1000</span>
<span class="go">1000</span>
</pre></div>
</div>
</section>
<section id="operations-on-different-dataframes">
<h2>Operations on different DataFrames<a class="headerlink" href="#operations-on-different-dataframes" title="Permalink to this headline">¶</a></h2>
<p>Pandas API on Spark disallows the operations on different DataFrames (or Series) by default to prevent expensive
operations. It internally performs a join operation which can be expensive in general.</p>
<p>This can be enabled by setting <cite>compute.ops_on_diff_frames</cite> to <cite>True</cite> to allow such cases.
See the examples below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf1</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf2</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">psdf1</span> <span class="o">-</span> <span class="n">psdf2</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="go">    id</span>
<span class="go">0 -5.0</span>
<span class="go">1 -3.0</span>
<span class="go">2 -1.0</span>
<span class="go">3  NaN</span>
<span class="go">4  NaN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psser_a</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># &#39;psser_a&#39; is not from &#39;psdf&#39; DataFrame. So it is considered as a Series not from &#39;psdf&#39;.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;new_col&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psser_a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span>
<span class="go">   id  new_col</span>
<span class="go">0   0      1.0</span>
<span class="go">1   1      2.0</span>
<span class="go">3   3      4.0</span>
<span class="go">2   2      3.0</span>
<span class="go">4   4      NaN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="default-index-type">
<h2>Default Index type<a class="headerlink" href="#default-index-type" title="Permalink to this headline">¶</a></h2>
<p>In pandas API on Spark, the default index is used in several cases, for instance,
when Spark DataFrame is converted into pandas-on-Spark DataFrame. In this case, internally pandas API on Spark attaches a
default index into pandas-on-Spark DataFrame.</p>
<p>There are several types of the default index that can be configured by <cite>compute.default_index_type</cite> as below:</p>
<p><strong>sequence</strong>: It implements a sequence that increases one by one, by PySpark’s Window function without
specifying partition. Therefore, it can end up with whole partition in single node.
This index type should be avoided when the data is large. This is default. See the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;sequence&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="o">.</span><span class="n">index</span>
<span class="go">Int64Index([0, 1, 2], dtype=&#39;int64&#39;)</span>
</pre></div>
</div>
<p>This is conceptually equivalent to the PySpark example as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">Window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sequential_index</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span>
<span class="gp">... </span>   <span class="n">Window</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">monotonically_increasing_id</span><span class="p">()</span><span class="o">.</span><span class="n">asc</span><span class="p">()))</span> <span class="o">-</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">sequential_index</span><span class="p">)</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[0, 1, 2]</span>
</pre></div>
</div>
<p><strong>distributed-sequence</strong>: It implements a sequence that increases one by one, by group-by and
group-map approach in a distributed manner. It still generates the sequential index globally.
If the default index must be the sequence in a large dataset, this
index has to be used.
Note that if more data are added to the data source after creating this index,
then it does not guarantee the sequential index. See the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;distributed-sequence&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="o">.</span><span class="n">index</span>
<span class="go">Int64Index([0, 1, 2], dtype=&#39;int64&#39;)</span>
</pre></div>
</div>
<p>This is conceptually equivalent to the PySpark example as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[0, 1, 2]</span>
</pre></div>
</div>
<p><strong>distributed</strong>: It implements a monotonically increasing sequence simply by using
PySpark’s <cite>monotonically_increasing_id</cite> function in a fully distributed manner. The
values are indeterministic. If the index does not have to be a sequence that increases
one by one, this index should be used. Performance-wise, this index almost does not
have any penalty comparing to other index types. See the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;distributed&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="o">.</span><span class="n">index</span>
<span class="go">Int64Index([25769803776, 60129542144, 94489280512], dtype=&#39;int64&#39;)</span>
</pre></div>
</div>
<p>This is conceptually equivalent to the PySpark example as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">monotonically_increasing_id</span><span class="p">())</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[25769803776, 60129542144, 94489280512]</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is very unlikely for this type of index to be used for computing two
different dataframes because it is not guaranteed to have the same indexes in two dataframes.
If you use this default index and turn on <cite>compute.ops_on_diff_frames</cite>, the result
from the operations between two different DataFrames will likely be an unexpected
output due to the indeterministic index values.</p>
</div>
</section>
<section id="available-options">
<h2>Available options<a class="headerlink" href="#available-options" title="Permalink to this headline">¶</a></h2>
<table class="table">
<colgroup>
<col style="width: 32%" />
<col style="width: 14%" />
<col style="width: 54%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Option</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>display.max_rows</p></td>
<td><p>1000</p></td>
<td><p>This sets the maximum number of rows pandas-on-Spark
should output when printing out various output. For
example, this value determines the number of rows to
be shown at the repr() in a dataframe. Set <cite>None</cite> to
unlimit the input length. Default is 1000.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.max_rows</p></td>
<td><p>1000</p></td>
<td><p>‘compute.max_rows’ sets the limit of the current
pandas-on-Spark DataFrame. Set <cite>None</cite> to unlimit the
input length. When the limit is set, it is executed
by the shortcut by collecting the data into the
driver, and then using the pandas API. If the limit
is unset, the operation is executed by PySpark.
Default is 1000.</p></td>
</tr>
<tr class="row-even"><td><p>compute.shortcut_limit</p></td>
<td><p>1000</p></td>
<td><p>‘compute.shortcut_limit’ sets the limit for a
shortcut. It computes specified number of rows and
use its schema. When the dataframe length is larger
than this limit, pandas-on-Spark uses PySpark to
compute.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.ops_on_diff_frames</p></td>
<td><p>False</p></td>
<td><p>This determines whether or not to operate between two
different dataframes. For example, ‘combine_frames’
function internally performs a join operation which
can be expensive in general. So, if
<cite>compute.ops_on_diff_frames</cite> variable is not True,
that method throws an exception.</p></td>
</tr>
<tr class="row-even"><td><p>compute.default_index_type</p></td>
<td><p>‘sequence’</p></td>
<td><p>This sets the default index type: sequence,
distributed and distributed-sequence.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.ordered_head</p></td>
<td><p>False</p></td>
<td><p>‘compute.ordered_head’ sets whether or not to operate
head with natural ordering. pandas-on-Spark does not
guarantee the row ordering so <cite>head</cite> could return
some rows from distributed partitions. If
‘compute.ordered_head’ is set to True, pandas-on-
Spark performs natural ordering beforehand, but it
will cause a performance overhead.</p></td>
</tr>
<tr class="row-even"><td><p>plotting.max_rows</p></td>
<td><p>1000</p></td>
<td><p>‘plotting.max_rows’ sets the visual limit on top-n-
based plots such as <cite>plot.bar</cite> and <cite>plot.pie</cite>. If it
is set to 1000, the first 1000 data points will be
used for plotting. Default is 1000.</p></td>
</tr>
<tr class="row-odd"><td><p>plotting.sample_ratio</p></td>
<td><p>None</p></td>
<td><p>‘plotting.sample_ratio’ sets the proportion of data
that will be plotted for sample-based plots such as
<cite>plot.line</cite> and <cite>plot.area</cite>. This option defaults to
‘plotting.max_rows’ option.</p></td>
</tr>
<tr class="row-even"><td><p>plotting.backend</p></td>
<td><p>‘plotly’</p></td>
<td><p>Backend to use for plotting. Default is plotly.
Supports any package that has a top-level <cite>.plot</cite>
method. Known options are: [matplotlib, plotly].</p></td>
</tr>
</tbody>
</table>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Pandas API on Spark</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="pandas_pyspark.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">From/to pandas and PySpark DataFrames</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright .<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>