<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_282) on Sat May 15 15:24:30 UTC 2021 -->
<title>NewHadoopRDD (Spark 2.4.8 JavaDoc)</title>
<meta name="date" content="2021-05-15">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="NewHadoopRDD (Spark 2.4.8 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":9,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.NewHadoopMapPartitionsWithSplitRDD$.html" title="class in org.apache.spark.rdd"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/NewHadoopRDD.html" target="_top">Frames</a></li>
<li><a href="NewHadoopRDD.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.rdd</div>
<h2 title="Class NewHadoopRDD" class="title">Class NewHadoopRDD&lt;K,V&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">org.apache.spark.rdd.RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.rdd.NewHadoopRDD&lt;K,V&gt;</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">NewHadoopRDD&lt;K,V&gt;</span>
extends <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;
implements <a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></pre>
<div class="block">:: DeveloperApi ::
 An RDD that provides core functionality for reading data stored in Hadoop (e.g., files in HDFS,
 sources in HBase, or S3), using the new MapReduce API (<code>org.apache.hadoop.mapreduce</code>).
 <p>
 param:  sc The SparkContext to associate the RDD with.
 param:  inputFormatClass Storage format of the data to be read.
 param:  keyClass Class of the key associated with the inputFormatClass.
 param:  valueClass Class of the value associated with the inputFormatClass.
 <p></div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../serialized-form.html#org.apache.spark.rdd.NewHadoopRDD">Serialized Form</a></dd>
<dt><span class="simpleTagLabel">Note:</span></dt>
<dd>Instantiating this class directly is not recommended, please use
 <code>org.apache.spark.SparkContext.newAPIHadoopRDD()</code></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.NewHadoopMapPartitionsWithSplitRDD$.html" title="class in org.apache.spark.rdd">NewHadoopRDD.NewHadoopMapPartitionsWithSplitRDD$</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#NewHadoopRDD-org.apache.spark.SparkContext-java.lang.Class-java.lang.Class-java.lang.Class-org.apache.hadoop.conf.Configuration-">NewHadoopRDD</a></span>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
            Class&lt;? extends org.apache.hadoop.mapreduce.InputFormat&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;&nbsp;inputFormatClass,
            Class&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>&gt;&nbsp;keyClass,
            Class&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&nbsp;valueClass,
            org.apache.hadoop.conf.Configuration&nbsp;_conf)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">compute</a></span>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;theSplit,
       <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</code>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#CONFIGURATION_INSTANTIATION_LOCK--">CONFIGURATION_INSTANTIATION_LOCK</a></span>()</code>
<div class="block">Configuration's constructor is not threadsafe (see SPARK-1097 and HADOOP-10456).</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>org.apache.hadoop.conf.Configuration</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#getConf--">getConf</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#getPartitions--">getPartitions</a></span>()</code>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#getPreferredLocations-org.apache.spark.Partition-">getPreferredLocations</a></span>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;hsplit)</code>
<div class="block">Optionally overridden by subclasses to specify placement preferences.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#mapPartitionsWithInputSplit-scala.Function2-boolean-scala.reflect.ClassTag-">mapPartitionsWithInputSplit</a></span>(scala.Function2&lt;org.apache.hadoop.mapreduce.InputSplit,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                           boolean&nbsp;preservesPartitioning,
                           scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</code>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a>&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html#persist-org.apache.spark.storage.StorageLevel-">persist</a></span>(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;storageLevel)</code>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.rdd.RDD">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.rdd.<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></h3>
<code><a href="../../../../org/apache/spark/rdd/RDD.html#aggregate-U-scala.Function2-scala.Function2-scala.reflect.ClassTag-">aggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#barrier--">barrier</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cache--">cache</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cartesian-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">cartesian</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#checkpoint--">checkpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#coalesce-int-boolean-scala.Option-scala.math.Ordering-">coalesce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect--">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect-scala.PartialFunction-scala.reflect.ClassTag-">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#context--">context</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#count--">count</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApprox-long-double-">countApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct-double-">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct-int-int-">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValue-scala.math.Ordering-">countByValue</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValueApprox-long-double-scala.math.Ordering-">countByValueApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#dependencies--">dependencies</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#distinct--">distinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#distinct-int-scala.math.Ordering-">distinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#doubleRDDToDoubleRDDFunctions-org.apache.spark.rdd.RDD-">doubleRDDToDoubleRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#filter-scala.Function1-">filter</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#first--">first</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#flatMap-scala.Function1-scala.reflect.ClassTag-">flatMap</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#fold-T-scala.Function2-">fold</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreach-scala.Function1-">foreach</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreachPartition-scala.Function1-">foreachPartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getCheckpointFile--">getCheckpointFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getNumPartitions--">getNumPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getStorageLevel--">getStorageLevel</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#glom--">glom</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy-scala.Function1-scala.reflect.ClassTag-">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy-scala.Function1-int-scala.reflect.ClassTag-">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy-scala.Function1-org.apache.spark.Partitioner-scala.reflect.ClassTag-scala.math.Ordering-">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#id--">id</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection-org.apache.spark.rdd.RDD-">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection-org.apache.spark.rdd.RDD-int-">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isCheckpointed--">isCheckpointed</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isEmpty--">isEmpty</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#iterator-org.apache.spark.Partition-org.apache.spark.TaskContext-">iterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#keyBy-scala.Function1-">keyBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#localCheckpoint--">localCheckpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#map-scala.Function1-scala.reflect.ClassTag-">map</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitions-scala.Function1-boolean-scala.reflect.ClassTag-">mapPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex-scala.Function2-boolean-scala.reflect.ClassTag-">mapPartitionsWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#max-scala.math.Ordering-">max</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#min-scala.math.Ordering-">min</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#name--">name</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#numericRDDToDoubleRDDFunctions-org.apache.spark.rdd.RDD-scala.math.Numeric-">numericRDDToDoubleRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitioner--">partitioner</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitions--">partitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#persist--">persist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe-scala.collection.Seq-scala.collection.Map-scala.Function1-scala.Function2-boolean-int-java.lang.String-">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe-java.lang.String-">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe-java.lang.String-scala.collection.Map-">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#preferredLocations-org.apache.spark.Partition-">preferredLocations</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#randomSplit-double:A-long-">randomSplit</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToAsyncRDDActions-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">rddToAsyncRDDActions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToOrderedRDDFunctions-org.apache.spark.rdd.RDD-scala.math.Ordering-scala.reflect.ClassTag-scala.reflect.ClassTag-">rddToOrderedRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToPairRDDFunctions-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.math.Ordering-">rddToPairRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToSequenceFileRDDFunctions-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-scala.reflect.ClassTag---">rddToSequenceFileRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#reduce-scala.Function2-">reduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#repartition-int-scala.math.Ordering-">repartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sample-boolean-double-long-">sample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsObjectFile-java.lang.String-">saveAsObjectFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile-java.lang.String-">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile-java.lang.String-java.lang.Class-">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#setName-java.lang.String-">setName</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sortBy-scala.Function1-boolean-int-scala.math.Ordering-scala.reflect.ClassTag-">sortBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sparkContext--">sparkContext</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract-org.apache.spark.rdd.RDD-">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract-org.apache.spark.rdd.RDD-int-">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#take-int-">take</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeOrdered-int-scala.math.Ordering-">takeOrdered</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeSample-boolean-int-long-">takeSample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toDebugString--">toDebugString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toJavaRDD--">toJavaRDD</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toLocalIterator--">toLocalIterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#top-int-scala.math.Ordering-">top</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toString--">toString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#treeAggregate-U-scala.Function2-scala.Function2-int-scala.reflect.ClassTag-">treeAggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#treeReduce-scala.Function2-int-">treeReduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#union-org.apache.spark.rdd.RDD-">union</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#unpersist-boolean-">unpersist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zip-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">zip</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-boolean-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithIndex--">zipWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithUniqueId--">zipWithUniqueId</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.internal.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.internal.<a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></h3>
<code><a href="../../../../org/apache/spark/internal/Logging.html#initializeLogging-boolean-boolean-">initializeLogging</a>, <a href="../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-">initializeLogIfNecessary</a>, <a href="../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-boolean-">initializeLogIfNecessary</a>, <a href="../../../../org/apache/spark/internal/Logging.html#isTraceEnabled--">isTraceEnabled</a>, <a href="../../../../org/apache/spark/internal/Logging.html#log_--">log_</a>, <a href="../../../../org/apache/spark/internal/Logging.html#log--">log</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-">logDebug</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-java.lang.Throwable-">logDebug</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-">logError</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-java.lang.Throwable-">logError</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-">logInfo</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-java.lang.Throwable-">logInfo</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logName--">logName</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-">logTrace</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-java.lang.Throwable-">logTrace</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-">logWarning</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-java.lang.Throwable-">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="NewHadoopRDD-org.apache.spark.SparkContext-java.lang.Class-java.lang.Class-java.lang.Class-org.apache.hadoop.conf.Configuration-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>NewHadoopRDD</h4>
<pre>public&nbsp;NewHadoopRDD(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                    Class&lt;? extends org.apache.hadoop.mapreduce.InputFormat&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;&nbsp;inputFormatClass,
                    Class&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>&gt;&nbsp;keyClass,
                    Class&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&nbsp;valueClass,
                    org.apache.hadoop.conf.Configuration&nbsp;_conf)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="CONFIGURATION_INSTANTIATION_LOCK--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CONFIGURATION_INSTANTIATION_LOCK</h4>
<pre>public static&nbsp;Object&nbsp;CONFIGURATION_INSTANTIATION_LOCK()</pre>
<div class="block">Configuration's constructor is not threadsafe (see SPARK-1097 and HADOOP-10456).
 Therefore, we synchronize on this lock before calling new Configuration().</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="getConf--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;org.apache.hadoop.conf.Configuration&nbsp;getConf()</pre>
</li>
</ul>
<a name="getPartitions--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitions</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]&nbsp;getPartitions()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#getPartitions--">RDD</a></code></span></div>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD. This method will only
 be called once, so it is safe to implement a time-consuming computation in it.
 <p>
 The partitions in this array must satisfy the following property:
   <code>rdd.partitions.zipWithIndex.forall { case (partition, index) =&gt; partition.index == index }</code></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>compute</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;&nbsp;compute(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;theSplit,
                                                        <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">RDD</a></code></span></div>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">compute</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;</code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>theSplit</code> - (undocumented)</dd>
<dd><code>context</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="mapPartitionsWithInputSplit-scala.Function2-boolean-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsWithInputSplit</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;mapPartitionsWithInputSplit(scala.Function2&lt;org.apache.hadoop.mapreduce.InputSplit,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                                              boolean&nbsp;preservesPartitioning,
                                              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</pre>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</li>
</ul>
<a name="getPreferredLocations-org.apache.spark.Partition-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPreferredLocations</h4>
<pre>public&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;getPreferredLocations(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;hsplit)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#getPreferredLocations-org.apache.spark.Partition-">RDD</a></code></span></div>
<div class="block">Optionally overridden by subclasses to specify placement preferences.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>hsplit</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="persist-org.apache.spark.storage.StorageLevel-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>persist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a>&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&nbsp;persist(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;storageLevel)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#persist-org.apache.spark.storage.StorageLevel-">RDD</a></code></span></div>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed. This can only be used to assign a new storage level if the RDD does not
 have a storage level set yet. Local checkpointing is an exception.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#persist-org.apache.spark.storage.StorageLevel-">persist</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt;&gt;</code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>storageLevel</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/JdbcRDD.ConnectionFactory.html" title="interface in org.apache.spark.rdd"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/NewHadoopRDD.NewHadoopMapPartitionsWithSplitRDD$.html" title="class in org.apache.spark.rdd"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/NewHadoopRDD.html" target="_top">Frames</a></li>
<li><a href="NewHadoopRDD.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
