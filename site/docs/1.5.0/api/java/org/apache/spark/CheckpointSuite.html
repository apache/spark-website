<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Tue Sep 08 16:00:15 PDT 2015 -->
<title>CheckpointSuite</title>
<meta name="date" content="2015-09-08">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="CheckpointSuite";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../org/apache/spark/CacheManagerSuite.html" title="class in org.apache.spark"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../org/apache/spark/Class1.html" title="class in org.apache.spark"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?org/apache/spark/CheckpointSuite.html" target="_top">Frames</a></li>
<li><a href="CheckpointSuite.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark</div>
<h2 title="Class CheckpointSuite" class="title">Class CheckpointSuite</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.scalatest.FunSuite</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.CheckpointSuite</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd><a href="../../../org/apache/spark/LocalSparkContext.html" title="interface in org.apache.spark">LocalSparkContext</a>, <a href="../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">CheckpointSuite</span>
extends org.scalatest.FunSuite
implements <a href="../../../org/apache/spark/LocalSparkContext.html" title="interface in org.apache.spark">LocalSparkContext</a>, <a href="../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></pre>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#CheckpointSuite()">CheckpointSuite</a></strong>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#afterEach()">afterEach</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#beforeEach()">beforeEach</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.io.File</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#checkpointDir()">checkpointDir</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;K,V&gt;&nbsp;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;V&gt;[]&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup</a></strong>(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;&nbsp;first,
       <a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;&nbsp;second,
       <a href="../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;part)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;java.lang.Object</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#defaultCollectFunc(org.apache.spark.rdd.RDD)">defaultCollectFunc</a></strong>(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;rdd)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;java.lang.Object,java.lang.Object&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#generateFatPairRDD()">generateFatPairRDD</a></strong>()</code>
<div class="block">Generate an pair RDD (with partitioner) such that both the RDD and its partitions
 have large size.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#generateFatRDD()">generateFatRDD</a></strong>()</code>
<div class="block">Generate an RDD such that both the RDD and its partitions have large size.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.Tuple2&lt;java.lang.Object,java.lang.Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#getSerializedSizes(org.apache.spark.rdd.RDD)">getSerializedSizes</a></strong>(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd)</code>
<div class="block">Get serialized sizes of the RDD and its partitions, in order to test whether the size shrinks
 upon checkpointing.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#initializeRdd(org.apache.spark.rdd.RDD)">initializeRdd</a></strong>(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd)</code>
<div class="block">Recursively force the initialization of the all members of an RDD and it parents.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#partitioner()">partitioner</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#serializeDeserialize(T)">serializeDeserialize</a></strong>(T&nbsp;obj)</code>
<div class="block">Serialize and deserialize an object.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#testRDD(scala.Function1, scala.Function1, scala.reflect.ClassTag)">testRDD</a></strong>(scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object&gt;,<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&gt;&nbsp;op,
       scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;,java.lang.Object&gt;&nbsp;collectFunc,
       scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</code>
<div class="block">Test checkpointing of the RDD generated by the given operation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;void</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#testRDDPartitions(scala.Function1, scala.Function1, scala.reflect.ClassTag)">testRDDPartitions</a></strong>(scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object&gt;,<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&gt;&nbsp;op,
                 scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;,java.lang.Object&gt;&nbsp;collectFunc,
                 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$2)</code>
<div class="block">Test whether checkpointing of the parent of the generated RDD also
 truncates the lineage or not.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.scalatest.Outcome</code></td>
<td class="colLast"><code><strong><a href="../../../org/apache/spark/CheckpointSuite.html#withFixture(org.scalatest.Suite.NoArgTest)">withFixture</a></strong>(org.scalatest.Suite.NoArgTest&nbsp;test)</code>
<div class="block">Log the suite name and the test name before and after each test.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.LocalSparkContext">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../org/apache/spark/LocalSparkContext.html" title="interface in org.apache.spark">LocalSparkContext</a></h3>
<code><a href="../../../org/apache/spark/LocalSparkContext.html#beforeAll()">beforeAll</a>, <a href="../../../org/apache/spark/LocalSparkContext.html#resetSparkContext()">resetSparkContext</a>, <a href="../../../org/apache/spark/LocalSparkContext.html#sc()">sc</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="CheckpointSuite()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>CheckpointSuite</h4>
<pre>public&nbsp;CheckpointSuite()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public static&nbsp;&lt;K,V&gt;&nbsp;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;V&gt;[]&gt;&gt;&nbsp;cogroup(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;&nbsp;first,
                                                                <a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;&nbsp;second,
                                                                <a href="../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;part)</pre>
</li>
</ul>
<a name="checkpointDir()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>checkpointDir</h4>
<pre>public&nbsp;java.io.File&nbsp;checkpointDir()</pre>
</li>
</ul>
<a name="partitioner()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitioner</h4>
<pre>public&nbsp;<a href="../../../org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a>&nbsp;partitioner()</pre>
</li>
</ul>
<a name="beforeEach()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>beforeEach</h4>
<pre>public&nbsp;void&nbsp;beforeEach()</pre>
</li>
</ul>
<a name="afterEach()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>afterEach</h4>
<pre>public&nbsp;void&nbsp;afterEach()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../org/apache/spark/LocalSparkContext.html#afterEach()">afterEach</a></code>&nbsp;in interface&nbsp;<code><a href="../../../org/apache/spark/LocalSparkContext.html" title="interface in org.apache.spark">LocalSparkContext</a></code></dd>
</dl>
</li>
</ul>
<a name="defaultCollectFunc(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultCollectFunc</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;java.lang.Object&nbsp;defaultCollectFunc(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;rdd)</pre>
</li>
</ul>
<a name="testRDD(scala.Function1, scala.Function1, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>testRDD</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;void&nbsp;testRDD(scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object&gt;,<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&gt;&nbsp;op,
               scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;,java.lang.Object&gt;&nbsp;collectFunc,
               scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</pre>
<div class="block">Test checkpointing of the RDD generated by the given operation. It tests whether the
 serialized size of the RDD is reduce after checkpointing or not. This function should be called
 on all RDDs that have a parent RDD (i.e., do not call on ParallelCollection, BlockRDD, etc.).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>op</code> - an operation to run on the RDD</dd><dd><code>collectFunc</code> - a function for collecting the values in the RDD, in case there are
   non-comparable types like arrays that we want to convert to something that supports ==</dd><dd><code>evidence$1</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="testRDDPartitions(scala.Function1, scala.Function1, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>testRDDPartitions</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;void&nbsp;testRDDPartitions(scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object&gt;,<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&gt;&nbsp;op,
                         scala.Function1&lt;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;,java.lang.Object&gt;&nbsp;collectFunc,
                         scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$2)</pre>
<div class="block">Test whether checkpointing of the parent of the generated RDD also
 truncates the lineage or not. Some RDDs like CoGroupedRDD hold on to its parent
 RDDs partitions. So even if the parent RDD is checkpointed and its partitions changed,
 the generated RDD will remember the partitions and therefore potentially the whole lineage.
 This function should be called only those RDD whose partitions refer to parent RDD's
 partitions (i.e., do not call it on simple RDD like MappedRDD).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>op</code> - an operation to run on the RDD</dd><dd><code>collectFunc</code> - a function for collecting the values in the RDD, in case there are
   non-comparable types like arrays that we want to convert to something that supports ==</dd><dd><code>evidence$2</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="generateFatRDD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>generateFatRDD</h4>
<pre>public&nbsp;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object&gt;&nbsp;generateFatRDD()</pre>
<div class="block">Generate an RDD such that both the RDD and its partitions have large size.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="generateFatPairRDD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>generateFatPairRDD</h4>
<pre>public&nbsp;<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;java.lang.Object,java.lang.Object&gt;&gt;&nbsp;generateFatPairRDD()</pre>
<div class="block">Generate an pair RDD (with partitioner) such that both the RDD and its partitions
 have large size.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getSerializedSizes(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSerializedSizes</h4>
<pre>public&nbsp;scala.Tuple2&lt;java.lang.Object,java.lang.Object&gt;&nbsp;getSerializedSizes(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd)</pre>
<div class="block">Get serialized sizes of the RDD and its partitions, in order to test whether the size shrinks
 upon checkpointing. Ignores the checkpointData field, which may grow when we checkpoint.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="serializeDeserialize(java.lang.Object)">
<!--   -->
</a><a name="serializeDeserialize(T)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>serializeDeserialize</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;T&nbsp;serializeDeserialize(T&nbsp;obj)</pre>
<div class="block">Serialize and deserialize an object. This is useful to verify the objects
 contents after deserialization (e.g., the contents of an RDD split after
 it is sent to a slave along with a task)</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>obj</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="initializeRdd(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeRdd</h4>
<pre>public&nbsp;void&nbsp;initializeRdd(<a href="../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd)</pre>
<div class="block">Recursively force the initialization of the all members of an RDD and it parents.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="withFixture(org.scalatest.Suite.NoArgTest)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>withFixture</h4>
<pre>protected final&nbsp;org.scalatest.Outcome&nbsp;withFixture(org.scalatest.Suite.NoArgTest&nbsp;test)</pre>
<div class="block">Log the suite name and the test name before and after each test.
 <p>
 Subclasses should never override this method. If they wish to run
 custom code before and after each test, they should mix in the
 {{org.scalatest.BeforeAndAfter}} trait instead.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>test</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-all.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../org/apache/spark/CacheManagerSuite.html" title="class in org.apache.spark"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../org/apache/spark/Class1.html" title="class in org.apache.spark"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?org/apache/spark/CheckpointSuite.html" target="_top">Frames</a></li>
<li><a href="CheckpointSuite.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../lib/api-javadocs.js"></script></body>
</html>
