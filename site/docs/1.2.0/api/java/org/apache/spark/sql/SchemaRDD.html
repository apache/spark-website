<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Thu Dec 18 23:24:53 UTC 2014 -->
<title>SchemaRDD (Spark 1.2.1 JavaDoc)</title>
<meta name="date" content="2014-12-18">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SchemaRDD (Spark 1.2.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SchemaRDD.html" target="_top">Frames</a></li>
<li><a href="SchemaRDD.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SchemaRDD" class="title">Class SchemaRDD</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">org.apache.spark.rdd.RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SchemaRDD</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql">SchemaRDDLike</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SchemaRDD</span>
extends <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;
implements <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql">SchemaRDDLike</a></pre>
<div class="block">:: AlphaComponent ::
 An RDD of <code>Row</code> objects that has an associated schema. In addition to standard RDD functions,
 SchemaRDDs can be used in relational queries, as shown in the examples below.
 <p>
 Importing a SQLContext brings an implicit into scope that automatically converts a standard RDD
 whose elements are scala case classes into a SchemaRDD.  This conversion can also be done
 explicitly using the <code>createSchemaRDD</code> function on a <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a>.
 <p>
 A <code>SchemaRDD</code> can also be created by loading data in from external sources.
 Examples are loading data from Parquet files by using the <code>parquetFile</code> method on <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a>
 and loading JSON datasets by using <code>jsonFile</code> and <code>jsonRDD</code> methods on <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a>.
 <p>
 == SQL Queries ==
 A SchemaRDD can be registered as a table in the <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a> that was used to create it.  Once
 an RDD has been registered as a table, it can be used in the FROM clause of SQL statements.
 <p>
 <pre><code>
  // One method for defining the schema of an RDD is to make a case class with the desired column
  // names and types.
  case class Record(key: Int, value: String)

  val sc: SparkContext // An existing spark context.
  val sqlContext = new SQLContext(sc)

  // Importing the SQL context gives access to all the SQL functions and implicit conversions.
  import sqlContext._

  val rdd = sc.parallelize((1 to 100).map(i =&gt; Record(i, s"val_$i")))
  // Any RDD containing case classes can be registered as a table.  The schema of the table is
  // automatically inferred using scala reflection.
  rdd.registerTempTable("records")

  val results: SchemaRDD = sql("SELECT * FROM records")
 </code></pre>
 <p>
 == Language Integrated Queries ==
 <p>
 <pre><code>

  case class Record(key: Int, value: String)

  val sc: SparkContext // An existing spark context.
  val sqlContext = new SQLContext(sc)

  // Importing the SQL context gives access to all the SQL functions and implicit conversions.
  import sqlContext._

  val rdd = sc.parallelize((1 to 100).map(i =&gt; Record(i, "val_" + i)))

  // Example of language integrated queries.
  rdd.where('key === 1).orderBy('value.asc).select('key).collect()
 </code></pre>
 <p></div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SchemaRDD">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#SchemaRDD(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">SchemaRDD</a></strong>(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext,
         org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;baseLogicalPlan)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#aggregate(scala.collection.Seq)">aggregate</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;aggregateExprs)</code>
<div class="block">Performs an aggregation over all Rows in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#as(scala.Symbol)">as</a></strong>(scala.Symbol&nbsp;alias)</code>
<div class="block">Applies a qualifier to the attributes of this relation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.plans.logical.LogicalPlan</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#baseLogicalPlan()">baseLogicalPlan</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#baseSchemaRDD()">baseSchemaRDD</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#cache()">cache</a></strong>()</code>
<div class="block">Overridden cache function will always use the in-memory columnar caching.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#coalesce(int, boolean, scala.math.Ordering)">coalesce</a></strong>(int&nbsp;numPartitions,
        boolean&nbsp;shuffle,
        scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</code>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.expressions.Row[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#collect()">collect</a></strong>()</code>
<div class="block">Return an array that contains all of the elements in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;byte[]&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#collectToPython()">collectToPython</a></strong>()</code>
<div class="block">Serializes the Array[Row] returned by SchemaRDD's optimized collect(), using the same
 format as javaToPython.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute</a></strong>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split,
       <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</code>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#count()">count</a></strong>()</code>
<div class="block">:: Experimental ::
 Return the number of elements in the RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#distinct()">distinct</a></strong>()</code>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#distinct(int, scala.math.Ordering)">distinct</a></strong>(int&nbsp;numPartitions,
        scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</code>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#except(org.apache.spark.sql.SchemaRDD)">except</a></strong>(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan)</code>
<div class="block">Performs a relational except on two SchemaRDDs</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#filter(scala.Function1)">filter</a></strong>(scala.Function1&lt;org.apache.spark.sql.catalyst.expressions.Row,Object&gt;&nbsp;f)</code>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#generate(org.apache.spark.sql.catalyst.expressions.Generator, boolean, boolean, scala.Option)">generate</a></strong>(org.apache.spark.sql.catalyst.expressions.Generator&nbsp;generator,
        boolean&nbsp;join,
        boolean&nbsp;outer,
        scala.Option&lt;String&gt;&nbsp;alias)</code>
<div class="block">:: Experimental ::
 Applies the given Generator, or table generating function, to this relation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#getPartitions()">getPartitions</a></strong>()</code>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#groupBy(scala.collection.Seq, scala.collection.Seq)">groupBy</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;groupingExprs,
       scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;aggregateExprs)</code>
<div class="block">Performs a grouping followed by an aggregation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#intersect(org.apache.spark.sql.SchemaRDD)">intersect</a></strong>(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan)</code>
<div class="block">Performs a relational intersect on two SchemaRDDs</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD)">intersection</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other)</code>
<div class="block">Return the intersection of this RDD and another one.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD, int)">intersection</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
            int&nbsp;numPartitions)</code>
<div class="block">Return the intersection of this RDD and another one.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">intersection</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
            <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
            scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</code>
<div class="block">Return the intersection of this RDD and another one.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;byte[]&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#javaToPython()">javaToPython</a></strong>()</code>
<div class="block">Converts a JavaRDD to a PythonRDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#join(org.apache.spark.sql.SchemaRDD, org.apache.spark.sql.catalyst.plans.JoinType, scala.Option)">join</a></strong>(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan,
    org.apache.spark.sql.catalyst.plans.JoinType&nbsp;joinType,
    scala.Option&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;on)</code>
<div class="block">Performs a relational join on two SchemaRDDs</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#limit(org.apache.spark.sql.catalyst.expressions.Expression)">limit</a></strong>(org.apache.spark.sql.catalyst.expressions.Expression&nbsp;limitExpr)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#limit(int)">limit</a></strong>(int&nbsp;limitNum)</code>
<div class="block">Limits the results by the given integer.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#orderBy(scala.collection.Seq)">orderBy</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.SortOrder&gt;&nbsp;sortExprs)</code>
<div class="block">Sorts the results by the given expressions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#persist(org.apache.spark.storage.StorageLevel)">persist</a></strong>(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;newLevel)</code>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#repartition(int, scala.math.Ordering)">repartition</a></strong>(int&nbsp;numPartitions,
           scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</code>
<div class="block">Return a new RDD that has exactly numPartitions partitions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#sample(boolean, double, long)">sample</a></strong>(boolean&nbsp;withReplacement,
      double&nbsp;fraction,
      long&nbsp;seed)</code>
<div class="block">:: Experimental ::
 Returns a sampled version of the underlying dataset.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.types.StructType</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#schema()">schema</a></strong>()</code>
<div class="block">Returns the schema of this SchemaRDD (represented by a <code>StructType</code>).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#select(scala.collection.Seq)">select</a></strong>(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;exprs)</code>
<div class="block">Changes the output of this relation to the given expressions, similar to the <code>SELECT</code> clause
 in SQL.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#sqlContext()">sqlContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD)">subtract</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other)</code>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD, int)">subtract</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
        int&nbsp;numPartitions)</code>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">subtract</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
        scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</code>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.apache.spark.sql.catalyst.expressions.Row[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#take(int)">take</a></strong>(int&nbsp;num)</code>
<div class="block">Take the first num elements of the RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#toJavaSchemaRDD()">toJavaSchemaRDD</a></strong>()</code>
<div class="block">Returns this RDD as a JavaSchemaRDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#toJSON()">toJSON</a></strong>()</code>
<div class="block">Returns a new RDD with each row transformed to a JSON string.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#toSchemaRDD()">toSchemaRDD</a></strong>()</code>
<div class="block">Returns this RDD as a SchemaRDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#unionAll(org.apache.spark.sql.SchemaRDD)">unionAll</a></strong>(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan)</code>
<div class="block">Combines the tuples of two RDDs with the same schema, keeping duplicates.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#unpersist(boolean)">unpersist</a></strong>(boolean&nbsp;blocking)</code>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#where(org.apache.spark.sql.catalyst.expressions.Expression)">where</a></strong>(org.apache.spark.sql.catalyst.expressions.Expression&nbsp;condition)</code>
<div class="block">Filters the output, only returning those rows where <code>condition</code> evaluates to true.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#where(scala.Function1)">where</a></strong>(scala.Function1&lt;org.apache.spark.sql.catalyst.expressions.DynamicRow,Object&gt;&nbsp;dynamicUdf)</code>
<div class="block">:: Experimental ::
 Filters tuples using a function over a <code>Dynamic</code> version of a given Row.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T1&gt;&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SchemaRDD.html#where(scala.Symbol, scala.Function1)">where</a></strong>(scala.Symbol&nbsp;arg1,
     scala.Function1&lt;T1,Object&gt;&nbsp;udf)</code>
<div class="block">Filters tuples using a function over the value of the specified column.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.rdd.RDD">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.rdd.<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></h3>
<code><a href="../../../../org/apache/spark/rdd/RDD.html#aggregate(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cartesian(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">cartesian</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#checkpoint()">checkpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#checkpointData()">checkpointData</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect(scala.PartialFunction, scala.reflect.ClassTag)">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collectPartitions()">collectPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#computeOrReadCheckpoint(org.apache.spark.Partition, org.apache.spark.TaskContext)">computeOrReadCheckpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#conf()">conf</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#context()">context</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApprox(long, double)">countApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(double)">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct(int, int)">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValue(scala.math.Ordering)">countByValue</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValueApprox(long, double, scala.math.Ordering)">countByValueApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#creationSite()">creationSite</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#dependencies()">dependencies</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#doCheckpoint()">doCheckpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#elementClassTag()">elementClassTag</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#filterWith(scala.Function1, scala.Function2)">filterWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#first()">first</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#flatMap(scala.Function1, scala.reflect.ClassTag)">flatMap</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#flatMapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">flatMapWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#fold(T, scala.Function2)">fold</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreach(scala.Function1)">foreach</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreachPartition(scala.Function1)">foreachPartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreachWith(scala.Function1, scala.Function2)">foreachWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getCheckpointFile()">getCheckpointFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getCreationSite()">getCreationSite</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getNarrowAncestors()">getNarrowAncestors</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getStorageLevel()">getStorageLevel</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#glom()">glom</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, scala.reflect.ClassTag)">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, int, scala.reflect.ClassTag)">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, org.apache.spark.Partitioner, scala.reflect.ClassTag, scala.math.Ordering)">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#id()">id</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isCheckpointed()">isCheckpointed</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)">iterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#keyBy(scala.Function1)">keyBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#map(scala.Function1, scala.reflect.ClassTag)">map</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)">mapPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithContext(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithContext</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithSplit(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithSplit</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">mapWith</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#markCheckpointed(org.apache.spark.rdd.RDD)">markCheckpointed</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#max(scala.math.Ordering)">max</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#min(scala.math.Ordering)">min</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#name()">name</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitioner()">partitioner</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitions()">partitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#persist()">persist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe(scala.collection.Seq, scala.collection.Map, scala.Function1, scala.Function2, boolean)">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String)">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe(java.lang.String, scala.collection.Map)">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#preferredLocations(org.apache.spark.Partition)">preferredLocations</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#randomSplit(double[], long)">randomSplit</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#reduce(scala.Function2)">reduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#retag(java.lang.Class)">retag</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#retag(scala.reflect.ClassTag)">retag</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String, java.lang.Class)">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#setName(java.lang.String)">setName</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sortBy(scala.Function1, boolean, int, scala.math.Ordering, scala.reflect.ClassTag)">sortBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sparkContext()">sparkContext</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeOrdered(int, scala.math.Ordering)">takeOrdered</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeSample(boolean, int, long)">takeSample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toArray()">toArray</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toDebugString()">toDebugString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toJavaRDD()">toJavaRDD</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toLocalIterator()">toLocalIterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#top(int, scala.math.Ordering)">top</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toString()">toString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#union(org.apache.spark.rdd.RDD)">union</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zip(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">zip</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, boolean, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithIndex()">zipWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithUniqueId()">zipWithUniqueId</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SchemaRDDLike">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql">SchemaRDDLike</a></h3>
<code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#insertInto(java.lang.String)">insertInto</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#insertInto(java.lang.String, boolean)">insertInto</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#logicalPlan()">logicalPlan</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#printSchema()">printSchema</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#queryExecution()">queryExecution</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#registerAsTable(java.lang.String)">registerAsTable</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#registerTempTable(java.lang.String)">registerTempTable</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#saveAsParquetFile(java.lang.String)">saveAsParquetFile</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#saveAsTable(java.lang.String)">saveAsTable</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#schemaString()">schemaString</a>, <a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#toString()">toString</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SchemaRDD(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SchemaRDD</h4>
<pre>public&nbsp;SchemaRDD(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext,
         org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;baseLogicalPlan)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="sqlContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sqlContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#sqlContext()">sqlContext</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql">SchemaRDDLike</a></code></dd>
</dl>
</li>
</ul>
<a name="baseLogicalPlan()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseLogicalPlan</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;baseLogicalPlan()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#baseLogicalPlan()">baseLogicalPlan</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql">SchemaRDDLike</a></code></dd>
</dl>
</li>
</ul>
<a name="baseSchemaRDD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseSchemaRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;baseSchemaRDD()</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html#baseSchemaRDD()">baseSchemaRDD</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql">SchemaRDDLike</a></code></dd>
</dl>
</li>
</ul>
<a name="compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>compute</h4>
<pre>public&nbsp;scala.collection.Iterator&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;compute(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split,
                                                                               <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">RDD</a></code></strong></div>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="getPartitions()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitions</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]&nbsp;getPartitions()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#getPartitions()">RDD</a></code></strong></div>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD. This method will only
 be called once, so it is safe to implement a time-consuming computation in it.</div>
</li>
</ul>
<a name="schema()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>schema</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.types.StructType&nbsp;schema()</pre>
<div class="block">Returns the schema of this SchemaRDD (represented by a <code>StructType</code>).
 <p></div>
</li>
</ul>
<a name="toJSON()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toJSON</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;toJSON()</pre>
<div class="block">Returns a new RDD with each row transformed to a JSON string.
 <p></div>
</li>
</ul>
<a name="select(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>select</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;select(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;exprs)</pre>
<div class="block">Changes the output of this relation to the given expressions, similar to the <code>SELECT</code> clause
 in SQL.
 <p>
 <pre><code>
   schemaRDD.select('a, 'b + 'c, 'd as 'aliasedName)
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>exprs</code> - a set of logical expression that will be evaluated for each input row.
 <p></dd></dl>
</li>
</ul>
<a name="where(org.apache.spark.sql.catalyst.expressions.Expression)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>where</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;where(org.apache.spark.sql.catalyst.expressions.Expression&nbsp;condition)</pre>
<div class="block">Filters the output, only returning those rows where <code>condition</code> evaluates to true.
 <p>
 <pre><code>
   schemaRDD.where('a === 'b)
   schemaRDD.where('a === 1)
   schemaRDD.where('a + 'b &gt; 10)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="join(org.apache.spark.sql.SchemaRDD, org.apache.spark.sql.catalyst.plans.JoinType, scala.Option)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;join(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan,
             org.apache.spark.sql.catalyst.plans.JoinType&nbsp;joinType,
             scala.Option&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;on)</pre>
<div class="block">Performs a relational join on two SchemaRDDs
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>otherPlan</code> - the <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> that should be joined with this one.</dd><dd><code>joinType</code> - One of <code>Inner</code>, <code>LeftOuter</code>, <code>RightOuter</code>, or <code>FullOuter</code>. Defaults to <code>Inner.</code></dd><dd><code>on</code> - An optional condition for the join operation.  This is equivalent to the <code>ON</code>
                 clause in standard SQL.  In the case of <code>Inner</code> joins, specifying a
                 <code>condition</code> is equivalent to adding <code>where</code> clauses after the <code>join</code>.
 <p></dd></dl>
</li>
</ul>
<a name="orderBy(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>orderBy</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;orderBy(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.SortOrder&gt;&nbsp;sortExprs)</pre>
<div class="block">Sorts the results by the given expressions.
 <pre><code>
   schemaRDD.orderBy('a)
   schemaRDD.orderBy('a, 'b)
   schemaRDD.orderBy('a.asc, 'b.desc)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="limit(org.apache.spark.sql.catalyst.expressions.Expression)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>limit</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;limit(org.apache.spark.sql.catalyst.expressions.Expression&nbsp;limitExpr)</pre>
</li>
</ul>
<a name="limit(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>limit</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;limit(int&nbsp;limitNum)</pre>
<div class="block">Limits the results by the given integer.
 <pre><code>
   schemaRDD.limit(10)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="groupBy(scala.collection.Seq, scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;groupBy(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;groupingExprs,
                scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;aggregateExprs)</pre>
<div class="block">Performs a grouping followed by an aggregation.
 <p>
 <pre><code>
   schemaRDD.groupBy('year)(Sum('sales) as 'totalSales)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="aggregate(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>aggregate</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;aggregate(scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Expression&gt;&nbsp;aggregateExprs)</pre>
<div class="block">Performs an aggregation over all Rows in this RDD.
 This is equivalent to a groupBy with no grouping expressions.
 <p>
 <pre><code>
   schemaRDD.aggregate(Sum('sales) as 'totalSales)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="as(scala.Symbol)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>as</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;as(scala.Symbol&nbsp;alias)</pre>
<div class="block">Applies a qualifier to the attributes of this relation.  Can be used to disambiguate attributes
 with the same name, for example, when performing self-joins.
 <p>
 <pre><code>
   val x = schemaRDD.where('a === 1).as('x)
   val y = schemaRDD.where('a === 2).as('y)
   x.join(y).where("x.a".attr === "y.a".attr),
 </code></pre>
 <p></div>
</li>
</ul>
<a name="unionAll(org.apache.spark.sql.SchemaRDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unionAll</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;unionAll(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan)</pre>
<div class="block">Combines the tuples of two RDDs with the same schema, keeping duplicates.
 <p></div>
</li>
</ul>
<a name="except(org.apache.spark.sql.SchemaRDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>except</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;except(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan)</pre>
<div class="block">Performs a relational except on two SchemaRDDs
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>otherPlan</code> - the <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> that should be excepted from this one.
 <p></dd></dl>
</li>
</ul>
<a name="intersect(org.apache.spark.sql.SchemaRDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersect</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;intersect(<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;otherPlan)</pre>
<div class="block">Performs a relational intersect on two SchemaRDDs
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>otherPlan</code> - the <a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> that should be intersected with this one.
 <p></dd></dl>
</li>
</ul>
<a name="where(scala.Symbol, scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>where</h4>
<pre>public&nbsp;&lt;T1&gt;&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;where(scala.Symbol&nbsp;arg1,
                   scala.Function1&lt;T1,Object&gt;&nbsp;udf)</pre>
<div class="block">Filters tuples using a function over the value of the specified column.
 <p>
 <pre><code>
   schemaRDD.where('a)((a: Int) =&gt; ...)
 </code></pre>
 <p></div>
</li>
</ul>
<a name="where(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>where</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;where(scala.Function1&lt;org.apache.spark.sql.catalyst.expressions.DynamicRow,Object&gt;&nbsp;dynamicUdf)</pre>
<div class="block">:: Experimental ::
 Filters tuples using a function over a <code>Dynamic</code> version of a given Row.  DynamicRows use
 scala's Dynamic trait to emulate an ORM of in a dynamically typed language.  Since the type of
 the column is not known at compile time, all attributes are converted to strings before
 being passed to the function.
 <p>
 <pre><code>
   schemaRDD.where(r =&gt; r.firstName == "Bob" && r.lastName == "Smith")
 </code></pre>
 <p></div>
</li>
</ul>
<a name="sample(boolean, double, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sample</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;sample(boolean&nbsp;withReplacement,
               double&nbsp;fraction,
               long&nbsp;seed)</pre>
<div class="block">:: Experimental ::
 Returns a sampled version of the underlying dataset.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#sample(boolean, double, long)">sample</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="count()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>count</h4>
<pre>public&nbsp;long&nbsp;count()</pre>
<div class="block">:: Experimental ::
 Return the number of elements in the RDD. Unlike the base RDD implementation of count, this
 implementation leverages the query optimizer to compute the count on the SchemaRDD, which
 supports features such as filter pushdown.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#count()">count</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="generate(org.apache.spark.sql.catalyst.expressions.Generator, boolean, boolean, scala.Option)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>generate</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;generate(org.apache.spark.sql.catalyst.expressions.Generator&nbsp;generator,
                 boolean&nbsp;join,
                 boolean&nbsp;outer,
                 scala.Option&lt;String&gt;&nbsp;alias)</pre>
<div class="block">:: Experimental ::
 Applies the given Generator, or table generating function, to this relation.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>generator</code> - A table generating function.  The API for such functions is likely to change
                  in future releases</dd><dd><code>join</code> - when set to true, each output row of the generator is joined with the input row
             that produced it.</dd><dd><code>outer</code> - when set to true, at least one row will be produced for each input row, similar to
              an <code>OUTER JOIN</code> in SQL.  When no output rows are produced by the generator for a
              given row, a single row will be output, with <code>NULL</code> values for each of the
              generated columns.</dd><dd><code>alias</code> - an optional alias that can be used as qualifier for the attributes that are
              produced by this generate operation.
 <p></dd></dl>
</li>
</ul>
<a name="toSchemaRDD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toSchemaRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;toSchemaRDD()</pre>
<div class="block">Returns this RDD as a SchemaRDD.  Intended primarily to force the invocation of the implicit
 conversion from a standard RDD to a SchemaRDD.
 <p></div>
</li>
</ul>
<a name="toJavaSchemaRDD()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toJavaSchemaRDD</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a>&nbsp;toJavaSchemaRDD()</pre>
<div class="block">Returns this RDD as a JavaSchemaRDD.
 <p></div>
</li>
</ul>
<a name="javaToPython()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>javaToPython</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;byte[]&gt;&nbsp;javaToPython()</pre>
<div class="block">Converts a JavaRDD to a PythonRDD. It is used by pyspark.</div>
</li>
</ul>
<a name="collectToPython()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collectToPython</h4>
<pre>public&nbsp;java.util.List&lt;byte[]&gt;&nbsp;collectToPython()</pre>
<div class="block">Serializes the Array[Row] returned by SchemaRDD's optimized collect(), using the same
 format as javaToPython. It is used by pyspark.</div>
</li>
</ul>
<a name="collect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collect</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.expressions.Row[]&nbsp;collect()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#collect()">RDD</a></code></strong></div>
<div class="block">Return an array that contains all of the elements in this RDD.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#collect()">collect</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="take(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>take</h4>
<pre>public&nbsp;org.apache.spark.sql.catalyst.expressions.Row[]&nbsp;take(int&nbsp;num)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#take(int)">RDD</a></code></strong></div>
<div class="block">Take the first num elements of the RDD. It works by first scanning one partition, and use the
 results from that partition to estimate the number of additional partitions needed to satisfy
 the limit.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#take(int)">take</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="coalesce(int, boolean, scala.math.Ordering)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>coalesce</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;coalesce(int&nbsp;numPartitions,
                 boolean&nbsp;shuffle,
                 scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#coalesce(int, boolean, scala.math.Ordering)">RDD</a></code></strong></div>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.
 <p>
 This results in a narrow dependency, e.g. if you go from 1000 partitions
 to 100 partitions, there will not be a shuffle, instead each of the 100
 new partitions will claim 10 of the current partitions.
 <p>
 However, if you're doing a drastic coalesce, e.g. to numPartitions = 1,
 this may result in your computation taking place on fewer nodes than
 you like (e.g. one node in the case of numPartitions = 1). To avoid this,
 you can pass shuffle = true. This will add a shuffle step, but means the
 current upstream partitions will be executed in parallel (per whatever
 the current partitioning is).
 <p>
 Note: With shuffle = true, you can actually coalesce to a larger number
 of partitions. This is useful if you have a small number of partitions,
 say 100, potentially with a few partitions being abnormally large. Calling
 coalesce(1000, shuffle = true) will result in 1000 partitions with the
 data distributed using a hash partitioner.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#coalesce(int, boolean, scala.math.Ordering)">coalesce</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="distinct()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>distinct</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;distinct()</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#distinct()">RDD</a></code></strong></div>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#distinct()">distinct</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="distinct(int, scala.math.Ordering)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>distinct</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;distinct(int&nbsp;numPartitions,
                 scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#distinct(int, scala.math.Ordering)">RDD</a></code></strong></div>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#distinct(int, scala.math.Ordering)">distinct</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="filter(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>filter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;filter(scala.Function1&lt;org.apache.spark.sql.catalyst.expressions.Row,Object&gt;&nbsp;f)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#filter(scala.Function1)">RDD</a></code></strong></div>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#filter(scala.Function1)">filter</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="intersection(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;intersection(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD)">RDD</a></code></strong></div>
<div class="block">Return the intersection of this RDD and another one. The output will not contain any duplicate
 elements, even if the input RDDs did.
 <p>
 Note that this method performs a shuffle internally.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD)">intersection</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;intersection(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
                     <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                     scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">RDD</a></code></strong></div>
<div class="block">Return the intersection of this RDD and another one. The output will not contain any duplicate
 elements, even if the input RDDs did.
 <p>
 Note that this method performs a shuffle internally.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">intersection</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
<dd><code>partitioner</code> - Partitioner to use for the resulting RDD</dd></dl>
</li>
</ul>
<a name="intersection(org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;intersection(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
                     int&nbsp;numPartitions)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, int)">RDD</a></code></strong></div>
<div class="block">Return the intersection of this RDD and another one. The output will not contain any duplicate
 elements, even if the input RDDs did.  Performs a hash partition across the cluster
 <p>
 Note that this method performs a shuffle internally.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, int)">intersection</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
<dd><code>numPartitions</code> - How many partitions to use in the resulting RDD</dd></dl>
</li>
</ul>
<a name="repartition(int, scala.math.Ordering)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>repartition</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;repartition(int&nbsp;numPartitions,
                    scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#repartition(int, scala.math.Ordering)">RDD</a></code></strong></div>
<div class="block">Return a new RDD that has exactly numPartitions partitions.
 <p>
 Can increase or decrease the level of parallelism in this RDD. Internally, this uses
 a shuffle to redistribute data.
 <p>
 If you are decreasing the number of partitions in this RDD, consider using <code>coalesce</code>,
 which can avoid performing a shuffle.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#repartition(int, scala.math.Ordering)">repartition</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="subtract(org.apache.spark.rdd.RDD)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;subtract(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD)">RDD</a></code></strong></div>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.
 <p>
 Uses <code>this</code> partitioner/partition size, because even if <code>other</code> is huge, the resulting
 RDD will be <= us.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD)">subtract</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="subtract(org.apache.spark.rdd.RDD, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;subtract(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
                 int&nbsp;numPartitions)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, int)">RDD</a></code></strong></div>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, int)">subtract</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;subtract(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;other,
                 <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
                 scala.math.Ordering&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;&nbsp;ord)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">RDD</a></code></strong></div>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">subtract</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="cache()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cache</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;cache()</pre>
<div class="block">Overridden cache function will always use the in-memory columnar caching.</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#cache()">cache</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="persist(org.apache.spark.storage.StorageLevel)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>persist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;persist(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;newLevel)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)">RDD</a></code></strong></div>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed. This can only be used to assign a new storage level if the RDD does not
 have a storage level set yet..</div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)">persist</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
</dl>
</li>
</ul>
<a name="unpersist(boolean)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>unpersist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;unpersist(boolean&nbsp;blocking)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#unpersist(boolean)">RDD</a></code></strong></div>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#unpersist(boolean)">unpersist</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;org.apache.spark.sql.catalyst.expressions.Row&gt;</code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>blocking</code> - Whether to block until all blocks are deleted.</dd>
<dt><span class="strong">Returns:</span></dt><dd>This RDD.</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SchemaRDDLike.html" title="interface in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SchemaRDD.html" target="_top">Frames</a></li>
<li><a href="SchemaRDD.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
