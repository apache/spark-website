<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Thu Dec 18 23:24:56 UTC 2014 -->
<title>HiveContext (Spark 1.2.1 JavaDoc)</title>
<meta name="date" content="2014-12-18">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="HiveContext (Spark 1.2.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/hive/HadoopTableReader.html" title="class in org.apache.spark.sql.hive"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/hive/HiveFunctionRegistry.html" title="class in org.apache.spark.sql.hive"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/hive/HiveContext.html" target="_top">Frames</a></li>
<li><a href="HiveContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.hive</div>
<h2 title="Class HiveContext" class="title">Class HiveContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">org.apache.spark.sql.SQLContext</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.hive.HiveContext</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql">CacheManager</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql">UDFRegistration</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../../org/apache/spark/sql/hive/LocalHiveContext.html" title="class in org.apache.spark.sql.hive">LocalHiveContext</a>, <a href="../../../../../org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">HiveContext</span>
extends <a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></pre>
<div class="block">An instance of the Spark SQL execution engine that integrates with data stored in Hive.
 Configuration for Hive is read from hive-site.xml on the classpath.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../../../serialized-form.html#org.apache.spark.sql.hive.HiveContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested_classes_inherited_from_class_org.apache.spark.sql.SQLConf">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SQLConf.Deprecated$.html" title="class in org.apache.spark.sql">SQLConf.Deprecated$</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#HiveContext(org.apache.spark.SparkContext)">HiveContext</a></strong>(<a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#analyze(java.lang.String)">analyze</a></strong>(String&nbsp;tableName)</code>
<div class="block">Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#convertMetastoreParquet()">convertMetastoreParquet</a></strong>()</code>
<div class="block">When true, enables an experimental feature where metastore tables that use the parquet SerDe
 are automatically converted to use the Spark SQL parquet table scan, instead of the Hive
 SerDe.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#createTable(java.lang.String, boolean, scala.reflect.api.TypeTags.TypeTag)">createTable</a></strong>(String&nbsp;tableName,
           boolean&nbsp;allowExisting,
           scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>
<div class="block">Creates a table using the schema of the given class.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#dialect()">dialect</a></strong>()</code>
<div class="block">The SQL dialect that is used when parsing queries.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.spark.sql.SQLContext.SparkPlanner</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hivePlanner()">hivePlanner</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hiveql(java.lang.String)">hiveql</a></strong>(String&nbsp;hqlQuery)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#hql(java.lang.String)">hql</a></strong>(String&nbsp;hqlQuery)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#setConf(java.lang.String, java.lang.String)">setConf</a></strong>(String&nbsp;key,
       String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/hive/HiveContext.html#sql(java.lang.String)">sql</a></strong>(String&nbsp;sqlText)</code>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SQLContext">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchema</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD, java.lang.String)">applySchemaToPythonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchemaToPythonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#baseRelationToSchemaRDD(org.apache.spark.sql.sources.BaseRelation)">baseRelationToSchemaRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">createParquetFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">createSchemaRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#dropTempTable(java.lang.String)">dropTempTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#extraStrategies()">extraStrategies</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">jsonFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">jsonRDD</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">logicalPlanToSparkQuery</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String)">parquetFile</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#parseDataType(java.lang.String)">parseDataType</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">registerRDDAsTable</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a>, <a href="../../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.<a href="../../../../../org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary</a>, <a href="../../../../../org/apache/spark/Logging.html#initializeLogging()">initializeLogging</a>, <a href="../../../../../org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/Logging.html#log_()">log_</a>, <a href="../../../../../org/apache/spark/Logging.html#log()">log</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo</a>, <a href="../../../../../org/apache/spark/Logging.html#logName()">logName</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning</a>, <a href="../../../../../org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.SQLConf">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/SQLConf.html" title="interface in org.apache.spark.sql">SQLConf</a></h3>
<code><a href="../../../../../org/apache/spark/sql/SQLConf.html#autoBroadcastJoinThreshold()">autoBroadcastJoinThreshold</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#clear()">clear</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#codegenEnabled()">codegenEnabled</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#columnBatchSize()">columnBatchSize</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#columnNameOfCorruptRecord()">columnNameOfCorruptRecord</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#defaultSizeInBytes()">defaultSizeInBytes</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#externalSortEnabled()">externalSortEnabled</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#getAllConfs()">getAllConfs</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#getConf(java.lang.String)">getConf</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#getConf(java.lang.String, java.lang.String)">getConf</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#inMemoryPartitionPruning()">inMemoryPartitionPruning</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#isParquetBinaryAsString()">isParquetBinaryAsString</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#numShufflePartitions()">numShufflePartitions</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#parquetCompressionCodec()">parquetCompressionCodec</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#parquetFilterPushDown()">parquetFilterPushDown</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#setConf(java.util.Properties)">setConf</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#settings()">settings</a>, <a href="../../../../../org/apache/spark/sql/SQLConf.html#useCompression()">useCompression</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.CacheManager">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/CacheManager.html" title="interface in org.apache.spark.sql">CacheManager</a></h3>
<code><a href="../../../../../org/apache/spark/sql/CacheManager.html#cachedData()">cachedData</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#cacheLock()">cacheLock</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#cacheQuery(org.apache.spark.sql.SchemaRDD, scala.Option, org.apache.spark.storage.StorageLevel)">cacheQuery</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#cacheTable(java.lang.String)">cacheTable</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#clearCache()">clearCache</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#invalidateCache(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">invalidateCache</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#isCached(java.lang.String)">isCached</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#lookupCachedData(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">lookupCachedData</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#lookupCachedData(org.apache.spark.sql.SchemaRDD)">lookupCachedData</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#readLock(scala.Function0)">readLock</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#tryUncacheQuery(org.apache.spark.sql.SchemaRDD, boolean)">tryUncacheQuery</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#uncacheQuery(org.apache.spark.sql.SchemaRDD, boolean)">uncacheQuery</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#uncacheTable(java.lang.String)">uncacheTable</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#useCachedData(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">useCachedData</a>, <a href="../../../../../org/apache/spark/sql/CacheManager.html#writeLock(scala.Function0)">writeLock</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_org.apache.spark.sql.UDFRegistration">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.sql.<a href="../../../../../org/apache/spark/sql/UDFRegistration.html" title="interface in org.apache.spark.sql">UDFRegistration</a></h3>
<code><a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function1, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function10, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function11, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function12, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function13, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function14, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function15, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function16, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function17, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function18, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function19, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function2, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function20, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function21, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function22, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function3, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function4, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function5, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function6, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function7, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function8, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerFunction(java.lang.String, scala.Function9, scala.reflect.api.TypeTags.TypeTag)">registerFunction</a>, <a href="../../../../../org/apache/spark/sql/UDFRegistration.html#registerPython(java.lang.String, byte[], java.util.Map, java.util.List, java.lang.String, java.util.List, org.apache.spark.Accumulator, java.lang.String)">registerPython</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="HiveContext(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HiveContext</h4>
<pre>public&nbsp;HiveContext(<a href="../../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="dialect()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dialect</h4>
<pre>public&nbsp;String&nbsp;dialect()</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLConf.html#dialect()">SQLConf</a></code></strong></div>
<div class="block">The SQL dialect that is used when parsing queries.  This defaults to 'sql' which uses
 a simple SQL parser provided by Spark SQL.  This is currently the only option for users of
 SQLContext.
 <p>
 When using a HiveContext, this value defaults to 'hiveql', which uses the Hive 0.12.0 HiveQL
 parser.  Users can change this to 'sql' if they want to run queries that aren't supported by
 HiveQL (e.g., SELECT 1).
 <p>
 Note that the choice of dialect does not affect things like what tables are available or
 how query execution is performed.</div>
</li>
</ul>
<a name="convertMetastoreParquet()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>convertMetastoreParquet</h4>
<pre>public&nbsp;boolean&nbsp;convertMetastoreParquet()</pre>
<div class="block">When true, enables an experimental feature where metastore tables that use the parquet SerDe
 are automatically converted to use the Spark SQL parquet table scan, instead of the Hive
 SerDe.</div>
</li>
</ul>
<a name="sql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;sql(String&nbsp;sqlText)</pre>
<div class="block"><strong>Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">SQLContext</a></code></strong></div>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.  The dialect that is
 used for SQL parsing can be configured with 'spark.sql.dialect'.
 <p></div>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code><a href="../../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></dd>
</dl>
</li>
</ul>
<a name="hiveql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hiveql</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;hiveql(String&nbsp;hqlQuery)</pre>
</li>
</ul>
<a name="hql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hql</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a>&nbsp;hql(String&nbsp;hqlQuery)</pre>
</li>
</ul>
<a name="createTable(java.lang.String, boolean, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createTable</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;void&nbsp;createTable(String&nbsp;tableName,
                                         boolean&nbsp;allowExisting,
                                         scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
<div class="block">Creates a table using the schema of the given class.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - The name of the table to create.</dd><dd><code>allowExisting</code> - When false, an exception will be thrown if the table already exists.</dd></dl>
</li>
</ul>
<a name="analyze(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>analyze</h4>
<pre>public&nbsp;void&nbsp;analyze(String&nbsp;tableName)</pre>
<div class="block">Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.
 <p>
 Right now, it only supports Hive tables and it only updates the size of a Hive table
 in the Hive metastore.</div>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(String&nbsp;key,
           String&nbsp;value)</pre>
<div class="block"><strong>Description copied from interface:&nbsp;<code><a href="../../../../../org/apache/spark/sql/SQLConf.html#setConf(java.lang.String, java.lang.String)">SQLConf</a></code></strong></div>
<div class="block">Set the given Spark SQL configuration property.</div>
</li>
</ul>
<a name="hivePlanner()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>hivePlanner</h4>
<pre>public&nbsp;org.apache.spark.sql.SQLContext.SparkPlanner&nbsp;hivePlanner()</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/hive/HadoopTableReader.html" title="class in org.apache.spark.sql.hive"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/hive/HiveFunctionRegistry.html" title="class in org.apache.spark.sql.hive"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/hive/HiveContext.html" target="_top">Frames</a></li>
<li><a href="HiveContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
