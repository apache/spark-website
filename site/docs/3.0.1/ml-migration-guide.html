
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Migration Guide: MLlib (Machine Learning) - Spark 3.0.1 Documentation</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html">
                      <img src="img/spark-logo-hd.png" style="height:50px;"/></a><span class="version">3.0.1</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">Overview</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Programming Guides<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">Quick Start</a></li>
                                <li><a href="rdd-programming-guide.html">RDDs, Accumulators, Broadcasts Vars</a></li>
                                <li><a href="sql-programming-guide.html">SQL, DataFrames, and Datasets</a></li>
                                <li><a href="structured-streaming-programming-guide.html">Structured Streaming</a></li>
                                <li><a href="streaming-programming-guide.html">Spark Streaming (DStreams)</a></li>
                                <li><a href="ml-guide.html">MLlib (Machine Learning)</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX (Graph Processing)</a></li>
                                <li><a href="sparkr.html">SparkR (R on Spark)</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Docs<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/org/apache/spark/index.html">Scala</a></li>
                                <li><a href="api/java/index.html">Java</a></li>
                                <li><a href="api/python/index.html">Python</a></li>
                                <li><a href="api/R/index.html">R</a></li>
                                <li><a href="api/sql/index.html">SQL, Built-in Functions</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Deploying<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">Overview</a></li>
                                <li><a href="submitting-applications.html">Submitting Applications</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark Standalone</a></li>
                                <li><a href="running-on-mesos.html">Mesos</a></li>
                                <li><a href="running-on-yarn.html">YARN</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">More<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">Configuration</a></li>
                                <li><a href="monitoring.html">Monitoring</a></li>
                                <li><a href="tuning.html">Tuning Guide</a></li>
                                <li><a href="job-scheduling.html">Job Scheduling</a></li>
                                <li><a href="security.html">Security</a></li>
                                <li><a href="hardware-provisioning.html">Hardware Provisioning</a></li>
                                <li><a href="migration-guide.html">Migration Guide</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">Building Spark</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">Contributing to Spark</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">Third Party Projects</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v3.0.1</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="migration-guide.html">Migration Guide</a></h3>
        
<ul>

    <li>
        <a href="core-migration-guide.html">
            
                Spark Core
            
        </a>
    </li>
    
    

    <li>
        <a href="sql-migration-guide.html">
            
                SQL, Datasets and DataFrame
            
        </a>
    </li>
    
    

    <li>
        <a href="ss-migration-guide.html">
            
                Structured Streaming
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-migration-guide.html">
            
                <b>MLlib (Machine Learning)</b>
            
        </a>
    </li>
    
    

    <li>
        <a href="pyspark-migration-guide.html">
            
                PySpark (Python on Spark)
            
        </a>
    </li>
    
    

    <li>
        <a href="sparkr-migration-guide.html">
            
                SparkR (R on Spark)
            
        </a>
    </li>
    
    

</ul>

    </div>
</div>

                
                <input id="nav-trigger" class="nav-trigger" checked type="checkbox">
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">Migration Guide: MLlib (Machine Learning)</h1>
                    

                    <ul id="markdown-toc">
  <li><a href="#upgrading-from-mllib-24-to-30" id="markdown-toc-upgrading-from-mllib-24-to-30">Upgrading from MLlib 2.4 to 3.0</a></li>
  <li><a href="#upgrading-from-mllib-22-to-23" id="markdown-toc-upgrading-from-mllib-22-to-23">Upgrading from MLlib 2.2 to 2.3</a></li>
  <li><a href="#upgrading-from-mllib-21-to-22" id="markdown-toc-upgrading-from-mllib-21-to-22">Upgrading from MLlib 2.1 to 2.2</a></li>
  <li><a href="#upgrading-from-mllib-20-to-21" id="markdown-toc-upgrading-from-mllib-20-to-21">Upgrading from MLlib 2.0 to 2.1</a></li>
  <li><a href="#upgrading-from-mllib-16-to-20" id="markdown-toc-upgrading-from-mllib-16-to-20">Upgrading from MLlib 1.6 to 2.0</a></li>
  <li><a href="#upgrading-from-mllib-15-to-16" id="markdown-toc-upgrading-from-mllib-15-to-16">Upgrading from MLlib 1.5 to 1.6</a></li>
  <li><a href="#upgrading-from-mllib-14-to-15" id="markdown-toc-upgrading-from-mllib-14-to-15">Upgrading from MLlib 1.4 to 1.5</a></li>
  <li><a href="#upgrading-from-mllib-13-to-14" id="markdown-toc-upgrading-from-mllib-13-to-14">Upgrading from MLlib 1.3 to 1.4</a></li>
  <li><a href="#upgrading-from-mllib-12-to-13" id="markdown-toc-upgrading-from-mllib-12-to-13">Upgrading from MLlib 1.2 to 1.3</a></li>
  <li><a href="#upgrading-from-mllib-11-to-12" id="markdown-toc-upgrading-from-mllib-11-to-12">Upgrading from MLlib 1.1 to 1.2</a></li>
  <li><a href="#upgrading-from-mllib-10-to-11" id="markdown-toc-upgrading-from-mllib-10-to-11">Upgrading from MLlib 1.0 to 1.1</a></li>
  <li><a href="#upgrading-from-mllib-09-to-10" id="markdown-toc-upgrading-from-mllib-09-to-10">Upgrading from MLlib 0.9 to 1.0</a></li>
</ul>

<p>Note that this migration guide describes the items specific to MLlib.
Many items of SQL migration can be applied when migrating MLlib to higher versions for DataFrame-based APIs.
Please refer <a href="sql-migration-guide.html">Migration Guide: SQL, Datasets and DataFrame</a>.</p>

<h2 id="upgrading-from-mllib-24-to-30">Upgrading from MLlib 2.4 to 3.0</h2>

<h3 class="no_toc" id="breaking-changes">Breaking changes</h3>

<ul>
  <li><code class="highlighter-rouge">OneHotEncoder</code> which is deprecated in 2.3, is removed in 3.0 and <code class="highlighter-rouge">OneHotEncoderEstimator</code> is now renamed to <code class="highlighter-rouge">OneHotEncoder</code>.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.image.ImageSchema.readImages</code> which is deprecated in 2.3, is removed in 3.0, use <code class="highlighter-rouge">spark.read.format('image')</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.clustering.KMeans.train</code> with param Int <code class="highlighter-rouge">runs</code> which is deprecated in 2.1, is removed in 3.0. Use <code class="highlighter-rouge">train</code> method without <code class="highlighter-rouge">runs</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.classification.LogisticRegressionWithSGD</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">org.apache.spark.ml.classification.LogisticRegression</code> or <code class="highlighter-rouge">spark.mllib.classification.LogisticRegressionWithLBFGS</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.feature.ChiSqSelectorModel.isSorted </code> which is deprecated in 2.1, is removed in 3.0, is not intended for subclasses to use.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.regression.RidgeRegressionWithSGD</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">org.apache.spark.ml.regression.LinearRegression</code> with <code class="highlighter-rouge">elasticNetParam</code> = 0.0. Note the default <code class="highlighter-rouge">regParam</code> is 0.01 for <code class="highlighter-rouge">RidgeRegressionWithSGD</code>, but is 0.0 for <code class="highlighter-rouge">LinearRegression</code>.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.regression.LassoWithSGD</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">org.apache.spark.ml.regression.LinearRegression</code> with <code class="highlighter-rouge">elasticNetParam</code> = 1.0. Note the default <code class="highlighter-rouge">regParam</code> is 0.01 for <code class="highlighter-rouge">LassoWithSGD</code>, but is 0.0 for <code class="highlighter-rouge">LinearRegression</code>.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.regression.LinearRegressionWithSGD</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">org.apache.spark.ml.regression.LinearRegression</code> or <code class="highlighter-rouge">LBFGS</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.mllib.clustering.KMeans.getRuns</code> and <code class="highlighter-rouge">setRuns</code> which are deprecated in 2.1, are removed in 3.0, have no effect since Spark 2.0.0.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.LinearSVCModel.setWeightCol</code> which is deprecated in 2.4, is removed in 3.0, is not intended for users.</li>
  <li>From 3.0, <code class="highlighter-rouge">org.apache.spark.ml.classification.MultilayerPerceptronClassificationModel</code> extends <code class="highlighter-rouge">MultilayerPerceptronParams</code> to expose the training params. As a result, <code class="highlighter-rouge">layers</code> in <code class="highlighter-rouge">MultilayerPerceptronClassificationModel</code> has been changed from <code class="highlighter-rouge">Array[Int]</code> to <code class="highlighter-rouge">IntArrayParam</code>. Users should use <code class="highlighter-rouge">MultilayerPerceptronClassificationModel.getLayers</code> instead of <code class="highlighter-rouge">MultilayerPerceptronClassificationModel.layers</code> to retrieve the size of layers.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.classification.GBTClassifier.numTrees</code>  which is deprecated in 2.4.5, is removed in 3.0, use <code class="highlighter-rouge">getNumTrees</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.clustering.KMeansModel.computeCost</code> which is deprecated in 2.4, is removed in 3.0, use <code class="highlighter-rouge">ClusteringEvaluator</code> instead.</li>
  <li>The member variable <code class="highlighter-rouge">precision</code> in <code class="highlighter-rouge">org.apache.spark.mllib.evaluation.MulticlassMetrics</code> which is deprecated in 2.0, is removed in 3.0. Use <code class="highlighter-rouge">accuracy</code> instead.</li>
  <li>The member variable <code class="highlighter-rouge">recall</code> in <code class="highlighter-rouge">org.apache.spark.mllib.evaluation.MulticlassMetrics</code> which is deprecated in 2.0, is removed in 3.0. Use <code class="highlighter-rouge">accuracy</code> instead.</li>
  <li>The member variable <code class="highlighter-rouge">fMeasure</code> in <code class="highlighter-rouge">org.apache.spark.mllib.evaluation.MulticlassMetrics</code> which is deprecated in 2.0, is removed in 3.0. Use <code class="highlighter-rouge">accuracy</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.util.GeneralMLWriter.context</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">session</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.util.MLWriter.context</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">session</code> instead.</li>
  <li><code class="highlighter-rouge">org.apache.spark.ml.util.MLReader.context</code> which is deprecated in 2.0, is removed in 3.0, use <code class="highlighter-rouge">session</code> instead.</li>
  <li><code class="highlighter-rouge">abstract class UnaryTransformer[IN, OUT, T &lt;: UnaryTransformer[IN, OUT, T]]</code> is changed to <code class="highlighter-rouge">abstract class UnaryTransformer[IN: TypeTag, OUT: TypeTag, T &lt;: UnaryTransformer[IN, OUT, T]]</code> in 3.0.</li>
</ul>

<h3 class="no_toc" id="deprecations-and-changes-of-behavior">Deprecations and changes of behavior</h3>

<p><strong>Deprecations</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11215">SPARK-11215</a>:
<code class="highlighter-rouge">labels</code> in <code class="highlighter-rouge">StringIndexerModel</code> is deprecated and will be removed in 3.1.0. Use <code class="highlighter-rouge">labelsArray</code> instead.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-25758">SPARK-25758</a>:
<code class="highlighter-rouge">computeCost</code> in <code class="highlighter-rouge">BisectingKMeansModel</code> is deprecated and will be removed in future versions. Use <code class="highlighter-rouge">ClusteringEvaluator</code> instead.</li>
</ul>

<p><strong>Changes of behavior</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11215">SPARK-11215</a>:
 In Spark 2.4 and previous versions, when specifying <code class="highlighter-rouge">frequencyDesc</code> or <code class="highlighter-rouge">frequencyAsc</code> as
 <code class="highlighter-rouge">stringOrderType</code> param in <code class="highlighter-rouge">StringIndexer</code>, in case of equal frequency, the order of
 strings is undefined. Since Spark 3.0, the strings with equal frequency are further
 sorted by alphabet. And since Spark 3.0, <code class="highlighter-rouge">StringIndexer</code> supports encoding multiple
 columns.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-20604">SPARK-20604</a>:
 In prior to 3.0 releases, <code class="highlighter-rouge">Imputer</code> requires input column to be Double or Float. In 3.0, this
 restriction is lifted so <code class="highlighter-rouge">Imputer</code> can handle all numeric types.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-23469">SPARK-23469</a>:
In Spark 3.0, the <code class="highlighter-rouge">HashingTF</code> Transformer uses a corrected implementation of the murmur3 hash
function to hash elements to vectors. <code class="highlighter-rouge">HashingTF</code> in Spark 3.0 will map elements to
different positions in vectors than in Spark 2. However, <code class="highlighter-rouge">HashingTF</code> created with Spark 2.x
and loaded with Spark 3.0 will still use the previous hash function and will not change behavior.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-28969">SPARK-28969</a>:
The <code class="highlighter-rouge">setClassifier</code> method in PySpark&#8217;s <code class="highlighter-rouge">OneVsRestModel</code> has been removed in 3.0 for parity with
the Scala implementation. Callers should not need to set the classifier in the model after
creation.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-25790">SPARK-25790</a>:
 PCA adds the support for more than 65535 column matrix in Spark 3.0.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-28927">SPARK-28927</a>:
 When fitting ALS model on nondeterministic input data, previously if rerun happens, users
 would see ArrayIndexOutOfBoundsException caused by mismatch between In/Out user/item blocks.
 From 3.0, a SparkException with more clear message will be thrown, and original
 ArrayIndexOutOfBoundsException is wrapped.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-29232">SPARK-29232</a>:
 In prior to 3.0 releases, <code class="highlighter-rouge">RandomForestRegressionModel</code> doesn&#8217;t update the parameter maps
 of the DecisionTreeRegressionModels underneath. This is fixed in 3.0.</li>
</ul>

<h2 id="upgrading-from-mllib-22-to-23">Upgrading from MLlib 2.2 to 2.3</h2>

<h3 class="no_toc" id="breaking-changes-1">Breaking changes</h3>

<ul>
  <li>The class and trait hierarchy for logistic regression model summaries was changed to be cleaner
and better accommodate the addition of the multi-class summary. This is a breaking change for user
code that casts a <code class="highlighter-rouge">LogisticRegressionTrainingSummary</code> to a
<code class="highlighter-rouge">BinaryLogisticRegressionTrainingSummary</code>. Users should instead use the <code class="highlighter-rouge">model.binarySummary</code>
method. See <a href="https://issues.apache.org/jira/browse/SPARK-17139">SPARK-17139</a> for more detail
(<em>note</em> this is an <code class="highlighter-rouge">Experimental</code> API). This <em>does not</em> affect the Python <code class="highlighter-rouge">summary</code> method, which
will still work correctly for both multinomial and binary cases.</li>
</ul>

<h3 class="no_toc" id="deprecations-and-changes-of-behavior-1">Deprecations and changes of behavior</h3>

<p><strong>Deprecations</strong></p>

<ul>
  <li><code class="highlighter-rouge">OneHotEncoder</code> has been deprecated and will be removed in <code class="highlighter-rouge">3.0</code>. It has been replaced by the
new <a href="ml-features.html#onehotencoderestimator"><code class="highlighter-rouge">OneHotEncoderEstimator</code></a>
(see <a href="https://issues.apache.org/jira/browse/SPARK-13030">SPARK-13030</a>). <strong>Note</strong> that
<code class="highlighter-rouge">OneHotEncoderEstimator</code> will be renamed to <code class="highlighter-rouge">OneHotEncoder</code> in <code class="highlighter-rouge">3.0</code> (but
<code class="highlighter-rouge">OneHotEncoderEstimator</code> will be kept as an alias).</li>
</ul>

<p><strong>Changes of behavior</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-21027">SPARK-21027</a>:
 The default parallelism used in <code class="highlighter-rouge">OneVsRest</code> is now set to 1 (i.e. serial). In <code class="highlighter-rouge">2.2</code> and
 earlier versions, the level of parallelism was set to the default threadpool size in Scala.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-22156">SPARK-22156</a>:
 The learning rate update for <code class="highlighter-rouge">Word2Vec</code> was incorrect when <code class="highlighter-rouge">numIterations</code> was set greater than
 <code class="highlighter-rouge">1</code>. This will cause training results to be different between <code class="highlighter-rouge">2.3</code> and earlier versions.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-21681">SPARK-21681</a>:
 Fixed an edge case bug in multinomial logistic regression that resulted in incorrect coefficients
 when some features had zero variance.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-16957">SPARK-16957</a>:
 Tree algorithms now use mid-points for split values. This may change results from model training.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14657">SPARK-14657</a>:
 Fixed an issue where the features generated by <code class="highlighter-rouge">RFormula</code> without an intercept were inconsistent
 with the output in R. This may change results from model training in this scenario.</li>
</ul>

<h2 id="upgrading-from-mllib-21-to-22">Upgrading from MLlib 2.1 to 2.2</h2>

<h3 class="no_toc" id="breaking-changes-2">Breaking changes</h3>

<p>There are no breaking changes.</p>

<h3 class="no_toc" id="deprecations-and-changes-of-behavior-2">Deprecations and changes of behavior</h3>

<p><strong>Deprecations</strong></p>

<p>There are no deprecations.</p>

<p><strong>Changes of behavior</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-19787">SPARK-19787</a>:
 Default value of <code class="highlighter-rouge">regParam</code> changed from <code class="highlighter-rouge">1.0</code> to <code class="highlighter-rouge">0.1</code> for <code class="highlighter-rouge">ALS.train</code> method (marked <code class="highlighter-rouge">DeveloperApi</code>).
 <strong>Note</strong> this does <em>not affect</em> the <code class="highlighter-rouge">ALS</code> Estimator or Model, nor MLlib&#8217;s <code class="highlighter-rouge">ALS</code> class.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14772">SPARK-14772</a>:
 Fixed inconsistency between Python and Scala APIs for <code class="highlighter-rouge">Param.copy</code> method.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11569">SPARK-11569</a>:
 <code class="highlighter-rouge">StringIndexer</code> now handles <code class="highlighter-rouge">NULL</code> values in the same way as unseen values. Previously an exception
 would always be thrown regardless of the setting of the <code class="highlighter-rouge">handleInvalid</code> parameter.</li>
</ul>

<h2 id="upgrading-from-mllib-20-to-21">Upgrading from MLlib 2.0 to 2.1</h2>

<h3 class="no_toc" id="breaking-changes-3">Breaking changes</h3>

<p><strong>Deprecated methods removed</strong></p>

<ul>
  <li><code class="highlighter-rouge">setLabelCol</code> in <code class="highlighter-rouge">feature.ChiSqSelectorModel</code></li>
  <li><code class="highlighter-rouge">numTrees</code> in <code class="highlighter-rouge">classification.RandomForestClassificationModel</code> (This now refers to the Param called <code class="highlighter-rouge">numTrees</code>)</li>
  <li><code class="highlighter-rouge">numTrees</code> in <code class="highlighter-rouge">regression.RandomForestRegressionModel</code> (This now refers to the Param called <code class="highlighter-rouge">numTrees</code>)</li>
  <li><code class="highlighter-rouge">model</code> in <code class="highlighter-rouge">regression.LinearRegressionSummary</code></li>
  <li><code class="highlighter-rouge">validateParams</code> in <code class="highlighter-rouge">PipelineStage</code></li>
  <li><code class="highlighter-rouge">validateParams</code> in <code class="highlighter-rouge">Evaluator</code></li>
</ul>

<h3 class="no_toc" id="deprecations-and-changes-of-behavior-3">Deprecations and changes of behavior</h3>

<p><strong>Deprecations</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-18592">SPARK-18592</a>:
Deprecate all Param setter methods except for input/output column Params for <code class="highlighter-rouge">DecisionTreeClassificationModel</code>, <code class="highlighter-rouge">GBTClassificationModel</code>, <code class="highlighter-rouge">RandomForestClassificationModel</code>, <code class="highlighter-rouge">DecisionTreeRegressionModel</code>, <code class="highlighter-rouge">GBTRegressionModel</code> and <code class="highlighter-rouge">RandomForestRegressionModel</code></li>
</ul>

<p><strong>Changes of behavior</strong></p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-17870">SPARK-17870</a>:
 Fix a bug of <code class="highlighter-rouge">ChiSqSelector</code> which will likely change its result. Now <code class="highlighter-rouge">ChiSquareSelector</code> use pValue rather than raw statistic to select a fixed number of top features.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-3261">SPARK-3261</a>:
 <code class="highlighter-rouge">KMeans</code> returns potentially fewer than k cluster centers in cases where k distinct centroids aren&#8217;t available or aren&#8217;t selected.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-17389">SPARK-17389</a>:
 <code class="highlighter-rouge">KMeans</code> reduces the default number of steps from 5 to 2 for the k-means|| initialization mode.</li>
</ul>

<h2 id="upgrading-from-mllib-16-to-20">Upgrading from MLlib 1.6 to 2.0</h2>

<h3 class="no_toc" id="breaking-changes-4">Breaking changes</h3>

<p>There were several breaking changes in Spark 2.0, which are outlined below.</p>

<p><strong>Linear algebra classes for DataFrame-based APIs</strong></p>

<p>Spark&#8217;s linear algebra dependencies were moved to a new project, <code class="highlighter-rouge">mllib-local</code> 
(see <a href="https://issues.apache.org/jira/browse/SPARK-13944">SPARK-13944</a>). 
As part of this change, the linear algebra classes were copied to a new package, <code class="highlighter-rouge">spark.ml.linalg</code>. 
The DataFrame-based APIs in <code class="highlighter-rouge">spark.ml</code> now depend on the <code class="highlighter-rouge">spark.ml.linalg</code> classes, 
leading to a few breaking changes, predominantly in various model classes 
(see <a href="https://issues.apache.org/jira/browse/SPARK-14810">SPARK-14810</a> for a full list).</p>

<p><strong>Note:</strong> the RDD-based APIs in <code class="highlighter-rouge">spark.mllib</code> continue to depend on the previous package <code class="highlighter-rouge">spark.mllib.linalg</code>.</p>

<p><em>Converting vectors and matrices</em></p>

<p>While most pipeline components support backward compatibility for loading, 
some existing <code class="highlighter-rouge">DataFrames</code> and pipelines in Spark versions prior to 2.0, that contain vector or matrix 
columns, may need to be migrated to the new <code class="highlighter-rouge">spark.ml</code> vector and matrix types. 
Utilities for converting <code class="highlighter-rouge">DataFrame</code> columns from <code class="highlighter-rouge">spark.mllib.linalg</code> to <code class="highlighter-rouge">spark.ml.linalg</code> types
(and vice versa) can be found in <code class="highlighter-rouge">spark.mllib.util.MLUtils</code>.</p>

<p>There are also utility methods available for converting single instances of 
vectors and matrices. Use the <code class="highlighter-rouge">asML</code> method on a <code class="highlighter-rouge">mllib.linalg.Vector</code> / <code class="highlighter-rouge">mllib.linalg.Matrix</code>
for converting to <code class="highlighter-rouge">ml.linalg</code> types, and 
<code class="highlighter-rouge">mllib.linalg.Vectors.fromML</code> / <code class="highlighter-rouge">mllib.linalg.Matrices.fromML</code> 
for converting to <code class="highlighter-rouge">mllib.linalg</code> types.</p>

<div class="codetabs">
<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="c1">// convert DataFrame columns</span>
<span class="k">val</span> <span class="nv">convertedVecDF</span> <span class="k">=</span> <span class="nv">MLUtils</span><span class="o">.</span><span class="py">convertVectorColumnsToML</span><span class="o">(</span><span class="n">vecDF</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">convertedMatrixDF</span> <span class="k">=</span> <span class="nv">MLUtils</span><span class="o">.</span><span class="py">convertMatrixColumnsToML</span><span class="o">(</span><span class="n">matrixDF</span><span class="o">)</span>
<span class="c1">// convert a single vector or matrix</span>
<span class="k">val</span> <span class="nv">mlVec</span><span class="k">:</span> <span class="kt">org.apache.spark.ml.linalg.Vector</span> <span class="o">=</span> <span class="nv">mllibVec</span><span class="o">.</span><span class="py">asML</span>
<span class="k">val</span> <span class="nv">mlMat</span><span class="k">:</span> <span class="kt">org.apache.spark.ml.linalg.Matrix</span> <span class="o">=</span> <span class="nv">mllibMat</span><span class="o">.</span><span class="py">asML</span></code></pre></figure>

    <p>Refer to the <a href="api/scala/org/apache/spark/mllib/util/MLUtils$.html"><code class="highlighter-rouge">MLUtils</code> Scala docs</a> for further detail.</p>
  </div>

<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>

<span class="c1">// convert DataFrame columns</span>
<span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">convertedVecDF</span> <span class="o">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="na">convertVectorColumnsToML</span><span class="o">(</span><span class="n">vecDF</span><span class="o">);</span>
<span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">convertedMatrixDF</span> <span class="o">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="na">convertMatrixColumnsToML</span><span class="o">(</span><span class="n">matrixDF</span><span class="o">);</span>
<span class="c1">// convert a single vector or matrix</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">ml</span><span class="o">.</span><span class="na">linalg</span><span class="o">.</span><span class="na">Vector</span> <span class="n">mlVec</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="na">asML</span><span class="o">();</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">ml</span><span class="o">.</span><span class="na">linalg</span><span class="o">.</span><span class="na">Matrix</span> <span class="n">mlMat</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="na">asML</span><span class="o">();</span></code></pre></figure>

    <p>Refer to the <a href="api/java/org/apache/spark/mllib/util/MLUtils.html"><code class="highlighter-rouge">MLUtils</code> Java docs</a> for further detail.</p>
  </div>

<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyspark.mllib.util</span> <span class="kn">import</span> <span class="n">MLUtils</span>

<span class="c1"># convert DataFrame columns
</span><span class="n">convertedVecDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="p">.</span><span class="n">convertVectorColumnsToML</span><span class="p">(</span><span class="n">vecDF</span><span class="p">)</span>
<span class="n">convertedMatrixDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="p">.</span><span class="n">convertMatrixColumnsToML</span><span class="p">(</span><span class="n">matrixDF</span><span class="p">)</span>
<span class="c1"># convert a single vector or matrix
</span><span class="n">mlVec</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="p">.</span><span class="n">asML</span><span class="p">()</span>
<span class="n">mlMat</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="p">.</span><span class="n">asML</span><span class="p">()</span></code></pre></figure>

    <p>Refer to the <a href="api/python/pyspark.mllib.html#pyspark.mllib.util.MLUtils"><code class="highlighter-rouge">MLUtils</code> Python docs</a> for further detail.</p>
  </div>
</div>

<p><strong>Deprecated methods removed</strong></p>

<p>Several deprecated methods were removed in the <code class="highlighter-rouge">spark.mllib</code> and <code class="highlighter-rouge">spark.ml</code> packages:</p>

<ul>
  <li><code class="highlighter-rouge">setScoreCol</code> in <code class="highlighter-rouge">ml.evaluation.BinaryClassificationEvaluator</code></li>
  <li><code class="highlighter-rouge">weights</code> in <code class="highlighter-rouge">LinearRegression</code> and <code class="highlighter-rouge">LogisticRegression</code> in <code class="highlighter-rouge">spark.ml</code></li>
  <li><code class="highlighter-rouge">setMaxNumIterations</code> in <code class="highlighter-rouge">mllib.optimization.LBFGS</code> (marked as <code class="highlighter-rouge">DeveloperApi</code>)</li>
  <li><code class="highlighter-rouge">treeReduce</code> and <code class="highlighter-rouge">treeAggregate</code> in <code class="highlighter-rouge">mllib.rdd.RDDFunctions</code> (these functions are available on <code class="highlighter-rouge">RDD</code>s directly, and were marked as <code class="highlighter-rouge">DeveloperApi</code>)</li>
  <li><code class="highlighter-rouge">defaultStategy</code> in <code class="highlighter-rouge">mllib.tree.configuration.Strategy</code></li>
  <li><code class="highlighter-rouge">build</code> in <code class="highlighter-rouge">mllib.tree.Node</code></li>
  <li>libsvm loaders for multiclass and load/save labeledData methods in <code class="highlighter-rouge">mllib.util.MLUtils</code></li>
</ul>

<p>A full list of breaking changes can be found at <a href="https://issues.apache.org/jira/browse/SPARK-14810">SPARK-14810</a>.</p>

<h3 class="no_toc" id="deprecations-and-changes-of-behavior-4">Deprecations and changes of behavior</h3>

<p><strong>Deprecations</strong></p>

<p>Deprecations in the <code class="highlighter-rouge">spark.mllib</code> and <code class="highlighter-rouge">spark.ml</code> packages include:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14984">SPARK-14984</a>:
 In <code class="highlighter-rouge">spark.ml.regression.LinearRegressionSummary</code>, the <code class="highlighter-rouge">model</code> field has been deprecated.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13784">SPARK-13784</a>:
 In <code class="highlighter-rouge">spark.ml.regression.RandomForestRegressionModel</code> and <code class="highlighter-rouge">spark.ml.classification.RandomForestClassificationModel</code>,
 the <code class="highlighter-rouge">numTrees</code> parameter has been deprecated in favor of <code class="highlighter-rouge">getNumTrees</code> method.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13761">SPARK-13761</a>:
 In <code class="highlighter-rouge">spark.ml.param.Params</code>, the <code class="highlighter-rouge">validateParams</code> method has been deprecated.
 We move all functionality in overridden methods to the corresponding <code class="highlighter-rouge">transformSchema</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14829">SPARK-14829</a>:
 In <code class="highlighter-rouge">spark.mllib</code> package, <code class="highlighter-rouge">LinearRegressionWithSGD</code>, <code class="highlighter-rouge">LassoWithSGD</code>, <code class="highlighter-rouge">RidgeRegressionWithSGD</code> and <code class="highlighter-rouge">LogisticRegressionWithSGD</code> have been deprecated.
 We encourage users to use <code class="highlighter-rouge">spark.ml.regression.LinearRegression</code> and <code class="highlighter-rouge">spark.ml.classification.LogisticRegression</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14900">SPARK-14900</a>:
 In <code class="highlighter-rouge">spark.mllib.evaluation.MulticlassMetrics</code>, the parameters <code class="highlighter-rouge">precision</code>, <code class="highlighter-rouge">recall</code> and <code class="highlighter-rouge">fMeasure</code> have been deprecated in favor of <code class="highlighter-rouge">accuracy</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-15644">SPARK-15644</a>:
 In <code class="highlighter-rouge">spark.ml.util.MLReader</code> and <code class="highlighter-rouge">spark.ml.util.MLWriter</code>, the <code class="highlighter-rouge">context</code> method has been deprecated in favor of <code class="highlighter-rouge">session</code>.</li>
  <li>In <code class="highlighter-rouge">spark.ml.feature.ChiSqSelectorModel</code>, the <code class="highlighter-rouge">setLabelCol</code> method has been deprecated since it was not used by <code class="highlighter-rouge">ChiSqSelectorModel</code>.</li>
</ul>

<p><strong>Changes of behavior</strong></p>

<p>Changes of behavior in the <code class="highlighter-rouge">spark.mllib</code> and <code class="highlighter-rouge">spark.ml</code> packages include:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-7780">SPARK-7780</a>:
 <code class="highlighter-rouge">spark.mllib.classification.LogisticRegressionWithLBFGS</code> directly calls <code class="highlighter-rouge">spark.ml.classification.LogisticRegression</code> for binary classification now.
 This will introduce the following behavior changes for <code class="highlighter-rouge">spark.mllib.classification.LogisticRegressionWithLBFGS</code>:
    <ul>
      <li>The intercept will not be regularized when training binary classification model with L1/L2 Updater.</li>
      <li>If users set without regularization, training with or without feature scaling will return the same solution by the same convergence rate.</li>
    </ul>
  </li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13429">SPARK-13429</a>:
 In order to provide better and consistent result with <code class="highlighter-rouge">spark.ml.classification.LogisticRegression</code>,
 the default value of <code class="highlighter-rouge">spark.mllib.classification.LogisticRegressionWithLBFGS</code>: <code class="highlighter-rouge">convergenceTol</code> has been changed from 1E-4 to 1E-6.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-12363">SPARK-12363</a>:
 Fix a bug of <code class="highlighter-rouge">PowerIterationClustering</code> which will likely change its result.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13048">SPARK-13048</a>:
 <code class="highlighter-rouge">LDA</code> using the <code class="highlighter-rouge">EM</code> optimizer will keep the last checkpoint by default, if checkpointing is being used.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-12153">SPARK-12153</a>:
 <code class="highlighter-rouge">Word2Vec</code> now respects sentence boundaries. Previously, it did not handle them correctly.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10574">SPARK-10574</a>:
 <code class="highlighter-rouge">HashingTF</code> uses <code class="highlighter-rouge">MurmurHash3</code> as default hash algorithm in both <code class="highlighter-rouge">spark.ml</code> and <code class="highlighter-rouge">spark.mllib</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14768">SPARK-14768</a>:
 The <code class="highlighter-rouge">expectedType</code> argument for PySpark <code class="highlighter-rouge">Param</code> was removed.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14931">SPARK-14931</a>:
 Some default <code class="highlighter-rouge">Param</code> values, which were mismatched between pipelines in Scala and Python, have been changed.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13600">SPARK-13600</a>:
 <code class="highlighter-rouge">QuantileDiscretizer</code> now uses <code class="highlighter-rouge">spark.sql.DataFrameStatFunctions.approxQuantile</code> to find splits (previously used custom sampling logic).
 The output buckets will differ for same input data and params.</li>
</ul>

<h2 id="upgrading-from-mllib-15-to-16">Upgrading from MLlib 1.5 to 1.6</h2>

<p>There are no breaking API changes in the <code class="highlighter-rouge">spark.mllib</code> or <code class="highlighter-rouge">spark.ml</code> packages, but there are
deprecations and changes of behavior.</p>

<p>Deprecations:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11358">SPARK-11358</a>:
 In <code class="highlighter-rouge">spark.mllib.clustering.KMeans</code>, the <code class="highlighter-rouge">runs</code> parameter has been deprecated.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10592">SPARK-10592</a>:
 In <code class="highlighter-rouge">spark.ml.classification.LogisticRegressionModel</code> and
 <code class="highlighter-rouge">spark.ml.regression.LinearRegressionModel</code>, the <code class="highlighter-rouge">weights</code> field has been deprecated in favor of
 the new name <code class="highlighter-rouge">coefficients</code>.  This helps disambiguate from instance (row) &#8220;weights&#8221; given to
 algorithms.</li>
</ul>

<p>Changes of behavior:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-7770">SPARK-7770</a>:
 <code class="highlighter-rouge">spark.mllib.tree.GradientBoostedTrees</code>: <code class="highlighter-rouge">validationTol</code> has changed semantics in 1.6.
 Previously, it was a threshold for absolute change in error. Now, it resembles the behavior of
 <code class="highlighter-rouge">GradientDescent</code>&#8217;s <code class="highlighter-rouge">convergenceTol</code>: For large errors, it uses relative error (relative to the
 previous error); for small errors (<code class="highlighter-rouge">&lt; 0.01</code>), it uses absolute error.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11069">SPARK-11069</a>:
 <code class="highlighter-rouge">spark.ml.feature.RegexTokenizer</code>: Previously, it did not convert strings to lowercase before
 tokenizing. Now, it converts to lowercase by default, with an option not to. This matches the
 behavior of the simpler <code class="highlighter-rouge">Tokenizer</code> transformer.</li>
</ul>

<h2 id="upgrading-from-mllib-14-to-15">Upgrading from MLlib 1.4 to 1.5</h2>

<p>In the <code class="highlighter-rouge">spark.mllib</code> package, there are no breaking API changes but several behavior changes:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-9005">SPARK-9005</a>:
<code class="highlighter-rouge">RegressionMetrics.explainedVariance</code> returns the average regression sum of squares.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-8600">SPARK-8600</a>: <code class="highlighter-rouge">NaiveBayesModel.labels</code> become
sorted.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-3382">SPARK-3382</a>: <code class="highlighter-rouge">GradientDescent</code> has a default
convergence tolerance <code class="highlighter-rouge">1e-3</code>, and hence iterations might end earlier than 1.4.</li>
</ul>

<p>In the <code class="highlighter-rouge">spark.ml</code> package, there exists one breaking API change and one behavior change:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-9268">SPARK-9268</a>: Java&#8217;s varargs support is removed
from <code class="highlighter-rouge">Params.setDefault</code> due to a
<a href="https://issues.scala-lang.org/browse/SI-9013">Scala compiler bug</a>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10097">SPARK-10097</a>: <code class="highlighter-rouge">Evaluator.isLargerBetter</code> is
added to indicate metric ordering. Metrics like RMSE no longer flip signs as in 1.4.</li>
</ul>

<h2 id="upgrading-from-mllib-13-to-14">Upgrading from MLlib 1.3 to 1.4</h2>

<p>In the <code class="highlighter-rouge">spark.mllib</code> package, there were several breaking changes, but all in <code class="highlighter-rouge">DeveloperApi</code> or <code class="highlighter-rouge">Experimental</code> APIs:</p>

<ul>
  <li>Gradient-Boosted Trees
    <ul>
      <li><em>(Breaking change)</em> The signature of the <a href="api/scala/org/apache/spark/mllib/tree/loss/Loss.html"><code class="highlighter-rouge">Loss.gradient</code></a> method was changed.  This is only an issues for users who wrote their own losses for GBTs.</li>
      <li><em>(Breaking change)</em> The <code class="highlighter-rouge">apply</code> and <code class="highlighter-rouge">copy</code> methods for the case class <a href="api/scala/org/apache/spark/mllib/tree/configuration/BoostingStrategy.html"><code class="highlighter-rouge">BoostingStrategy</code></a> have been changed because of a modification to the case class fields.  This could be an issue for users who use <code class="highlighter-rouge">BoostingStrategy</code> to set GBT parameters.</li>
    </ul>
  </li>
  <li><em>(Breaking change)</em> The return value of <a href="api/scala/org/apache/spark/mllib/clustering/LDA.html"><code class="highlighter-rouge">LDA.run</code></a> has changed.  It now returns an abstract class <code class="highlighter-rouge">LDAModel</code> instead of the concrete class <code class="highlighter-rouge">DistributedLDAModel</code>.  The object of type <code class="highlighter-rouge">LDAModel</code> can still be cast to the appropriate concrete type, which depends on the optimization algorithm.</li>
</ul>

<p>In the <code class="highlighter-rouge">spark.ml</code> package, several major API changes occurred, including:</p>

<ul>
  <li><code class="highlighter-rouge">Param</code> and other APIs for specifying parameters</li>
  <li><code class="highlighter-rouge">uid</code> unique IDs for Pipeline components</li>
  <li>Reorganization of certain classes</li>
</ul>

<p>Since the <code class="highlighter-rouge">spark.ml</code> API was an alpha component in Spark 1.3, we do not list all changes here.
However, since 1.4 <code class="highlighter-rouge">spark.ml</code> is no longer an alpha component, we will provide details on any API
changes for future releases.</p>

<h2 id="upgrading-from-mllib-12-to-13">Upgrading from MLlib 1.2 to 1.3</h2>

<p>In the <code class="highlighter-rouge">spark.mllib</code> package, there were several breaking changes.  The first change (in <code class="highlighter-rouge">ALS</code>) is the only one in a component not marked as Alpha or Experimental.</p>

<ul>
  <li><em>(Breaking change)</em> In <a href="api/scala/org/apache/spark/mllib/recommendation/ALS.html"><code class="highlighter-rouge">ALS</code></a>, the extraneous method <code class="highlighter-rouge">solveLeastSquares</code> has been removed.  The <code class="highlighter-rouge">DeveloperApi</code> method <code class="highlighter-rouge">analyzeBlocks</code> was also removed.</li>
  <li><em>(Breaking change)</em> <a href="api/scala/org/apache/spark/mllib/feature/StandardScalerModel.html"><code class="highlighter-rouge">StandardScalerModel</code></a> remains an Alpha component. In it, the <code class="highlighter-rouge">variance</code> method has been replaced with the <code class="highlighter-rouge">std</code> method.  To compute the column variance values returned by the original <code class="highlighter-rouge">variance</code> method, simply square the standard deviation values returned by <code class="highlighter-rouge">std</code>.</li>
  <li><em>(Breaking change)</em> <a href="api/scala/org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html"><code class="highlighter-rouge">StreamingLinearRegressionWithSGD</code></a> remains an Experimental component.  In it, there were two changes:
    <ul>
      <li>The constructor taking arguments was removed in favor of a builder pattern using the default constructor plus parameter setter methods.</li>
      <li>Variable <code class="highlighter-rouge">model</code> is no longer public.</li>
    </ul>
  </li>
  <li><em>(Breaking change)</em> <a href="api/scala/org/apache/spark/mllib/tree/DecisionTree.html"><code class="highlighter-rouge">DecisionTree</code></a> remains an Experimental component.  In it and its associated classes, there were several changes:
    <ul>
      <li>In <code class="highlighter-rouge">DecisionTree</code>, the deprecated class method <code class="highlighter-rouge">train</code> has been removed.  (The object/static <code class="highlighter-rouge">train</code> methods remain.)</li>
      <li>In <code class="highlighter-rouge">Strategy</code>, the <code class="highlighter-rouge">checkpointDir</code> parameter has been removed.  Checkpointing is still supported, but the checkpoint directory must be set before calling tree and tree ensemble training.</li>
    </ul>
  </li>
  <li><code class="highlighter-rouge">PythonMLlibAPI</code> (the interface between Scala/Java and Python for MLlib) was a public API but is now private, declared <code class="highlighter-rouge">private[python]</code>.  This was never meant for external use.</li>
  <li>In linear regression (including Lasso and ridge regression), the squared loss is now divided by 2.
So in order to produce the same result as in 1.2, the regularization parameter needs to be divided by 2 and the step size needs to be multiplied by 2.</li>
</ul>

<p>In the <code class="highlighter-rouge">spark.ml</code> package, the main API changes are from Spark SQL.  We list the most important changes here:</p>

<ul>
  <li>The old <a href="https://spark.apache.org/docs/1.2.1/api/scala/index.html#org.apache.spark.sql.SchemaRDD">SchemaRDD</a> has been replaced with <a href="api/scala/org/apache/spark/sql/DataFrame.html">DataFrame</a> with a somewhat modified API.  All algorithms in <code class="highlighter-rouge">spark.ml</code> which used to use SchemaRDD now use DataFrame.</li>
  <li>In Spark 1.2, we used implicit conversions from <code class="highlighter-rouge">RDD</code>s of <code class="highlighter-rouge">LabeledPoint</code> into <code class="highlighter-rouge">SchemaRDD</code>s by calling <code class="highlighter-rouge">import sqlContext._</code> where <code class="highlighter-rouge">sqlContext</code> was an instance of <code class="highlighter-rouge">SQLContext</code>.  These implicits have been moved, so we now call <code class="highlighter-rouge">import sqlContext.implicits._</code>.</li>
  <li>Java APIs for SQL have also changed accordingly.  Please see the examples above and the <a href="sql-programming-guide.html">Spark SQL Programming Guide</a> for details.</li>
</ul>

<p>Other changes were in <code class="highlighter-rouge">LogisticRegression</code>:</p>

<ul>
  <li>The <code class="highlighter-rouge">scoreCol</code> output column (with default value &#8220;score&#8221;) was renamed to be <code class="highlighter-rouge">probabilityCol</code> (with default value &#8220;probability&#8221;).  The type was originally <code class="highlighter-rouge">Double</code> (for the probability of class 1.0), but it is now <code class="highlighter-rouge">Vector</code> (for the probability of each class, to support multiclass classification in the future).</li>
  <li>In Spark 1.2, <code class="highlighter-rouge">LogisticRegressionModel</code> did not include an intercept.  In Spark 1.3, it includes an intercept; however, it will always be 0.0 since it uses the default settings for <a href="api/scala/org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html">spark.mllib.LogisticRegressionWithLBFGS</a>.  The option to use an intercept will be added in the future.</li>
</ul>

<h2 id="upgrading-from-mllib-11-to-12">Upgrading from MLlib 1.1 to 1.2</h2>

<p>The only API changes in MLlib v1.2 are in
<a href="api/scala/org/apache/spark/mllib/tree/DecisionTree.html"><code class="highlighter-rouge">DecisionTree</code></a>,
which continues to be an experimental API in MLlib 1.2:</p>

<ol>
  <li>
    <p><em>(Breaking change)</em> The Scala API for classification takes a named argument specifying the number
of classes.  In MLlib v1.1, this argument was called <code class="highlighter-rouge">numClasses</code> in Python and
<code class="highlighter-rouge">numClassesForClassification</code> in Scala.  In MLlib v1.2, the names are both set to <code class="highlighter-rouge">numClasses</code>.
This <code class="highlighter-rouge">numClasses</code> parameter is specified either via
<a href="api/scala/org/apache/spark/mllib/tree/configuration/Strategy.html"><code class="highlighter-rouge">Strategy</code></a>
or via <a href="api/scala/org/apache/spark/mllib/tree/DecisionTree.html"><code class="highlighter-rouge">DecisionTree</code></a>
static <code class="highlighter-rouge">trainClassifier</code> and <code class="highlighter-rouge">trainRegressor</code> methods.</p>
  </li>
  <li>
    <p><em>(Breaking change)</em> The API for
<a href="api/scala/org/apache/spark/mllib/tree/model/Node.html"><code class="highlighter-rouge">Node</code></a> has changed.
This should generally not affect user code, unless the user manually constructs decision trees
(instead of using the <code class="highlighter-rouge">trainClassifier</code> or <code class="highlighter-rouge">trainRegressor</code> methods).
The tree <code class="highlighter-rouge">Node</code> now includes more information, including the probability of the predicted label
(for classification).</p>
  </li>
  <li>
    <p>Printing methods&#8217; output has changed.  The <code class="highlighter-rouge">toString</code> (Scala/Java) and <code class="highlighter-rouge">__repr__</code> (Python) methods used to print the full model; they now print a summary.  For the full model, use <code class="highlighter-rouge">toDebugString</code>.</p>
  </li>
</ol>

<p>Examples in the Spark distribution and examples in the
<a href="mllib-decision-tree.html#examples">Decision Trees Guide</a> have been updated accordingly.</p>

<h2 id="upgrading-from-mllib-10-to-11">Upgrading from MLlib 1.0 to 1.1</h2>

<p>The only API changes in MLlib v1.1 are in
<a href="api/scala/org/apache/spark/mllib/tree/DecisionTree.html"><code class="highlighter-rouge">DecisionTree</code></a>,
which continues to be an experimental API in MLlib 1.1:</p>

<ol>
  <li>
    <p><em>(Breaking change)</em> The meaning of tree depth has been changed by 1 in order to match
the implementations of trees in
<a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree">scikit-learn</a>
and in <a href="http://cran.r-project.org/web/packages/rpart/index.html">rpart</a>.
In MLlib v1.0, a depth-1 tree had 1 leaf node, and a depth-2 tree had 1 root node and 2 leaf nodes.
In MLlib v1.1, a depth-0 tree has 1 leaf node, and a depth-1 tree has 1 root node and 2 leaf nodes.
This depth is specified by the <code class="highlighter-rouge">maxDepth</code> parameter in
<a href="api/scala/org/apache/spark/mllib/tree/configuration/Strategy.html"><code class="highlighter-rouge">Strategy</code></a>
or via <a href="api/scala/org/apache/spark/mllib/tree/DecisionTree.html"><code class="highlighter-rouge">DecisionTree</code></a>
static <code class="highlighter-rouge">trainClassifier</code> and <code class="highlighter-rouge">trainRegressor</code> methods.</p>
  </li>
  <li>
    <p><em>(Non-breaking change)</em> We recommend using the newly added <code class="highlighter-rouge">trainClassifier</code> and <code class="highlighter-rouge">trainRegressor</code>
methods to build a <a href="api/scala/org/apache/spark/mllib/tree/DecisionTree.html"><code class="highlighter-rouge">DecisionTree</code></a>,
rather than using the old parameter class <code class="highlighter-rouge">Strategy</code>.  These new training methods explicitly
separate classification and regression, and they replace specialized parameter types with
simple <code class="highlighter-rouge">String</code> types.</p>
  </li>
</ol>

<p>Examples of the new recommended <code class="highlighter-rouge">trainClassifier</code> and <code class="highlighter-rouge">trainRegressor</code> are given in the
<a href="mllib-decision-tree.html#examples">Decision Trees Guide</a>.</p>

<h2 id="upgrading-from-mllib-09-to-10">Upgrading from MLlib 0.9 to 1.0</h2>

<p>In MLlib v1.0, we support both dense and sparse input in a unified way, which introduces a few
breaking changes.  If your data is sparse, please store it in a sparse format instead of dense to
take advantage of sparsity in both storage and computation. Details are described below.</p>



                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-3.4.1.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    </body>
</html>
