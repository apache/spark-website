
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>pyspark.pandas.sql_formatter &#8212; PySpark master documentation</title>
    
    <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="../../../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/pyspark.css" />
    
    <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/_modules/pyspark/pandas/sql_formatter.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/spark-logo-reverse.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../index.html">
  Overview
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../user_guide/index.html">
  User Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../development/index.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../migration_guide/index.html">
  Migration Guides
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<div id="version-button" class="dropdown">
    <button type="button" class="btn btn-secondary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        master
        <span class="caret"></span>
    </button>
    <div id="version_switcher" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<script type="text/javascript">
// Function to construct the target URL from the JSON components
function buildURL(entry) {
    var template = "https://spark.apache.org/docs/{version}/api/python/index.html";  // supplied by jinja
    template = template.replace("{version}", entry.version);
    return template;
}

// Function to check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "_modules/pyspark/pandas/sql_formatter.html",
          otherDocsHomepage = event.target.getAttribute("href");
    let tryUrl = `${otherDocsHomepage}${currentFilePath}`;
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    return false;
}

// Function to populate the version switcher
(function () {
    // get JSON config
    $.getJSON("_static/versions.json", function(data, textStatus, jqXHR) {
        // create the nodes first (before AJAX calls) to ensure the order is
        // correct (for now, links will go to doc version homepage)
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // construct the appropriate URL, and add it to the dropdown
            entry.url = buildURL(entry);
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.setAttribute("href", `${entry.url}`);
            node.textContent = `${entry.name}`;
            node.onclick = checkPageExistsAndRedirect;
            $("#version_switcher").append(node);
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for pyspark.pandas.sql_formatter</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c1"># contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c1"># this work for additional information regarding copyright ownership.</span>
<span class="c1"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c1"># (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c1"># the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">from</span> <span class="nn">pyspark.pandas.internal</span> <span class="kn">import</span> <span class="n">InternalFrame</span>
<span class="kn">from</span> <span class="nn">pyspark.pandas.namespace</span> <span class="kn">import</span> <span class="n">_get_index_map</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">ps</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">pyspark.pandas.utils</span> <span class="kn">import</span> <span class="n">default_session</span>
<span class="kn">from</span> <span class="nn">pyspark.pandas.frame</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">pyspark.pandas.series</span> <span class="kn">import</span> <span class="n">Series</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sql&quot;</span><span class="p">]</span>


<span class="c1"># This is not used in this file. It&#39;s for legacy sql_processor.</span>
<span class="n">_CAPTURE_SCOPES</span> <span class="o">=</span> <span class="mi">3</span>


<div class="viewcode-block" id="sql"><a class="viewcode-back" href="../../../reference/pyspark.pandas/api/pyspark.pandas.sql.html#pyspark.pandas.sql">[docs]</a><span class="k">def</span> <span class="nf">sql</span><span class="p">(</span>
    <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">index_col</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Execute a SQL query and return the result as a pandas-on-Spark DataFrame.</span>

<span class="sd">    This function acts as a standard Python string formatter with understanding</span>
<span class="sd">    the following variable types:</span>

<span class="sd">        * pandas-on-Spark DataFrame</span>
<span class="sd">        * pandas-on-Spark Series</span>
<span class="sd">        * pandas DataFrame</span>
<span class="sd">        * pandas Series</span>
<span class="sd">        * string</span>

<span class="sd">    Also the method can bind named parameters to SQL literals from `args`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    query : str</span>
<span class="sd">        the SQL query</span>
<span class="sd">    index_col : str or list of str, optional</span>
<span class="sd">        Column names to be used in Spark to represent pandas-on-Spark&#39;s index. The index name</span>
<span class="sd">        in pandas-on-Spark is ignored. By default, the index is always lost.</span>

<span class="sd">        .. note:: If you want to preserve the index, explicitly use :func:`DataFrame.reset_index`,</span>
<span class="sd">            and pass it to the SQL statement with `index_col` parameter.</span>

<span class="sd">            For example,</span>

<span class="sd">            &gt;&gt;&gt; psdf = ps.DataFrame({&quot;A&quot;: [1, 2, 3], &quot;B&quot;:[4, 5, 6]}, index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])</span>
<span class="sd">            &gt;&gt;&gt; new_psdf = psdf.reset_index()</span>
<span class="sd">            &gt;&gt;&gt; ps.sql(&quot;SELECT * FROM {new_psdf}&quot;, index_col=&quot;index&quot;, new_psdf=new_psdf)</span>
<span class="sd">            ... # doctest: +NORMALIZE_WHITESPACE</span>
<span class="sd">                   A  B</span>
<span class="sd">            index</span>
<span class="sd">            a      1  4</span>
<span class="sd">            b      2  5</span>
<span class="sd">            c      3  6</span>

<span class="sd">            For MultiIndex,</span>

<span class="sd">            &gt;&gt;&gt; psdf = ps.DataFrame(</span>
<span class="sd">            ...     {&quot;A&quot;: [1, 2, 3], &quot;B&quot;: [4, 5, 6]},</span>
<span class="sd">            ...     index=pd.MultiIndex.from_tuples(</span>
<span class="sd">            ...         [(&quot;a&quot;, &quot;b&quot;), (&quot;c&quot;, &quot;d&quot;), (&quot;e&quot;, &quot;f&quot;)], names=[&quot;index1&quot;, &quot;index2&quot;]</span>
<span class="sd">            ...     ),</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; new_psdf = psdf.reset_index()</span>
<span class="sd">            &gt;&gt;&gt; ps.sql(</span>
<span class="sd">            ...     &quot;SELECT * FROM {new_psdf}&quot;, index_col=[&quot;index1&quot;, &quot;index2&quot;], new_psdf=new_psdf)</span>
<span class="sd">            ... # doctest: +NORMALIZE_WHITESPACE</span>
<span class="sd">                           A  B</span>
<span class="sd">            index1 index2</span>
<span class="sd">            a      b       1  4</span>
<span class="sd">            c      d       2  5</span>
<span class="sd">            e      f       3  6</span>

<span class="sd">            Also note that the index name(s) should be matched to the existing name.</span>
<span class="sd">    args : dict or list</span>
<span class="sd">        A dictionary of parameter names to Python objects or a list of Python objects</span>
<span class="sd">        that can be converted to SQL literal expressions. See</span>
<span class="sd">        &lt;a href=&quot;https://spark.apache.org/docs/latest/sql-ref-datatypes.html&quot;&gt;</span>
<span class="sd">        Supported Data Types&lt;/a&gt; for supported value types in Python.</span>
<span class="sd">        For example, dictionary keys: &quot;rank&quot;, &quot;name&quot;, &quot;birthdate&quot;;</span>
<span class="sd">        dictionary values: 1, &quot;Steven&quot;, datetime.date(2023, 4, 2).</span>
<span class="sd">        A value can be also a `Column` of literal expression, in that case it is taken as is.</span>


<span class="sd">        .. versionadded:: 3.4.0</span>

<span class="sd">        .. versionchanged:: 3.5.0</span>
<span class="sd">            Added positional parameters.</span>

<span class="sd">    kwargs</span>
<span class="sd">        other variables that the user want to set that can be referenced in the query</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pandas-on-Spark DataFrame</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    Calling a built-in SQL function.</span>

<span class="sd">    &gt;&gt;&gt; ps.sql(&quot;SELECT * FROM range(10) where id &gt; 7&quot;)</span>
<span class="sd">       id</span>
<span class="sd">    0   8</span>
<span class="sd">    1   9</span>

<span class="sd">    &gt;&gt;&gt; ps.sql(&quot;SELECT * FROM range(10) WHERE id &gt; {bound1} AND id &lt; {bound2}&quot;, bound1=7, bound2=9)</span>
<span class="sd">       id</span>
<span class="sd">    0   8</span>

<span class="sd">    &gt;&gt;&gt; mydf = ps.range(10)</span>
<span class="sd">    &gt;&gt;&gt; x = tuple(range(4))</span>
<span class="sd">    &gt;&gt;&gt; ps.sql(&quot;SELECT {ser} FROM {mydf} WHERE id IN {x}&quot;, ser=mydf.id, mydf=mydf, x=x)</span>
<span class="sd">       id</span>
<span class="sd">    0   0</span>
<span class="sd">    1   1</span>
<span class="sd">    2   2</span>
<span class="sd">    3   3</span>

<span class="sd">    Mixing pandas-on-Spark and pandas DataFrames in a join operation. Note that the index is</span>
<span class="sd">    dropped.</span>

<span class="sd">    &gt;&gt;&gt; ps.sql(&#39;&#39;&#39;</span>
<span class="sd">    ...   SELECT m1.a, m2.b</span>
<span class="sd">    ...   FROM {table1} m1 INNER JOIN {table2} m2</span>
<span class="sd">    ...   ON m1.key = m2.key</span>
<span class="sd">    ...   ORDER BY m1.a, m2.b&#39;&#39;&#39;,</span>
<span class="sd">    ...   table1=ps.DataFrame({&quot;a&quot;: [1,2], &quot;key&quot;: [&quot;a&quot;, &quot;b&quot;]}),</span>
<span class="sd">    ...   table2=pd.DataFrame({&quot;b&quot;: [3,4,5], &quot;key&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;]}))</span>
<span class="sd">       a  b</span>
<span class="sd">    0  1  3</span>
<span class="sd">    1  2  4</span>
<span class="sd">    2  2  5</span>

<span class="sd">    Also, it is possible to query using Series.</span>

<span class="sd">    &gt;&gt;&gt; psdf = ps.DataFrame({&quot;A&quot;: [1, 2, 3], &quot;B&quot;:[4, 5, 6]}, index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; ps.sql(&quot;SELECT {mydf.A} FROM {mydf}&quot;, mydf=psdf)</span>
<span class="sd">       A</span>
<span class="sd">    0  1</span>
<span class="sd">    1  2</span>
<span class="sd">    2  3</span>

<span class="sd">    And substitude named parameters with the `:` prefix by SQL literals.</span>

<span class="sd">    &gt;&gt;&gt; ps.sql(&quot;SELECT * FROM range(10) WHERE id &gt; :bound1&quot;, args={&quot;bound1&quot;:7})</span>
<span class="sd">       id</span>
<span class="sd">    0   8</span>
<span class="sd">    1   9</span>

<span class="sd">    Or positional parameters marked by `?` in the SQL query by SQL literals.</span>

<span class="sd">    &gt;&gt;&gt; ps.sql(&quot;SELECT * FROM range(10) WHERE id &gt; ?&quot;, args=[7])</span>
<span class="sd">       id</span>
<span class="sd">    0   8</span>
<span class="sd">    1   9</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PYSPARK_PANDAS_SQL_LEGACY&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;1&quot;</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyspark.pandas</span> <span class="kn">import</span> <span class="n">sql_processor</span>

        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Deprecated in 3.3.0, and the legacy behavior &quot;</span>
            <span class="s2">&quot;will be removed in the future releases.&quot;</span><span class="p">,</span>
            <span class="ne">FutureWarning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">sql_processor</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="n">index_col</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">session</span> <span class="o">=</span> <span class="n">default_session</span><span class="p">()</span>
    <span class="n">formatter</span> <span class="o">=</span> <span class="n">PandasSQLStringFormatter</span><span class="p">(</span><span class="n">session</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">sdf</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="n">formatter</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">args</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">formatter</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="n">index_spark_columns</span><span class="p">,</span> <span class="n">index_names</span> <span class="o">=</span> <span class="n">_get_index_map</span><span class="p">(</span><span class="n">sdf</span><span class="p">,</span> <span class="n">index_col</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">InternalFrame</span><span class="p">(</span>
            <span class="n">spark_frame</span><span class="o">=</span><span class="n">sdf</span><span class="p">,</span> <span class="n">index_spark_columns</span><span class="o">=</span><span class="n">index_spark_columns</span><span class="p">,</span> <span class="n">index_names</span><span class="o">=</span><span class="n">index_names</span>
        <span class="p">)</span>
    <span class="p">)</span></div>


<span class="k">class</span> <span class="nc">PandasSQLStringFormatter</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">Formatter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A standard ``string.Formatter`` in Python that can understand pandas-on-Spark instances</span>
<span class="sd">    with basic Python objects. This object must be clear after the use for single SQL</span>
<span class="sd">    query; cannot be reused across multiple SQL queries without cleaning.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">:</span> <span class="n">SparkSession</span> <span class="o">=</span> <span class="n">session</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_temp_views</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">DataFrame</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ref_sers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Series</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">vformat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">format_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PandasSQLStringFormatter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">vformat</span><span class="p">(</span><span class="n">format_string</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ref</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ref_sers</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">((</span><span class="n">ref</span> <span class="ow">is</span> <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">_pssers</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="k">for</span> <span class="n">df</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_temp_views</span><span class="p">):</span>
                <span class="c1"># If referred DataFrame does not hold the given Series, raise an error.</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The series in {</span><span class="si">%s</span><span class="s2">} does not refer any dataframe specified.&quot;</span> <span class="o">%</span> <span class="n">n</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">def</span> <span class="nf">get_field</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">field_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">obj</span><span class="p">,</span> <span class="n">first</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PandasSQLStringFormatter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">get_field</span><span class="p">(</span><span class="n">field_name</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_value</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">field_name</span><span class="p">),</span> <span class="n">first</span>

    <span class="k">def</span> <span class="nf">_convert_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Converts the given value into a SQL string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="c1"># Return the column name from pandas Series directly.</span>
            <span class="k">return</span> <span class="n">ps</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span><span class="o">.</span><span class="n">_to_spark</span><span class="p">()</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">Series</span><span class="p">):</span>
            <span class="c1"># Return the column name of pandas-on-Spark Series iff its DataFrame was</span>
            <span class="c1"># referred. The check will be done in `vformat` after we parse all.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ref_sers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">val</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">val</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span><span class="o">.</span><span class="n">_to_spark</span><span class="p">()</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="p">(</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)):</span>
            <span class="n">df_name</span> <span class="o">=</span> <span class="s2">&quot;_pandas_api_</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="c1"># Don&#39;t store temp view for plain pandas instances</span>
                <span class="c1"># because it is unable to know which pandas DataFrame</span>
                <span class="c1"># holds which Series.</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">df</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_temp_views</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">df</span> <span class="ow">is</span> <span class="n">val</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">n</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_temp_views</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">val</span><span class="p">,</span> <span class="n">df_name</span><span class="p">))</span>

            <span class="n">val</span><span class="o">.</span><span class="n">_to_spark</span><span class="p">()</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="n">df_name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">df_name</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="c1"># This is matched to behavior from JVM implementation.</span>
            <span class="c1"># See `sql` definition from `sql/catalyst/src/main/scala/org/apache/spark/</span>
            <span class="c1"># sql/catalyst/expressions/literals.scala`</span>
            <span class="k">return</span> <span class="s2">&quot;&#39;&quot;</span> <span class="o">+</span> <span class="n">val</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\\\\</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&#39;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;&#39;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">val</span>

    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_temp_views</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">dropTempView</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_temp_views</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ref_sers</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">def</span> <span class="nf">_test</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
    <span class="kn">import</span> <span class="nn">pyspark.pandas.sql_formatter</span>

    <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;SPARK_HOME&quot;</span><span class="p">])</span>

    <span class="n">globs</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">pandas</span><span class="o">.</span><span class="n">sql_formatter</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">globs</span><span class="p">[</span><span class="s2">&quot;ps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">pandas</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[4]&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;pyspark.pandas.sql_formatter tests&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">failure_count</span><span class="p">,</span> <span class="n">test_count</span><span class="p">)</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">(</span>
        <span class="n">pyspark</span><span class="o">.</span><span class="n">pandas</span><span class="o">.</span><span class="n">sql_formatter</span><span class="p">,</span>
        <span class="n">globs</span><span class="o">=</span><span class="n">globs</span><span class="p">,</span>
        <span class="n">optionflags</span><span class="o">=</span><span class="n">doctest</span><span class="o">.</span><span class="n">ELLIPSIS</span> <span class="o">|</span> <span class="n">doctest</span><span class="o">.</span><span class="n">NORMALIZE_WHITESPACE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">failure_count</span><span class="p">:</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">_test</span><span class="p">()</span>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright .<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>