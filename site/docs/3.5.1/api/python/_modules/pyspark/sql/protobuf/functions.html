
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>pyspark.sql.protobuf.functions &#8212; PySpark 3.5.2-SNAPSHOT documentation</title>
    
    <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="../../../../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/pyspark.css" />
    
    <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/language_data.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/protobuf/functions.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/spark-logo-reverse.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../index.html">
  Overview
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../user_guide/index.html">
  User Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../development/index.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../migration_guide/index.html">
  Migration Guides
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<div id="version-button" class="dropdown">
    <button type="button" class="btn btn-secondary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        3.5.2-SNAPSHOT
        <span class="caret"></span>
    </button>
    <div id="version_switcher" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<script type="text/javascript">
// Function to construct the target URL from the JSON components
function buildURL(entry) {
    var template = "https://spark.apache.org/docs/{version}/api/python/index.html";  // supplied by jinja
    template = template.replace("{version}", entry.version);
    return template;
}

// Function to check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "_modules/pyspark/sql/protobuf/functions.html",
          otherDocsHomepage = event.target.getAttribute("href");
    let tryUrl = `${otherDocsHomepage}${currentFilePath}`;
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    return false;
}

// Function to populate the version switcher
(function () {
    // get JSON config
    $.getJSON("_static/versions.json", function(data, textStatus, jqXHR) {
        // create the nodes first (before AJAX calls) to ensure the order is
        // correct (for now, links will go to doc version homepage)
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // construct the appropriate URL, and add it to the dropdown
            entry.url = buildURL(entry);
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.setAttribute("href", `${entry.url}`);
            node.textContent = `${entry.name}`;
            node.onclick = checkPageExistsAndRedirect;
            $("#version_switcher").append(node);
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for pyspark.sql.protobuf.functions</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c1"># contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c1"># this work for additional information regarding copyright ownership.</span>
<span class="c1"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c1"># (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c1"># the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A collections of builtin protobuf functions</span>
<span class="sd">&quot;&quot;&quot;</span>


<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">from</span> <span class="nn">py4j.java_gateway</span> <span class="kn">import</span> <span class="n">JVMView</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.column</span> <span class="kn">import</span> <span class="n">Column</span><span class="p">,</span> <span class="n">_to_java_column</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.utils</span> <span class="kn">import</span> <span class="n">get_active_spark_context</span><span class="p">,</span> <span class="n">try_remote_protobuf_functions</span>
<span class="kn">from</span> <span class="nn">pyspark.util</span> <span class="kn">import</span> <span class="n">_print_missing_jar</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql._typing</span> <span class="kn">import</span> <span class="n">ColumnOrName</span>


<div class="viewcode-block" id="from_protobuf"><a class="viewcode-back" href="../../../../reference/pyspark.sql/api/pyspark.sql.protobuf.functions.from_protobuf.html#pyspark.sql.protobuf.functions.from_protobuf">[docs]</a><span class="nd">@try_remote_protobuf_functions</span>
<span class="k">def</span> <span class="nf">from_protobuf</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;ColumnOrName&quot;</span><span class="p">,</span>
    <span class="n">messageName</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">descFilePath</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">binaryDescriptorSet</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Column</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a binary column of Protobuf format into its corresponding catalyst value.</span>
<span class="sd">    The Protobuf definition is provided in one of these ways:</span>

<span class="sd">       - Protobuf descriptor file: E.g. a descriptor file created with</span>
<span class="sd">          `protoc --include_imports --descriptor_set_out=abc.desc abc.proto`</span>
<span class="sd">       - Protobuf descriptor as binary: Rather than file path as in previous option,</span>
<span class="sd">         we can provide the binary content of the file. This allows flexibility in how the</span>
<span class="sd">         descriptor set is created and fetched.</span>
<span class="sd">       - Jar containing Protobuf Java class: The jar containing Java class should be shaded.</span>
<span class="sd">         Specifically, `com.google.protobuf.*` should be shaded to</span>
<span class="sd">         `org.sparkproject.spark_protobuf.protobuf.*`.</span>
<span class="sd">         https://github.com/rangadi/shaded-protobuf-classes is useful to create shaded jar from</span>
<span class="sd">         Protobuf files. The jar file can be added with spark-submit option --jars.</span>

<span class="sd">    .. versionadded:: 3.4.0</span>

<span class="sd">    .. versionchanged:: 3.5.0</span>
<span class="sd">        Supports `binaryDescriptorSet` arg to pass binary descriptor directly.</span>
<span class="sd">        Supports Spark Connect.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : :class:`~pyspark.sql.Column` or str</span>
<span class="sd">        the binary column.</span>
<span class="sd">    messageName: str, optional</span>
<span class="sd">        the protobuf message name to look for in descriptor file, or</span>
<span class="sd">        The Protobuf class name when descFilePath parameter is not set.</span>
<span class="sd">        E.g. `com.example.protos.ExampleEvent`.</span>
<span class="sd">    descFilePath : str, optional</span>
<span class="sd">        The Protobuf descriptor file.</span>
<span class="sd">    options : dict, optional</span>
<span class="sd">        options to control how the protobuf record is parsed.</span>
<span class="sd">    binaryDescriptorSet: bytes, optional</span>
<span class="sd">        The Protobuf `FileDescriptorSet` serialized as binary.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Protobuf functionality is provided as an pluggable external module.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tempfile</span>
<span class="sd">    &gt;&gt;&gt; data = [(&quot;1&quot;, (2, &quot;Alice&quot;, 109200))]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;key STRING, value STRUCT&lt;age: INTEGER, name: STRING, score: LONG&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; desc_hex = str(&#39;0ACE010A41636F6E6E6563746F722F70726F746F6275662F7372632F746573742F726&#39;</span>
<span class="sd">    ...    &#39;5736F75726365732F70726F746F6275662F7079737061726B5F746573742E70726F746F121D6F72672E61&#39;</span>
<span class="sd">    ...    &#39;70616368652E737061726B2E73716C2E70726F746F627566224B0A0D53696D706C654D657373616765121&#39;</span>
<span class="sd">    ...    &#39;00A03616765180120012805520361676512120A046E616D6518022001280952046E616D6512140A057363&#39;</span>
<span class="sd">    ...    &#39;6F7265180320012803520573636F72654215421353696D706C654D65737361676550726F746F736206707&#39;</span>
<span class="sd">    ...    &#39;26F746F33&#39;)</span>
<span class="sd">    &gt;&gt;&gt; # Writing a protobuf description into a file, generated by using</span>
<span class="sd">    &gt;&gt;&gt; # connector/protobuf/src/test/resources/protobuf/pyspark_test.proto file</span>
<span class="sd">    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:</span>
<span class="sd">    ...     desc_file_path = &quot;%s/pyspark_test.desc&quot; % tmp_dir</span>
<span class="sd">    ...     with open(desc_file_path, &quot;wb&quot;) as f:</span>
<span class="sd">    ...         _ = f.write(bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...         f.flush()</span>
<span class="sd">    ...         message_name = &#39;SimpleMessage&#39;</span>
<span class="sd">    ...         proto_df = df.select(</span>
<span class="sd">    ...             to_protobuf(df.value, message_name, desc_file_path).alias(&quot;value&quot;))</span>
<span class="sd">    ...         proto_df.show(truncate=False)</span>
<span class="sd">    ...         proto_df_1 = proto_df.select( # With file name for descriptor</span>
<span class="sd">    ...             from_protobuf(proto_df.value, message_name, desc_file_path).alias(&quot;value&quot;))</span>
<span class="sd">    ...         proto_df_1.show(truncate=False)</span>
<span class="sd">    ...         proto_df_2 = proto_df.select( # With binary for descriptor</span>
<span class="sd">    ...             from_protobuf(proto_df.value, message_name,</span>
<span class="sd">    ...                           binaryDescriptorSet = bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...             .alias(&quot;value&quot;))</span>
<span class="sd">    ...         proto_df_2.show(truncate=False)</span>
<span class="sd">    +----------------------------------------+</span>
<span class="sd">    |value                                   |</span>
<span class="sd">    +----------------------------------------+</span>
<span class="sd">    |[08 02 12 05 41 6C 69 63 65 18 90 D5 06]|</span>
<span class="sd">    +----------------------------------------+</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |value             |</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |{2, Alice, 109200}|</span>
<span class="sd">    +------------------+</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |value             |</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |{2, Alice, 109200}|</span>
<span class="sd">    +------------------+</span>
<span class="sd">    &gt;&gt;&gt; data = [([(1668035962, 2020)])]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;value struct&lt;seconds: LONG, nanos: INT&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; message_class_name = &quot;org.sparkproject.spark_protobuf.protobuf.Timestamp&quot;</span>
<span class="sd">    &gt;&gt;&gt; to_proto_df = df.select(to_protobuf(df.value, message_class_name).alias(&quot;value&quot;))</span>
<span class="sd">    &gt;&gt;&gt; from_proto_df = to_proto_df.select(</span>
<span class="sd">    ...     from_protobuf(to_proto_df.value, message_class_name).alias(&quot;value&quot;))</span>
<span class="sd">    &gt;&gt;&gt; from_proto_df.show(truncate=False)</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |value             |</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |{1668035962, 2020}|</span>
<span class="sd">    +------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sc</span> <span class="o">=</span> <span class="n">get_active_spark_context</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">binary_proto</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">binaryDescriptorSet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">binaryDescriptorSet</span>
        <span class="k">elif</span> <span class="n">descFilePath</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">_read_descriptor_set_file</span><span class="p">(</span><span class="n">descFilePath</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">binary_proto</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">from_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">binary_proto</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">from_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;&#39;JavaPackage&#39; object is not callable&quot;</span><span class="p">:</span>
            <span class="n">_print_missing_jar</span><span class="p">(</span><span class="s2">&quot;Protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
        <span class="k">raise</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span></div>


<div class="viewcode-block" id="to_protobuf"><a class="viewcode-back" href="../../../../reference/pyspark.sql/api/pyspark.sql.protobuf.functions.to_protobuf.html#pyspark.sql.protobuf.functions.to_protobuf">[docs]</a><span class="nd">@try_remote_protobuf_functions</span>
<span class="k">def</span> <span class="nf">to_protobuf</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;ColumnOrName&quot;</span><span class="p">,</span>
    <span class="n">messageName</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">descFilePath</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">binaryDescriptorSet</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Column</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a column into binary of protobuf format. The Protobuf definition is provided in one</span>
<span class="sd">    of these ways:</span>

<span class="sd">       - Protobuf descriptor file: E.g. a descriptor file created with</span>
<span class="sd">          `protoc --include_imports --descriptor_set_out=abc.desc abc.proto`</span>
<span class="sd">       - Protobuf descriptor as binary: Rather than file path as in previous option,</span>
<span class="sd">         we can provide the binary content of the file. This allows flexibility in how the</span>
<span class="sd">         descriptor set is created and fetched.</span>
<span class="sd">       - Jar containing Protobuf Java class: The jar containing Java class should be shaded.</span>
<span class="sd">         Specifically, `com.google.protobuf.*` should be shaded to</span>
<span class="sd">         `org.sparkproject.spark_protobuf.protobuf.*`.</span>
<span class="sd">         https://github.com/rangadi/shaded-protobuf-classes is useful to create shaded jar from</span>
<span class="sd">         Protobuf files. The jar file can be added with spark-submit option --jars.</span>

<span class="sd">    .. versionadded:: 3.4.0</span>

<span class="sd">    .. versionchanged:: 3.5.0</span>
<span class="sd">        Supports `binaryDescriptorSet` arg to pass binary descriptor directly.</span>
<span class="sd">        Supports Spark Connect.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : :class:`~pyspark.sql.Column` or str</span>
<span class="sd">        the data column.</span>
<span class="sd">    messageName: str, optional</span>
<span class="sd">        the protobuf message name to look for in descriptor file, or</span>
<span class="sd">        The Protobuf class name when descFilePath parameter is not set.</span>
<span class="sd">        E.g. `com.example.protos.ExampleEvent`.</span>
<span class="sd">    descFilePath : str, optional</span>
<span class="sd">        the Protobuf descriptor file.</span>
<span class="sd">    options : dict, optional</span>
<span class="sd">    binaryDescriptorSet: bytes, optional</span>
<span class="sd">        The Protobuf `FileDescriptorSet` serialized as binary.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Protobuf functionality is provided as a pluggable external module</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tempfile</span>
<span class="sd">    &gt;&gt;&gt; data = [([(2, &quot;Alice&quot;, 13093020)])]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;value struct&lt;age: INTEGER, name: STRING, score: LONG&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; desc_hex = str(&#39;0ACE010A41636F6E6E6563746F722F70726F746F6275662F7372632F746573742F726&#39;</span>
<span class="sd">    ...    &#39;5736F75726365732F70726F746F6275662F7079737061726B5F746573742E70726F746F121D6F72672E61&#39;</span>
<span class="sd">    ...    &#39;70616368652E737061726B2E73716C2E70726F746F627566224B0A0D53696D706C654D657373616765121&#39;</span>
<span class="sd">    ...    &#39;00A03616765180120012805520361676512120A046E616D6518022001280952046E616D6512140A057363&#39;</span>
<span class="sd">    ...    &#39;6F7265180320012803520573636F72654215421353696D706C654D65737361676550726F746F736206707&#39;</span>
<span class="sd">    ...    &#39;26F746F33&#39;)</span>
<span class="sd">    &gt;&gt;&gt; # Writing a protobuf description into a file, generated by using</span>
<span class="sd">    &gt;&gt;&gt; # connector/protobuf/src/test/resources/protobuf/pyspark_test.proto file</span>
<span class="sd">    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:</span>
<span class="sd">    ...     desc_file_path = &quot;%s/pyspark_test.desc&quot; % tmp_dir</span>
<span class="sd">    ...     with open(desc_file_path, &quot;wb&quot;) as f:</span>
<span class="sd">    ...         _ = f.write(bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...         f.flush()</span>
<span class="sd">    ...         message_name = &#39;SimpleMessage&#39;</span>
<span class="sd">    ...         proto_df = df.select( # With file name for descriptor</span>
<span class="sd">    ...             to_protobuf(df.value, message_name, desc_file_path).alias(&quot;suite&quot;))</span>
<span class="sd">    ...         proto_df.show(truncate=False)</span>
<span class="sd">    ...         proto_df_2 = df.select( # With binary for descriptor</span>
<span class="sd">    ...             to_protobuf(df.value, message_name,</span>
<span class="sd">    ...                         binaryDescriptorSet=bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...             .alias(&quot;suite&quot;))</span>
<span class="sd">    ...         proto_df_2.show(truncate=False)</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |suite                                      |</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |[08 02 12 05 41 6C 69 63 65 18 9C 91 9F 06]|</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |suite                                      |</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |[08 02 12 05 41 6C 69 63 65 18 9C 91 9F 06]|</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    &gt;&gt;&gt; data = [([(1668035962, 2020)])]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;value struct&lt;seconds: LONG, nanos: INT&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; message_class_name = &quot;org.sparkproject.spark_protobuf.protobuf.Timestamp&quot;</span>
<span class="sd">    &gt;&gt;&gt; proto_df = df.select(to_protobuf(df.value, message_class_name).alias(&quot;suite&quot;))</span>
<span class="sd">    &gt;&gt;&gt; proto_df.show(truncate=False)</span>
<span class="sd">    +----------------------------+</span>
<span class="sd">    |suite                       |</span>
<span class="sd">    +----------------------------+</span>
<span class="sd">    |[08 FA EA B0 9B 06 10 E4 0F]|</span>
<span class="sd">    +----------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sc</span> <span class="o">=</span> <span class="n">get_active_spark_context</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">binary_proto</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">binaryDescriptorSet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">binaryDescriptorSet</span>
        <span class="k">elif</span> <span class="n">descFilePath</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">_read_descriptor_set_file</span><span class="p">(</span><span class="n">descFilePath</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">binary_proto</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">to_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">binary_proto</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">to_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>

    <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;&#39;JavaPackage&#39; object is not callable&quot;</span><span class="p">:</span>
            <span class="n">_print_missing_jar</span><span class="p">(</span><span class="s2">&quot;Protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
        <span class="k">raise</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_read_descriptor_set_file</span><span class="p">(</span><span class="n">filePath</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
    <span class="c1"># TODO(SPARK-43847): Throw structured errors like &quot;PROTOBUF_DESCRIPTOR_FILE_NOT_FOUND&quot; etc.</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filePath</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_test</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="kn">from</span> <span class="nn">pyspark.testing.utils</span> <span class="kn">import</span> <span class="n">search_jar</span>

    <span class="n">protobuf_jar</span> <span class="o">=</span> <span class="n">search_jar</span><span class="p">(</span><span class="s2">&quot;connector/protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;spark-protobuf-assembly-&quot;</span><span class="p">,</span> <span class="s2">&quot;spark-protobuf&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">protobuf_jar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Skipping all Protobuf Python tests as the optional Protobuf project was &quot;</span>
            <span class="s2">&quot;not compiled into a JAR. To run these tests, &quot;</span>
            <span class="s2">&quot;you need to build Spark with &#39;build/sbt package&#39; or &quot;</span>
            <span class="s2">&quot;&#39;build/mvn package&#39; before running this test.&quot;</span>
        <span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">existing_args</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PYSPARK_SUBMIT_ARGS&quot;</span><span class="p">,</span> <span class="s2">&quot;pyspark-shell&quot;</span><span class="p">)</span>
        <span class="n">jars_args</span> <span class="o">=</span> <span class="s2">&quot;--jars </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">protobuf_jar</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYSPARK_SUBMIT_ARGS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">jars_args</span><span class="p">,</span> <span class="n">existing_args</span><span class="p">])</span>

    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
    <span class="kn">import</span> <span class="nn">pyspark.sql.protobuf.functions</span>

    <span class="n">globs</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;sql.protobuf.functions tests&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">globs</span><span class="p">[</span><span class="s2">&quot;spark&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spark</span>
    <span class="p">(</span><span class="n">failure_count</span><span class="p">,</span> <span class="n">test_count</span><span class="p">)</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">(</span>
        <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="p">,</span>
        <span class="n">globs</span><span class="o">=</span><span class="n">globs</span><span class="p">,</span>
        <span class="n">optionflags</span><span class="o">=</span><span class="n">doctest</span><span class="o">.</span><span class="n">ELLIPSIS</span> <span class="o">|</span> <span class="n">doctest</span><span class="o">.</span><span class="n">NORMALIZE_WHITESPACE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">failure_count</span><span class="p">:</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">_test</span><span class="p">()</span>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright .<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>