<!DOCTYPE HTML>
<html lang="ko">
<head>
<!-- Generated by javadoc (17) on Sat Feb 24 16:16:59 KST 2024 -->
<title>PairDStreamFunctions (Spark 3.5.1 JavaDoc)</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-02-24">
<meta name="description" content="declaration: package: org.apache.spark.streaming.dstream, class: PairDStreamFunctions">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
<script type="text/javascript" src="../../../../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top">
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html#class">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor-summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor-detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" value="search" disabled="disabled">
<input type="reset" id="reset-button" value="reset" disabled="disabled">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">org.apache.spark.streaming.dstream</a></div>
<h1 title="Class PairDStreamFunctions" class="title">Class PairDStreamFunctions&lt;K,<wbr>V&gt;</h1>
</div>
<div class="inheritance" title="Inheritance Tree"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>
<div class="inheritance">org.apache.spark.streaming.dstream.PairDStreamFunctions&lt;K,<wbr>V&gt;</div>
</div>
<section class="class-description" id="class-description">
<dl class="notes">
<dt>All Implemented Interfaces:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html" title="class or interface in java.io" class="external-link">Serializable</a></code>, <code>scala.Serializable</code></dd>
</dl>
<hr>
<div class="type-signature"><span class="modifiers">public class </span><span class="element-name type-name-label">PairDStreamFunctions&lt;K,<wbr>V&gt;</span>
<span class="extends-implements">extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>
implements scala.Serializable</span></div>
<div class="block">Extra functions available on DStream of (key, value) pairs through an implicit conversion.</div>
<dl class="notes">
<dt>See Also:</dt>
<dd>
<ul class="see-list">
<li><a href="../../../../../serialized-form.html#org.apache.spark.streaming.dstream.PairDStreamFunctions">Serialized Form</a></li>
</ul>
</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<li>
<section class="constructor-summary" id="constructor-summary">
<h2>Constructor Summary</h2>
<div class="caption"><span>Constructors</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Constructor</div>
<div class="table-header col-last">Description</div>
<div class="col-constructor-name even-row-color"><code><a href="#%3Cinit%3E(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)" class="member-name-link">PairDStreamFunctions</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;self,
 scala.reflect.ClassTag&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;kt,
 scala.reflect.ClassTag&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;vt,
 scala.math.Ordering&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;ord)</code></div>
<div class="col-last even-row-color">&nbsp;</div>
</div>
</section>
</li>
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab2" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab2', 3)" class="table-tab">Instance Methods</button><button id="method-summary-table-tab4" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab4', 3)" class="table-tab">Concrete Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<div class="summary-table three-column-summary" aria-labelledby="method-summary-table-tab0">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cogroup(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)" class="member-name-link">cogroup</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$14)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cogroup(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)" class="member-name-link">cogroup</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$15)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cogroup(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)" class="member-name-link">cogroup</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$13)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;C&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>C&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,scala.reflect.ClassTag)" class="member-name-link">combineByKey</a><wbr>(scala.Function1&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>C&gt;&nbsp;createCombiner,
 scala.Function2&lt;C,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>C&gt;&nbsp;mergeValue,
 scala.Function2&lt;C,<wbr>C,<wbr>C&gt;&nbsp;mergeCombiner,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;mapSideCombine,
 scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$1)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Combine elements of each key in DStream's RDDs using custom functions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>U&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#flatMapValues(scala.Function1,scala.reflect.ClassTag)" class="member-name-link">flatMapValues</a><wbr>(scala.Function1&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;flatMapValuesFunc,
 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$12)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#fullOuterJoin(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)" class="member-name-link">fullOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$26)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#fullOuterJoin(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)" class="member-name-link">fullOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$27)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#fullOuterJoin(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)" class="member-name-link">fullOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$25)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKey()" class="member-name-link">groupByKey</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKey(int)" class="member-name-link">groupByKey</a><wbr>(int&nbsp;numPartitions)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKey(org.apache.spark.Partitioner)" class="member-name-link">groupByKey</a><wbr>(<a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>groupByKey</code> on each RDD.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKeyAndWindow(org.apache.spark.streaming.Duration)" class="member-name-link">groupByKeyAndWindow</a><wbr>(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKeyAndWindow(org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration)" class="member-name-link">groupByKeyAndWindow</a><wbr>(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKeyAndWindow(org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,int)" class="member-name-link">groupByKeyAndWindow</a><wbr>(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 int&nbsp;numPartitions)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKeyAndWindow(org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,org.apache.spark.Partitioner)" class="member-name-link">groupByKeyAndWindow</a><wbr>(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>W&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)" class="member-name-link">join</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$17)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>W&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)" class="member-name-link">join</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$18)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>W&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)" class="member-name-link">join</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$16)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#leftOuterJoin(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)" class="member-name-link">leftOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$20)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#leftOuterJoin(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)" class="member-name-link">leftOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$21)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#leftOuterJoin(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)" class="member-name-link">leftOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$19)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>U&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#mapValues(scala.Function1,scala.reflect.ClassTag)" class="member-name-link">mapValues</a><wbr>(scala.Function1&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>U&gt;&nbsp;mapValuesFunc,
 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$11)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;StateType,<wbr>
MappedType&gt;<br><a href="MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream">MapWithStateDStream</a>&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>StateType,<wbr>MappedType&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#mapWithState(org.apache.spark.streaming.StateSpec,scala.reflect.ClassTag,scala.reflect.ClassTag)" class="member-name-link">mapWithState</a><wbr>(<a href="../StateSpec.html" title="class in org.apache.spark.streaming">StateSpec</a>&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>StateType,<wbr>MappedType&gt;&nbsp;spec,
 scala.reflect.ClassTag&lt;StateType&gt;&nbsp;evidence$2,
 scala.reflect.ClassTag&lt;MappedType&gt;&nbsp;evidence$3)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a <a href="MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream"><code>MapWithStateDStream</code></a> by applying a function to every key-value element of
 <code>this</code> stream, while maintaining some state data for each unique key.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKey(scala.Function2)" class="member-name-link">reduceByKey</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKey(scala.Function2,int)" class="member-name-link">reduceByKey</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 int&nbsp;numPartitions)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKey(scala.Function2,org.apache.spark.Partitioner)" class="member-name-link">reduceByKey</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration)" class="member-name-link">reduceByKeyAndWindow</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration)" class="member-name-link">reduceByKeyAndWindow</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,int)" class="member-name-link">reduceByKeyAndWindow</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 int&nbsp;numPartitions)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,org.apache.spark.Partitioner)" class="member-name-link">reduceByKeyAndWindow</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKeyAndWindow(scala.Function2,scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,int,scala.Function1)" class="member-name-link">reduceByKeyAndWindow</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 int&nbsp;numPartitions,
 scala.Function1&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;filterFunc)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduceByKeyAndWindow(scala.Function2,scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,org.apache.spark.Partitioner,scala.Function1)" class="member-name-link">reduceByKeyAndWindow</a><wbr>(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.Function1&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;filterFunc)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>W&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rightOuterJoin(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)" class="member-name-link">rightOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$23)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>W&gt;&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rightOuterJoin(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)" class="member-name-link">rightOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$24)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;W&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>W&gt;&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rightOuterJoin(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)" class="member-name-link">rightOuterJoin</a><wbr>(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$22)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#saveAsHadoopFiles(java.lang.String,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)" class="member-name-link">saveAsHadoopFiles</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;keyClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;valueClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,<wbr>?&gt;&gt;&nbsp;outputFormatClass,
 org.apache.hadoop.mapred.JobConf&nbsp;conf)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>
<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;<br>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#saveAsHadoopFiles(java.lang.String,java.lang.String,scala.reflect.ClassTag)" class="member-name-link">saveAsHadoopFiles</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#saveAsNewAPIHadoopFiles(java.lang.String,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)" class="member-name-link">saveAsNewAPIHadoopFiles</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;keyClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;valueClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,<wbr>?&gt;&gt;&nbsp;outputFormatClass,
 org.apache.hadoop.conf.Configuration&nbsp;conf)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>
<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;<br>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#saveAsNewAPIHadoopFiles(java.lang.String,java.lang.String,scala.reflect.ClassTag)" class="member-name-link">saveAsNewAPIHadoopFiles</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function1,org.apache.spark.Partitioner,boolean,org.apache.spark.rdd.RDD,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;&gt;&gt;,<wbr>scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;rememberPartitioner,
 <a href="../../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&nbsp;initialRDD,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$9)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function1,org.apache.spark.Partitioner,boolean,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;&gt;&gt;,<wbr>scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;rememberPartitioner,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$7)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function2,int,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$5)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function2,org.apache.spark.Partitioner,org.apache.spark.rdd.RDD,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 <a href="../../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&nbsp;initialRDD,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$8)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function2,org.apache.spark.Partitioner,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$6)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function2,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$4)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;S&gt;&nbsp;<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#updateStateByKey(scala.Function4,org.apache.spark.Partitioner,boolean,scala.Option,scala.reflect.ClassTag)" class="member-name-link">updateStateByKey</a><wbr>(scala.Function4&lt;<a href="../Time.html" title="class in org.apache.spark.streaming">Time</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;rememberPartitioner,
 scala.Option&lt;<a href="../../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&gt;&nbsp;initialRDD,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$10)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</div>
</div>
</div>
</div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-Object">Methods inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></h3>
<code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object)" title="class or interface in java.lang" class="external-link">equals</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#getClass()" title="class or interface in java.lang" class="external-link">getClass</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#hashCode()" title="class or interface in java.lang" class="external-link">hashCode</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#notify()" title="class or interface in java.lang" class="external-link">notify</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#notifyAll()" title="class or interface in java.lang" class="external-link">notifyAll</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#toString()" title="class or interface in java.lang" class="external-link">toString</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait()" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait(long)" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait(long,int)" title="class or interface in java.lang" class="external-link">wait</a></code></div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<li>
<section class="constructor-details" id="constructor-detail">
<h2>Constructor Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="&lt;init&gt;(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag,scala.reflect.ClassTag,scala.math.Ordering)">
<h3>PairDStreamFunctions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="element-name">PairDStreamFunctions</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;self,
 scala.reflect.ClassTag&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;kt,
 scala.reflect.ClassTag&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;vt,
 scala.math.Ordering&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;ord)</span></div>
</section>
</li>
</ul>
</section>
</li>
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="cogroup(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)">
<h3>cogroup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">cogroup</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$13)</span></div>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with Spark's default number
 of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$13</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cogroup(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)">
<h3>cogroup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">cogroup</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$14)</span></div>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$14</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cogroup(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)">
<h3>cogroup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">cogroup</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$15)</span></div>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 The supplied org.apache.spark.Partitioner is used to partition the generated RDDs.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$15</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="combineByKey(scala.Function1,scala.Function2,scala.Function2,org.apache.spark.Partitioner,boolean,scala.reflect.ClassTag)">
<h3>combineByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;C&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>C&gt;&gt;</span>&nbsp;<span class="element-name">combineByKey</span><wbr><span class="parameters">(scala.Function1&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>C&gt;&nbsp;createCombiner,
 scala.Function2&lt;C,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>C&gt;&nbsp;mergeValue,
 scala.Function2&lt;C,<wbr>C,<wbr>C&gt;&nbsp;mergeCombiner,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;mapSideCombine,
 scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$1)</span></div>
<div class="block">Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
 combineByKey for RDDs. Please refer to combineByKey in
 org.apache.spark.rdd.PairRDDFunctions in the Spark core documentation for more information.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>createCombiner</code> - (undocumented)</dd>
<dd><code>mergeValue</code> - (undocumented)</dd>
<dd><code>mergeCombiner</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>mapSideCombine</code> - (undocumented)</dd>
<dd><code>evidence$1</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMapValues(scala.Function1,scala.reflect.ClassTag)">
<h3>flatMapValues</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>U&gt;&gt;</span>&nbsp;<span class="element-name">flatMapValues</span><wbr><span class="parameters">(scala.Function1&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;flatMapValuesFunc,
 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$12)</span></div>
<div class="block">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>flatMapValuesFunc</code> - (undocumented)</dd>
<dd><code>evidence$12</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="fullOuterJoin(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)">
<h3>fullOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">fullOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$25)</span></div>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$25</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="fullOuterJoin(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)">
<h3>fullOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">fullOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$26)</span></div>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$26</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="fullOuterJoin(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)">
<h3>fullOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">fullOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$27)</span></div>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$27</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey()">
<h3>groupByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKey</span>()</div>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey(int)">
<h3>groupByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKey</span><wbr><span class="parameters">(int&nbsp;numPartitions)</span></div>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
 generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey(org.apache.spark.Partitioner)">
<h3>groupByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKey</span><wbr><span class="parameters">(<a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</span></div>
<div class="block">Return a new DStream by applying <code>groupByKey</code> on each RDD. The supplied
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>partitioner</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKeyAndWindow(org.apache.spark.streaming.Duration)">
<h3>groupByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKeyAndWindow</span><wbr><span class="parameters">(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</span></div>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
 <code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
 with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
 Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKeyAndWindow(org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration)">
<h3>groupByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKeyAndWindow</span><wbr><span class="parameters">(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</span></div>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
 <code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKeyAndWindow(org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,int)">
<h3>groupByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKeyAndWindow</span><wbr><span class="parameters">(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 int&nbsp;numPartitions)</span></div>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>numPartitions</code> - number of partitions of each RDD in the new DStream; if not specified
                       then Spark's default number of partitions will be used</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKeyAndWindow(org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,org.apache.spark.Partitioner)">
<h3>groupByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Iterable&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</span>&nbsp;<span class="element-name">groupByKeyAndWindow</span><wbr><span class="parameters">(<a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</span></div>
<div class="block">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>partitioner</code> - partitioner for controlling the partitioning of each RDD in the new
                       DStream.</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>W&gt;&gt;&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$16)</span></div>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$16</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>W&gt;&gt;&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$17)</span></div>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$17</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>W&gt;&gt;&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$18)</span></div>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 The supplied org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$18</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftOuterJoin(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)">
<h3>leftOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">leftOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$19)</span></div>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$19</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftOuterJoin(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)">
<h3>leftOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">leftOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$20)</span></div>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$20</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="leftOuterJoin(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)">
<h3>leftOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>scala.Option&lt;W&gt;&gt;&gt;&gt;</span>&nbsp;<span class="element-name">leftOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$21)</span></div>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$21</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapValues(scala.Function1,scala.reflect.ClassTag)">
<h3>mapValues</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>U&gt;&gt;</span>&nbsp;<span class="element-name">mapValues</span><wbr><span class="parameters">(scala.Function1&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>U&gt;&nbsp;mapValuesFunc,
 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$11)</span></div>
<div class="block">Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>mapValuesFunc</code> - (undocumented)</dd>
<dd><code>evidence$11</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapWithState(org.apache.spark.streaming.StateSpec,scala.reflect.ClassTag,scala.reflect.ClassTag)">
<h3>mapWithState</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;StateType,<wbr>
MappedType&gt;</span>
<span class="return-type"><a href="MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream">MapWithStateDStream</a>&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>StateType,<wbr>MappedType&gt;</span>&nbsp;<span class="element-name">mapWithState</span><wbr><span class="parameters">(<a href="../StateSpec.html" title="class in org.apache.spark.streaming">StateSpec</a>&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr>StateType,<wbr>MappedType&gt;&nbsp;spec,
 scala.reflect.ClassTag&lt;StateType&gt;&nbsp;evidence$2,
 scala.reflect.ClassTag&lt;MappedType&gt;&nbsp;evidence$3)</span></div>
<div class="block">Return a <a href="MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream"><code>MapWithStateDStream</code></a> by applying a function to every key-value element of
 <code>this</code> stream, while maintaining some state data for each unique key. The mapping function
 and other specification (e.g. partitioners, timeouts, initial state data, etc.) of this
 transformation can be specified using <code>StateSpec</code> class. The state data is accessible in
 as a parameter of type <code>State</code> in the mapping function.
 <p>
 Example of using <code>mapWithState</code>:
 <pre><code>
    // A mapping function that maintains an integer state and return a String
    def mappingFunction(key: String, value: Option[Int], state: State[Int]): Option[String] = {
      // Use state.exists(), state.get(), state.update() and state.remove()
      // to manage state, and return the necessary string
    }

    val spec = StateSpec.function(mappingFunction).numPartitions(10)

    val mapWithStateDStream = keyValueDStream.mapWithState[StateType, MappedType](spec)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>spec</code> - Specification of this transformation</dd>
<dd><code>evidence$2</code> - (undocumented)</dd>
<dd><code>evidence$3</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKey(scala.Function2)">
<h3>reduceByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKey</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the associative and commutative reduce function. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKey(scala.Function2,int)">
<h3>reduceByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKey</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 int&nbsp;numPartitions)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
 with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKey(scala.Function2,org.apache.spark.Partitioner)">
<h3>reduceByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKey</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the supplied reduce function. org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration)">
<h3>reduceByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKeyAndWindow</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
 generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
 the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration)">
<h3>reduceByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKeyAndWindow</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
 <code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,int)">
<h3>reduceByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKeyAndWindow</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 int&nbsp;numPartitions)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
 <code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>numPartitions</code> - number of partitions of each RDD in the new DStream.</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKeyAndWindow(scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,org.apache.spark.Partitioner)">
<h3>reduceByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKeyAndWindow</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</span></div>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
 <code>DStream.reduceByKey()</code>, but applies it over a sliding window.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>partitioner</code> - partitioner for controlling the partitioning of each RDD
                       in the new DStream.</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKeyAndWindow(scala.Function2,scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,int,scala.Function1)">
<h3>reduceByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKeyAndWindow</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 int&nbsp;numPartitions,
 scala.Function1&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;filterFunc)</span></div>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
 The reduced value of over a new window is calculated using the old window's reduced value :
  1. reduce the new values that entered the window (e.g., adding new counts)
 <p>
  2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
 <p>
 This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
 However, it is applicable to only "invertible reduce functions".
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>invReduceFunc</code> - inverse reduce function; such that for all y, invertible x:
                      <code>invReduceFunc(reduceFunc(x, y), x) = y</code></dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>filterFunc</code> - Optional function to filter expired key-value pairs;
                       only pairs that satisfy the function are retained</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduceByKeyAndWindow(scala.Function2,scala.Function2,org.apache.spark.streaming.Duration,org.apache.spark.streaming.Duration,org.apache.spark.Partitioner,scala.Function1)">
<h3>reduceByKeyAndWindow</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>&nbsp;<span class="element-name">reduceByKeyAndWindow</span><wbr><span class="parameters">(scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
 scala.Function2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
 <a href="../Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.Function1&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;filterFunc)</span></div>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
 The reduced value of over a new window is calculated using the old window's reduced value :
  1. reduce the new values that entered the window (e.g., adding new counts)
  2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
 This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
 However, it is applicable to only "invertible reduce functions".</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>invReduceFunc</code> - inverse reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>partitioner</code> - partitioner for controlling the partitioning of each RDD in the new
                       DStream.</dd>
<dd><code>filterFunc</code> - Optional function to filter expired key-value pairs;
                       only pairs that satisfy the function are retained</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rightOuterJoin(org.apache.spark.streaming.dstream.DStream,scala.reflect.ClassTag)">
<h3>rightOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>W&gt;&gt;&gt;</span>&nbsp;<span class="element-name">rightOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$22)</span></div>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$22</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rightOuterJoin(org.apache.spark.streaming.dstream.DStream,int,scala.reflect.ClassTag)">
<h3>rightOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>W&gt;&gt;&gt;</span>&nbsp;<span class="element-name">rightOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$23)</span></div>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$23</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rightOuterJoin(org.apache.spark.streaming.dstream.DStream,org.apache.spark.Partitioner,scala.reflect.ClassTag)">
<h3>rightOuterJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;W&gt;</span>
<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.Tuple2&lt;scala.Option&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>W&gt;&gt;&gt;</span>&nbsp;<span class="element-name">rightOuterJoin</span><wbr><span class="parameters">(<a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>W&gt;&gt;&nbsp;other,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$24)</span></div>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$24</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="saveAsHadoopFiles(java.lang.String,java.lang.String,scala.reflect.ClassTag)">
<h3>saveAsHadoopFiles</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters-long">&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>
<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>
<span class="return-type">void</span>&nbsp;<span class="element-name">saveAsHadoopFiles</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</span></div>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
 is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>fm</code> - (undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="saveAsHadoopFiles(java.lang.String,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.mapred.JobConf)">
<h3>saveAsHadoopFiles</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">saveAsHadoopFiles</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;keyClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;valueClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,<wbr>?&gt;&gt;&nbsp;outputFormatClass,
 org.apache.hadoop.mapred.JobConf&nbsp;conf)</span></div>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
 is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>keyClass</code> - (undocumented)</dd>
<dd><code>valueClass</code> - (undocumented)</dd>
<dd><code>outputFormatClass</code> - (undocumented)</dd>
<dd><code>conf</code> - (undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="saveAsNewAPIHadoopFiles(java.lang.String,java.lang.String,scala.reflect.ClassTag)">
<h3>saveAsNewAPIHadoopFiles</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters-long">&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>
<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</span>
<span class="return-type">void</span>&nbsp;<span class="element-name">saveAsNewAPIHadoopFiles</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</span></div>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
 generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>fm</code> - (undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="saveAsNewAPIHadoopFiles(java.lang.String,java.lang.String,java.lang.Class,java.lang.Class,java.lang.Class,org.apache.hadoop.conf.Configuration)">
<h3>saveAsNewAPIHadoopFiles</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">saveAsNewAPIHadoopFiles</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;prefix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;suffix,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;keyClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;?&gt;&nbsp;valueClass,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html" title="class or interface in java.lang" class="external-link">Class</a>&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,<wbr>?&gt;&gt;&nbsp;outputFormatClass,
 org.apache.hadoop.conf.Configuration&nbsp;conf)</span></div>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
 generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>keyClass</code> - (undocumented)</dd>
<dd><code>valueClass</code> - (undocumented)</dd>
<dd><code>outputFormatClass</code> - (undocumented)</dd>
<dd><code>conf</code> - (undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function2,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$4)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>evidence$4</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function2,int,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 int&nbsp;numPartitions,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$5)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>numPartitions</code> - Number of partitions of each RDD in the new DStream.</dd>
<dd><code>evidence$5</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function2,org.apache.spark.Partitioner,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$6)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 <a href="../../Partitioner.html" title="class in org.apache.spark"><code>Partitioner</code></a> is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.</dd>
<dd><code>evidence$6</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function1,org.apache.spark.Partitioner,boolean,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;&gt;&gt;,<wbr>scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;rememberPartitioner,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$7)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 <a href="../../Partitioner.html" title="class in org.apache.spark"><code>Partitioner</code></a> is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. Note, that this function may generate a different
                   tuple with a different key than the input key. Therefore keys may be removed
                   or added in this way. It is up to the developer to decide whether to
                   remember the partitioner despite the key being changed.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream</dd>
<dd><code>rememberPartitioner</code> - Whether to remember the partitioner object in the generated RDDs.</dd>
<dd><code>evidence$7</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function2,org.apache.spark.Partitioner,org.apache.spark.rdd.RDD,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function2&lt;scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 <a href="../../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&nbsp;initialRDD,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$8)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.</dd>
<dd><code>initialRDD</code> - initial state value of each key.</dd>
<dd><code>evidence$8</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function1,org.apache.spark.Partitioner,boolean,org.apache.spark.rdd.RDD,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;&gt;&gt;,<wbr>scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;rememberPartitioner,
 <a href="../../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&nbsp;initialRDD,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$9)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. Note, that this function may generate a different
                   tuple with a different key than the input key. Therefore keys may be removed
                   or added in this way. It is up to the developer to decide whether to
                   remember the  partitioner despite the key being changed.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream</dd>
<dd><code>rememberPartitioner</code> - Whether to remember the partitioner object in the generated RDDs.</dd>
<dd><code>initialRDD</code> - initial state value of each key.</dd>
<dd><code>evidence$9</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="updateStateByKey(scala.Function4,org.apache.spark.Partitioner,boolean,scala.Option,scala.reflect.ClassTag)">
<h3>updateStateByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;S&gt;</span>&nbsp;<span class="return-type"><a href="DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;</span>&nbsp;<span class="element-name">updateStateByKey</span><wbr><span class="parameters">(scala.Function4&lt;<a href="../Time.html" title="class in org.apache.spark.streaming">Time</a>,<wbr><a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>scala.collection.Seq&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,<wbr>scala.Option&lt;S&gt;,<wbr>scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
 <a href="../../Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
 boolean&nbsp;rememberPartitioner,
 scala.Option&lt;<a href="../../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<wbr>S&gt;&gt;&gt;&nbsp;initialRDD,
 scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$10)</span></div>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.</dd>
<dd><code>rememberPartitioner</code> - (undocumented)</dd>
<dd><code>initialRDD</code> - (undocumented)</dd>
<dd><code>evidence$10</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
</dl>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
</div>
</div>
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
