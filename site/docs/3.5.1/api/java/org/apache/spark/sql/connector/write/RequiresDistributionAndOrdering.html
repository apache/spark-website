<!DOCTYPE HTML>
<html lang="ko">
<head>
<!-- Generated by javadoc (17) on Sat Feb 24 16:16:59 KST 2024 -->
<title>RequiresDistributionAndOrdering (Spark 3.5.1 JavaDoc)</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-02-24">
<meta name="description" content="declaration: package: org.apache.spark.sql.connector.write, interface: RequiresDistributionAndOrdering">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../../../script.js"></script>
<script type="text/javascript" src="../../../../../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top">
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="../../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../../help-doc.html#class">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" value="search" disabled="disabled">
<input type="reset" id="reset-button" value="reset" disabled="disabled">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">org.apache.spark.sql.connector.write</a></div>
<h1 title="Interface RequiresDistributionAndOrdering" class="title">Interface RequiresDistributionAndOrdering</h1>
</div>
<section class="class-description" id="class-description">
<dl class="notes">
<dt>All Superinterfaces:</dt>
<dd><code><a href="Write.html" title="interface in org.apache.spark.sql.connector.write">Write</a></code></dd>
</dl>
<hr>
<div class="type-signature"><span class="annotations">@Experimental
</span><span class="modifiers">public interface </span><span class="element-name type-name-label">RequiresDistributionAndOrdering</span><span class="extends-implements">
extends <a href="Write.html" title="interface in org.apache.spark.sql.connector.write">Write</a></span></div>
<div class="block">A write that requires a specific distribution and ordering of data.</div>
<dl class="notes">
<dt>Since:</dt>
<dd>3.2.0</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab2" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab2', 3)" class="table-tab">Instance Methods</button><button id="method-summary-table-tab3" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab3', 3)" class="table-tab">Abstract Methods</button><button id="method-summary-table-tab5" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab5', 3)" class="table-tab">Default Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<div class="summary-table three-column-summary" aria-labelledby="method-summary-table-tab0">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code>default long</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code><a href="#advisoryPartitionSizeInBytes()" class="member-name-link">advisoryPartitionSizeInBytes</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5">
<div class="block">Returns the advisory (not guaranteed) shuffle partition size in bytes for this write.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code>default boolean</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code><a href="#distributionStrictlyRequired()" class="member-name-link">distributionStrictlyRequired</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5">
<div class="block">Returns if the distribution required by this write is strictly required or best effort only.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="../distributions/Distribution.html" title="interface in org.apache.spark.sql.connector.distributions">Distribution</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#requiredDistribution()" class="member-name-link">requiredDistribution</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">Returns the distribution required by this write.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code>default int</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code><a href="#requiredNumPartitions()" class="member-name-link">requiredNumPartitions</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5">
<div class="block">Returns the number of partitions required by this write.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="../expressions/SortOrder.html" title="interface in org.apache.spark.sql.connector.expressions">SortOrder</a>[]</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#requiredOrdering()" class="member-name-link">requiredOrdering</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">Returns the ordering required by this write.</div>
</div>
</div>
</div>
</div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-org.apache.spark.sql.connector.write.Write">Methods inherited from interface&nbsp;org.apache.spark.sql.connector.write.<a href="Write.html" title="interface in org.apache.spark.sql.connector.write">Write</a></h3>
<code><a href="Write.html#description()">description</a>, <a href="Write.html#supportedCustomMetrics()">supportedCustomMetrics</a>, <a href="Write.html#toBatch()">toBatch</a>, <a href="Write.html#toStreaming()">toStreaming</a></code></div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="requiredDistribution()">
<h3>requiredDistribution</h3>
<div class="member-signature"><span class="return-type"><a href="../distributions/Distribution.html" title="interface in org.apache.spark.sql.connector.distributions">Distribution</a></span>&nbsp;<span class="element-name">requiredDistribution</span>()</div>
<div class="block">Returns the distribution required by this write.
 <p>
 Spark will distribute incoming records across partitions to satisfy the required distribution
 before passing the records to the data source table on write.
 <p>
 Batch and micro-batch writes can request a particular data distribution.
 If a distribution is requested in the micro-batch context, incoming records in each micro batch
 will satisfy the required distribution (but not across micro batches). The continuous execution
 mode continuously processes streaming data and does not support distribution requirements.
 <p>
 Implementations may return <a href="../distributions/UnspecifiedDistribution.html" title="interface in org.apache.spark.sql.connector.distributions"><code>UnspecifiedDistribution</code></a> if they don't require any specific
 distribution of data on write.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>the required distribution</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="distributionStrictlyRequired()">
<h3>distributionStrictlyRequired</h3>
<div class="member-signature"><span class="modifiers">default</span>&nbsp;<span class="return-type">boolean</span>&nbsp;<span class="element-name">distributionStrictlyRequired</span>()</div>
<div class="block">Returns if the distribution required by this write is strictly required or best effort only.
 <p>
 If true, Spark will strictly distribute incoming records across partitions to satisfy
 the required distribution before passing the records to the data source table on write.
 Otherwise, Spark may apply certain optimizations to speed up the query but break
 the distribution requirement.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>true if the distribution required by this write is strictly required; false otherwise.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="requiredNumPartitions()">
<h3>requiredNumPartitions</h3>
<div class="member-signature"><span class="modifiers">default</span>&nbsp;<span class="return-type">int</span>&nbsp;<span class="element-name">requiredNumPartitions</span>()</div>
<div class="block">Returns the number of partitions required by this write.
 <p>
 Implementations may override this to require a specific number of input partitions.
 <p>
 Note that Spark doesn't support the number of partitions on <a href="../distributions/UnspecifiedDistribution.html" title="interface in org.apache.spark.sql.connector.distributions"><code>UnspecifiedDistribution</code></a>,
 the query will fail if the number of partitions are provided but the distribution is
 unspecified. Data sources may either request a particular number of partitions or
 a preferred partition size via <a href="#advisoryPartitionSizeInBytes()"><code>advisoryPartitionSizeInBytes()</code></a>, not both.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>the required number of partitions, any value less than 1 mean no requirement.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="advisoryPartitionSizeInBytes()">
<h3>advisoryPartitionSizeInBytes</h3>
<div class="member-signature"><span class="modifiers">default</span>&nbsp;<span class="return-type">long</span>&nbsp;<span class="element-name">advisoryPartitionSizeInBytes</span>()</div>
<div class="block">Returns the advisory (not guaranteed) shuffle partition size in bytes for this write.
 <p>
 Implementations may override this to indicate the preferable partition size in shuffles
 performed to satisfy the requested distribution. Note that Spark doesn't support setting
 the advisory partition size for <a href="../distributions/UnspecifiedDistribution.html" title="interface in org.apache.spark.sql.connector.distributions"><code>UnspecifiedDistribution</code></a>, the query will fail if
 the advisory partition size is set but the distribution is unspecified. Data sources may
 either request a particular number of partitions via <a href="#requiredNumPartitions()"><code>requiredNumPartitions()</code></a> or
 a preferred partition size, not both.
 <p>
 Data sources should be careful with large advisory sizes as it will impact the writing
 parallelism and may degrade the overall job performance.
 <p>
 Note this value only acts like a guidance and Spark does not guarantee the actual and advisory
 shuffle partition sizes will match. Ignored if the adaptive execution is disabled.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>the advisory partition size, any value less than 1 means no preference.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="requiredOrdering()">
<h3>requiredOrdering</h3>
<div class="member-signature"><span class="return-type"><a href="../expressions/SortOrder.html" title="interface in org.apache.spark.sql.connector.expressions">SortOrder</a>[]</span>&nbsp;<span class="element-name">requiredOrdering</span>()</div>
<div class="block">Returns the ordering required by this write.
 <p>
 Spark will order incoming records within partitions to satisfy the required ordering
 before passing those records to the data source table on write.
 <p>
 Batch and micro-batch writes can request a particular data ordering.
 If an ordering is requested in the micro-batch context, incoming records in each micro batch
 will satisfy the required ordering (but not across micro batches). The continuous execution
 mode continuously processes streaming data and does not support ordering requirements.
 <p>
 Implementations may return an empty array if they don't require any specific ordering of data
 on write.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>the required ordering</dd>
</dl>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
</div>
</div>
<script defer="defer" type="text/javascript" src="../../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../../lib/api-javadocs.js"></script></body>
</html>
