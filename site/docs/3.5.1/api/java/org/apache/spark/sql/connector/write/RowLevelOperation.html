<!DOCTYPE HTML>
<html lang="ko">
<head>
<!-- Generated by javadoc (17) on Sat Feb 24 16:16:59 KST 2024 -->
<title>RowLevelOperation (Spark 3.5.1 JavaDoc)</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-02-24">
<meta name="description" content="declaration: package: org.apache.spark.sql.connector.write, interface: RowLevelOperation">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../../../script.js"></script>
<script type="text/javascript" src="../../../../../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top">
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="../../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../../help-doc.html#class">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li><a href="#nested-class-summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" value="search" disabled="disabled">
<input type="reset" id="reset-button" value="reset" disabled="disabled">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">org.apache.spark.sql.connector.write</a></div>
<h1 title="Interface RowLevelOperation" class="title">Interface RowLevelOperation</h1>
</div>
<section class="class-description" id="class-description">
<dl class="notes">
<dt>All Known Subinterfaces:</dt>
<dd><code><a href="SupportsDelta.html" title="interface in org.apache.spark.sql.connector.write">SupportsDelta</a></code></dd>
</dl>
<hr>
<div class="type-signature"><span class="annotations">@Experimental
</span><span class="modifiers">public interface </span><span class="element-name type-name-label">RowLevelOperation</span></div>
<div class="block">A logical representation of a data source DELETE, UPDATE, or MERGE operation that requires
 rewriting data.</div>
<dl class="notes">
<dt>Since:</dt>
<dd>3.3.0</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<li>
<section class="nested-class-summary" id="nested-class-summary">
<h2>Nested Class Summary</h2>
<div class="caption"><span>Nested Classes</span></div>
<div class="summary-table three-column-summary">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Interface</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color"><code>static enum&nbsp;</code></div>
<div class="col-second even-row-color"><code><a href="RowLevelOperation.Command.html" class="type-name-link" title="enum class in org.apache.spark.sql.connector.write">RowLevelOperation.Command</a></code></div>
<div class="col-last even-row-color">
<div class="block">A row-level SQL command.</div>
</div>
</div>
</section>
</li>
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab2" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab2', 3)" class="table-tab">Instance Methods</button><button id="method-summary-table-tab3" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab3', 3)" class="table-tab">Abstract Methods</button><button id="method-summary-table-tab5" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab5', 3)" class="table-tab">Default Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<div class="summary-table three-column-summary" aria-labelledby="method-summary-table-tab0">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="RowLevelOperation.Command.html" title="enum class in org.apache.spark.sql.connector.write">RowLevelOperation.Command</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#command()" class="member-name-link">command</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">Returns the SQL command that is being performed.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code>default <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code><a href="#description()" class="member-name-link">description</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5">
<div class="block">Returns the description associated with this row-level operation.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="../read/ScanBuilder.html" title="interface in org.apache.spark.sql.connector.read">ScanBuilder</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#newScanBuilder(org.apache.spark.sql.util.CaseInsensitiveStringMap)" class="member-name-link">newScanBuilder</a><wbr>(<a href="../../util/CaseInsensitiveStringMap.html" title="class in org.apache.spark.sql.util">CaseInsensitiveStringMap</a>&nbsp;options)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">Returns a <a href="../read/ScanBuilder.html" title="interface in org.apache.spark.sql.connector.read"><code>ScanBuilder</code></a> to configure a <a href="../read/Scan.html" title="interface in org.apache.spark.sql.connector.read"><code>Scan</code></a> for this row-level operation.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="WriteBuilder.html" title="interface in org.apache.spark.sql.connector.write">WriteBuilder</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3"><code><a href="#newWriteBuilder(org.apache.spark.sql.connector.write.LogicalWriteInfo)" class="member-name-link">newWriteBuilder</a><wbr>(<a href="LogicalWriteInfo.html" title="interface in org.apache.spark.sql.connector.write">LogicalWriteInfo</a>&nbsp;info)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab3">
<div class="block">Returns a <a href="WriteBuilder.html" title="interface in org.apache.spark.sql.connector.write"><code>WriteBuilder</code></a> to configure a <a href="Write.html" title="interface in org.apache.spark.sql.connector.write"><code>Write</code></a> for this row-level operation.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code>default <a href="../expressions/NamedReference.html" title="interface in org.apache.spark.sql.connector.expressions">NamedReference</a>[]</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5"><code><a href="#requiredMetadataAttributes()" class="member-name-link">requiredMetadataAttributes</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab5">
<div class="block">Returns metadata attributes that are required to perform this row-level operation.</div>
</div>
</div>
</div>
</div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="description()">
<h3>description</h3>
<div class="member-signature"><span class="modifiers">default</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></span>&nbsp;<span class="element-name">description</span>()</div>
<div class="block">Returns the description associated with this row-level operation.</div>
</section>
</li>
<li>
<section class="detail" id="command()">
<h3>command</h3>
<div class="member-signature"><span class="return-type"><a href="RowLevelOperation.Command.html" title="enum class in org.apache.spark.sql.connector.write">RowLevelOperation.Command</a></span>&nbsp;<span class="element-name">command</span>()</div>
<div class="block">Returns the SQL command that is being performed.</div>
</section>
</li>
<li>
<section class="detail" id="newScanBuilder(org.apache.spark.sql.util.CaseInsensitiveStringMap)">
<h3>newScanBuilder</h3>
<div class="member-signature"><span class="return-type"><a href="../read/ScanBuilder.html" title="interface in org.apache.spark.sql.connector.read">ScanBuilder</a></span>&nbsp;<span class="element-name">newScanBuilder</span><wbr><span class="parameters">(<a href="../../util/CaseInsensitiveStringMap.html" title="class in org.apache.spark.sql.util">CaseInsensitiveStringMap</a>&nbsp;options)</span></div>
<div class="block">Returns a <a href="../read/ScanBuilder.html" title="interface in org.apache.spark.sql.connector.read"><code>ScanBuilder</code></a> to configure a <a href="../read/Scan.html" title="interface in org.apache.spark.sql.connector.read"><code>Scan</code></a> for this row-level operation.
 <p>
 Data sources fall into two categories: those that can handle a delta of rows and those that
 need to replace groups (e.g. partitions, files). Data sources that handle deltas allow Spark
 to quickly discard unchanged rows and have no requirements for input scans. Data sources that
 replace groups of rows can discard deleted rows but need to keep unchanged rows to be passed
 back into the source. This means that scans for such data sources must produce all rows
 in a group if any are returned. Some data sources will avoid pushing filters into files (file
 granularity), while others will avoid pruning files within a partition (partition granularity).
 <p>
 For example, if a data source can only replace partitions, all rows from a partition must
 be returned by the scan, even if a filter can narrow the set of changes to a single file
 in the partition. Similarly, a data source that can swap individual files must produce all
 rows from files where at least one record must be changed, not just rows that must be changed.
 <p>
 Data sources that replace groups of data (e.g. files, partitions) may prune entire groups
 using provided data source filters when building a scan for this row-level operation.
 However, such data skipping is limited as not all expressions can be converted into data source
 filters and some can only be evaluated by Spark (e.g. subqueries). Since rewriting groups is
 expensive, Spark allows group-based data sources to filter groups at runtime. The runtime
 filtering enables data sources to narrow down the scope of rewriting to only groups that must
 be rewritten. If the row-level operation scan implements <a href="../read/SupportsRuntimeV2Filtering.html" title="interface in org.apache.spark.sql.connector.read"><code>SupportsRuntimeV2Filtering</code></a>,
 Spark will execute a query at runtime to find which records match the row-level condition.
 The runtime group filter subquery will leverage a regular batch scan, which isn't required to
 produce all rows in a group if any are returned. The information about matching records will
 be passed back into the row-level operation scan, allowing data sources to discard groups
 that don't have to be rewritten.</div>
</section>
</li>
<li>
<section class="detail" id="newWriteBuilder(org.apache.spark.sql.connector.write.LogicalWriteInfo)">
<h3>newWriteBuilder</h3>
<div class="member-signature"><span class="return-type"><a href="WriteBuilder.html" title="interface in org.apache.spark.sql.connector.write">WriteBuilder</a></span>&nbsp;<span class="element-name">newWriteBuilder</span><wbr><span class="parameters">(<a href="LogicalWriteInfo.html" title="interface in org.apache.spark.sql.connector.write">LogicalWriteInfo</a>&nbsp;info)</span></div>
<div class="block">Returns a <a href="WriteBuilder.html" title="interface in org.apache.spark.sql.connector.write"><code>WriteBuilder</code></a> to configure a <a href="Write.html" title="interface in org.apache.spark.sql.connector.write"><code>Write</code></a> for this row-level operation.
 <p>
 Note that Spark will first configure the scan and then the write, allowing data sources to pass
 information from the scan to the write. For example, the scan can report which condition was
 used to read the data that may be needed by the write under certain isolation levels.
 Implementations may capture the built scan or required scan information and then use it
 while building the write.</div>
</section>
</li>
<li>
<section class="detail" id="requiredMetadataAttributes()">
<h3>requiredMetadataAttributes</h3>
<div class="member-signature"><span class="modifiers">default</span>&nbsp;<span class="return-type"><a href="../expressions/NamedReference.html" title="interface in org.apache.spark.sql.connector.expressions">NamedReference</a>[]</span>&nbsp;<span class="element-name">requiredMetadataAttributes</span>()</div>
<div class="block">Returns metadata attributes that are required to perform this row-level operation.
 <p>
 Data sources that can use this method to project metadata columns needed for writing
 the data back (e.g. metadata columns for grouping data).</div>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
</div>
</div>
<script defer="defer" type="text/javascript" src="../../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../../lib/api-javadocs.js"></script></body>
</html>
