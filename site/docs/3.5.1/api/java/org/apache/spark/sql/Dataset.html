<!DOCTYPE HTML>
<html lang="ko">
<head>
<!-- Generated by javadoc (17) on Sat Feb 24 16:16:59 KST 2024 -->
<title>Dataset (Spark 3.5.1 JavaDoc)</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-02-24">
<meta name="description" content="declaration: package: org.apache.spark.sql, class: Dataset">
<meta name="generator" content="javadoc/ClassWriterImpl">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../script-dir/jquery-ui.min.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../../../jquery-ui.overrides.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
<script type="text/javascript" src="../../../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../../../script-dir/jquery-ui.min.js"></script>
</head>
<body class="class-declaration-page">
<script type="text/javascript">var evenRowColor = "even-row-color";
var oddRowColor = "odd-row-color";
var tableTab = "table-tab";
var activeTableTab = "active-table-tab";
var pathtoroot = "../../../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top">
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../../../index.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="nav-bar-cell1-rev">Class</li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html#class">Help</a></li>
</ul>
</div>
<div class="sub-nav">
<div>
<ul class="sub-nav-list">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor-summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method-summary">Method</a></li>
</ul>
<ul class="sub-nav-list">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor-detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method-detail">Method</a></li>
</ul>
</div>
<div class="nav-list-search"><label for="search-input">SEARCH:</label>
<input type="text" id="search-input" value="search" disabled="disabled">
<input type="reset" id="reset-button" value="reset" disabled="disabled">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="sub-title"><span class="package-label-in-type">Package</span>&nbsp;<a href="package-summary.html">org.apache.spark.sql</a></div>
<h1 title="Class Dataset" class="title">Class Dataset&lt;T&gt;</h1>
</div>
<div class="inheritance" title="Inheritance Tree"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>
<div class="inheritance">org.apache.spark.sql.Dataset&lt;T&gt;</div>
</div>
<section class="class-description" id="class-description">
<dl class="notes">
<dt>All Implemented Interfaces:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html" title="class or interface in java.io" class="external-link">Serializable</a></code>, <code>scala.Serializable</code></dd>
</dl>
<hr>
<div class="type-signature"><span class="modifiers">public class </span><span class="element-name type-name-label">Dataset&lt;T&gt;</span>
<span class="extends-implements">extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>
implements scala.Serializable</span></div>
<div class="block">A Dataset is a strongly typed collection of domain-specific objects that can be transformed
 in parallel using functional or relational operations. Each Dataset also has an untyped view
 called a <code>DataFrame</code>, which is a Dataset of <a href="Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>.
 <p>
 Operations available on Datasets are divided into transformations and actions. Transformations
 are the ones that produce new Datasets, and actions are the ones that trigger computation and
 return results. Example transformations include map, filter, select, and aggregate (<code>groupBy</code>).
 Example actions count, show, or writing data out to file systems.
 <p>
 Datasets are "lazy", i.e. computations are only triggered when an action is invoked. Internally,
 a Dataset represents a logical plan that describes the computation required to produce the data.
 When an action is invoked, Spark's query optimizer optimizes the logical plan and generates a
 physical plan for efficient execution in a parallel and distributed manner. To explore the
 logical plan as well as optimized physical plan, use the <code>explain</code> function.
 <p>
 To efficiently support domain-specific objects, an <a href="Encoder.html" title="interface in org.apache.spark.sql"><code>Encoder</code></a> is required. The encoder maps
 the domain specific type <code>T</code> to Spark's internal type system. For example, given a class <code>Person</code>
 with two fields, <code>name</code> (string) and <code>age</code> (int), an encoder is used to tell Spark to generate
 code at runtime to serialize the <code>Person</code> object into a binary structure. This binary structure
 often has much lower memory footprint as well as are optimized for efficiency in data processing
 (e.g. in a columnar format). To understand the internal binary representation for data, use the
 <code>schema</code> function.
 <p>
 There are typically two ways to create a Dataset. The most common way is by pointing Spark
 to some files on storage systems, using the <code>read</code> function available on a <code>SparkSession</code>.
 <pre><code>
   val people = spark.read.parquet("...").as[Person]  // Scala
   Dataset&lt;Person&gt; people = spark.read().parquet("...").as(Encoders.bean(Person.class)); // Java
 </code></pre>
 <p>
 Datasets can also be created through transformations available on existing Datasets. For example,
 the following creates a new Dataset by applying a filter on the existing one:
 <pre><code>
   val names = people.map(_.name)  // in Scala; names is a Dataset[String]
   Dataset&lt;String&gt; names = people.map((Person p) -&gt; p.name, Encoders.STRING));
 </code></pre>
 <p>
 Dataset operations can also be untyped, through various domain-specific-language (DSL)
 functions defined in: Dataset (this class), <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>, and <a href="functions.html" title="class in org.apache.spark.sql"><code>functions</code></a>. These operations
 are very similar to the operations available in the data frame abstraction in R or Python.
 <p>
 To select a column from the Dataset, use <code>apply</code> method in Scala and <code>col</code> in Java.
 <pre><code>
   val ageCol = people("age")  // in Scala
   Column ageCol = people.col("age"); // in Java
 </code></pre>
 <p>
 Note that the <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> type can also be manipulated through its various functions.
 <pre><code>
   // The following creates a new column that increases everybody's age by 10.
   people("age") + 10  // in Scala
   people.col("age").plus(10);  // in Java
 </code></pre>
 <p>
 A more concrete example in Scala:
 <pre><code>
   // To create Dataset[Row] using SparkSession
   val people = spark.read.parquet("...")
   val department = spark.read.parquet("...")

   people.filter("age &gt; 30")
     .join(department, people("deptId") === department("id"))
     .groupBy(department("name"), people("gender"))
     .agg(avg(people("salary")), max(people("age")))
 </code></pre>
 <p>
 and in Java:
 <pre><code>
   // To create Dataset&lt;Row&gt; using SparkSession
   Dataset&lt;Row&gt; people = spark.read().parquet("...");
   Dataset&lt;Row&gt; department = spark.read().parquet("...");

   people.filter(people.col("age").gt(30))
     .join(department, people.col("deptId").equalTo(department.col("id")))
     .groupBy(department.col("name"), people.col("gender"))
     .agg(avg(people.col("salary")), max(people.col("age")));
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Since:</dt>
<dd>1.6.0</dd>
<dt>See Also:</dt>
<dd>
<ul class="see-list">
<li><a href="../../../../serialized-form.html#org.apache.spark.sql.Dataset">Serialized Form</a></li>
</ul>
</dd>
</dl>
</section>
<section class="summary">
<ul class="summary-list">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<li>
<section class="constructor-summary" id="constructor-summary">
<h2>Constructor Summary</h2>
<div class="caption"><span>Constructors</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Constructor</div>
<div class="table-header col-last">Description</div>
<div class="col-constructor-name even-row-color"><code><a href="#%3Cinit%3E(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.Encoder)" class="member-name-link">Dataset</a><wbr>(<a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;encoder)</code></div>
<div class="col-last even-row-color">&nbsp;</div>
<div class="col-constructor-name odd-row-color"><code><a href="#%3Cinit%3E(org.apache.spark.sql.SQLContext,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.Encoder)" class="member-name-link">Dataset</a><wbr>(<a href="SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;encoder)</code></div>
<div class="col-last odd-row-color">&nbsp;</div>
</div>
</section>
</li>
<!-- ========== METHOD SUMMARY =========== -->
<li>
<section class="method-summary" id="method-summary">
<h2>Method Summary</h2>
<div id="method-summary-table">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="method-summary-table-tab0" role="tab" aria-selected="true" aria-controls="method-summary-table.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table', 3)" class="active-table-tab">All Methods</button><button id="method-summary-table-tab1" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab1', 3)" class="table-tab">Static Methods</button><button id="method-summary-table-tab2" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab2', 3)" class="table-tab">Instance Methods</button><button id="method-summary-table-tab4" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab4', 3)" class="table-tab">Concrete Methods</button><button id="method-summary-table-tab6" role="tab" aria-selected="false" aria-controls="method-summary-table.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('method-summary-table', 'method-summary-table-tab6', 3)" class="table-tab">Deprecated Methods</button></div>
<div id="method-summary-table.tabpanel" role="tabpanel">
<div class="summary-table three-column-summary" aria-labelledby="method-summary-table-tab0">
<div class="table-header col-first">Modifier and Type</div>
<div class="table-header col-second">Method</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#agg(java.util.Map)" class="member-name-link">agg</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html" title="class or interface in java.util" class="external-link">Map</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;exprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific) Aggregates on the entire Dataset without groups.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#agg(org.apache.spark.sql.Column,org.apache.spark.sql.Column...)" class="member-name-link">agg</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;exprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Aggregates on the entire Dataset without groups.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#agg(org.apache.spark.sql.Column,scala.collection.Seq)" class="member-name-link">agg</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;exprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Aggregates on the entire Dataset without groups.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#agg(scala.collection.immutable.Map)" class="member-name-link">agg</a><wbr>(scala.collection.immutable.Map&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;exprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Aggregates on the entire Dataset without groups.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#agg(scala.Tuple2,scala.collection.Seq)" class="member-name-link">agg</a><wbr>(scala.Tuple2&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;aggExpr,
 scala.collection.Seq&lt;scala.Tuple2&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&gt;&nbsp;aggExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Aggregates on the entire Dataset without groups.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#alias(java.lang.String)" class="member-name-link">alias</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;alias)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with an alias set.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#alias(scala.Symbol)" class="member-name-link">alias</a><wbr>(scala.Symbol&nbsp;alias)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Returns a new Dataset with an alias set.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Column.html" title="class in org.apache.spark.sql">Column</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#apply(java.lang.String)" class="member-name-link">apply</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects column based on the column name and returns it as a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#as(java.lang.String)" class="member-name-link">as</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;alias)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with an alias set.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#as(org.apache.spark.sql.Encoder)" class="member-name-link">as</a><wbr>(<a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$2)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset where each record has been mapped on to the specified type.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#as(scala.Symbol)" class="member-name-link">as</a><wbr>(scala.Symbol&nbsp;alias)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Returns a new Dataset with an alias set.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cache()" class="member-name-link">cache</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Persist this Dataset with the default storage level (<code>MEMORY_AND_DISK</code>).</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#checkpoint()" class="member-name-link">checkpoint</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Eagerly checkpoint a Dataset and return the new Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#checkpoint(boolean)" class="member-name-link">checkpoint</a><wbr>(boolean&nbsp;eager)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a checkpointed version of this Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>scala.reflect.ClassTag&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#classTag()" class="member-name-link">classTag</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#coalesce(int)" class="member-name-link">coalesce</a><wbr>(int&nbsp;numPartitions)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset that has exactly <code>numPartitions</code> partitions, when the fewer partitions
 are requested.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Column.html" title="class in org.apache.spark.sql">Column</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#col(java.lang.String)" class="member-name-link">col</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects column based on the column name and returns it as a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#COL_POS_KEY()" class="member-name-link">COL_POS_KEY</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">&nbsp;</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#collect()" class="member-name-link">collect</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns an array that contains all rows in this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#collectAsList()" class="member-name-link">collectAsList</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a Java list that contains all rows in this Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Column.html" title="class in org.apache.spark.sql">Column</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#colRegex(java.lang.String)" class="member-name-link">colRegex</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects column based on the column name specified as a regex and returns it as <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#columns()" class="member-name-link">columns</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns all column names as an array.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>long</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#count()" class="member-name-link">count</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the number of rows in the Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#createGlobalTempView(java.lang.String)" class="member-name-link">createGlobalTempView</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Creates a global temporary view using the given name.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#createOrReplaceGlobalTempView(java.lang.String)" class="member-name-link">createOrReplaceGlobalTempView</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Creates or replaces a global temporary view using the given name.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#createOrReplaceTempView(java.lang.String)" class="member-name-link">createOrReplaceTempView</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Creates a local temporary view using the given name.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#createTempView(java.lang.String)" class="member-name-link">createTempView</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Creates a local temporary view using the given name.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#crossJoin(org.apache.spark.sql.Dataset)" class="member-name-link">crossJoin</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Explicit cartesian join with another <code>DataFrame</code>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cube(java.lang.String,java.lang.String...)" class="member-name-link">cube</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cube(java.lang.String,scala.collection.Seq)" class="member-name-link">cube</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cube(org.apache.spark.sql.Column...)" class="member-name-link">cube</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#cube(scala.collection.Seq)" class="member-name-link">cube</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/atomic/AtomicLong.html" title="class or interface in java.util.concurrent.atomic" class="external-link">AtomicLong</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#curId()" class="member-name-link">curId</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#DATASET_ID_KEY()" class="member-name-link">DATASET_ID_KEY</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">&nbsp;</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static org.apache.spark.sql.catalyst.trees.TreeNodeTag&lt;scala.collection.mutable.HashSet&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#DATASET_ID_TAG()" class="member-name-link">DATASET_ID_TAG</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#describe(java.lang.String...)" class="member-name-link">describe</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Computes basic statistics for numeric and string columns, including count, mean, stddev, min,
 and max.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#describe(scala.collection.Seq)" class="member-name-link">describe</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Computes basic statistics for numeric and string columns, including count, mean, stddev, min,
 and max.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#distinct()" class="member-name-link">distinct</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset that contains only the unique rows from this Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#drop(java.lang.String)" class="member-name-link">drop</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with a column dropped.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#drop(java.lang.String...)" class="member-name-link">drop</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;colNames)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with columns dropped.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#drop(org.apache.spark.sql.Column)" class="member-name-link">drop</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with column dropped.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#drop(org.apache.spark.sql.Column,org.apache.spark.sql.Column...)" class="member-name-link">drop</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with columns dropped.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#drop(org.apache.spark.sql.Column,scala.collection.Seq)" class="member-name-link">drop</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with columns dropped.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#drop(scala.collection.Seq)" class="member-name-link">drop</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with columns dropped.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicates()" class="member-name-link">dropDuplicates</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset that contains only the unique rows from this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicates(java.lang.String%5B%5D)" class="member-name-link">dropDuplicates</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;colNames)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with duplicate rows removed, considering only
 the subset of columns.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicates(java.lang.String,java.lang.String...)" class="member-name-link">dropDuplicates</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with duplicate rows removed, considering only
 the subset of columns.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicates(java.lang.String,scala.collection.Seq)" class="member-name-link">dropDuplicates</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with duplicate rows removed, considering only
 the subset of columns.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicates(scala.collection.Seq)" class="member-name-link">dropDuplicates</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Returns a new Dataset with duplicate rows removed, considering only
 the subset of columns.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicatesWithinWatermark()" class="member-name-link">dropDuplicatesWithinWatermark</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with duplicates rows removed, within watermark.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicatesWithinWatermark(java.lang.String%5B%5D)" class="member-name-link">dropDuplicatesWithinWatermark</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;colNames)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicatesWithinWatermark(java.lang.String,java.lang.String...)" class="member-name-link">dropDuplicatesWithinWatermark</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicatesWithinWatermark(java.lang.String,scala.collection.Seq)" class="member-name-link">dropDuplicatesWithinWatermark</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dropDuplicatesWithinWatermark(scala.collection.Seq)" class="member-name-link">dropDuplicatesWithinWatermark</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>scala.Tuple2&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;[]</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#dtypes()" class="member-name-link">dtypes</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns all column names and their data types as an array.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#encoder()" class="member-name-link">encoder</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#except(org.apache.spark.sql.Dataset)" class="member-name-link">except</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing rows in this Dataset but not in another Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#exceptAll(org.apache.spark.sql.Dataset)" class="member-name-link">exceptAll</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing rows in this Dataset but not in another Dataset while
 preserving the duplicates.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#explain()" class="member-name-link">explain</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Prints the physical plan to the console for debugging purposes.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#explain(boolean)" class="member-name-link">explain</a><wbr>(boolean&nbsp;extended)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Prints the plans (logical and physical) to the console for debugging purposes.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#explain(java.lang.String)" class="member-name-link">explain</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;mode)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Prints the plans (logical and physical) with a format specified by a given explain mode.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6"><code>&lt;A,<wbr>
B&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6"><code><a href="#explode(java.lang.String,java.lang.String,scala.Function1,scala.reflect.api.TypeTags.TypeTag)" class="member-name-link">explode</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;inputColumn,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;outputColumn,
 scala.Function1&lt;A,<wbr>scala.collection.TraversableOnce&lt;B&gt;&gt;&nbsp;f,
 scala.reflect.api.TypeTags.TypeTag&lt;B&gt;&nbsp;evidence$5)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">use flatMap() or select() with functions.explode() instead.</div>
</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6"><code>&lt;A extends scala.Product&gt;<br><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6"><code><a href="#explode(scala.collection.Seq,scala.Function1,scala.reflect.api.TypeTags.TypeTag)" class="member-name-link">explode</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;input,
 scala.Function1&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>,<wbr>scala.collection.TraversableOnce&lt;A&gt;&gt;&nbsp;f,
 scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$4)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">use flatMap() or select() with functions.explode() instead.</div>
</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#filter(java.lang.String)" class="member-name-link">filter</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;conditionExpr)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Filters rows using the given SQL expression.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#filter(org.apache.spark.api.java.function.FilterFunction)" class="member-name-link">filter</a><wbr>(<a href="../api/java/function/FilterFunction.html" title="interface in org.apache.spark.api.java.function">FilterFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Returns a new Dataset that only contains elements where <code>func</code> returns <code>true</code>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#filter(org.apache.spark.sql.Column)" class="member-name-link">filter</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Filters rows using the given condition.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#filter(scala.Function1)" class="member-name-link">filter</a><wbr>(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;func)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Returns a new Dataset that only contains elements where <code>func</code> returns <code>true</code>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="type parameter in Dataset">T</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#first()" class="member-name-link">first</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the first row.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#flatMap(org.apache.spark.api.java.function.FlatMapFunction,org.apache.spark.sql.Encoder)" class="member-name-link">flatMap</a><wbr>(<a href="../api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;f,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Returns a new Dataset by first applying a function to all elements of this Dataset,
 and then flattening the results.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#flatMap(scala.Function1,org.apache.spark.sql.Encoder)" class="member-name-link">flatMap</a><wbr>(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$8)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Returns a new Dataset by first applying a function to all elements of this Dataset,
 and then flattening the results.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#foreach(org.apache.spark.api.java.function.ForeachFunction)" class="member-name-link">foreach</a><wbr>(<a href="../api/java/function/ForeachFunction.html" title="interface in org.apache.spark.api.java.function">ForeachFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Runs <code>func</code> on each element of this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#foreach(scala.Function1)" class="member-name-link">foreach</a><wbr>(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>scala.runtime.BoxedUnit&gt;&nbsp;f)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Applies a function <code>f</code> to all rows.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#foreachPartition(org.apache.spark.api.java.function.ForeachPartitionFunction)" class="member-name-link">foreachPartition</a><wbr>(<a href="../api/java/function/ForeachPartitionFunction.html" title="interface in org.apache.spark.api.java.function">ForeachPartitionFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Runs <code>func</code> on each partition of this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#foreachPartition(scala.Function1)" class="member-name-link">foreachPartition</a><wbr>(scala.Function1&lt;scala.collection.Iterator&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;,<wbr>scala.runtime.BoxedUnit&gt;&nbsp;f)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Applies a function <code>f</code> to each partition of this Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupBy(java.lang.String,java.lang.String...)" class="member-name-link">groupBy</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Groups the Dataset using the specified columns, so that we can run aggregation on them.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupBy(java.lang.String,scala.collection.Seq)" class="member-name-link">groupBy</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Groups the Dataset using the specified columns, so that we can run aggregation on them.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupBy(org.apache.spark.sql.Column...)" class="member-name-link">groupBy</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Groups the Dataset using the specified columns, so we can run aggregation on them.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupBy(scala.collection.Seq)" class="member-name-link">groupBy</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Groups the Dataset using the specified columns, so we can run aggregation on them.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;K&gt;&nbsp;<a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql">KeyValueGroupedDataset</a>&lt;K,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKey(org.apache.spark.api.java.function.MapFunction,org.apache.spark.sql.Encoder)" class="member-name-link">groupByKey</a><wbr>(<a href="../api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>K&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;encoder)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Returns a <a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql"><code>KeyValueGroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;K&gt;&nbsp;<a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql">KeyValueGroupedDataset</a>&lt;K,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#groupByKey(scala.Function1,org.apache.spark.sql.Encoder)" class="member-name-link">groupByKey</a><wbr>(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>K&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;evidence$3)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Returns a <a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql"><code>KeyValueGroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="type parameter in Dataset">T</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#head()" class="member-name-link">head</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the first row.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#head(int)" class="member-name-link">head</a><wbr>(int&nbsp;n)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the first <code>n</code> rows.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#hint(java.lang.String,java.lang.Object...)" class="member-name-link">hint</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>...&nbsp;parameters)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Specifies some hint on the current Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#hint(java.lang.String,scala.collection.Seq)" class="member-name-link">hint</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;parameters)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Specifies some hint on the current Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#inputFiles()" class="member-name-link">inputFiles</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a best-effort snapshot of the files that compose this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#intersect(org.apache.spark.sql.Dataset)" class="member-name-link">intersect</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing rows only in both this Dataset and another Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#intersectAll(org.apache.spark.sql.Dataset)" class="member-name-link">intersectAll</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing rows only in both this Dataset and another Dataset while
 preserving the duplicates.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>boolean</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#isEmpty()" class="member-name-link">isEmpty</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns true if the <code>Dataset</code> is empty.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>boolean</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#isLocal()" class="member-name-link">isLocal</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns true if the <code>collect</code> and <code>take</code> methods can be run locally
 (without any Spark executors).</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>boolean</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#isStreaming()" class="member-name-link">isStreaming</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns true if this Dataset contains one or more sources that continuously
 return data as it arrives.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="../api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#javaRDD()" class="member-name-link">javaRDD</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the content of the Dataset as a <code>JavaRDD</code> of <code>T</code>s.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Join with another <code>DataFrame</code>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,java.lang.String)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;usingColumn)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Inner equi-join with another <code>DataFrame</code> using the given column.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,java.lang.String%5B%5D)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;usingColumns)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific) Inner equi-join with another <code>DataFrame</code> using the given columns.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,java.lang.String%5B%5D,java.lang.String)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;usingColumns,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific) Equi-join with another <code>DataFrame</code> using the given columns.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,java.lang.String,java.lang.String)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;usingColumn,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Equi-join with another <code>DataFrame</code> using the given column.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;joinExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Inner join with another <code>DataFrame</code>, using the given join expression.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column,java.lang.String)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;joinExprs,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Join with another <code>DataFrame</code>, using the given join expression.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,scala.collection.Seq)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;usingColumns)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Inner equi-join with another <code>DataFrame</code> using the given columns.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#join(org.apache.spark.sql.Dataset,scala.collection.Seq,java.lang.String)" class="member-name-link">join</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;usingColumns,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Equi-join with another <code>DataFrame</code> using the given columns.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#joinWith(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column)" class="member-name-link">joinWith</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Using inner equi-join to join this Dataset returning a <code>Tuple2</code> for each pair
 where <code>condition</code> evaluates to true.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#joinWith(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column,java.lang.String)" class="member-name-link">joinWith</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Joins this Dataset returning a <code>Tuple2</code> for each pair where <code>condition</code> evaluates to
 true.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#limit(int)" class="member-name-link">limit</a><wbr>(int&nbsp;n)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by taking the first <code>n</code> rows.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#localCheckpoint()" class="member-name-link">localCheckpoint</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Eagerly locally checkpoints a Dataset and return the new Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#localCheckpoint(boolean)" class="member-name-link">localCheckpoint</a><wbr>(boolean&nbsp;eager)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Locally checkpoints a Dataset and return the new Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#map(org.apache.spark.api.java.function.MapFunction,org.apache.spark.sql.Encoder)" class="member-name-link">map</a><wbr>(<a href="../api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Returns a new Dataset that contains the result of applying <code>func</code> to each element.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#map(scala.Function1,org.apache.spark.sql.Encoder)" class="member-name-link">map</a><wbr>(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$6)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Returns a new Dataset that contains the result of applying <code>func</code> to each element.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#mapPartitions(org.apache.spark.api.java.function.MapPartitionsFunction,org.apache.spark.sql.Encoder)" class="member-name-link">mapPartitions</a><wbr>(<a href="../api/java/function/MapPartitionsFunction.html" title="interface in org.apache.spark.api.java.function">MapPartitionsFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;f,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Returns a new Dataset that contains the result of applying <code>f</code> to each partition.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#mapPartitions(scala.Function1,org.apache.spark.sql.Encoder)" class="member-name-link">mapPartitions</a><wbr>(scala.Function1&lt;scala.collection.Iterator&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;,<wbr>scala.collection.Iterator&lt;U&gt;&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$7)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Returns a new Dataset that contains the result of applying <code>func</code> to each partition.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#melt(org.apache.spark.sql.Column%5B%5D,java.lang.String,java.lang.String)" class="member-name-link">melt</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#melt(org.apache.spark.sql.Column%5B%5D,org.apache.spark.sql.Column%5B%5D,java.lang.String,java.lang.String)" class="member-name-link">melt</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;values,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Column.html" title="class in org.apache.spark.sql">Column</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#metadataColumn(java.lang.String)" class="member-name-link">metadataColumn</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a metadata column based on its logical column name, and returns it as a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#na()" class="member-name-link">na</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a <a href="DataFrameNaFunctions.html" title="class in org.apache.spark.sql"><code>DataFrameNaFunctions</code></a> for working with missing data.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#observe(java.lang.String,org.apache.spark.sql.Column,org.apache.spark.sql.Column...)" class="member-name-link">observe</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;exprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Define (named) metrics to observe on the Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#observe(java.lang.String,org.apache.spark.sql.Column,scala.collection.Seq)" class="member-name-link">observe</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;exprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Define (named) metrics to observe on the Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#observe(org.apache.spark.sql.Observation,org.apache.spark.sql.Column,org.apache.spark.sql.Column...)" class="member-name-link">observe</a><wbr>(<a href="Observation.html" title="class in org.apache.spark.sql">Observation</a>&nbsp;observation,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;exprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Observe (named) metrics through an <code>org.apache.spark.sql.Observation</code> instance.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#observe(org.apache.spark.sql.Observation,org.apache.spark.sql.Column,scala.collection.Seq)" class="member-name-link">observe</a><wbr>(<a href="Observation.html" title="class in org.apache.spark.sql">Observation</a>&nbsp;observation,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;exprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Observe (named) metrics through an <code>org.apache.spark.sql.Observation</code> instance.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#offset(int)" class="member-name-link">offset</a><wbr>(int&nbsp;n)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by skipping the first <code>n</code> rows.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#ofRows(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)" class="member-name-link">ofRows</a><wbr>(<a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code>static <a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4"><code><a href="#ofRows(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.QueryPlanningTracker)" class="member-name-link">ofRows</a><wbr>(<a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
 org.apache.spark.sql.catalyst.QueryPlanningTracker&nbsp;tracker)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab1 method-summary-table-tab4">
<div class="block">A variant of ofRows that allows passing in a tracker so we can track query parsing time.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#orderBy(java.lang.String,java.lang.String...)" class="member-name-link">orderBy</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;sortCols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the given expressions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#orderBy(java.lang.String,scala.collection.Seq)" class="member-name-link">orderBy</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;sortCols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the given expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#orderBy(org.apache.spark.sql.Column...)" class="member-name-link">orderBy</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;sortExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the given expressions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#orderBy(scala.collection.Seq)" class="member-name-link">orderBy</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;sortExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the given expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#persist()" class="member-name-link">persist</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Persist this Dataset with the default storage level (<code>MEMORY_AND_DISK</code>).</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#persist(org.apache.spark.storage.StorageLevel)" class="member-name-link">persist</a><wbr>(<a href="../storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;newLevel)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Persist this Dataset with the given storage level.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#printSchema()" class="member-name-link">printSchema</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Prints the schema to the console in a nice tree format.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#printSchema(int)" class="member-name-link">printSchema</a><wbr>(int&nbsp;level)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Prints the schema up to the given level to the console in a nice tree format.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>org.apache.spark.sql.execution.QueryExecution</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#queryExecution()" class="member-name-link">queryExecution</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;[]</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#randomSplit(double%5B%5D)" class="member-name-link">randomSplit</a><wbr>(double[]&nbsp;weights)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Randomly splits this Dataset with the provided weights.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;[]</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#randomSplit(double%5B%5D,long)" class="member-name-link">randomSplit</a><wbr>(double[]&nbsp;weights,
 long&nbsp;seed)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Randomly splits this Dataset with the provided weights.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#randomSplitAsList(double%5B%5D,long)" class="member-name-link">randomSplitAsList</a><wbr>(double[]&nbsp;weights,
 long&nbsp;seed)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a Java list that contains randomly split Dataset with the provided weights.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rdd()" class="member-name-link">rdd</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="type parameter in Dataset">T</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduce(org.apache.spark.api.java.function.ReduceFunction)" class="member-name-link">reduce</a><wbr>(<a href="../api/java/function/ReduceFunction.html" title="interface in org.apache.spark.api.java.function">ReduceFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Reduces the elements of this Dataset using the specified binary function.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="type parameter in Dataset">T</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#reduce(scala.Function2)" class="member-name-link">reduce</a><wbr>(scala.Function2&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Reduces the elements of this Dataset using the specified binary function.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6"><code><a href="#registerTempTable(java.lang.String)" class="member-name-link">registerTempTable</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;tableName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4 method-summary-table-tab6">
<div class="block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">Use createOrReplaceTempView(viewName) instead.</div>
</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartition(int)" class="member-name-link">repartition</a><wbr>(int&nbsp;numPartitions)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset that has exactly <code>numPartitions</code> partitions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartition(int,org.apache.spark.sql.Column...)" class="member-name-link">repartition</a><wbr>(int&nbsp;numPartitions,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartition(int,scala.collection.Seq)" class="member-name-link">repartition</a><wbr>(int&nbsp;numPartitions,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartition(org.apache.spark.sql.Column...)" class="member-name-link">repartition</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartition(scala.collection.Seq)" class="member-name-link">repartition</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartitionByRange(int,org.apache.spark.sql.Column...)" class="member-name-link">repartitionByRange</a><wbr>(int&nbsp;numPartitions,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartitionByRange(int,scala.collection.Seq)" class="member-name-link">repartitionByRange</a><wbr>(int&nbsp;numPartitions,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartitionByRange(org.apache.spark.sql.Column...)" class="member-name-link">repartitionByRange</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#repartitionByRange(scala.collection.Seq)" class="member-name-link">repartitionByRange</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rollup(java.lang.String,java.lang.String...)" class="member-name-link">rollup</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rollup(java.lang.String,scala.collection.Seq)" class="member-name-link">rollup</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rollup(org.apache.spark.sql.Column...)" class="member-name-link">rollup</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#rollup(scala.collection.Seq)" class="member-name-link">rollup</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>boolean</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sameSemantics(org.apache.spark.sql.Dataset)" class="member-name-link">sameSemantics</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns <code>true</code> when the logical query plans inside both <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>s are equal and
 therefore return same results.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sample(boolean,double)" class="member-name-link">sample</a><wbr>(boolean&nbsp;withReplacement,
 double&nbsp;fraction)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows, using a random seed.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sample(boolean,double,long)" class="member-name-link">sample</a><wbr>(boolean&nbsp;withReplacement,
 double&nbsp;fraction,
 long&nbsp;seed)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows, using a user-supplied seed.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sample(double)" class="member-name-link">sample</a><wbr>(double&nbsp;fraction)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows (without replacement),
 using a random seed.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sample(double,long)" class="member-name-link">sample</a><wbr>(double&nbsp;fraction,
 long&nbsp;seed)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows (without replacement),
 using a user-supplied seed.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#schema()" class="member-name-link">schema</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the schema of this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(java.lang.String,java.lang.String...)" class="member-name-link">select</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a set of columns.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(java.lang.String,scala.collection.Seq)" class="member-name-link">select</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a set of columns.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(org.apache.spark.sql.Column...)" class="member-name-link">select</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a set of column based expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U1&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U1&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(org.apache.spark.sql.TypedColumn)" class="member-name-link">select</a><wbr>(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expression for each element.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U1,<wbr>
U2&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;U1,<wbr>U2&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)" class="member-name-link">select</a><wbr>(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U1,<wbr>
U2,<wbr>
U3&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple3&lt;U1,<wbr>U2,<wbr>U3&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)" class="member-name-link">select</a><wbr>(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U3&gt;&nbsp;c3)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U1,<wbr>
U2,<wbr>
U3,<wbr>
U4&gt;<br><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple4&lt;U1,<wbr>U2,<wbr>U3,<wbr>U4&gt;&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)" class="member-name-link">select</a><wbr>(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U3&gt;&nbsp;c3,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U4&gt;&nbsp;c4)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U1,<wbr>
U2,<wbr>
U3,<wbr>
U4,<wbr>
U5&gt;<br><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple5&lt;U1,<wbr>U2,<wbr>U3,<wbr>U4,<wbr>U5&gt;&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)" class="member-name-link">select</a><wbr>(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U3&gt;&nbsp;c3,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U4&gt;&nbsp;c4,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U5&gt;&nbsp;c5)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#select(scala.collection.Seq)" class="member-name-link">select</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a set of column based expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#selectExpr(java.lang.String...)" class="member-name-link">selectExpr</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;exprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a set of SQL expressions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#selectExpr(scala.collection.Seq)" class="member-name-link">selectExpr</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;exprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Selects a set of SQL expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>int</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#semanticHash()" class="member-name-link">semanticHash</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a <code>hashCode</code> of the logical query plan against this <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#show()" class="member-name-link">show</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Displays the top 20 rows of Dataset in a tabular form.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#show(boolean)" class="member-name-link">show</a><wbr>(boolean&nbsp;truncate)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Displays the top 20 rows of Dataset in a tabular form.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#show(int)" class="member-name-link">show</a><wbr>(int&nbsp;numRows)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Displays the Dataset in a tabular form.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#show(int,boolean)" class="member-name-link">show</a><wbr>(int&nbsp;numRows,
 boolean&nbsp;truncate)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Displays the Dataset in a tabular form.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#show(int,int)" class="member-name-link">show</a><wbr>(int&nbsp;numRows,
 int&nbsp;truncate)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Displays the Dataset in a tabular form.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>void</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#show(int,int,boolean)" class="member-name-link">show</a><wbr>(int&nbsp;numRows,
 int&nbsp;truncate,
 boolean&nbsp;vertical)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Displays the Dataset in a tabular form.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sort(java.lang.String,java.lang.String...)" class="member-name-link">sort</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;sortCols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the specified column, all in ascending order.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sort(java.lang.String,scala.collection.Seq)" class="member-name-link">sort</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;sortCols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the specified column, all in ascending order.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sort(org.apache.spark.sql.Column...)" class="member-name-link">sort</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;sortExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the given expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sort(scala.collection.Seq)" class="member-name-link">sort</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;sortExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset sorted by the given expressions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sortWithinPartitions(java.lang.String,java.lang.String...)" class="member-name-link">sortWithinPartitions</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;sortCols)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sortWithinPartitions(java.lang.String,scala.collection.Seq)" class="member-name-link">sortWithinPartitions</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;sortCols)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sortWithinPartitions(org.apache.spark.sql.Column...)" class="member-name-link">sortWithinPartitions</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;sortExprs)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sortWithinPartitions(scala.collection.Seq)" class="member-name-link">sortWithinPartitions</a><wbr>(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;sortExprs)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sparkSession()" class="member-name-link">sparkSession</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#sqlContext()" class="member-name-link">sqlContext</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#stat()" class="member-name-link">stat</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a <a href="DataFrameStatFunctions.html" title="class in org.apache.spark.sql"><code>DataFrameStatFunctions</code></a> for working statistic functions support.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="../storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#storageLevel()" class="member-name-link">storageLevel</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Get the Dataset's current storage level, or StorageLevel.NONE if not persisted.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#summary(java.lang.String...)" class="member-name-link">summary</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;statistics)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Computes specified statistics for numeric and string columns.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#summary(scala.collection.Seq)" class="member-name-link">summary</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;statistics)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Computes specified statistics for numeric and string columns.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#tail(int)" class="member-name-link">tail</a><wbr>(int&nbsp;n)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the last <code>n</code> rows in the Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#take(int)" class="member-name-link">take</a><wbr>(int&nbsp;n)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the first <code>n</code> rows in the Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#takeAsList(int)" class="member-name-link">takeAsList</a><wbr>(int&nbsp;n)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the first <code>n</code> rows in the Dataset as a list.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#to(org.apache.spark.sql.types.StructType)" class="member-name-link">to</a><wbr>(<a href="types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new DataFrame where each row is reconciled to match the specified schema.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toDF()" class="member-name-link">toDF</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Converts this strongly typed collection of data to generic Dataframe.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toDF(java.lang.String...)" class="member-name-link">toDF</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;colNames)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Converts this strongly typed collection of data to generic <code>DataFrame</code> with columns renamed.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toDF(scala.collection.Seq)" class="member-name-link">toDF</a><wbr>(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Converts this strongly typed collection of data to generic <code>DataFrame</code> with columns renamed.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="../api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toJavaRDD()" class="member-name-link">toJavaRDD</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the content of the Dataset as a <code>JavaRDD</code> of <code>T</code>s.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toJSON()" class="member-name-link">toJSON</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns the content of the Dataset as a Dataset of JSON strings.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Iterator.html" title="class or interface in java.util" class="external-link">Iterator</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toLocalIterator()" class="member-name-link">toLocalIterator</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns an iterator that contains all rows in this Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#toString()" class="member-name-link">toString</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">&nbsp;</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code>&lt;U&gt;&nbsp;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#transform(scala.Function1)" class="member-name-link">transform</a><wbr>(scala.Function1&lt;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;,<wbr><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&gt;&nbsp;t)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Concise syntax for chaining custom transformations.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#union(org.apache.spark.sql.Dataset)" class="member-name-link">union</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unionAll(org.apache.spark.sql.Dataset)" class="member-name-link">unionAll</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unionByName(org.apache.spark.sql.Dataset)" class="member-name-link">unionByName</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unionByName(org.apache.spark.sql.Dataset,boolean)" class="member-name-link">unionByName</a><wbr>(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other,
 boolean&nbsp;allowMissingColumns)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unpersist()" class="member-name-link">unpersist</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unpersist(boolean)" class="member-name-link">unpersist</a><wbr>(boolean&nbsp;blocking)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unpivot(org.apache.spark.sql.Column%5B%5D,java.lang.String,java.lang.String)" class="member-name-link">unpivot</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#unpivot(org.apache.spark.sql.Column%5B%5D,org.apache.spark.sql.Column%5B%5D,java.lang.String,java.lang.String)" class="member-name-link">unpivot</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;values,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#where(java.lang.String)" class="member-name-link">where</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;conditionExpr)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Filters rows using the given SQL expression.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#where(org.apache.spark.sql.Column)" class="member-name-link">where</a><wbr>(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Filters rows using the given condition.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withColumn(java.lang.String,org.apache.spark.sql.Column)" class="member-name-link">withColumn</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by adding a column or replacing the existing column that has
 the same name.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withColumnRenamed(java.lang.String,java.lang.String)" class="member-name-link">withColumnRenamed</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;existingName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;newName)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset with a column renamed.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withColumns(java.util.Map)" class="member-name-link">withColumns</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html" title="class or interface in java.util" class="external-link">Map</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;colsMap)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific) Returns a new Dataset by adding columns or replacing the existing columns
 that has the same names.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withColumns(scala.collection.immutable.Map)" class="member-name-link">withColumns</a><wbr>(scala.collection.immutable.Map&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;colsMap)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific) Returns a new Dataset by adding columns or replacing the existing columns
 that has the same names.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withColumnsRenamed(java.util.Map)" class="member-name-link">withColumnsRenamed</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html" title="class or interface in java.util" class="external-link">Map</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colsMap)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Java-specific)
 Returns a new Dataset with a columns renamed.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withColumnsRenamed(scala.collection.immutable.Map)" class="member-name-link">withColumnsRenamed</a><wbr>(scala.collection.immutable.Map&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colsMap)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">(Scala-specific)
 Returns a new Dataset with a columns renamed.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withMetadata(java.lang.String,org.apache.spark.sql.types.Metadata)" class="member-name-link">withMetadata</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;columnName,
 <a href="types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</a>&nbsp;metadata)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Returns a new Dataset by updating an existing column with metadata.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#withWatermark(java.lang.String,java.lang.String)" class="member-name-link">withWatermark</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;eventTime,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;delayThreshold)</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Defines an event time watermark for this <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#write()" class="member-name-link">write</a>()</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Interface for saving the content of the non-streaming Dataset out into external storage.</div>
</div>
<div class="col-first even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#writeStream()" class="member-name-link">writeStream</a>()</code></div>
<div class="col-last even-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Interface for saving the content of the streaming Dataset out into external storage.</div>
</div>
<div class="col-first odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="DataFrameWriterV2.html" title="class in org.apache.spark.sql">DataFrameWriterV2</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</code></div>
<div class="col-second odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4"><code><a href="#writeTo(java.lang.String)" class="member-name-link">writeTo</a><wbr>(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;table)</code></div>
<div class="col-last odd-row-color method-summary-table method-summary-table-tab2 method-summary-table-tab4">
<div class="block">Create a write configuration builder for v2 sources.</div>
</div>
</div>
</div>
</div>
<div class="inherited-list">
<h3 id="methods-inherited-from-class-Object">Methods inherited from class&nbsp;java.lang.<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></h3>
<code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object)" title="class or interface in java.lang" class="external-link">equals</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#getClass()" title="class or interface in java.lang" class="external-link">getClass</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#hashCode()" title="class or interface in java.lang" class="external-link">hashCode</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#notify()" title="class or interface in java.lang" class="external-link">notify</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#notifyAll()" title="class or interface in java.lang" class="external-link">notifyAll</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait()" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait(long)" title="class or interface in java.lang" class="external-link">wait</a>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#wait(long,int)" title="class or interface in java.lang" class="external-link">wait</a></code></div>
</section>
</li>
</ul>
</section>
<section class="details">
<ul class="details-list">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<li>
<section class="constructor-details" id="constructor-detail">
<h2>Constructor Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="&lt;init&gt;(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.Encoder)">
<h3>Dataset</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="element-name">Dataset</span><wbr><span class="parameters">(<a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;encoder)</span></div>
</section>
</li>
<li>
<section class="detail" id="&lt;init&gt;(org.apache.spark.sql.SQLContext,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.Encoder)">
<h3>Dataset</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="element-name">Dataset</span><wbr><span class="parameters">(<a href="SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;encoder)</span></div>
</section>
</li>
</ul>
</section>
</li>
<!-- ============ METHOD DETAIL ========== -->
<li>
<section class="method-details" id="method-detail">
<h2>Method Details</h2>
<ul class="member-list">
<li>
<section class="detail" id="curId()">
<h3>curId</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/concurrent/atomic/AtomicLong.html" title="class or interface in java.util.concurrent.atomic" class="external-link">AtomicLong</a></span>&nbsp;<span class="element-name">curId</span>()</div>
</section>
</li>
<li>
<section class="detail" id="DATASET_ID_KEY()">
<h3>DATASET_ID_KEY</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></span>&nbsp;<span class="element-name">DATASET_ID_KEY</span>()</div>
</section>
</li>
<li>
<section class="detail" id="COL_POS_KEY()">
<h3>COL_POS_KEY</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></span>&nbsp;<span class="element-name">COL_POS_KEY</span>()</div>
</section>
</li>
<li>
<section class="detail" id="DATASET_ID_TAG()">
<h3>DATASET_ID_TAG</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type">org.apache.spark.sql.catalyst.trees.TreeNodeTag&lt;scala.collection.mutable.HashSet&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&gt;</span>&nbsp;<span class="element-name">DATASET_ID_TAG</span>()</div>
</section>
</li>
<li>
<section class="detail" id="ofRows(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<h3>ofRows</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">ofRows</span><wbr><span class="parameters">(<a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan)</span></div>
</section>
</li>
<li>
<section class="detail" id="ofRows(org.apache.spark.sql.SparkSession,org.apache.spark.sql.catalyst.plans.logical.LogicalPlan,org.apache.spark.sql.catalyst.QueryPlanningTracker)">
<h3>ofRows</h3>
<div class="member-signature"><span class="modifiers">public static</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">ofRows</span><wbr><span class="parameters">(<a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession,
 org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;logicalPlan,
 org.apache.spark.sql.catalyst.QueryPlanningTracker&nbsp;tracker)</span></div>
<div class="block">A variant of ofRows that allows passing in a tracker so we can track query parsing time.</div>
</section>
</li>
<li>
<section class="detail" id="toDF(java.lang.String...)">
<h3>toDF</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">toDF</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;colNames)</span></div>
<div class="block">Converts this strongly typed collection of data to generic <code>DataFrame</code> with columns renamed.
 This can be quite convenient in conversion from an RDD of tuples into a <code>DataFrame</code> with
 meaningful names. For example:
 <pre><code>
   val rdd: RDD[(Int, String)] = ...
   rdd.toDF()  // this implicit conversion creates a DataFrame with column name `_1` and `_2`
   rdd.toDF("id", "name")  // this creates a DataFrame with column name "id" and "name"
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sortWithinPartitions(java.lang.String,java.lang.String...)">
<h3>sortWithinPartitions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sortWithinPartitions</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;sortCols)</span></div>
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.
 <p>
 This is the same operation as "SORT BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortCol</code> - (undocumented)</dd>
<dd><code>sortCols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sortWithinPartitions(org.apache.spark.sql.Column...)">
<h3>sortWithinPartitions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sortWithinPartitions</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;sortExprs)</span></div>
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.
 <p>
 This is the same operation as "SORT BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sort(java.lang.String,java.lang.String...)">
<h3>sort</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sort</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;sortCols)</span></div>
<div class="block">Returns a new Dataset sorted by the specified column, all in ascending order.
 <pre><code>
   // The following 3 are equivalent
   ds.sort("sortcol")
   ds.sort($"sortcol")
   ds.sort($"sortcol".asc)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortCol</code> - (undocumented)</dd>
<dd><code>sortCols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sort(org.apache.spark.sql.Column...)">
<h3>sort</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sort</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;sortExprs)</span></div>
<div class="block">Returns a new Dataset sorted by the given expressions. For example:
 <pre><code>
   ds.sort($"col1", $"col2".desc)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="orderBy(java.lang.String,java.lang.String...)">
<h3>orderBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">orderBy</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;sortCols)</span></div>
<div class="block">Returns a new Dataset sorted by the given expressions.
 This is an alias of the <code>sort</code> function.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortCol</code> - (undocumented)</dd>
<dd><code>sortCols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="orderBy(org.apache.spark.sql.Column...)">
<h3>orderBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">orderBy</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;sortExprs)</span></div>
<div class="block">Returns a new Dataset sorted by the given expressions.
 This is an alias of the <code>sort</code> function.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="hint(java.lang.String,java.lang.Object...)">
<h3>hint</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">hint</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>...&nbsp;parameters)</span></div>
<div class="block">Specifies some hint on the current Dataset. As an example, the following code specifies
 that one of the plan can be broadcasted:
 <p>
 <pre><code>
   df1.join(df2.hint("broadcast"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>name</code> - (undocumented)</dd>
<dd><code>parameters</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.2.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(org.apache.spark.sql.Column...)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</span></div>
<div class="block">Selects a set of column based expressions.
 <pre><code>
   ds.select($"colA", $"colB" + 1)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(java.lang.String,java.lang.String...)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Selects a set of columns. This is a variant of <code>select</code> that can only select
 existing columns using column names (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // The following two are equivalent:
   ds.select("colA", "colB")
   ds.select($"colA", $"colB")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="selectExpr(java.lang.String...)">
<h3>selectExpr</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">selectExpr</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;exprs)</span></div>
<div class="block">Selects a set of SQL expressions. This is a variant of <code>select</code> that accepts
 SQL expressions.
 <p>
 <pre><code>
   // The following are equivalent:
   ds.selectExpr("colA", "colB as newName", "abs(colC)")
   ds.select(expr("colA"), expr("colB as newName"), expr("abs(colC)"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupBy(org.apache.spark.sql.Column...)">
<h3>groupBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">groupBy</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</span></div>
<div class="block">Groups the Dataset using the specified columns, so we can run aggregation on them. See
 <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 <pre><code>
   // Compute the average for all numeric columns grouped by department.
   ds.groupBy($"department").avg()

   // Compute the max age and average salary, grouped by department and gender.
   ds.groupBy($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rollup(org.apache.spark.sql.Column...)">
<h3>rollup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">rollup</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 <pre><code>
   // Compute the average for all numeric columns rolled up by department and group.
   ds.rollup($"department", $"group").avg()

   // Compute the max age and average salary, rolled up by department and gender.
   ds.rollup($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cube(org.apache.spark.sql.Column...)">
<h3>cube</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">cube</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 <pre><code>
   // Compute the average for all numeric columns cubed by department and group.
   ds.cube($"department", $"group").avg()

   // Compute the max age and average salary, cubed by department and gender.
   ds.cube($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupBy(java.lang.String,java.lang.String...)">
<h3>groupBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">groupBy</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Groups the Dataset using the specified columns, so that we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 This is a variant of groupBy that can only group by existing columns using column names
 (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // Compute the average for all numeric columns grouped by department.
   ds.groupBy("department").avg()

   // Compute the max age and average salary, grouped by department and gender.
   ds.groupBy($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rollup(java.lang.String,java.lang.String...)">
<h3>rollup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">rollup</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 This is a variant of rollup that can only group by existing columns using column names
 (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // Compute the average for all numeric columns rolled up by department and group.
   ds.rollup("department", "group").avg()

   // Compute the max age and average salary, rolled up by department and gender.
   ds.rollup($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cube(java.lang.String,java.lang.String...)">
<h3>cube</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">cube</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 This is a variant of cube that can only group by existing columns using column names
 (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // Compute the average for all numeric columns cubed by department and group.
   ds.cube("department", "group").avg()

   // Compute the max age and average salary, cubed by department and gender.
   ds.cube($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="agg(org.apache.spark.sql.Column,org.apache.spark.sql.Column...)">
<h3>agg</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">agg</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;exprs)</span></div>
<div class="block">Aggregates on the entire Dataset without groups.
 <pre><code>
   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)
   ds.agg(max($"age"), avg($"salary"))
   ds.groupBy().agg(max($"age"), avg($"salary"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>expr</code> - (undocumented)</dd>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="observe(java.lang.String,org.apache.spark.sql.Column,org.apache.spark.sql.Column...)">
<h3>observe</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">observe</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;exprs)</span></div>
<div class="block">Define (named) metrics to observe on the Dataset. This method returns an 'observed' Dataset
 that returns the same result as the input, with the following guarantees:
 <ul>
   <li>It will compute the defined aggregates (metrics) on all the data that is flowing through
   the Dataset at that point.</li>
   <li>It will report the value of the defined aggregate columns as soon as we reach a completion
   point. A completion point is either the end of a query (batch mode) or the end of a streaming
   epoch. The value of the aggregates only reflects the data processed since the previous
   completion point.</li>
 </ul>
 Please note that continuous execution is currently not supported.
 <p>
 The metrics columns must either contain a literal (e.g. lit(42)), or should contain one or
 more aggregate functions (e.g. sum(a) or sum(a + b) + avg(c) - lit(1)). Expressions that
 contain references to the input Dataset's columns must always be wrapped in an aggregate
 function.
 <p>
 A user can observe these metrics by either adding
 <a href="streaming/StreamingQueryListener.html" title="class in org.apache.spark.sql.streaming"><code>StreamingQueryListener</code></a> or a
 <a href="util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a> to the spark session.
 <p>
 <pre><code>
   // Monitor the metrics using a listener.
   spark.streams.addListener(new StreamingQueryListener() {
     override def onQueryStarted(event: QueryStartedEvent): Unit = {}
     override def onQueryProgress(event: QueryProgressEvent): Unit = {
       event.progress.observedMetrics.asScala.get("my_event").foreach { row =&gt;
         // Trigger if the number of errors exceeds 5 percent
         val num_rows = row.getAs[Long]("rc")
         val num_error_rows = row.getAs[Long]("erc")
         val ratio = num_error_rows.toDouble / num_rows
         if (ratio &gt; 0.05) {
           // Trigger alert
         }
       }
     }
     override def onQueryTerminated(event: QueryTerminatedEvent): Unit = {}
   })
   // Observe row count (rc) and error row count (erc) in the streaming Dataset
   val observed_ds = ds.observe("my_event", count(lit(1)).as("rc"), count($"error").as("erc"))
   observed_ds.writeStream.format("...").start()
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>name</code> - (undocumented)</dd>
<dd><code>expr</code> - (undocumented)</dd>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="observe(org.apache.spark.sql.Observation,org.apache.spark.sql.Column,org.apache.spark.sql.Column...)">
<h3>observe</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">observe</span><wbr><span class="parameters">(<a href="Observation.html" title="class in org.apache.spark.sql">Observation</a>&nbsp;observation,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;exprs)</span></div>
<div class="block">Observe (named) metrics through an <code>org.apache.spark.sql.Observation</code> instance.
 This is equivalent to calling <code>observe(String, Column, Column*)</code> but does not require
 adding <code>org.apache.spark.sql.util.QueryExecutionListener</code> to the spark session.
 This method does not support streaming datasets.
 <p>
 A user can retrieve the metrics by accessing <code>org.apache.spark.sql.Observation.get</code>.
 <p>
 <pre><code>
   // Observe row count (rows) and highest id (maxid) in the Dataset while writing it
   val observation = Observation("my_metrics")
   val observed_ds = ds.observe(observation, count(lit(1)).as("rows"), max($"id").as("maxid"))
   observed_ds.write.parquet("ds.parquet")
   val metrics = observation.get
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>observation</code> - (undocumented)</dd>
<dd><code>expr</code> - (undocumented)</dd>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Throws:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/IllegalArgumentException.html" title="class or interface in java.lang" class="external-link">IllegalArgumentException</a></code> - If this is a streaming Dataset (this.isStreaming == true)
 <p></dd>
<dt>Since:</dt>
<dd>3.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="drop(java.lang.String...)">
<h3>drop</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">drop</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;colNames)</span></div>
<div class="block">Returns a new Dataset with columns dropped.
 This is a no-op if schema doesn't contain column name(s).
 <p>
 This method can only be used to drop top level columns. the colName string is treated literally
 without further interpretation.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="drop(org.apache.spark.sql.Column,org.apache.spark.sql.Column...)">
<h3>drop</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">drop</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;cols)</span></div>
<div class="block">Returns a new Dataset with columns dropped.
 <p>
 This method can only be used to drop top level columns.
 This is a no-op if the Dataset doesn't have a columns
 with an equivalent expression.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicates(java.lang.String,java.lang.String...)">
<h3>dropDuplicates</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicates</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with duplicate rows removed, considering only
 the subset of columns.
 <p>
 For a static batch <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it just drops duplicate rows. For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it
 will keep all data across triggers as intermediate state to drop duplicates rows. You can use
 <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a> to limit how late the duplicate data can be and system will accordingly limit
 the state. In addition, too late data older than watermark will be dropped to avoid any
 possibility of duplicates.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicatesWithinWatermark(java.lang.String,java.lang.String...)">
<h3>dropDuplicatesWithinWatermark</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicatesWithinWatermark</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.
 <p>
 This only works with streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, and watermark for the input <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> must be
 set via <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a>.
 <p>
 For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, this will keep all data across triggers as intermediate state
 to drop duplicated rows. The state will be kept to guarantee the semantic, "Events are
 deduplicated as long as the time distance of earliest and latest events are smaller than the
 delay threshold of watermark." Users are encouraged to set the delay threshold of watermark
 longer than max timestamp differences among duplicated events.
 <p>
 Note: too late data older than watermark will be dropped.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.5.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="describe(java.lang.String...)">
<h3>describe</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">describe</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;cols)</span></div>
<div class="block">Computes basic statistics for numeric and string columns, including count, mean, stddev, min,
 and max. If no columns are given, this function computes statistics for all numerical or
 string columns.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting Dataset. If you want to
 programmatically compute summary statistics, use the <code>agg</code> function instead.
 <p>
 <pre><code>
   ds.describe("age", "height").show()

   // output:
   // summary age   height
   // count   10.0  10.0
   // mean    53.3  178.05
   // stddev  11.6  15.7
   // min     18.0  163.0
   // max     92.0  192.0
 </code></pre>
 <p>
 Use <a href="#summary(java.lang.String...)"><code>summary(java.lang.String...)</code></a> for expanded statistics and control over which statistics to compute.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - Columns to compute statistics on.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="summary(java.lang.String...)">
<h3>summary</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">summary</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>...&nbsp;statistics)</span></div>
<div class="block">Computes specified statistics for numeric and string columns. Available statistics are:
 <ul>
   <li>count</li>
   <li>mean</li>
   <li>stddev</li>
   <li>min</li>
   <li>max</li>
   <li>arbitrary approximate percentiles specified as a percentage (e.g. 75%)</li>
   <li>count_distinct</li>
   <li>approx_count_distinct</li>
 </ul>
 <p>
 If no statistics are given, this function computes count, mean, stddev, min,
 approximate quartiles (percentiles at 25%, 50%, and 75%), and max.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting Dataset. If you want to
 programmatically compute summary statistics, use the <code>agg</code> function instead.
 <p>
 <pre><code>
   ds.summary().show()

   // output:
   // summary age   height
   // count   10.0  10.0
   // mean    53.3  178.05
   // stddev  11.6  15.7
   // min     18.0  163.0
   // 25%     24.0  176.0
   // 50%     24.0  176.0
   // 75%     32.0  180.0
   // max     92.0  192.0
 </code></pre>
 <p>
 <pre><code>
   ds.summary("count", "min", "25%", "75%", "max").show()

   // output:
   // summary age   height
   // count   10.0  10.0
   // min     18.0  163.0
   // 25%     24.0  176.0
   // 75%     32.0  180.0
   // max     92.0  192.0
 </code></pre>
 <p>
 To do a summary for specific columns first select them:
 <p>
 <pre><code>
   ds.select("age", "height").summary().show()
 </code></pre>
 <p>
 Specify statistics to output custom summaries:
 <p>
 <pre><code>
   ds.summary("count", "count_distinct").show()
 </code></pre>
 <p>
 The distinct count isn't included by default.
 <p>
 You can also run approximate distinct counts which are faster:
 <p>
 <pre><code>
   ds.summary("count", "approx_count_distinct").show()
 </code></pre>
 <p>
 See also <a href="#describe(java.lang.String...)"><code>describe(java.lang.String...)</code></a> for basic statistics.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>statistics</code> - Statistics from above list to be computed.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition(int,org.apache.spark.sql.Column...)">
<h3>repartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartition</span><wbr><span class="parameters">(int&nbsp;numPartitions,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>. The resulting Dataset is hash partitioned.
 <p>
 This is the same operation as "DISTRIBUTE BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition(org.apache.spark.sql.Column...)">
<h3>repartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartition</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.
 The resulting Dataset is hash partitioned.
 <p>
 This is the same operation as "DISTRIBUTE BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartitionByRange(int,org.apache.spark.sql.Column...)">
<h3>repartitionByRange</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartitionByRange</span><wbr><span class="parameters">(int&nbsp;numPartitions,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>. The resulting Dataset is range partitioned.
 <p>
 At least one partition-by expression must be specified.
 When no explicit sort order is specified, "ascending nulls first" is assumed.
 Note, the rows are not sorted in each partition of the resulting Dataset.
 <p>
 Note that due to performance reasons this method uses sampling to estimate the ranges.
 Hence, the output may not be consistent, since sampling can return different values.
 The sample size can be controlled by the config
 <code>spark.sql.execution.rangeExchange.sampleSizePerPartition</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartitionByRange(org.apache.spark.sql.Column...)">
<h3>repartitionByRange</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartitionByRange</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>...&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.
 The resulting Dataset is range partitioned.
 <p>
 At least one partition-by expression must be specified.
 When no explicit sort order is specified, "ascending nulls first" is assumed.
 Note, the rows are not sorted in each partition of the resulting Dataset.
 <p>
 Note that due to performance reasons this method uses sampling to estimate the ranges.
 Hence, the output may not be consistent, since sampling can return different values.
 The sample size can be controlled by the config
 <code>spark.sql.execution.rangeExchange.sampleSizePerPartition</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="queryExecution()">
<h3>queryExecution</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">org.apache.spark.sql.execution.QueryExecution</span>&nbsp;<span class="element-name">queryExecution</span>()</div>
</section>
</li>
<li>
<section class="detail" id="encoder()">
<h3>encoder</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">encoder</span>()</div>
</section>
</li>
<li>
<section class="detail" id="sparkSession()">
<h3>sparkSession</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a></span>&nbsp;<span class="element-name">sparkSession</span>()</div>
</section>
</li>
<li>
<section class="detail" id="classTag()">
<h3>classTag</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">scala.reflect.ClassTag&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">classTag</span>()</div>
</section>
</li>
<li>
<section class="detail" id="sqlContext()">
<h3>sqlContext</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></span>&nbsp;<span class="element-name">sqlContext</span>()</div>
</section>
</li>
<li>
<section class="detail" id="toString()">
<h3>toString</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a></span>&nbsp;<span class="element-name">toString</span>()</div>
<dl class="notes">
<dt>Overrides:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#toString()" title="class or interface in java.lang" class="external-link">toString</a></code>&nbsp;in class&nbsp;<code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></code></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toDF()">
<h3>toDF</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">toDF</span>()</div>
<div class="block">Converts this strongly typed collection of data to generic Dataframe. In contrast to the
 strongly typed objects that Dataset operations work on, a Dataframe returns generic <a href="Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>
 objects that allow fields to be accessed by ordinal or name.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="as(org.apache.spark.sql.Encoder)">
<h3>as</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">as</span><wbr><span class="parameters">(<a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$2)</span></div>
<div class="block">Returns a new Dataset where each record has been mapped on to the specified type. The
 method used to map columns depend on the type of <code>U</code>:
 <ul>
   <li>When <code>U</code> is a class, fields for the class will be mapped to columns of the same name
   (case sensitivity is determined by <code>spark.sql.caseSensitive</code>).</li>
   <li>When <code>U</code> is a tuple, the columns will be mapped by ordinal (i.e. the first column will
   be assigned to <code>_1</code>).</li>
   <li>When <code>U</code> is a primitive type (i.e. String, Int, etc), then the first column of the
   <code>DataFrame</code> will be used.</li>
 </ul>
 <p>
 If the schema of the Dataset does not match the desired <code>U</code> type, you can use <code>select</code>
 along with <code>alias</code> or <code>as</code> to rearrange or rename as required.
 <p>
 Note that <code>as[]</code> only changes the view of the data that is passed into typed operations,
 such as <code>map()</code>, and does not eagerly project away any columns that are not present in
 the specified class.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>evidence$2</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="to(org.apache.spark.sql.types.StructType)">
<h3>to</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">to</span><wbr><span class="parameters">(<a href="types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</span></div>
<div class="block">Returns a new DataFrame where each row is reconciled to match the specified schema. Spark will:
 <ul>
   <li>Reorder columns and/or inner fields by name to match the specified schema.</li>
   <li>Project away columns and/or inner fields that are not needed by the specified schema.
   Missing columns and/or inner fields (present in the specified schema but not input DataFrame)
   lead to failures.</li>
   <li>Cast the columns and/or inner fields to match the data types in the specified schema, if
   the types are compatible, e.g., numeric to numeric (error if overflows), but not string to
   int.</li>
   <li>Carry over the metadata from the specified schema, while the columns and/or inner fields
   still keep their own metadata if not overwritten by the specified schema.</li>
   <li>Fail if the nullability is not compatible. For example, the column and/or inner field is
   nullable but the specified schema requires them to be not nullable.</li>
 </ul>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>schema</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toDF(scala.collection.Seq)">
<h3>toDF</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">toDF</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</span></div>
<div class="block">Converts this strongly typed collection of data to generic <code>DataFrame</code> with columns renamed.
 This can be quite convenient in conversion from an RDD of tuples into a <code>DataFrame</code> with
 meaningful names. For example:
 <pre><code>
   val rdd: RDD[(Int, String)] = ...
   rdd.toDF()  // this implicit conversion creates a DataFrame with column name `_1` and `_2`
   rdd.toDF("id", "name")  // this creates a DataFrame with column name "id" and "name"
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="schema()">
<h3>schema</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a></span>&nbsp;<span class="element-name">schema</span>()</div>
<div class="block">Returns the schema of this Dataset.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="printSchema()">
<h3>printSchema</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">printSchema</span>()</div>
<div class="block">Prints the schema to the console in a nice tree format.
 <p></div>
<dl class="notes">
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="printSchema(int)">
<h3>printSchema</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">printSchema</span><wbr><span class="parameters">(int&nbsp;level)</span></div>
<div class="block">Prints the schema up to the given level to the console in a nice tree format.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>level</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>3.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="explain(java.lang.String)">
<h3>explain</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">explain</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;mode)</span></div>
<div class="block">Prints the plans (logical and physical) with a format specified by a given explain mode.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>mode</code> - specifies the expected output format of plans.
             <ul>
               <li><code>simple</code> Print only a physical plan.</li>
               <li><code>extended</code>: Print both logical and physical plans.</li>
               <li><code>codegen</code>: Print a physical plan and generated codes if they are
                 available.</li>
               <li><code>cost</code>: Print a logical plan and statistics if they are available.</li>
               <li><code>formatted</code>: Split explain output into two sections: a physical plan outline
                 and node details.</li>
             </ul></dd>
<dt>Since:</dt>
<dd>3.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="explain(boolean)">
<h3>explain</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">explain</span><wbr><span class="parameters">(boolean&nbsp;extended)</span></div>
<div class="block">Prints the plans (logical and physical) to the console for debugging purposes.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>extended</code> - default <code>false</code>. If <code>false</code>, prints only the physical plan.
 <p></dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="explain()">
<h3>explain</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">explain</span>()</div>
<div class="block">Prints the physical plan to the console for debugging purposes.
 <p></div>
<dl class="notes">
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dtypes()">
<h3>dtypes</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">scala.Tuple2&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;[]</span>&nbsp;<span class="element-name">dtypes</span>()</div>
<div class="block">Returns all column names and their data types as an array.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="columns()">
<h3>columns</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]</span>&nbsp;<span class="element-name">columns</span>()</div>
<div class="block">Returns all column names as an array.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="isLocal()">
<h3>isLocal</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">boolean</span>&nbsp;<span class="element-name">isLocal</span>()</div>
<div class="block">Returns true if the <code>collect</code> and <code>take</code> methods can be run locally
 (without any Spark executors).
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="isEmpty()">
<h3>isEmpty</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">boolean</span>&nbsp;<span class="element-name">isEmpty</span>()</div>
<div class="block">Returns true if the <code>Dataset</code> is empty.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="isStreaming()">
<h3>isStreaming</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">boolean</span>&nbsp;<span class="element-name">isStreaming</span>()</div>
<div class="block">Returns true if this Dataset contains one or more sources that continuously
 return data as it arrives. A Dataset that reads data from a streaming source
 must be executed as a <code>StreamingQuery</code> using the <code>start()</code> method in
 <code>DataStreamWriter</code>. Methods that return a single answer, e.g. <code>count()</code> or
 <code>collect()</code>, will throw an <a href="AnalysisException.html" title="class in org.apache.spark.sql"><code>AnalysisException</code></a> when there is a streaming
 source present.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="checkpoint()">
<h3>checkpoint</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">checkpoint</span>()</div>
<div class="block">Eagerly checkpoint a Dataset and return the new Dataset. Checkpointing can be used to truncate
 the logical plan of this Dataset, which is especially useful in iterative algorithms where the
 plan may grow exponentially. It will be saved to files inside the checkpoint
 directory set with <code>SparkContext#setCheckpointDir</code>.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.1.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="checkpoint(boolean)">
<h3>checkpoint</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">checkpoint</span><wbr><span class="parameters">(boolean&nbsp;eager)</span></div>
<div class="block">Returns a checkpointed version of this Dataset. Checkpointing can be used to truncate the
 logical plan of this Dataset, which is especially useful in iterative algorithms where the
 plan may grow exponentially. It will be saved to files inside the checkpoint
 directory set with <code>SparkContext#setCheckpointDir</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>eager</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.1.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="localCheckpoint()">
<h3>localCheckpoint</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">localCheckpoint</span>()</div>
<div class="block">Eagerly locally checkpoints a Dataset and return the new Dataset. Checkpointing can be
 used to truncate the logical plan of this Dataset, which is especially useful in iterative
 algorithms where the plan may grow exponentially. Local checkpoints are written to executor
 storage and despite potentially faster they are unreliable and may compromise job completion.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="localCheckpoint(boolean)">
<h3>localCheckpoint</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">localCheckpoint</span><wbr><span class="parameters">(boolean&nbsp;eager)</span></div>
<div class="block">Locally checkpoints a Dataset and return the new Dataset. Checkpointing can be used to truncate
 the logical plan of this Dataset, which is especially useful in iterative algorithms where the
 plan may grow exponentially. Local checkpoints are written to executor storage and despite
 potentially faster they are unreliable and may compromise job completion.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>eager</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withWatermark(java.lang.String,java.lang.String)">
<h3>withWatermark</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">withWatermark</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;eventTime,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;delayThreshold)</span></div>
<div class="block">Defines an event time watermark for this <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>. A watermark tracks a point in time
 before which we assume no more late data is going to arrive.
 <p>
 Spark will use this watermark for several purposes:
 <ul>
   <li>To know when a given time window aggregation can be finalized and thus can be emitted
   when using output modes that do not allow updates.</li>
   <li>To minimize the amount of state that we need to keep for on-going aggregations,
    <code>mapGroupsWithState</code> and <code>dropDuplicates</code> operators.</li>
 </ul>
  The current watermark is computed by looking at the <code>MAX(eventTime)</code> seen across
  all of the partitions in the query minus a user specified <code>delayThreshold</code>.  Due to the cost
  of coordinating this value across partitions, the actual watermark used is only guaranteed
  to be at least <code>delayThreshold</code> behind the actual event time.  In some cases we may still
  process records that arrive more than <code>delayThreshold</code> late.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>eventTime</code> - the name of the column that contains the event time of the row.</dd>
<dd><code>delayThreshold</code> - the minimum delay to wait to data to arrive late, relative to the latest
                       record that has been processed in the form of an interval
                       (e.g. "1 minute" or "5 hours"). NOTE: This should not be negative.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.1.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="show(int)">
<h3>show</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">show</span><wbr><span class="parameters">(int&nbsp;numRows)</span></div>
<div class="block">Displays the Dataset in a tabular form. Strings more than 20 characters will be truncated,
 and all cells will be aligned right. For example:
 <pre><code>
   year  month AVG('Adj Close) MAX('Adj Close)
   1980  12    0.503218        0.595103
   1981  01    0.523289        0.570307
   1982  02    0.436504        0.475256
   1983  03    0.410516        0.442194
   1984  04    0.450090        0.483521
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numRows</code> - Number of rows to show
 <p></dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="show()">
<h3>show</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">show</span>()</div>
<div class="block">Displays the top 20 rows of Dataset in a tabular form. Strings more than 20 characters
 will be truncated, and all cells will be aligned right.
 <p></div>
<dl class="notes">
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="show(boolean)">
<h3>show</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">show</span><wbr><span class="parameters">(boolean&nbsp;truncate)</span></div>
<div class="block">Displays the top 20 rows of Dataset in a tabular form.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>truncate</code> - Whether truncate long strings. If true, strings more than 20 characters will
                 be truncated and all cells will be aligned right
 <p></dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="show(int,boolean)">
<h3>show</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">show</span><wbr><span class="parameters">(int&nbsp;numRows,
 boolean&nbsp;truncate)</span></div>
<div class="block">Displays the Dataset in a tabular form. For example:
 <pre><code>
   year  month AVG('Adj Close) MAX('Adj Close)
   1980  12    0.503218        0.595103
   1981  01    0.523289        0.570307
   1982  02    0.436504        0.475256
   1983  03    0.410516        0.442194
   1984  04    0.450090        0.483521
 </code></pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numRows</code> - Number of rows to show</dd>
<dd><code>truncate</code> - Whether truncate long strings. If true, strings more than 20 characters will
              be truncated and all cells will be aligned right
 <p></dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="show(int,int)">
<h3>show</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">show</span><wbr><span class="parameters">(int&nbsp;numRows,
 int&nbsp;truncate)</span></div>
<div class="block">Displays the Dataset in a tabular form. For example:
 <pre><code>
   year  month AVG('Adj Close) MAX('Adj Close)
   1980  12    0.503218        0.595103
   1981  01    0.523289        0.570307
   1982  02    0.436504        0.475256
   1983  03    0.410516        0.442194
   1984  04    0.450090        0.483521
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numRows</code> - Number of rows to show</dd>
<dd><code>truncate</code> - If set to more than 0, truncates strings to <code>truncate</code> characters and
                    all cells will be aligned right.</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="show(int,int,boolean)">
<h3>show</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">show</span><wbr><span class="parameters">(int&nbsp;numRows,
 int&nbsp;truncate,
 boolean&nbsp;vertical)</span></div>
<div class="block">Displays the Dataset in a tabular form. For example:
 <pre><code>
   year  month AVG('Adj Close) MAX('Adj Close)
   1980  12    0.503218        0.595103
   1981  01    0.523289        0.570307
   1982  02    0.436504        0.475256
   1983  03    0.410516        0.442194
   1984  04    0.450090        0.483521
 </code></pre>
 <p>
 If <code>vertical</code> enabled, this command prints output rows vertically (one line per column value)?
 <p>
 <pre><code>
 -RECORD 0-------------------
  year            | 1980
  month           | 12
  AVG('Adj Close) | 0.503218
  AVG('Adj Close) | 0.595103
 -RECORD 1-------------------
  year            | 1981
  month           | 01
  AVG('Adj Close) | 0.523289
  AVG('Adj Close) | 0.570307
 -RECORD 2-------------------
  year            | 1982
  month           | 02
  AVG('Adj Close) | 0.436504
  AVG('Adj Close) | 0.475256
 -RECORD 3-------------------
  year            | 1983
  month           | 03
  AVG('Adj Close) | 0.410516
  AVG('Adj Close) | 0.442194
 -RECORD 4-------------------
  year            | 1984
  month           | 04
  AVG('Adj Close) | 0.450090
  AVG('Adj Close) | 0.483521
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numRows</code> - Number of rows to show</dd>
<dd><code>truncate</code> - If set to more than 0, truncates strings to <code>truncate</code> characters and
                    all cells will be aligned right.</dd>
<dd><code>vertical</code> - If set to true, prints output rows vertically (one line per column value).</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="na()">
<h3>na</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DataFrameNaFunctions.html" title="class in org.apache.spark.sql">DataFrameNaFunctions</a></span>&nbsp;<span class="element-name">na</span>()</div>
<div class="block">Returns a <a href="DataFrameNaFunctions.html" title="class in org.apache.spark.sql"><code>DataFrameNaFunctions</code></a> for working with missing data.
 <pre><code>
   // Dropping rows containing any null values.
   ds.na.drop()
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="stat()">
<h3>stat</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DataFrameStatFunctions.html" title="class in org.apache.spark.sql">DataFrameStatFunctions</a></span>&nbsp;<span class="element-name">stat</span>()</div>
<div class="block">Returns a <a href="DataFrameStatFunctions.html" title="class in org.apache.spark.sql"><code>DataFrameStatFunctions</code></a> for working statistic functions support.
 <pre><code>
   // Finding frequent items in column with name 'a'.
   ds.stat.freqItems(Seq("a"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right)</span></div>
<div class="block">Join with another <code>DataFrame</code>.
 <p>
 Behaves as an INNER JOIN and requires a subsequent join predicate.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,java.lang.String)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;usingColumn)</span></div>
<div class="block">Inner equi-join with another <code>DataFrame</code> using the given column.
 <p>
 Different from other join functions, the join column will only appear once in the output,
 i.e. similar to SQL's <code>JOIN USING</code> syntax.
 <p>
 <pre><code>
   // Joining df1 and df2 using the column "user_id"
   df1.join(df2, "user_id")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.</dd>
<dd><code>usingColumn</code> - Name of the column to join on. This column must exist on both sides.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>If you perform a self-join using this function without aliasing the input
 <code>DataFrame</code>s, you will NOT be able to reference any columns after the join, since
 there is no way to disambiguate which side of the join you would like to reference.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,java.lang.String[])">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;usingColumns)</span></div>
<div class="block">(Java-specific) Inner equi-join with another <code>DataFrame</code> using the given columns. See the
 Scala-specific overload for more details.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.</dd>
<dd><code>usingColumns</code> - Names of the columns to join on. This columns must exist on both sides.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,scala.collection.Seq)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;usingColumns)</span></div>
<div class="block">(Scala-specific) Inner equi-join with another <code>DataFrame</code> using the given columns.
 <p>
 Different from other join functions, the join columns will only appear once in the output,
 i.e. similar to SQL's <code>JOIN USING</code> syntax.
 <p>
 <pre><code>
   // Joining df1 and df2 using the columns "user_id" and "user_name"
   df1.join(df2, Seq("user_id", "user_name"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.</dd>
<dd><code>usingColumns</code> - Names of the columns to join on. This columns must exist on both sides.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>If you perform a self-join using this function without aliasing the input
 <code>DataFrame</code>s, you will NOT be able to reference any columns after the join, since
 there is no way to disambiguate which side of the join you would like to reference.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,java.lang.String,java.lang.String)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;usingColumn,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</span></div>
<div class="block">Equi-join with another <code>DataFrame</code> using the given column. A cross join with a predicate
 is specified as an inner join. If you would explicitly like to perform a cross join use the
 <code>crossJoin</code> method.
 <p>
 Different from other join functions, the join column will only appear once in the output,
 i.e. similar to SQL's <code>JOIN USING</code> syntax.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.</dd>
<dd><code>usingColumn</code> - Name of the column to join on. This column must exist on both sides.</dd>
<dd><code>joinType</code> - Type of join to perform. Default <code>inner</code>. Must be one of:
                 <code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>fullouter</code>, <code>full_outer</code>, <code>left</code>,
                 <code>leftouter</code>, <code>left_outer</code>, <code>right</code>, <code>rightouter</code>, <code>right_outer</code>,
                 <code>semi</code>, <code>leftsemi</code>, <code>left_semi</code>, <code>anti</code>, <code>leftanti</code>, left_anti<code>.</code>
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
<dt>Note:</dt>
<dd>If you perform a self-join using this function without aliasing the input
 <code>DataFrame</code>s, you will NOT be able to reference any columns after the join, since
 there is no way to disambiguate which side of the join you would like to reference.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,java.lang.String[],java.lang.String)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;usingColumns,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</span></div>
<div class="block">(Java-specific) Equi-join with another <code>DataFrame</code> using the given columns. See the
 Scala-specific overload for more details.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.</dd>
<dd><code>usingColumns</code> - Names of the columns to join on. This columns must exist on both sides.</dd>
<dd><code>joinType</code> - Type of join to perform. Default <code>inner</code>. Must be one of:
                 <code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>fullouter</code>, <code>full_outer</code>, <code>left</code>,
                 <code>leftouter</code>, <code>left_outer</code>, <code>right</code>, <code>rightouter</code>, <code>right_outer</code>,
                 <code>semi</code>, <code>leftsemi</code>, <code>left_semi</code>, <code>anti</code>, <code>leftanti</code>, left_anti<code>.</code>
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,scala.collection.Seq,java.lang.String)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;usingColumns,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</span></div>
<div class="block">(Scala-specific) Equi-join with another <code>DataFrame</code> using the given columns. A cross join
 with a predicate is specified as an inner join. If you would explicitly like to perform a
 cross join use the <code>crossJoin</code> method.
 <p>
 Different from other join functions, the join columns will only appear once in the output,
 i.e. similar to SQL's <code>JOIN USING</code> syntax.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.</dd>
<dd><code>usingColumns</code> - Names of the columns to join on. This columns must exist on both sides.</dd>
<dd><code>joinType</code> - Type of join to perform. Default <code>inner</code>. Must be one of:
                 <code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>fullouter</code>, <code>full_outer</code>, <code>left</code>,
                 <code>leftouter</code>, <code>left_outer</code>, <code>right</code>, <code>rightouter</code>, <code>right_outer</code>,
                 <code>semi</code>, <code>leftsemi</code>, <code>left_semi</code>, <code>anti</code>, <code>leftanti</code>, <code>left_anti</code>.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>If you perform a self-join using this function without aliasing the input
 <code>DataFrame</code>s, you will NOT be able to reference any columns after the join, since
 there is no way to disambiguate which side of the join you would like to reference.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;joinExprs)</span></div>
<div class="block">Inner join with another <code>DataFrame</code>, using the given join expression.
 <p>
 <pre><code>
   // The following two are equivalent:
   df1.join(df2, $"df1Key" === $"df2Key")
   df1.join(df2).where($"df1Key" === $"df2Key")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - (undocumented)</dd>
<dd><code>joinExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="join(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column,java.lang.String)">
<h3>join</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">join</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;joinExprs,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</span></div>
<div class="block">Join with another <code>DataFrame</code>, using the given join expression. The following performs
 a full outer join between <code>df1</code> and <code>df2</code>.
 <p>
 <pre><code>
   // Scala:
   import org.apache.spark.sql.functions._
   df1.join(df2, $"df1Key" === $"df2Key", "outer")

   // Java:
   import static org.apache.spark.sql.functions.*;
   df1.join(df2, col("df1Key").equalTo(col("df2Key")), "outer");
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join.</dd>
<dd><code>joinExprs</code> - Join expression.</dd>
<dd><code>joinType</code> - Type of join to perform. Default <code>inner</code>. Must be one of:
                 <code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>fullouter</code>, <code>full_outer</code>, <code>left</code>,
                 <code>leftouter</code>, <code>left_outer</code>, <code>right</code>, <code>rightouter</code>, <code>right_outer</code>,
                 <code>semi</code>, <code>leftsemi</code>, <code>left_semi</code>, <code>anti</code>, <code>leftanti</code>, left_anti<code>.</code>
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="crossJoin(org.apache.spark.sql.Dataset)">
<h3>crossJoin</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">crossJoin</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;?&gt;&nbsp;right)</span></div>
<div class="block">Explicit cartesian join with another <code>DataFrame</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>right</code> - Right side of the join operation.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.1.0</dd>
<dt>Note:</dt>
<dd>Cartesian joins are very expensive without an extra filter that can be pushed down.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="joinWith(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column,java.lang.String)">
<h3>joinWith</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&gt;</span>&nbsp;<span class="element-name">joinWith</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;joinType)</span></div>
<div class="block">Joins this Dataset returning a <code>Tuple2</code> for each pair where <code>condition</code> evaluates to
 true.
 <p>
 This is similar to the relation <code>join</code> function with one important difference in the
 result schema. Since <code>joinWith</code> preserves objects present on either side of the join, the
 result schema is similarly nested into a tuple under the column names <code>_1</code> and <code>_2</code>.
 <p>
 This type of join can be useful both for preserving type-safety with the original object
 types as well as working with relational data where either side of the join has column
 names in common.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - Right side of the join.</dd>
<dd><code>condition</code> - Join expression.</dd>
<dd><code>joinType</code> - Type of join to perform. Default <code>inner</code>. Must be one of:
                 <code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>fullouter</code>,<code>full_outer</code>, <code>left</code>,
                 <code>leftouter</code>, <code>left_outer</code>, <code>right</code>, <code>rightouter</code>, <code>right_outer</code>.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="joinWith(org.apache.spark.sql.Dataset,org.apache.spark.sql.Column)">
<h3>joinWith</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&gt;</span>&nbsp;<span class="element-name">joinWith</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&nbsp;other,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</span></div>
<div class="block">Using inner equi-join to join this Dataset returning a <code>Tuple2</code> for each pair
 where <code>condition</code> evaluates to true.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - Right side of the join.</dd>
<dd><code>condition</code> - Join expression.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sortWithinPartitions(java.lang.String,scala.collection.Seq)">
<h3>sortWithinPartitions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sortWithinPartitions</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;sortCols)</span></div>
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.
 <p>
 This is the same operation as "SORT BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortCol</code> - (undocumented)</dd>
<dd><code>sortCols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sortWithinPartitions(scala.collection.Seq)">
<h3>sortWithinPartitions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sortWithinPartitions</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;sortExprs)</span></div>
<div class="block">Returns a new Dataset with each partition sorted by the given expressions.
 <p>
 This is the same operation as "SORT BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sort(java.lang.String,scala.collection.Seq)">
<h3>sort</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sort</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;sortCols)</span></div>
<div class="block">Returns a new Dataset sorted by the specified column, all in ascending order.
 <pre><code>
   // The following 3 are equivalent
   ds.sort("sortcol")
   ds.sort($"sortcol")
   ds.sort($"sortcol".asc)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortCol</code> - (undocumented)</dd>
<dd><code>sortCols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sort(scala.collection.Seq)">
<h3>sort</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sort</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;sortExprs)</span></div>
<div class="block">Returns a new Dataset sorted by the given expressions. For example:
 <pre><code>
   ds.sort($"col1", $"col2".desc)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="orderBy(java.lang.String,scala.collection.Seq)">
<h3>orderBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">orderBy</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;sortCol,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;sortCols)</span></div>
<div class="block">Returns a new Dataset sorted by the given expressions.
 This is an alias of the <code>sort</code> function.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortCol</code> - (undocumented)</dd>
<dd><code>sortCols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="orderBy(scala.collection.Seq)">
<h3>orderBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">orderBy</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;sortExprs)</span></div>
<div class="block">Returns a new Dataset sorted by the given expressions.
 This is an alias of the <code>sort</code> function.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>sortExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="apply(java.lang.String)">
<h3>apply</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Column.html" title="class in org.apache.spark.sql">Column</a></span>&nbsp;<span class="element-name">apply</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</span></div>
<div class="block">Selects column based on the column name and returns it as a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colName</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>The column name can also reference to a nested column like <code>a.b</code>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="hint(java.lang.String,scala.collection.Seq)">
<h3>hint</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">hint</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;parameters)</span></div>
<div class="block">Specifies some hint on the current Dataset. As an example, the following code specifies
 that one of the plan can be broadcasted:
 <p>
 <pre><code>
   df1.join(df2.hint("broadcast"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>name</code> - (undocumented)</dd>
<dd><code>parameters</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.2.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="col(java.lang.String)">
<h3>col</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Column.html" title="class in org.apache.spark.sql">Column</a></span>&nbsp;<span class="element-name">col</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</span></div>
<div class="block">Selects column based on the column name and returns it as a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colName</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>The column name can also reference to a nested column like <code>a.b</code>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="metadataColumn(java.lang.String)">
<h3>metadataColumn</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Column.html" title="class in org.apache.spark.sql">Column</a></span>&nbsp;<span class="element-name">metadataColumn</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</span></div>
<div class="block">Selects a metadata column based on its logical column name, and returns it as a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.
 <p>
 A metadata column can be accessed this way even if the underlying data source defines a data
 column with a conflicting name.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colName</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.5.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="colRegex(java.lang.String)">
<h3>colRegex</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Column.html" title="class in org.apache.spark.sql">Column</a></span>&nbsp;<span class="element-name">colRegex</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</span></div>
<div class="block">Selects column based on the column name specified as a regex and returns it as <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a>.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colName</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="as(java.lang.String)">
<h3>as</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">as</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;alias)</span></div>
<div class="block">Returns a new Dataset with an alias set.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>alias</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="as(scala.Symbol)">
<h3>as</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">as</span><wbr><span class="parameters">(scala.Symbol&nbsp;alias)</span></div>
<div class="block">(Scala-specific) Returns a new Dataset with an alias set.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>alias</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="alias(java.lang.String)">
<h3>alias</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">alias</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;alias)</span></div>
<div class="block">Returns a new Dataset with an alias set. Same as <code>as</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>alias</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="alias(scala.Symbol)">
<h3>alias</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">alias</span><wbr><span class="parameters">(scala.Symbol&nbsp;alias)</span></div>
<div class="block">(Scala-specific) Returns a new Dataset with an alias set. Same as <code>as</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>alias</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(scala.collection.Seq)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</span></div>
<div class="block">Selects a set of column based expressions.
 <pre><code>
   ds.select($"colA", $"colB" + 1)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(java.lang.String,scala.collection.Seq)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Selects a set of columns. This is a variant of <code>select</code> that can only select
 existing columns using column names (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // The following two are equivalent:
   ds.select("colA", "colB")
   ds.select($"colA", $"colB")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="selectExpr(scala.collection.Seq)">
<h3>selectExpr</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">selectExpr</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;exprs)</span></div>
<div class="block">Selects a set of SQL expressions. This is a variant of <code>select</code> that accepts
 SQL expressions.
 <p>
 <pre><code>
   // The following are equivalent:
   ds.selectExpr("colA", "colB as newName", "abs(colC)")
   ds.select(expr("colA"), expr("colB as newName"), expr("abs(colC)"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(org.apache.spark.sql.TypedColumn)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U1&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U1&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1)</span></div>
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expression for each element.
 <p>
 <pre><code>
   val ds = Seq(1, 2, 3).toDS()
   val newDS = ds.select(expr("value + 1").as[Int])
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>c1</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U1,<wbr>
U2&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple2&lt;U1,<wbr>U2&gt;&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2)</span></div>
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>c1</code> - (undocumented)</dd>
<dd><code>c2</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U1,<wbr>
U2,<wbr>
U3&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple3&lt;U1,<wbr>U2,<wbr>U3&gt;&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U3&gt;&nbsp;c3)</span></div>
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>c1</code> - (undocumented)</dd>
<dd><code>c2</code> - (undocumented)</dd>
<dd><code>c3</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U1,<wbr>
U2,<wbr>
U3,<wbr>
U4&gt;</span>
<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple4&lt;U1,<wbr>U2,<wbr>U3,<wbr>U4&gt;&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U3&gt;&nbsp;c3,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U4&gt;&nbsp;c4)</span></div>
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>c1</code> - (undocumented)</dd>
<dd><code>c2</code> - (undocumented)</dd>
<dd><code>c3</code> - (undocumented)</dd>
<dd><code>c4</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="select(org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn,org.apache.spark.sql.TypedColumn)">
<h3>select</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U1,<wbr>
U2,<wbr>
U3,<wbr>
U4,<wbr>
U5&gt;</span>
<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;scala.Tuple5&lt;U1,<wbr>U2,<wbr>U3,<wbr>U4,<wbr>U5&gt;&gt;</span>&nbsp;<span class="element-name">select</span><wbr><span class="parameters">(<a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U1&gt;&nbsp;c1,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U2&gt;&nbsp;c2,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U3&gt;&nbsp;c3,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U4&gt;&nbsp;c4,
 <a href="TypedColumn.html" title="class in org.apache.spark.sql">TypedColumn</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U5&gt;&nbsp;c5)</span></div>
<div class="block">Returns a new Dataset by computing the given <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> expressions for each element.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>c1</code> - (undocumented)</dd>
<dd><code>c2</code> - (undocumented)</dd>
<dd><code>c3</code> - (undocumented)</dd>
<dd><code>c4</code> - (undocumented)</dd>
<dd><code>c5</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filter(org.apache.spark.sql.Column)">
<h3>filter</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">filter</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</span></div>
<div class="block">Filters rows using the given condition.
 <pre><code>
   // The following are equivalent:
   peopleDs.filter($"age" &gt; 15)
   peopleDs.where($"age" &gt; 15)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>condition</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filter(java.lang.String)">
<h3>filter</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">filter</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;conditionExpr)</span></div>
<div class="block">Filters rows using the given SQL expression.
 <pre><code>
   peopleDs.filter("age &gt; 15")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>conditionExpr</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="where(org.apache.spark.sql.Column)">
<h3>where</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">where</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;condition)</span></div>
<div class="block">Filters rows using the given condition. This is an alias for <code>filter</code>.
 <pre><code>
   // The following are equivalent:
   peopleDs.filter($"age" &gt; 15)
   peopleDs.where($"age" &gt; 15)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>condition</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="where(java.lang.String)">
<h3>where</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">where</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;conditionExpr)</span></div>
<div class="block">Filters rows using the given SQL expression.
 <pre><code>
   peopleDs.where("age &gt; 15")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>conditionExpr</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupBy(scala.collection.Seq)">
<h3>groupBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">groupBy</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</span></div>
<div class="block">Groups the Dataset using the specified columns, so we can run aggregation on them. See
 <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 <pre><code>
   // Compute the average for all numeric columns grouped by department.
   ds.groupBy($"department").avg()

   // Compute the max age and average salary, grouped by department and gender.
   ds.groupBy($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rollup(scala.collection.Seq)">
<h3>rollup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">rollup</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 <pre><code>
   // Compute the average for all numeric columns rolled up by department and group.
   ds.rollup($"department", $"group").avg()

   // Compute the max age and average salary, rolled up by department and gender.
   ds.rollup($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cube(scala.collection.Seq)">
<h3>cube</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">cube</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 <pre><code>
   // Compute the average for all numeric columns cubed by department and group.
   ds.cube($"department", $"group").avg()

   // Compute the max age and average salary, cubed by department and gender.
   ds.cube($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupBy(java.lang.String,scala.collection.Seq)">
<h3>groupBy</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">groupBy</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Groups the Dataset using the specified columns, so that we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 This is a variant of groupBy that can only group by existing columns using column names
 (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // Compute the average for all numeric columns grouped by department.
   ds.groupBy("department").avg()

   // Compute the max age and average salary, grouped by department and gender.
   ds.groupBy($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduce(scala.Function2)">
<h3>reduce</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="type parameter in Dataset">T</a></span>&nbsp;<span class="element-name">reduce</span><wbr><span class="parameters">(scala.Function2&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</span></div>
<div class="block">(Scala-specific)
 Reduces the elements of this Dataset using the specified binary function. The given <code>func</code>
 must be commutative and associative or the result may be non-deterministic.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="reduce(org.apache.spark.api.java.function.ReduceFunction)">
<h3>reduce</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="type parameter in Dataset">T</a></span>&nbsp;<span class="element-name">reduce</span><wbr><span class="parameters">(<a href="../api/java/function/ReduceFunction.html" title="interface in org.apache.spark.api.java.function">ReduceFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</span></div>
<div class="block">(Java-specific)
 Reduces the elements of this Dataset using the specified binary function. The given <code>func</code>
 must be commutative and associative or the result may be non-deterministic.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey(scala.Function1,org.apache.spark.sql.Encoder)">
<h3>groupByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;K&gt;</span>&nbsp;<span class="return-type"><a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql">KeyValueGroupedDataset</a>&lt;K,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">groupByKey</span><wbr><span class="parameters">(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>K&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;evidence$3)</span></div>
<div class="block">(Scala-specific)
 Returns a <a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql"><code>KeyValueGroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dd><code>evidence$3</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="groupByKey(org.apache.spark.api.java.function.MapFunction,org.apache.spark.sql.Encoder)">
<h3>groupByKey</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;K&gt;</span>&nbsp;<span class="return-type"><a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql">KeyValueGroupedDataset</a>&lt;K,<wbr><a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">groupByKey</span><wbr><span class="parameters">(<a href="../api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>K&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;K&gt;&nbsp;encoder)</span></div>
<div class="block">(Java-specific)
 Returns a <a href="KeyValueGroupedDataset.html" title="class in org.apache.spark.sql"><code>KeyValueGroupedDataset</code></a> where the data is grouped by the given key <code>func</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dd><code>encoder</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rollup(java.lang.String,scala.collection.Seq)">
<h3>rollup</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">rollup</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional rollup for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 This is a variant of rollup that can only group by existing columns using column names
 (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // Compute the average for all numeric columns rolled up by department and group.
   ds.rollup("department", "group").avg()

   // Compute the max age and average salary, rolled up by department and gender.
   ds.rollup($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cube(java.lang.String,scala.collection.Seq)">
<h3>cube</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql">RelationalGroupedDataset</a></span>&nbsp;<span class="element-name">cube</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Create a multi-dimensional cube for the current Dataset using the specified columns,
 so we can run aggregation on them.
 See <a href="RelationalGroupedDataset.html" title="class in org.apache.spark.sql"><code>RelationalGroupedDataset</code></a> for all the available aggregate functions.
 <p>
 This is a variant of cube that can only group by existing columns using column names
 (i.e. cannot construct expressions).
 <p>
 <pre><code>
   // Compute the average for all numeric columns cubed by department and group.
   ds.cube("department", "group").avg()

   // Compute the max age and average salary, cubed by department and gender.
   ds.cube($"department", $"gender").agg(Map(
     "salary" -&gt; "avg",
     "age" -&gt; "max"
   ))
 </code></pre></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="agg(scala.Tuple2,scala.collection.Seq)">
<h3>agg</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">agg</span><wbr><span class="parameters">(scala.Tuple2&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;aggExpr,
 scala.collection.Seq&lt;scala.Tuple2&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&gt;&nbsp;aggExprs)</span></div>
<div class="block">(Scala-specific) Aggregates on the entire Dataset without groups.
 <pre><code>
   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)
   ds.agg("age" -&gt; "max", "salary" -&gt; "avg")
   ds.groupBy().agg("age" -&gt; "max", "salary" -&gt; "avg")
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>aggExpr</code> - (undocumented)</dd>
<dd><code>aggExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="agg(scala.collection.immutable.Map)">
<h3>agg</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">agg</span><wbr><span class="parameters">(scala.collection.immutable.Map&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;exprs)</span></div>
<div class="block">(Scala-specific) Aggregates on the entire Dataset without groups.
 <pre><code>
   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)
   ds.agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))
   ds.groupBy().agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="agg(java.util.Map)">
<h3>agg</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">agg</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html" title="class or interface in java.util" class="external-link">Map</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;exprs)</span></div>
<div class="block">(Java-specific) Aggregates on the entire Dataset without groups.
 <pre><code>
   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)
   ds.agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))
   ds.groupBy().agg(Map("age" -&gt; "max", "salary" -&gt; "avg"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="agg(org.apache.spark.sql.Column,scala.collection.Seq)">
<h3>agg</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">agg</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;exprs)</span></div>
<div class="block">Aggregates on the entire Dataset without groups.
 <pre><code>
   // ds.agg(...) is a shorthand for ds.groupBy().agg(...)
   ds.agg(max($"age"), avg($"salary"))
   ds.groupBy().agg(max($"age"), avg($"salary"))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>expr</code> - (undocumented)</dd>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unpivot(org.apache.spark.sql.Column[],org.apache.spark.sql.Column[],java.lang.String,java.lang.String)">
<h3>unpivot</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">unpivot</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;values,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</span></div>
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.
 This is the reverse to <code>groupBy(...).pivot(...).agg(...)</code>, except for the aggregation,
 which cannot be reversed.
 <p>
 This function is useful to massage a DataFrame into a format where some
 columns are identifier columns ("ids"), while all other columns ("values")
 are "unpivoted" to the rows, leaving just two non-id columns, named as given
 by <code>variableColumnName</code> and <code>valueColumnName</code>.
 <p>
 <pre><code>
   val df = Seq((1, 11, 12L), (2, 21, 22L)).toDF("id", "int", "long")
   df.show()
   // output:
   // +---+---+----+
   // | id|int|long|
   // +---+---+----+
   // |  1| 11|  12|
   // |  2| 21|  22|
   // +---+---+----+

   df.unpivot(Array($"id"), Array($"int", $"long"), "variable", "value").show()
   // output:
   // +---+--------+-----+
   // | id|variable|value|
   // +---+--------+-----+
   // |  1|     int|   11|
   // |  1|    long|   12|
   // |  2|     int|   21|
   // |  2|    long|   22|
   // +---+--------+-----+
   // schema:
   //root
   // |-- id: integer (nullable = false)
   // |-- variable: string (nullable = false)
   // |-- value: long (nullable = true)
 </code></pre>
 <p>
 When no "id" columns are given, the unpivoted DataFrame consists of only the
 "variable" and "value" columns.
 <p>
 All "value" columns must share a least common data type. Unless they are the same data type,
 all "value" columns are cast to the nearest common data type. For instance,
 types <code>IntegerType</code> and <code>LongType</code> are cast to <code>LongType</code>, while <code>IntegerType</code> and <code>StringType</code>
 do not have a common data type and <code>unpivot</code> fails with an <code>AnalysisException</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>ids</code> - Id columns</dd>
<dd><code>values</code> - Value columns to unpivot</dd>
<dd><code>variableColumnName</code> - Name of the variable column</dd>
<dd><code>valueColumnName</code> - Name of the value column
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unpivot(org.apache.spark.sql.Column[],java.lang.String,java.lang.String)">
<h3>unpivot</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">unpivot</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</span></div>
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.
 This is the reverse to <code>groupBy(...).pivot(...).agg(...)</code>, except for the aggregation,
 which cannot be reversed.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>ids</code> - Id columns</dd>
<dd><code>variableColumnName</code> - Name of the variable column</dd>
<dd><code>valueColumnName</code> - Name of the value column
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
<dt>See Also:</dt>
<dd>
<ul class="see-list-long">
<li><code>org.apache.spark.sql.Dataset.unpivot(Array, Array, String, String)</code>
 <p>
 This is equivalent to calling <code>Dataset#unpivot(Array, Array, String, String)</code>
 where <code>values</code> is set to all non-id columns that exist in the DataFrame.
 <p></li>
</ul>
</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="melt(org.apache.spark.sql.Column[],org.apache.spark.sql.Column[],java.lang.String,java.lang.String)">
<h3>melt</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">melt</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;values,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</span></div>
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.
 This is the reverse to <code>groupBy(...).pivot(...).agg(...)</code>, except for the aggregation,
 which cannot be reversed. This is an alias for <code>unpivot</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>ids</code> - Id columns</dd>
<dd><code>values</code> - Value columns to unpivot</dd>
<dd><code>variableColumnName</code> - Name of the variable column</dd>
<dd><code>valueColumnName</code> - Name of the value column
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
<dt>See Also:</dt>
<dd>
<ul class="see-list-long">
<li><code>org.apache.spark.sql.Dataset.unpivot(Array, Array, String, String)</code>
 <p></li>
</ul>
</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="melt(org.apache.spark.sql.Column[],java.lang.String,java.lang.String)">
<h3>melt</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">melt</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>[]&nbsp;ids,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;variableColumnName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;valueColumnName)</span></div>
<div class="block">Unpivot a DataFrame from wide format to long format, optionally leaving identifier columns set.
 This is the reverse to <code>groupBy(...).pivot(...).agg(...)</code>, except for the aggregation,
 which cannot be reversed. This is an alias for <code>unpivot</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>ids</code> - Id columns</dd>
<dd><code>variableColumnName</code> - Name of the variable column</dd>
<dd><code>valueColumnName</code> - Name of the value column
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
<dt>See Also:</dt>
<dd>
<ul class="see-list-long">
<li><code>org.apache.spark.sql.Dataset.unpivot(Array, Array, String, String)</code>
 <p>
 This is equivalent to calling <code>Dataset#unpivot(Array, Array, String, String)</code>
 where <code>values</code> is set to all non-id columns that exist in the DataFrame.
 <p></li>
</ul>
</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="observe(java.lang.String,org.apache.spark.sql.Column,scala.collection.Seq)">
<h3>observe</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">observe</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;name,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;exprs)</span></div>
<div class="block">Define (named) metrics to observe on the Dataset. This method returns an 'observed' Dataset
 that returns the same result as the input, with the following guarantees:
 <ul>
   <li>It will compute the defined aggregates (metrics) on all the data that is flowing through
   the Dataset at that point.</li>
   <li>It will report the value of the defined aggregate columns as soon as we reach a completion
   point. A completion point is either the end of a query (batch mode) or the end of a streaming
   epoch. The value of the aggregates only reflects the data processed since the previous
   completion point.</li>
 </ul>
 Please note that continuous execution is currently not supported.
 <p>
 The metrics columns must either contain a literal (e.g. lit(42)), or should contain one or
 more aggregate functions (e.g. sum(a) or sum(a + b) + avg(c) - lit(1)). Expressions that
 contain references to the input Dataset's columns must always be wrapped in an aggregate
 function.
 <p>
 A user can observe these metrics by either adding
 <a href="streaming/StreamingQueryListener.html" title="class in org.apache.spark.sql.streaming"><code>StreamingQueryListener</code></a> or a
 <a href="util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a> to the spark session.
 <p>
 <pre><code>
   // Monitor the metrics using a listener.
   spark.streams.addListener(new StreamingQueryListener() {
     override def onQueryStarted(event: QueryStartedEvent): Unit = {}
     override def onQueryProgress(event: QueryProgressEvent): Unit = {
       event.progress.observedMetrics.asScala.get("my_event").foreach { row =&gt;
         // Trigger if the number of errors exceeds 5 percent
         val num_rows = row.getAs[Long]("rc")
         val num_error_rows = row.getAs[Long]("erc")
         val ratio = num_error_rows.toDouble / num_rows
         if (ratio &gt; 0.05) {
           // Trigger alert
         }
       }
     }
     override def onQueryTerminated(event: QueryTerminatedEvent): Unit = {}
   })
   // Observe row count (rc) and error row count (erc) in the streaming Dataset
   val observed_ds = ds.observe("my_event", count(lit(1)).as("rc"), count($"error").as("erc"))
   observed_ds.writeStream.format("...").start()
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>name</code> - (undocumented)</dd>
<dd><code>expr</code> - (undocumented)</dd>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="observe(org.apache.spark.sql.Observation,org.apache.spark.sql.Column,scala.collection.Seq)">
<h3>observe</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">observe</span><wbr><span class="parameters">(<a href="Observation.html" title="class in org.apache.spark.sql">Observation</a>&nbsp;observation,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;expr,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;exprs)</span></div>
<div class="block">Observe (named) metrics through an <code>org.apache.spark.sql.Observation</code> instance.
 This is equivalent to calling <code>observe(String, Column, Column*)</code> but does not require
 adding <code>org.apache.spark.sql.util.QueryExecutionListener</code> to the spark session.
 This method does not support streaming datasets.
 <p>
 A user can retrieve the metrics by accessing <code>org.apache.spark.sql.Observation.get</code>.
 <p>
 <pre><code>
   // Observe row count (rows) and highest id (maxid) in the Dataset while writing it
   val observation = Observation("my_metrics")
   val observed_ds = ds.observe(observation, count(lit(1)).as("rows"), max($"id").as("maxid"))
   observed_ds.write.parquet("ds.parquet")
   val metrics = observation.get
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>observation</code> - (undocumented)</dd>
<dd><code>expr</code> - (undocumented)</dd>
<dd><code>exprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Throws:</dt>
<dd><code><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/IllegalArgumentException.html" title="class or interface in java.lang" class="external-link">IllegalArgumentException</a></code> - If this is a streaming Dataset (this.isStreaming == true)
 <p></dd>
<dt>Since:</dt>
<dd>3.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="limit(int)">
<h3>limit</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">limit</span><wbr><span class="parameters">(int&nbsp;n)</span></div>
<div class="block">Returns a new Dataset by taking the first <code>n</code> rows. The difference between this function
 and <code>head</code> is that <code>head</code> is an action and returns an array (by triggering query execution)
 while <code>limit</code> returns a new Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>n</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="offset(int)">
<h3>offset</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">offset</span><wbr><span class="parameters">(int&nbsp;n)</span></div>
<div class="block">Returns a new Dataset by skipping the first <code>n</code> rows.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>n</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="union(org.apache.spark.sql.Dataset)">
<h3>union</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">union</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.
 <p>
 This is equivalent to <code>UNION ALL</code> in SQL. To do a SQL-style set union (that does
 deduplication of elements), use this function followed by a <a href="#distinct()"><code>distinct()</code></a>.
 <p>
 Also as standard in SQL, this function resolves columns by position (not by name):
 <p>
 <pre><code>
   val df1 = Seq((1, 2, 3)).toDF("col0", "col1", "col2")
   val df2 = Seq((4, 5, 6)).toDF("col1", "col2", "col0")
   df1.union(df2).show

   // output:
   // +----+----+----+
   // |col0|col1|col2|
   // +----+----+----+
   // |   1|   2|   3|
   // |   4|   5|   6|
   // +----+----+----+
 </code></pre>
 <p>
 Notice that the column positions in the schema aren't necessarily matched with the
 fields in the strongly typed objects in a Dataset. This function resolves columns
 by their positions in the schema, not the fields in the strongly typed objects. Use
 <a href="#unionByName(org.apache.spark.sql.Dataset)"><code>unionByName(org.apache.spark.sql.Dataset&lt;T&gt;)</code></a> to resolve columns by field name in the typed objects.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unionAll(org.apache.spark.sql.Dataset)">
<h3>unionAll</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">unionAll</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.
 This is an alias for <code>union</code>.
 <p>
 This is equivalent to <code>UNION ALL</code> in SQL. To do a SQL-style set union (that does
 deduplication of elements), use this function followed by a <a href="#distinct()"><code>distinct()</code></a>.
 <p>
 Also as standard in SQL, this function resolves columns by position (not by name).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unionByName(org.apache.spark.sql.Dataset)">
<h3>unionByName</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">unionByName</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.
 <p>
 This is different from both <code>UNION ALL</code> and <code>UNION DISTINCT</code> in SQL. To do a SQL-style set
 union (that does deduplication of elements), use this function followed by a <a href="#distinct()"><code>distinct()</code></a>.
 <p>
 The difference between this function and <a href="#union(org.apache.spark.sql.Dataset)"><code>union(org.apache.spark.sql.Dataset&lt;T&gt;)</code></a> is that this function
 resolves columns by name (not by position):
 <p>
 <pre><code>
   val df1 = Seq((1, 2, 3)).toDF("col0", "col1", "col2")
   val df2 = Seq((4, 5, 6)).toDF("col1", "col2", "col0")
   df1.unionByName(df2).show

   // output:
   // +----+----+----+
   // |col0|col1|col2|
   // +----+----+----+
   // |   1|   2|   3|
   // |   6|   4|   5|
   // +----+----+----+
 </code></pre>
 <p>
 Note that this supports nested columns in struct and array types. Nested columns in map types
 are not currently supported.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unionByName(org.apache.spark.sql.Dataset,boolean)">
<h3>unionByName</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">unionByName</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other,
 boolean&nbsp;allowMissingColumns)</span></div>
<div class="block">Returns a new Dataset containing union of rows in this Dataset and another Dataset.
 <p>
 The difference between this function and <a href="#union(org.apache.spark.sql.Dataset)"><code>union(org.apache.spark.sql.Dataset&lt;T&gt;)</code></a> is that this function
 resolves columns by name (not by position).
 <p>
 When the parameter <code>allowMissingColumns</code> is <code>true</code>, the set of column names
 in this and other <code>Dataset</code> can differ; missing columns will be filled with null.
 Further, the missing columns of this <code>Dataset</code> will be added at the end
 in the schema of the union result:
 <p>
 <pre><code>
   val df1 = Seq((1, 2, 3)).toDF("col0", "col1", "col2")
   val df2 = Seq((4, 5, 6)).toDF("col1", "col0", "col3")
   df1.unionByName(df2, true).show

   // output: "col3" is missing at left df1 and added at the end of schema.
   // +----+----+----+----+
   // |col0|col1|col2|col3|
   // +----+----+----+----+
   // |   1|   2|   3|NULL|
   // |   5|   4|NULL|   6|
   // +----+----+----+----+

   df2.unionByName(df1, true).show

   // output: "col2" is missing at left df2 and added at the end of schema.
   // +----+----+----+----+
   // |col1|col0|col3|col2|
   // +----+----+----+----+
   // |   4|   5|   6|NULL|
   // |   2|   1|NULL|   3|
   // +----+----+----+----+
 </code></pre>
 <p>
 Note that this supports nested columns in struct and array types. With <code>allowMissingColumns</code>,
 missing nested columns of struct columns with the same name will also be filled with null
 values and added to the end of struct. Nested columns in map types are not currently
 supported.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>allowMissingColumns</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.1.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="intersect(org.apache.spark.sql.Dataset)">
<h3>intersect</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">intersect</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing rows only in both this Dataset and another Dataset.
 This is equivalent to <code>INTERSECT</code> in SQL.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
<dt>Note:</dt>
<dd>Equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="intersectAll(org.apache.spark.sql.Dataset)">
<h3>intersectAll</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">intersectAll</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing rows only in both this Dataset and another Dataset while
 preserving the duplicates.
 This is equivalent to <code>INTERSECT ALL</code> in SQL.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.4.0</dd>
<dt>Note:</dt>
<dd>Equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>. Also as standard
 in SQL, this function resolves columns by position (not by name).
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="except(org.apache.spark.sql.Dataset)">
<h3>except</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">except</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing rows in this Dataset but not in another Dataset.
 This is equivalent to <code>EXCEPT DISTINCT</code> in SQL.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>Equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="exceptAll(org.apache.spark.sql.Dataset)">
<h3>exceptAll</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">exceptAll</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns a new Dataset containing rows in this Dataset but not in another Dataset while
 preserving the duplicates.
 This is equivalent to <code>EXCEPT ALL</code> in SQL.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.4.0</dd>
<dt>Note:</dt>
<dd>Equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>. Also as standard in
 SQL, this function resolves columns by position (not by name).
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sample(double,long)">
<h3>sample</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sample</span><wbr><span class="parameters">(double&nbsp;fraction,
 long&nbsp;seed)</span></div>
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows (without replacement),
 using a user-supplied seed.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>fraction</code> - Fraction of rows to generate, range [0.0, 1.0].</dd>
<dd><code>seed</code> - Seed for sampling.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
<dt>Note:</dt>
<dd>This is NOT guaranteed to provide exactly the fraction of the count
 of the given <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sample(double)">
<h3>sample</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sample</span><wbr><span class="parameters">(double&nbsp;fraction)</span></div>
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows (without replacement),
 using a random seed.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>fraction</code> - Fraction of rows to generate, range [0.0, 1.0].
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
<dt>Note:</dt>
<dd>This is NOT guaranteed to provide exactly the fraction of the count
 of the given <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sample(boolean,double,long)">
<h3>sample</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sample</span><wbr><span class="parameters">(boolean&nbsp;withReplacement,
 double&nbsp;fraction,
 long&nbsp;seed)</span></div>
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows, using a user-supplied seed.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>withReplacement</code> - Sample with replacement or not.</dd>
<dd><code>fraction</code> - Fraction of rows to generate, range [0.0, 1.0].</dd>
<dd><code>seed</code> - Seed for sampling.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
<dt>Note:</dt>
<dd>This is NOT guaranteed to provide exactly the fraction of the count
 of the given <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sample(boolean,double)">
<h3>sample</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">sample</span><wbr><span class="parameters">(boolean&nbsp;withReplacement,
 double&nbsp;fraction)</span></div>
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> by sampling a fraction of rows, using a random seed.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>withReplacement</code> - Sample with replacement or not.</dd>
<dd><code>fraction</code> - Fraction of rows to generate, range [0.0, 1.0].
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
<dt>Note:</dt>
<dd>This is NOT guaranteed to provide exactly the fraction of the total count
 of the given <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="randomSplit(double[],long)">
<h3>randomSplit</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;[]</span>&nbsp;<span class="element-name">randomSplit</span><wbr><span class="parameters">(double[]&nbsp;weights,
 long&nbsp;seed)</span></div>
<div class="block">Randomly splits this Dataset with the provided weights.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>weights</code> - weights for splits, will be normalized if they don't sum to 1.</dd>
<dd><code>seed</code> - Seed for sampling.
 <p>
 For Java API, use <a href="#randomSplitAsList(double%5B%5D,long)"><code>randomSplitAsList(double[],long)</code></a>.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="randomSplitAsList(double[],long)">
<h3>randomSplitAsList</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&gt;</span>&nbsp;<span class="element-name">randomSplitAsList</span><wbr><span class="parameters">(double[]&nbsp;weights,
 long&nbsp;seed)</span></div>
<div class="block">Returns a Java list that contains randomly split Dataset with the provided weights.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>weights</code> - weights for splits, will be normalized if they don't sum to 1.</dd>
<dd><code>seed</code> - Seed for sampling.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="randomSplit(double[])">
<h3>randomSplit</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;[]</span>&nbsp;<span class="element-name">randomSplit</span><wbr><span class="parameters">(double[]&nbsp;weights)</span></div>
<div class="block">Randomly splits this Dataset with the provided weights.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>weights</code> - weights for splits, will be normalized if they don't sum to 1.</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="explode(scala.collection.Seq,scala.Function1,scala.reflect.api.TypeTags.TypeTag)">
<h3>explode</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;A extends scala.Product&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">explode</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;input,
 scala.Function1&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>,<wbr>scala.collection.TraversableOnce&lt;A&gt;&gt;&nbsp;f,
 scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$4)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">use flatMap() or select() with functions.explode() instead. Since 2.0.0.</div>
</div>
<div class="block">(Scala-specific) Returns a new Dataset where each row has been expanded to zero or more
 rows by the provided function. This is similar to a <code>LATERAL VIEW</code> in HiveQL. The columns of
 the input row are implicitly joined with each row that is output by the function.
 <p>
 Given that this is deprecated, as an alternative, you can explode columns either using
 <code>functions.explode()</code> or <code>flatMap()</code>. The following example uses these alternatives to count
 the number of books that contain a given word:
 <p>
 <pre><code>
   case class Book(title: String, words: String)
   val ds: Dataset[Book]

   val allWords = ds.select($"title", explode(split($"words", " ")).as("word"))

   val bookCountPerWord = allWords.groupBy("word").agg(count_distinct("title"))
 </code></pre>
 <p>
 Using <code>flatMap()</code> this can similarly be exploded as:
 <p>
 <pre><code>
   ds.flatMap(_.words.split(" "))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>input</code> - (undocumented)</dd>
<dd><code>f</code> - (undocumented)</dd>
<dd><code>evidence$4</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="explode(java.lang.String,java.lang.String,scala.Function1,scala.reflect.api.TypeTags.TypeTag)">
<h3>explode</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;A,<wbr>
B&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">explode</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;inputColumn,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;outputColumn,
 scala.Function1&lt;A,<wbr>scala.collection.TraversableOnce&lt;B&gt;&gt;&nbsp;f,
 scala.reflect.api.TypeTags.TypeTag&lt;B&gt;&nbsp;evidence$5)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">use flatMap() or select() with functions.explode() instead. Since 2.0.0.</div>
</div>
<div class="block">(Scala-specific) Returns a new Dataset where a single column has been expanded to zero
 or more rows by the provided function. This is similar to a <code>LATERAL VIEW</code> in HiveQL. All
 columns of the input row are implicitly joined with each value that is output by the function.
 <p>
 Given that this is deprecated, as an alternative, you can explode columns either using
 <code>functions.explode()</code>:
 <p>
 <pre><code>
   ds.select(explode(split($"words", " ")).as("word"))
 </code></pre>
 <p>
 or <code>flatMap()</code>:
 <p>
 <pre><code>
   ds.flatMap(_.words.split(" "))
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>inputColumn</code> - (undocumented)</dd>
<dd><code>outputColumn</code> - (undocumented)</dd>
<dd><code>f</code> - (undocumented)</dd>
<dd><code>evidence$5</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withColumn(java.lang.String,org.apache.spark.sql.Column)">
<h3>withColumn</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withColumn</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName,
 <a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col)</span></div>
<div class="block">Returns a new Dataset by adding a column or replacing the existing column that has
 the same name.
 <p>
 <code>column</code>'s expression must only refer to attributes supplied by this Dataset. It is an
 error to add a column that refers to some other Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colName</code> - (undocumented)</dd>
<dd><code>col</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>this method introduces a projection internally. Therefore, calling it multiple times,
 for instance, via loops in order to add multiple columns can generate big plans which
 can cause performance issues and even <code>StackOverflowException</code>. To avoid this,
 use <code>select</code> with the multiple columns at once.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withColumns(scala.collection.immutable.Map)">
<h3>withColumns</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withColumns</span><wbr><span class="parameters">(scala.collection.immutable.Map&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;colsMap)</span></div>
<div class="block">(Scala-specific) Returns a new Dataset by adding columns or replacing the existing columns
 that has the same names.
 <p>
 <code>colsMap</code> is a map of column name and column, the column must only refer to attributes
 supplied by this Dataset. It is an error to add columns that refers to some other Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colsMap</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withColumns(java.util.Map)">
<h3>withColumns</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withColumns</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html" title="class or interface in java.util" class="external-link">Map</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;colsMap)</span></div>
<div class="block">(Java-specific) Returns a new Dataset by adding columns or replacing the existing columns
 that has the same names.
 <p>
 <code>colsMap</code> is a map of column name and column, the column must only refer to attribute
 supplied by this Dataset. It is an error to add columns that refers to some other Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colsMap</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withColumnRenamed(java.lang.String,java.lang.String)">
<h3>withColumnRenamed</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withColumnRenamed</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;existingName,
 <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;newName)</span></div>
<div class="block">Returns a new Dataset with a column renamed.
 This is a no-op if schema doesn't contain existingName.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>existingName</code> - (undocumented)</dd>
<dd><code>newName</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withColumnsRenamed(scala.collection.immutable.Map)">
<h3>withColumnsRenamed</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withColumnsRenamed</span><wbr><span class="parameters">(scala.collection.immutable.Map&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colsMap)</span>
                                throws <span class="exceptions"><a href="AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</a></span></div>
<div class="block">(Scala-specific)
 Returns a new Dataset with a columns renamed.
 This is a no-op if schema doesn't contain existingName.
 <p>
 <code>colsMap</code> is a map of existing column name and new column name.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colsMap</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Throws:</dt>
<dd><code><a href="AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</a></code> - if there are duplicate names in resulting projection
 <p></dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withColumnsRenamed(java.util.Map)">
<h3>withColumnsRenamed</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withColumnsRenamed</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html" title="class or interface in java.util" class="external-link">Map</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colsMap)</span></div>
<div class="block">(Java-specific)
 Returns a new Dataset with a columns renamed.
 This is a no-op if schema doesn't contain existingName.
 <p>
 <code>colsMap</code> is a map of existing column name and new column name.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colsMap</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="withMetadata(java.lang.String,org.apache.spark.sql.types.Metadata)">
<h3>withMetadata</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">withMetadata</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;columnName,
 <a href="types/Metadata.html" title="class in org.apache.spark.sql.types">Metadata</a>&nbsp;metadata)</span></div>
<div class="block">Returns a new Dataset by updating an existing column with metadata.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>columnName</code> - (undocumented)</dd>
<dd><code>metadata</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="drop(java.lang.String)">
<h3>drop</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">drop</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;colName)</span></div>
<div class="block">Returns a new Dataset with a column dropped. This is a no-op if schema doesn't contain
 column name.
 <p>
 This method can only be used to drop top level columns. the colName string is treated
 literally without further interpretation.
 <p>
 Note: <code>drop(colName)</code> has different semantic with <code>drop(col(colName))</code>, for example:
 1, multi column have the same colName:
 <pre><code>
   val df1 = spark.range(0, 2).withColumn("key1", lit(1))
   val df2 = spark.range(0, 2).withColumn("key2", lit(2))
   val df3 = df1.join(df2)

   df3.show
   // +---+----+---+----+
   // | id|key1| id|key2|
   // +---+----+---+----+
   // |  0|   1|  0|   2|
   // |  0|   1|  1|   2|
   // |  1|   1|  0|   2|
   // |  1|   1|  1|   2|
   // +---+----+---+----+

   df3.drop("id").show()
   // output: the two 'id' columns are both dropped.
   // |key1|key2|
   // +----+----+
   // |   1|   2|
   // |   1|   2|
   // |   1|   2|
   // |   1|   2|
   // +----+----+

   df3.drop(col("id")).show()
   // ...AnalysisException: [AMBIGUOUS_REFERENCE] Reference `id` is ambiguous...
 </code></pre>
 <p>
 2, colName contains special characters, like dot.
 <pre><code>
   val df = spark.range(0, 2).withColumn("a.b.c", lit(1))

   df.show()
   // +---+-----+
   // | id|a.b.c|
   // +---+-----+
   // |  0|    1|
   // |  1|    1|
   // +---+-----+

   df.drop("a.b.c").show()
   // +---+
   // | id|
   // +---+
   // |  0|
   // |  1|
   // +---+

   df.drop(col("a.b.c")).show()
   // no column match the expression 'a.b.c'
   // +---+-----+
   // | id|a.b.c|
   // +---+-----+
   // |  0|    1|
   // |  1|    1|
   // +---+-----+
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colName</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="drop(scala.collection.Seq)">
<h3>drop</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">drop</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</span></div>
<div class="block">Returns a new Dataset with columns dropped.
 This is a no-op if schema doesn't contain column name(s).
 <p>
 This method can only be used to drop top level columns. the colName string is treated literally
 without further interpretation.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="drop(org.apache.spark.sql.Column)">
<h3>drop</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">drop</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col)</span></div>
<div class="block">Returns a new Dataset with column dropped.
 <p>
 This method can only be used to drop top level column.
 This version of drop accepts a <a href="Column.html" title="class in org.apache.spark.sql"><code>Column</code></a> rather than a name.
 This is a no-op if the Dataset doesn't have a column
 with an equivalent expression.
 <p>
 Note: <code>drop(col(colName))</code> has different semantic with <code>drop(colName)</code>,
 please refer to <code>Dataset#drop(colName: String)</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="drop(org.apache.spark.sql.Column,scala.collection.Seq)">
<h3>drop</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">drop</span><wbr><span class="parameters">(<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;cols)</span></div>
<div class="block">Returns a new Dataset with columns dropped.
 <p>
 This method can only be used to drop top level columns.
 This is a no-op if the Dataset doesn't have a columns
 with an equivalent expression.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.4.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicates()">
<h3>dropDuplicates</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicates</span>()</div>
<div class="block">Returns a new Dataset that contains only the unique rows from this Dataset.
 This is an alias for <code>distinct</code>.
 <p>
 For a static batch <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it just drops duplicate rows. For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it
 will keep all data across triggers as intermediate state to drop duplicates rows. You can use
 <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a> to limit how late the duplicate data can be and system will accordingly limit
 the state. In addition, too late data older than watermark will be dropped to avoid any
 possibility of duplicates.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicates(scala.collection.Seq)">
<h3>dropDuplicates</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicates</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</span></div>
<div class="block">(Scala-specific) Returns a new Dataset with duplicate rows removed, considering only
 the subset of columns.
 <p>
 For a static batch <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it just drops duplicate rows. For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it
 will keep all data across triggers as intermediate state to drop duplicates rows. You can use
 <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a> to limit how late the duplicate data can be and system will accordingly limit
 the state. In addition, too late data older than watermark will be dropped to avoid any
 possibility of duplicates.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicates(java.lang.String[])">
<h3>dropDuplicates</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicates</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;colNames)</span></div>
<div class="block">Returns a new Dataset with duplicate rows removed, considering only
 the subset of columns.
 <p>
 For a static batch <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it just drops duplicate rows. For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it
 will keep all data across triggers as intermediate state to drop duplicates rows. You can use
 <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a> to limit how late the duplicate data can be and system will accordingly limit
 the state. In addition, too late data older than watermark will be dropped to avoid any
 possibility of duplicates.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicates(java.lang.String,scala.collection.Seq)">
<h3>dropDuplicates</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicates</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Returns a new <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with duplicate rows removed, considering only
 the subset of columns.
 <p>
 For a static batch <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it just drops duplicate rows. For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, it
 will keep all data across triggers as intermediate state to drop duplicates rows. You can use
 <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a> to limit how late the duplicate data can be and system will accordingly limit
 the state. In addition, too late data older than watermark will be dropped to avoid any
 possibility of duplicates.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicatesWithinWatermark()">
<h3>dropDuplicatesWithinWatermark</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicatesWithinWatermark</span>()</div>
<div class="block">Returns a new Dataset with duplicates rows removed, within watermark.
 <p>
 This only works with streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, and watermark for the input <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> must be
 set via <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a>.
 <p>
 For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, this will keep all data across triggers as intermediate state
 to drop duplicated rows. The state will be kept to guarantee the semantic, "Events are
 deduplicated as long as the time distance of earliest and latest events are smaller than the
 delay threshold of watermark." Users are encouraged to set the delay threshold of watermark
 longer than max timestamp differences among duplicated events.
 <p>
 Note: too late data older than watermark will be dropped.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.5.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicatesWithinWatermark(scala.collection.Seq)">
<h3>dropDuplicatesWithinWatermark</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicatesWithinWatermark</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;colNames)</span></div>
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.
 <p>
 This only works with streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, and watermark for the input <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> must be
 set via <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a>.
 <p>
 For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, this will keep all data across triggers as intermediate state
 to drop duplicated rows. The state will be kept to guarantee the semantic, "Events are
 deduplicated as long as the time distance of earliest and latest events are smaller than the
 delay threshold of watermark." Users are encouraged to set the delay threshold of watermark
 longer than max timestamp differences among duplicated events.
 <p>
 Note: too late data older than watermark will be dropped.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.5.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicatesWithinWatermark(java.lang.String[])">
<h3>dropDuplicatesWithinWatermark</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicatesWithinWatermark</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]&nbsp;colNames)</span></div>
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.
 <p>
 This only works with streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, and watermark for the input <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> must be
 set via <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a>.
 <p>
 For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, this will keep all data across triggers as intermediate state
 to drop duplicated rows. The state will be kept to guarantee the semantic, "Events are
 deduplicated as long as the time distance of earliest and latest events are smaller than the
 delay threshold of watermark." Users are encouraged to set the delay threshold of watermark
 longer than max timestamp differences among duplicated events.
 <p>
 Note: too late data older than watermark will be dropped.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.5.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="dropDuplicatesWithinWatermark(java.lang.String,scala.collection.Seq)">
<h3>dropDuplicatesWithinWatermark</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">dropDuplicatesWithinWatermark</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;col1,
 scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Returns a new Dataset with duplicates rows removed, considering only the subset of columns,
 within watermark.
 <p>
 This only works with streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, and watermark for the input <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> must be
 set via <a href="#withWatermark(java.lang.String,java.lang.String)"><code>withWatermark(java.lang.String,java.lang.String)</code></a>.
 <p>
 For a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, this will keep all data across triggers as intermediate state
 to drop duplicated rows. The state will be kept to guarantee the semantic, "Events are
 deduplicated as long as the time distance of earliest and latest events are smaller than the
 delay threshold of watermark." Users are encouraged to set the delay threshold of watermark
 longer than max timestamp differences among duplicated events.
 <p>
 Note: too late data older than watermark will be dropped.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>col1</code> - (undocumented)</dd>
<dd><code>cols</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.5.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="describe(scala.collection.Seq)">
<h3>describe</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">describe</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;cols)</span></div>
<div class="block">Computes basic statistics for numeric and string columns, including count, mean, stddev, min,
 and max. If no columns are given, this function computes statistics for all numerical or
 string columns.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting Dataset. If you want to
 programmatically compute summary statistics, use the <code>agg</code> function instead.
 <p>
 <pre><code>
   ds.describe("age", "height").show()

   // output:
   // summary age   height
   // count   10.0  10.0
   // mean    53.3  178.05
   // stddev  11.6  15.7
   // min     18.0  163.0
   // max     92.0  192.0
 </code></pre>
 <p>
 Use <a href="#summary(java.lang.String...)"><code>summary(java.lang.String...)</code></a> for expanded statistics and control over which statistics to compute.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>cols</code> - Columns to compute statistics on.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="summary(scala.collection.Seq)">
<h3>summary</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</span>&nbsp;<span class="element-name">summary</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;&nbsp;statistics)</span></div>
<div class="block">Computes specified statistics for numeric and string columns. Available statistics are:
 <ul>
   <li>count</li>
   <li>mean</li>
   <li>stddev</li>
   <li>min</li>
   <li>max</li>
   <li>arbitrary approximate percentiles specified as a percentage (e.g. 75%)</li>
   <li>count_distinct</li>
   <li>approx_count_distinct</li>
 </ul>
 <p>
 If no statistics are given, this function computes count, mean, stddev, min,
 approximate quartiles (percentiles at 25%, 50%, and 75%), and max.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting Dataset. If you want to
 programmatically compute summary statistics, use the <code>agg</code> function instead.
 <p>
 <pre><code>
   ds.summary().show()

   // output:
   // summary age   height
   // count   10.0  10.0
   // mean    53.3  178.05
   // stddev  11.6  15.7
   // min     18.0  163.0
   // 25%     24.0  176.0
   // 50%     24.0  176.0
   // 75%     32.0  180.0
   // max     92.0  192.0
 </code></pre>
 <p>
 <pre><code>
   ds.summary("count", "min", "25%", "75%", "max").show()

   // output:
   // summary age   height
   // count   10.0  10.0
   // min     18.0  163.0
   // 25%     24.0  176.0
   // 75%     32.0  180.0
   // max     92.0  192.0
 </code></pre>
 <p>
 To do a summary for specific columns first select them:
 <p>
 <pre><code>
   ds.select("age", "height").summary().show()
 </code></pre>
 <p>
 Specify statistics to output custom summaries:
 <p>
 <pre><code>
   ds.summary("count", "count_distinct").show()
 </code></pre>
 <p>
 The distinct count isn't included by default.
 <p>
 You can also run approximate distinct counts which are faster:
 <p>
 <pre><code>
   ds.summary("count", "approx_count_distinct").show()
 </code></pre>
 <p>
 See also <a href="#describe(java.lang.String...)"><code>describe(java.lang.String...)</code></a> for basic statistics.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>statistics</code> - Statistics from above list to be computed.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="head(int)">
<h3>head</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></span>&nbsp;<span class="element-name">head</span><wbr><span class="parameters">(int&nbsp;n)</span></div>
<div class="block">Returns the first <code>n</code> rows.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>n</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
<dt>Note:</dt>
<dd>this method should only be used if the resulting array is expected to be small, as
 all the data is loaded into the driver's memory.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="head()">
<h3>head</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="type parameter in Dataset">T</a></span>&nbsp;<span class="element-name">head</span>()</div>
<div class="block">Returns the first row.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="first()">
<h3>first</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="type parameter in Dataset">T</a></span>&nbsp;<span class="element-name">first</span>()</div>
<div class="block">Returns the first row. Alias for head().</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="transform(scala.Function1)">
<h3>transform</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">transform</span><wbr><span class="parameters">(scala.Function1&lt;<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;,<wbr><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;&gt;&nbsp;t)</span></div>
<div class="block">Concise syntax for chaining custom transformations.
 <pre><code>
   def featurize(ds: Dataset[T]): Dataset[U] = ...

   ds
     .transform(featurize)
     .transform(...)
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>t</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filter(scala.Function1)">
<h3>filter</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">filter</span><wbr><span class="parameters">(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a>&gt;&nbsp;func)</span></div>
<div class="block">(Scala-specific)
 Returns a new Dataset that only contains elements where <code>func</code> returns <code>true</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="filter(org.apache.spark.api.java.function.FilterFunction)">
<h3>filter</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">filter</span><wbr><span class="parameters">(<a href="../api/java/function/FilterFunction.html" title="interface in org.apache.spark.api.java.function">FilterFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</span></div>
<div class="block">(Java-specific)
 Returns a new Dataset that only contains elements where <code>func</code> returns <code>true</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="map(scala.Function1,org.apache.spark.sql.Encoder)">
<h3>map</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">map</span><wbr><span class="parameters">(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$6)</span></div>
<div class="block">(Scala-specific)
 Returns a new Dataset that contains the result of applying <code>func</code> to each element.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dd><code>evidence$6</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="map(org.apache.spark.api.java.function.MapFunction,org.apache.spark.sql.Encoder)">
<h3>map</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">map</span><wbr><span class="parameters">(<a href="../api/java/function/MapFunction.html" title="interface in org.apache.spark.api.java.function">MapFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</span></div>
<div class="block">(Java-specific)
 Returns a new Dataset that contains the result of applying <code>func</code> to each element.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dd><code>encoder</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapPartitions(scala.Function1,org.apache.spark.sql.Encoder)">
<h3>mapPartitions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">mapPartitions</span><wbr><span class="parameters">(scala.Function1&lt;scala.collection.Iterator&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;,<wbr>scala.collection.Iterator&lt;U&gt;&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$7)</span></div>
<div class="block">(Scala-specific)
 Returns a new Dataset that contains the result of applying <code>func</code> to each partition.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dd><code>evidence$7</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="mapPartitions(org.apache.spark.api.java.function.MapPartitionsFunction,org.apache.spark.sql.Encoder)">
<h3>mapPartitions</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">mapPartitions</span><wbr><span class="parameters">(<a href="../api/java/function/MapPartitionsFunction.html" title="interface in org.apache.spark.api.java.function">MapPartitionsFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;f,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</span></div>
<div class="block">(Java-specific)
 Returns a new Dataset that contains the result of applying <code>f</code> to each partition.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>f</code> - (undocumented)</dd>
<dd><code>encoder</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMap(scala.Function1,org.apache.spark.sql.Encoder)">
<h3>flatMap</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">flatMap</span><wbr><span class="parameters">(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;func,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;evidence$8)</span></div>
<div class="block">(Scala-specific)
 Returns a new Dataset by first applying a function to all elements of this Dataset,
 and then flattening the results.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dd><code>evidence$8</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="flatMap(org.apache.spark.api.java.function.FlatMapFunction,org.apache.spark.sql.Encoder)">
<h3>flatMap</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="type-parameters">&lt;U&gt;</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;U&gt;</span>&nbsp;<span class="element-name">flatMap</span><wbr><span class="parameters">(<a href="../api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>U&gt;&nbsp;f,
 <a href="Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;U&gt;&nbsp;encoder)</span></div>
<div class="block">(Java-specific)
 Returns a new Dataset by first applying a function to all elements of this Dataset,
 and then flattening the results.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>f</code> - (undocumented)</dd>
<dd><code>encoder</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="foreach(scala.Function1)">
<h3>foreach</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">foreach</span><wbr><span class="parameters">(scala.Function1&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>,<wbr>scala.runtime.BoxedUnit&gt;&nbsp;f)</span></div>
<div class="block">Applies a function <code>f</code> to all rows.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>f</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="foreach(org.apache.spark.api.java.function.ForeachFunction)">
<h3>foreach</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">foreach</span><wbr><span class="parameters">(<a href="../api/java/function/ForeachFunction.html" title="interface in org.apache.spark.api.java.function">ForeachFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</span></div>
<div class="block">(Java-specific)
 Runs <code>func</code> on each element of this Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="foreachPartition(scala.Function1)">
<h3>foreachPartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">foreachPartition</span><wbr><span class="parameters">(scala.Function1&lt;scala.collection.Iterator&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;,<wbr>scala.runtime.BoxedUnit&gt;&nbsp;f)</span></div>
<div class="block">Applies a function <code>f</code> to each partition of this Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>f</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="foreachPartition(org.apache.spark.api.java.function.ForeachPartitionFunction)">
<h3>foreachPartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">foreachPartition</span><wbr><span class="parameters">(<a href="../api/java/function/ForeachPartitionFunction.html" title="interface in org.apache.spark.api.java.function">ForeachPartitionFunction</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;func)</span></div>
<div class="block">(Java-specific)
 Runs <code>func</code> on each partition of this Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>func</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="take(int)">
<h3>take</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></span>&nbsp;<span class="element-name">take</span><wbr><span class="parameters">(int&nbsp;n)</span></div>
<div class="block">Returns the first <code>n</code> rows in the Dataset.
 <p>
 Running take requires moving data into the application's driver process, and doing so with
 a very large <code>n</code> can crash the driver process with OutOfMemoryError.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>n</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="tail(int)">
<h3>tail</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></span>&nbsp;<span class="element-name">tail</span><wbr><span class="parameters">(int&nbsp;n)</span></div>
<div class="block">Returns the last <code>n</code> rows in the Dataset.
 <p>
 Running tail requires moving data into the application's driver process, and doing so with
 a very large <code>n</code> can crash the driver process with OutOfMemoryError.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>n</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="takeAsList(int)">
<h3>takeAsList</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">takeAsList</span><wbr><span class="parameters">(int&nbsp;n)</span></div>
<div class="block">Returns the first <code>n</code> rows in the Dataset as a list.
 <p>
 Running take requires moving data into the application's driver process, and doing so with
 a very large <code>n</code> can crash the driver process with OutOfMemoryError.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>n</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="collect()">
<h3>collect</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html" title="class or interface in java.lang" class="external-link">Object</a></span>&nbsp;<span class="element-name">collect</span>()</div>
<div class="block">Returns an array that contains all rows in this Dataset.
 <p>
 Running collect requires moving all the data into the application's driver process, and
 doing so on a very large dataset can crash the driver process with OutOfMemoryError.
 <p>
 For Java API, use <a href="#collectAsList()"><code>collectAsList()</code></a>.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="collectAsList()">
<h3>collectAsList</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/List.html" title="class or interface in java.util" class="external-link">List</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">collectAsList</span>()</div>
<div class="block">Returns a Java list that contains all rows in this Dataset.
 <p>
 Running collect requires moving all the data into the application's driver process, and
 doing so on a very large dataset can crash the driver process with OutOfMemoryError.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toLocalIterator()">
<h3>toLocalIterator</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Iterator.html" title="class or interface in java.util" class="external-link">Iterator</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">toLocalIterator</span>()</div>
<div class="block">Returns an iterator that contains all rows in this Dataset.
 <p>
 The iterator will consume as much memory as the largest partition in this Dataset.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>this results in multiple Spark jobs, and if the input Dataset is the result
 of a wide transformation (e.g. join with different partitioners), to avoid
 recomputing the input Dataset should be cached first.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="count()">
<h3>count</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">long</span>&nbsp;<span class="element-name">count</span>()</div>
<div class="block">Returns the number of rows in the Dataset.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition(int)">
<h3>repartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartition</span><wbr><span class="parameters">(int&nbsp;numPartitions)</span></div>
<div class="block">Returns a new Dataset that has exactly <code>numPartitions</code> partitions.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition(int,scala.collection.Seq)">
<h3>repartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartition</span><wbr><span class="parameters">(int&nbsp;numPartitions,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>. The resulting Dataset is hash partitioned.
 <p>
 This is the same operation as "DISTRIBUTE BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartition(scala.collection.Seq)">
<h3>repartition</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartition</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.
 The resulting Dataset is hash partitioned.
 <p>
 This is the same operation as "DISTRIBUTE BY" in SQL (Hive QL).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartitionByRange(int,scala.collection.Seq)">
<h3>repartitionByRange</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartitionByRange</span><wbr><span class="parameters">(int&nbsp;numPartitions,
 scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions into
 <code>numPartitions</code>. The resulting Dataset is range partitioned.
 <p>
 At least one partition-by expression must be specified.
 When no explicit sort order is specified, "ascending nulls first" is assumed.
 Note, the rows are not sorted in each partition of the resulting Dataset.
 <p>
 Note that due to performance reasons this method uses sampling to estimate the ranges.
 Hence, the output may not be consistent, since sampling can return different values.
 The sample size can be controlled by the config
 <code>spark.sql.execution.rangeExchange.sampleSizePerPartition</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="repartitionByRange(scala.collection.Seq)">
<h3>repartitionByRange</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">repartitionByRange</span><wbr><span class="parameters">(scala.collection.Seq&lt;<a href="Column.html" title="class in org.apache.spark.sql">Column</a>&gt;&nbsp;partitionExprs)</span></div>
<div class="block">Returns a new Dataset partitioned by the given partitioning expressions, using
 <code>spark.sql.shuffle.partitions</code> as number of partitions.
 The resulting Dataset is range partitioned.
 <p>
 At least one partition-by expression must be specified.
 When no explicit sort order is specified, "ascending nulls first" is assumed.
 Note, the rows are not sorted in each partition of the resulting Dataset.
 <p>
 Note that due to performance reasons this method uses sampling to estimate the ranges.
 Hence, the output may not be consistent, since sampling can return different values.
 The sample size can be controlled by the config
 <code>spark.sql.execution.rangeExchange.sampleSizePerPartition</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>partitionExprs</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.3.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="coalesce(int)">
<h3>coalesce</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">coalesce</span><wbr><span class="parameters">(int&nbsp;numPartitions)</span></div>
<div class="block">Returns a new Dataset that has exactly <code>numPartitions</code> partitions, when the fewer partitions
 are requested. If a larger number of partitions is requested, it will stay at the current
 number of partitions. Similar to coalesce defined on an <code>RDD</code>, this operation results in
 a narrow dependency, e.g. if you go from 1000 partitions to 100 partitions, there will not
 be a shuffle, instead each of the 100 new partitions will claim 10 of the current partitions.
 <p>
 However, if you're doing a drastic coalesce, e.g. to numPartitions = 1,
 this may result in your computation taking place on fewer nodes than
 you like (e.g. one node in the case of numPartitions = 1). To avoid this,
 you can call repartition. This will add a shuffle step, but means the
 current upstream partitions will be executed in parallel (per whatever
 the current partitioning is).
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="distinct()">
<h3>distinct</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">distinct</span>()</div>
<div class="block">Returns a new Dataset that contains only the unique rows from this Dataset.
 This is an alias for <code>dropDuplicates</code>.
 <p>
 Note that for a streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>, this method returns distinct rows only once
 regardless of the output mode, which the behavior may not be same with <code>DISTINCT</code> in SQL
 against streaming <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
<dt>Note:</dt>
<dd>Equality checking is performed directly on the encoded representation of the data
 and thus is not affected by a custom <code>equals</code> function defined on <code>T</code>.
 <p></dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="persist()">
<h3>persist</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">persist</span>()</div>
<div class="block">Persist this Dataset with the default storage level (<code>MEMORY_AND_DISK</code>).
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="cache()">
<h3>cache</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">cache</span>()</div>
<div class="block">Persist this Dataset with the default storage level (<code>MEMORY_AND_DISK</code>).
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="persist(org.apache.spark.storage.StorageLevel)">
<h3>persist</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">persist</span><wbr><span class="parameters">(<a href="../storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;newLevel)</span></div>
<div class="block">Persist this Dataset with the given storage level.</div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>newLevel</code> - One of: <code>MEMORY_ONLY</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_ONLY_SER</code>,
                 <code>MEMORY_AND_DISK_SER</code>, <code>DISK_ONLY</code>, <code>MEMORY_ONLY_2</code>,
                 <code>MEMORY_AND_DISK_2</code>, etc.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="storageLevel()">
<h3>storageLevel</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="../storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></span>&nbsp;<span class="element-name">storageLevel</span>()</div>
<div class="block">Get the Dataset's current storage level, or StorageLevel.NONE if not persisted.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.1.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unpersist(boolean)">
<h3>unpersist</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">unpersist</span><wbr><span class="parameters">(boolean&nbsp;blocking)</span></div>
<div class="block">Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.
 This will not un-persist any cached data that is built upon this Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>blocking</code> - Whether to block until all blocks are deleted.
 <p></dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="unpersist()">
<h3>unpersist</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">unpersist</span>()</div>
<div class="block">Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.
 This will not un-persist any cached data that is built upon this Dataset.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="rdd()">
<h3>rdd</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="../rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">rdd</span>()</div>
</section>
</li>
<li>
<section class="detail" id="toJavaRDD()">
<h3>toJavaRDD</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="../api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">toJavaRDD</span>()</div>
<div class="block">Returns the content of the Dataset as a <code>JavaRDD</code> of <code>T</code>s.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="javaRDD()">
<h3>javaRDD</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="../api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">javaRDD</span>()</div>
<div class="block">Returns the content of the Dataset as a <code>JavaRDD</code> of <code>T</code>s.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="registerTempTable(java.lang.String)">
<h3>registerTempTable</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">registerTempTable</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;tableName)</span></div>
<div class="deprecation-block"><span class="deprecated-label">Deprecated.</span>
<div class="deprecation-comment">Use createOrReplaceTempView(viewName) instead. Since 2.0.0.</div>
</div>
<div class="block">Registers this Dataset as a temporary table using the given name. The lifetime of this
 temporary table is tied to the <a href="SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a> that was used to create this Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>tableName</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="createTempView(java.lang.String)">
<h3>createTempView</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">createTempView</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</span>
                    throws <span class="exceptions"><a href="AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</a></span></div>
<div class="block">Creates a local temporary view using the given name. The lifetime of this
 temporary view is tied to the <a href="SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a> that was used to create this Dataset.
 <p>
 Local temporary view is session-scoped. Its lifetime is the lifetime of the session that
 created it, i.e. it will be automatically dropped when the session terminates. It's not
 tied to any databases, i.e. we can't use <code>db1.view1</code> to reference a local temporary view.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>viewName</code> - (undocumented)</dd>
<dt>Throws:</dt>
<dd><code><a href="AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</a></code> - if the view name is invalid or already exists
 <p></dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="createOrReplaceTempView(java.lang.String)">
<h3>createOrReplaceTempView</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">createOrReplaceTempView</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</span></div>
<div class="block">Creates a local temporary view using the given name. The lifetime of this
 temporary view is tied to the <a href="SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a> that was used to create this Dataset.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>viewName</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="createGlobalTempView(java.lang.String)">
<h3>createGlobalTempView</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">createGlobalTempView</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</span>
                          throws <span class="exceptions"><a href="AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</a></span></div>
<div class="block">Creates a global temporary view using the given name. The lifetime of this
 temporary view is tied to this Spark application.
 <p>
 Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,
 i.e. it will be automatically dropped when the application terminates. It's tied to a system
 preserved database <code>global_temp</code>, and we must use the qualified name to refer a global temp
 view, e.g. <code>SELECT * FROM global_temp.view1</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>viewName</code> - (undocumented)</dd>
<dt>Throws:</dt>
<dd><code><a href="AnalysisException.html" title="class in org.apache.spark.sql">AnalysisException</a></code> - if the view name is invalid or already exists
 <p></dd>
<dt>Since:</dt>
<dd>2.1.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="createOrReplaceGlobalTempView(java.lang.String)">
<h3>createOrReplaceGlobalTempView</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">void</span>&nbsp;<span class="element-name">createOrReplaceGlobalTempView</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;viewName)</span></div>
<div class="block">Creates or replaces a global temporary view using the given name. The lifetime of this
 temporary view is tied to this Spark application.
 <p>
 Global temporary view is cross-session. Its lifetime is the lifetime of the Spark application,
 i.e. it will be automatically dropped when the application terminates. It's tied to a system
 preserved database <code>global_temp</code>, and we must use the qualified name to refer a global temp
 view, e.g. <code>SELECT * FROM global_temp.view1</code>.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>viewName</code> - (undocumented)</dd>
<dt>Since:</dt>
<dd>2.2.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="write()">
<h3>write</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DataFrameWriter.html" title="class in org.apache.spark.sql">DataFrameWriter</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">write</span>()</div>
<div class="block">Interface for saving the content of the non-streaming Dataset out into external storage.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>1.6.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="writeTo(java.lang.String)">
<h3>writeTo</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="DataFrameWriterV2.html" title="class in org.apache.spark.sql">DataFrameWriterV2</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">writeTo</span><wbr><span class="parameters">(<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&nbsp;table)</span></div>
<div class="block">Create a write configuration builder for v2 sources.
 <p>
 This builder is used to configure and execute write operations. For example, to append to an
 existing table, run:
 <p>
 <pre><code>
   df.writeTo("catalog.db.table").append()
 </code></pre>
 <p>
 This can also be used to create or replace existing tables:
 <p>
 <pre><code>
   df.writeTo("catalog.db.table").partitionedBy($"col").createOrReplace()
 </code></pre>
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>table</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="writeStream()">
<h3>writeStream</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;</span>&nbsp;<span class="element-name">writeStream</span>()</div>
<div class="block">Interface for saving the content of the streaming Dataset out into external storage.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="toJSON()">
<h3>toJSON</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>&gt;</span>&nbsp;<span class="element-name">toJSON</span>()</div>
<div class="block">Returns the content of the Dataset as a Dataset of JSON strings.</div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="inputFiles()">
<h3>inputFiles</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html" title="class or interface in java.lang" class="external-link">String</a>[]</span>&nbsp;<span class="element-name">inputFiles</span>()</div>
<div class="block">Returns a best-effort snapshot of the files that compose this Dataset. This method simply
 asks each constituent BaseRelation for its respective files and takes the union of all results.
 Depending on the source relations, this may not find all input files. Duplicates are removed.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>2.0.0</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="sameSemantics(org.apache.spark.sql.Dataset)">
<h3>sameSemantics</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">boolean</span>&nbsp;<span class="element-name">sameSemantics</span><wbr><span class="parameters">(<a href="Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="Dataset.html" title="type parameter in Dataset">T</a>&gt;&nbsp;other)</span></div>
<div class="block">Returns <code>true</code> when the logical query plans inside both <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>s are equal and
 therefore return same results.
 <p></div>
<dl class="notes">
<dt>Parameters:</dt>
<dd><code>other</code> - (undocumented)</dd>
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.1.0</dd>
<dt>Note:</dt>
<dd>The equality comparison here is simplified by tolerating the cosmetic differences
       such as attribute names., This API can compare both <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>s very fast but can still return <code>false</code> on
       the <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> that return the same results, for instance, from different plans. Such
       false negative semantic can be useful when caching as an example.</dd>
</dl>
</section>
</li>
<li>
<section class="detail" id="semanticHash()">
<h3>semanticHash</h3>
<div class="member-signature"><span class="modifiers">public</span>&nbsp;<span class="return-type">int</span>&nbsp;<span class="element-name">semanticHash</span>()</div>
<div class="block">Returns a <code>hashCode</code> of the logical query plan against this <a href="Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a>.
 <p></div>
<dl class="notes">
<dt>Returns:</dt>
<dd>(undocumented)</dd>
<dt>Since:</dt>
<dd>3.1.0</dd>
<dt>Note:</dt>
<dd>Unlike the standard <code>hashCode</code>, the hash is calculated against the query plan
       simplified by tolerating the cosmetic differences such as attribute names.</dd>
</dl>
</section>
</li>
</ul>
</section>
</li>
</ul>
</section>
<!-- ========= END OF CLASS DATA ========= -->
</main>
</div>
</div>
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
