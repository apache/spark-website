<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_80) on Wed Jun 08 10:02:50 BST 2016 -->
<title>SQLContext</title>
<meta name="date" content="2016-06-08">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="SQLContext";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SparkSession.implicits$.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SQLContext" class="title">Class SQLContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SQLContext</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable</dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="strong">SQLContext</span>
extends java.lang.Object
implements scala.Serializable</pre>
<div class="block">The entry point for working with structured data (rows and columns) in Spark, in Spark 1.x.
 <p>
 As of Spark 2.0, this is replaced by <a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a>. However, we are keeping the class here
 for backward compatibility.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd>
<dt><span class="strong">See Also:</span></dt><dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SQLContext">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a></strong></code>
<div class="block">:: Experimental ::
 (Scala-specific) Implicit methods available in Scala for converting
 common Scala objects into <code>DataFrame</code>s.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.api.java.JavaSparkContext)">SQLContext</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sparkContext)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.SparkContext)">SQLContext</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20java.lang.String)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                      java.lang.String&nbsp;schemaString)</code>
<div class="block">Apply a schema defined by the schemaString to an RDD.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#applySchemaToPythonRDD(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">applySchemaToPythonRDD</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                      <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">Apply a schema defined by the schema to an RDD.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">baseRelationToDataFrame</a></strong>(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</code>
<div class="block">Convert a <code>BaseRelation</code> created for external data sources into a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.CacheManager</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#cacheManager()">cacheManager</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)">cacheTable</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Caches the specified table in-memory.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#clearActive()">clearActive</a></strong>()</code>
<div class="block">Clears the active SQLContext for current thread.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#clearCache()">clearCache</a></strong>()</code>
<div class="block">Removes all cached tables from the in-memory cache.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.internal.SQLConf</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#conf()">conf</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20java.lang.Class)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.api.java.JavaRDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>JavaRDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(java.util.List,%20java.lang.Class)">createDataFrame</a></strong>(java.util.List&lt;?&gt;&nbsp;data,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an List of Java Beans.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(java.util.List,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>List</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20java.lang.Class)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
               java.lang.Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>
<div class="block">:: Experimental ::
 Creates a DataFrame from an RDD of Product (e.g.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.types.StructType)">createDataFrame</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>RDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;&nbsp;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame(scala.collection.Seq,%20scala.reflect.api.TypeTags.TypeTag)">createDataFrame</a></strong>(scala.collection.Seq&lt;A&gt;&nbsp;data,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</code>
<div class="block">:: Experimental ::
 Creates a DataFrame from a local Seq of Product.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset(java.util.List,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(java.util.List&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset(org.apache.spark.rdd.RDD,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset(scala.collection.Seq,%20org.apache.spark.sql.Encoder)">createDataset</a></strong>(scala.collection.Seq&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;path)</code>
<div class="block">:: Experimental ::
 Creates an external table from the given path and returns the corresponding DataFrame.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20java.util.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block">:: Experimental ::
 Creates an external table from the given path based on a data source and a set of options.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20scala.collection.immutable.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block">:: Experimental ::
 (Scala-specific)
 Creates an external table from the given path based on a data source and a set of options.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20java.lang.String)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;path,
                   java.lang.String&nbsp;source)</code>
<div class="block">:: Experimental ::
 Creates an external table from the given path based on a data source
 and returns the corresponding DataFrame.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20org.apache.spark.sql.types.StructType,%20java.util.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                   java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block">:: Experimental ::
 Create an external table from the given path based on a data source, a schema and
 a set of options.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#createExternalTable(java.lang.String,%20java.lang.String,%20org.apache.spark.sql.types.StructType,%20scala.collection.immutable.Map)">createExternalTable</a></strong>(java.lang.String&nbsp;tableName,
                   java.lang.String&nbsp;source,
                   <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                   scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</code>
<div class="block">:: Experimental ::
 (Scala-specific)
 Create an external table from the given path based on a data source, a schema and
 a set of options.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#dropTempTable(java.lang.String)">dropTempTable</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Drops the temporary table with the given table name in the catalog.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#emptyDataFrame()">emptyDataFrame</a></strong>()</code>
<div class="block">:: Experimental ::
 Returns a <code>DataFrame</code> with no rows or columns.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">executePlan</a></strong>(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.QueryExecution</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#executeSql(java.lang.String)">executeSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#experimental()">experimental</a></strong>()</code>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.catalog.ExternalCatalog</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#externalCatalog()">externalCatalog</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getAllConfs()">getAllConfs</a></strong>()</code>
<div class="block">Return all the configuration properties that have been set (i.e.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String)">getConf</a></strong>(java.lang.String&nbsp;key)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf(java.lang.String,%20java.lang.String)">getConf</a></strong>(java.lang.String&nbsp;key,
       java.lang.String&nbsp;defaultValue)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#getOrCreate(org.apache.spark.SparkContext)">getOrCreate</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</code>
<div class="block">Get the singleton SQLContext if it exists or create a new one using the given SparkContext.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#implicits()">implicits</a></strong>()</code>
<div class="block">Accessor for nested Scala object</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#initializeLogIfNecessary(boolean)">initializeLogIfNecessary</a></strong>(boolean&nbsp;isInterpreter)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)">isCached</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Returns true if the table is currently cached in-memory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isRootContext()">isRootContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#isTraceEnabled()">isTraceEnabled</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.execution.ui.SQLListener</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#listener()">listener</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#listenerManager()">listenerManager</a></strong>()</code>
<div class="block">An interface to register custom <a href="../../../../org/apache/spark/sql/util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a>s
 that listen for execution metrics.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static org.slf4j.Logger</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#log()">log</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logDebug(scala.Function0)">logDebug</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logDebug(scala.Function0,%20java.lang.Throwable)">logDebug</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
        java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logError(scala.Function0)">logError</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logError(scala.Function0,%20java.lang.Throwable)">logError</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
        java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logInfo(scala.Function0)">logInfo</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logInfo(scala.Function0,%20java.lang.Throwable)">logInfo</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
       java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logName()">logName</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logTrace(scala.Function0)">logTrace</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logTrace(scala.Function0,%20java.lang.Throwable)">logTrace</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
        java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logWarning(scala.Function0)">logWarning</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#logWarning(scala.Function0,%20java.lang.Throwable)">logWarning</a></strong>(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
          java.lang.Throwable&nbsp;throwable)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#newSession()">newSession</a></strong>()</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a> as new session, with separated SQL configurations, temporary
 tables, registered functions, but sharing the same <code>SparkContext</code>, cached data and
 other things.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parseDataType(java.lang.String)">parseDataType</a></strong>(java.lang.String&nbsp;dataTypeString)</code>
<div class="block">Parses the data type in our internal string representation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.apache.spark.sql.catalyst.plans.logical.LogicalPlan</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#parseSql(java.lang.String)">parseSql</a></strong>(java.lang.String&nbsp;sql)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long)">range</a></strong>(long&nbsp;end)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from 0 to <code>end</code> (exclusive) with step value 1.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long)">range</a></strong>(long&nbsp;start,
     long&nbsp;end)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with step value 1.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long,%20long)">range</a></strong>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#range(long,%20long,%20long,%20int)">range</a></strong>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step,
     int&nbsp;numPartitions)</code>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
 specified.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#read()">read</a></strong>()</code>
<div class="block">:: Experimental ::
 Returns a <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><code>DataFrameReader</code></a> that can be used to read data and streams in as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/apache/spark/sql/RuntimeConfig.html" title="class in org.apache.spark.sql">RuntimeConfig</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#runtimeConf()">runtimeConf</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.internal.SessionState</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sessionState()">sessionState</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setActive(org.apache.spark.sql.SQLContext)">setActive</a></strong>(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</code>
<div class="block">Changes the SQLContext that will be returned in this thread and its children when
 SQLContext.getOrCreate() is called.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf(java.util.Properties)">setConf</a></strong>(java.util.Properties&nbsp;props)</code>
<div class="block">Set Spark SQL configuration properties.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf(java.lang.String,%20java.lang.String)">setConf</a></strong>(java.lang.String&nbsp;key,
       java.lang.String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.apache.spark.sql.internal.SharedState</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sharedState()">sharedState</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkSession()">sparkSession</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql</a></strong>(java.lang.String&nbsp;sqlText)</code>
<div class="block">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql">ContinuousQueryManager</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#streams()">streams</a></strong>()</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql"><code>ContinuousQueryManager</code></a> that allows managing all the
 <a href="../../../../org/apache/spark/sql/ContinuousQuery.html" title="interface in org.apache.spark.sql"><code>ContinuousQueries</code></a> active on <code>this</code> context.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Returns the specified table as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.lang.String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tableNames()">tableNames</a></strong>()</code>
<div class="block">Returns the names of tables in the current database as an array.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.lang.String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tableNames(java.lang.String)">tableNames</a></strong>(java.lang.String&nbsp;databaseName)</code>
<div class="block">Returns the names of tables in the given database as an array.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tables()">tables</a></strong>()</code>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the current database.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#tables(java.lang.String)">tables</a></strong>(java.lang.String&nbsp;databaseName)</code>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the given database.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#udf()">udf</a></strong>()</code>
<div class="block">A collection of methods for registering user-defined functions (UDF).</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)">uncacheTable</a></strong>(java.lang.String&nbsp;tableName)</code>
<div class="block">Removes the specified table from the in-memory cache.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="SQLContext(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>SQLContext</h4>
<pre>public&nbsp;SQLContext(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc)</pre>
</li>
</ul>
<a name="SQLContext(org.apache.spark.api.java.JavaSparkContext)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>SQLContext</h4>
<pre>public&nbsp;SQLContext(<a href="../../../../org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a>&nbsp;sparkContext)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="getOrCreate(org.apache.spark.SparkContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOrCreate</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;getOrCreate(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext)</pre>
<div class="block">Get the singleton SQLContext if it exists or create a new one using the given SparkContext.
 <p>
 This function can be used to create a singleton SQLContext object that can be shared across
 the JVM.
 <p>
 If there is an active SQLContext for current thread, it will be returned instead of the global
 one.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sparkContext</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.5.0</dd></dl>
</li>
</ul>
<a name="setActive(org.apache.spark.sql.SQLContext)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setActive</h4>
<pre>public static&nbsp;void&nbsp;setActive(<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;sqlContext)</pre>
<div class="block">Changes the SQLContext that will be returned in this thread and its children when
 SQLContext.getOrCreate() is called. This can be used to ensure that a given thread receives
 a SQLContext with an isolated session, instead of the global (first created) context.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sqlContext</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="clearActive()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearActive</h4>
<pre>public static&nbsp;void&nbsp;clearActive()</pre>
<div class="block">Clears the active SQLContext for current thread. Subsequent calls to getOrCreate will
 return the first created context instead of a thread-local override.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="logName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logName</h4>
<pre>protected static&nbsp;java.lang.String&nbsp;logName()</pre>
</li>
</ul>
<a name="log()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>log</h4>
<pre>protected static&nbsp;org.slf4j.Logger&nbsp;log()</pre>
</li>
</ul>
<a name="logInfo(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logInfo</h4>
<pre>protected static&nbsp;void&nbsp;logInfo(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logDebug(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logDebug</h4>
<pre>protected static&nbsp;void&nbsp;logDebug(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logTrace(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logTrace</h4>
<pre>protected static&nbsp;void&nbsp;logTrace(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logWarning(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logWarning</h4>
<pre>protected static&nbsp;void&nbsp;logWarning(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logError(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logError</h4>
<pre>protected static&nbsp;void&nbsp;logError(scala.Function0&lt;java.lang.String&gt;&nbsp;msg)</pre>
</li>
</ul>
<a name="logInfo(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logInfo</h4>
<pre>protected static&nbsp;void&nbsp;logInfo(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
           java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logDebug(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logDebug</h4>
<pre>protected static&nbsp;void&nbsp;logDebug(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
            java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logTrace(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logTrace</h4>
<pre>protected static&nbsp;void&nbsp;logTrace(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
            java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logWarning(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logWarning</h4>
<pre>protected static&nbsp;void&nbsp;logWarning(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
              java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="logError(scala.Function0, java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logError</h4>
<pre>protected static&nbsp;void&nbsp;logError(scala.Function0&lt;java.lang.String&gt;&nbsp;msg,
            java.lang.Throwable&nbsp;throwable)</pre>
</li>
</ul>
<a name="isTraceEnabled()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isTraceEnabled</h4>
<pre>protected static&nbsp;boolean&nbsp;isTraceEnabled()</pre>
</li>
</ul>
<a name="initializeLogIfNecessary(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeLogIfNecessary</h4>
<pre>protected static&nbsp;void&nbsp;initializeLogIfNecessary(boolean&nbsp;isInterpreter)</pre>
</li>
</ul>
<a name="sparkSession()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkSession</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession()</pre>
</li>
</ul>
<a name="isRootContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isRootContext</h4>
<pre>public&nbsp;boolean&nbsp;isRootContext()</pre>
</li>
</ul>
<a name="sessionState()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sessionState</h4>
<pre>protected&nbsp;org.apache.spark.sql.internal.SessionState&nbsp;sessionState()</pre>
</li>
</ul>
<a name="sharedState()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sharedState</h4>
<pre>protected&nbsp;org.apache.spark.sql.internal.SharedState&nbsp;sharedState()</pre>
</li>
</ul>
<a name="conf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>protected&nbsp;org.apache.spark.sql.internal.SQLConf&nbsp;conf()</pre>
</li>
</ul>
<a name="runtimeConf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>runtimeConf</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/RuntimeConfig.html" title="class in org.apache.spark.sql">RuntimeConfig</a>&nbsp;runtimeConf()</pre>
</li>
</ul>
<a name="cacheManager()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheManager</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.CacheManager&nbsp;cacheManager()</pre>
</li>
</ul>
<a name="listener()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listener</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.ui.SQLListener&nbsp;listener()</pre>
</li>
</ul>
<a name="externalCatalog()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>externalCatalog</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.catalog.ExternalCatalog&nbsp;externalCatalog()</pre>
</li>
</ul>
<a name="sparkContext()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="newSession()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newSession</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;newSession()</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a> as new session, with separated SQL configurations, temporary
 tables, registered functions, but sharing the same <code>SparkContext</code>, cached data and
 other things.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="listenerManager()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listenerManager</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a>&nbsp;listenerManager()</pre>
<div class="block">An interface to register custom <a href="../../../../org/apache/spark/sql/util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a>s
 that listen for execution metrics.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="setConf(java.util.Properties)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.util.Properties&nbsp;props)</pre>
<div class="block">Set Spark SQL configuration properties.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>props</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="setConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.lang.String&nbsp;key,
           java.lang.String&nbsp;value)</pre>
<div class="block">Set the given Spark SQL configuration property.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="getConf(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;java.lang.String&nbsp;getConf(java.lang.String&nbsp;key)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="getConf(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;java.lang.String&nbsp;getConf(java.lang.String&nbsp;key,
                       java.lang.String&nbsp;defaultValue)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key. If the key is not set
 yet, return <code>defaultValue</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>defaultValue</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="getAllConfs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllConfs</h4>
<pre>public&nbsp;scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;getAllConfs()</pre>
<div class="block">Return all the configuration properties that have been set (i.e. not the default).
 This creates a new copy of the config properties in the form of a Map.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.0.0</dd></dl>
</li>
</ul>
<a name="parseSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;parseSql(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="executeSql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executeSql</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;executeSql(java.lang.String&nbsp;sql)</pre>
</li>
</ul>
<a name="executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executePlan</h4>
<pre>protected&nbsp;org.apache.spark.sql.execution.QueryExecution&nbsp;executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan&nbsp;plan)</pre>
</li>
</ul>
<a name="experimental()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>experimental</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a>&nbsp;experimental()</pre>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="emptyDataFrame()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>emptyDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;emptyDataFrame()</pre>
<div class="block">:: Experimental ::
 Returns a <code>DataFrame</code> with no rows or columns.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="udf()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>udf</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a>&nbsp;udf()</pre>
<div class="block">A collection of methods for registering user-defined functions (UDF).
 <p>
 The following example registers a Scala closure as UDF:
 <pre><code>
   sqlContext.udf.register("myUDF", (arg1: Int, arg2: String) =&gt; arg2 + arg1)
 </code></pre>
 <p>
 The following example registers a UDF in Java:
 <pre><code>
   sqlContext.udf().register("myUDF",
       new UDF2&lt;Integer, String, String&gt;() {
           &#64;Override
           public String call(Integer arg1, String arg2) {
               return arg2 + arg1;
           }
      }, DataTypes.StringType);
 </code></pre>
 <p>
 Or, to use Java 8 lambda syntax:
 <pre><code>
   sqlContext.udf().register("myUDF",
       (Integer arg1, String arg2) -&gt; arg2 + arg1,
       DataTypes.StringType);
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="isCached(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isCached</h4>
<pre>public&nbsp;boolean&nbsp;isCached(java.lang.String&nbsp;tableName)</pre>
<div class="block">Returns true if the table is currently cached in-memory.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="cacheTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheTable</h4>
<pre>public&nbsp;void&nbsp;cacheTable(java.lang.String&nbsp;tableName)</pre>
<div class="block">Caches the specified table in-memory.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="uncacheTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>uncacheTable</h4>
<pre>public&nbsp;void&nbsp;uncacheTable(java.lang.String&nbsp;tableName)</pre>
<div class="block">Removes the specified table from the in-memory cache.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="clearCache()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearCache</h4>
<pre>public&nbsp;void&nbsp;clearCache()</pre>
<div class="block">Removes all cached tables from the in-memory cache.</div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="implicits()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>implicits</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a>&nbsp;implicits()</pre>
<div class="block">Accessor for nested Scala object</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
                                                     scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
<div class="block">:: Experimental ::
 Creates a DataFrame from an RDD of Product (e.g. case classes, tuples).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>evidence$1</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(scala.collection.Seq, scala.reflect.api.TypeTags.TypeTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(scala.collection.Seq&lt;A&gt;&nbsp;data,
                                                     scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</pre>
<div class="block">:: Experimental ::
 Creates a DataFrame from a local Seq of Product.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - (undocumented)</dd><dd><code>evidence$2</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="baseRelationToDataFrame(org.apache.spark.sql.sources.BaseRelation)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseRelationToDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;baseRelationToDataFrame(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</pre>
<div class="block">Convert a <code>BaseRelation</code> created for external data sources into a <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>baseRelation</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>RDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 Example:
 <pre><code>
  import org.apache.spark.sql._
  import org.apache.spark.sql.types._
  val sqlContext = new org.apache.spark.sql.SQLContext(sc)

  val schema =
    StructType(
      StructField("name", StringType, false) ::
      StructField("age", IntegerType, true) :: Nil)

  val people =
    sc.textFile("examples/src/main/resources/people.txt").map(
      _.split(",")).map(p =&gt; Row(p(0), p(1).trim.toInt))
  val dataFrame = sqlContext.createDataFrame(people, schema)
  dataFrame.printSchema
  // root
  // |-- name: string (nullable = false)
  // |-- age: integer (nullable = true)

  dataFrame.createOrReplaceTempView("people")
  sqlContext.sql("select name from people").collect.foreach(println)
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rowRDD</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createDataset(scala.collection.Seq, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(scala.collection.Seq&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</pre>
</li>
</ul>
<a name="createDataset(org.apache.spark.rdd.RDD, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</pre>
</li>
</ul>
<a name="createDataset(java.util.List, org.apache.spark.sql.Encoder)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(java.util.List&lt;T&gt;&nbsp;data,
                           <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</pre>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>JavaRDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rowRDD</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(java.util.List, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
                           <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>List</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided List matches
 the provided schema. Otherwise, there will be runtime exception.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rows</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.rdd.RDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
                           java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an RDD of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(org.apache.spark.api.java.JavaRDD, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
                           java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an RDD of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createDataFrame(java.util.List, java.lang.Class)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(java.util.List&lt;?&gt;&nbsp;data,
                           java.lang.Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an List of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - (undocumented)</dd><dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.6.0</dd></dl>
</li>
</ul>
<a name="read()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>read</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;read()</pre>
<div class="block">:: Experimental ::
 Returns a <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><code>DataFrameReader</code></a> that can be used to read data and streams in as a <code>DataFrame</code>.
 <pre><code>
   sqlContext.read.parquet("/path/to/file.parquet")
   sqlContext.read.schema(schema).json("/path/to/file.json")
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                               java.lang.String&nbsp;path)</pre>
<div class="block">:: Experimental ::
 Creates an external table from the given path and returns the corresponding DataFrame.
 It will use the default data source configured by spark.sql.sources.default.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                               java.lang.String&nbsp;path,
                               java.lang.String&nbsp;source)</pre>
<div class="block">:: Experimental ::
 Creates an external table from the given path based on a data source
 and returns the corresponding DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dd><code>path</code> - (undocumented)</dd><dd><code>source</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                               java.lang.String&nbsp;source,
                               java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block">:: Experimental ::
 Creates an external table from the given path based on a data source and a set of options.
 Then, returns the corresponding DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dd><code>source</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                               java.lang.String&nbsp;source,
                               scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block">:: Experimental ::
 (Scala-specific)
 Creates an external table from the given path based on a data source and a set of options.
 Then, returns the corresponding DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dd><code>source</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, org.apache.spark.sql.types.StructType, java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                               java.lang.String&nbsp;source,
                               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                               java.util.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block">:: Experimental ::
 Create an external table from the given path based on a data source, a schema and
 a set of options. Then, returns the corresponding DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dd><code>source</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="createExternalTable(java.lang.String, java.lang.String, org.apache.spark.sql.types.StructType, scala.collection.immutable.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createExternalTable</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createExternalTable(java.lang.String&nbsp;tableName,
                               java.lang.String&nbsp;source,
                               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema,
                               scala.collection.immutable.Map&lt;java.lang.String,java.lang.String&gt;&nbsp;options)</pre>
<div class="block">:: Experimental ::
 (Scala-specific)
 Create an external table from the given path based on a data source, a schema and
 a set of options. Then, returns the corresponding DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd><dd><code>source</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="dropTempTable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dropTempTable</h4>
<pre>public&nbsp;void&nbsp;dropTempTable(java.lang.String&nbsp;tableName)</pre>
<div class="block">Drops the temporary table with the given table name in the catalog. If the table has been
 cached/persisted before, it's also unpersisted.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - the name of the table to be unregistered.</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="range(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;end)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from 0 to <code>end</code> (exclusive) with step value 1.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>end</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="range(long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;start,
                            long&nbsp;end)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with step value 1.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="range(long, long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;start,
                            long&nbsp;end,
                            long&nbsp;step)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd><dd><code>step</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="range(long, long, long, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;java.lang.Long&gt;&nbsp;range(long&nbsp;start,
                            long&nbsp;end,
                            long&nbsp;step,
                            int&nbsp;numPartitions)</pre>
<div class="block">:: Experimental ::
 Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
 specified.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd><dd><code>step</code> - (undocumented)</dd><dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="sql(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sql(java.lang.String&nbsp;sqlText)</pre>
<div class="block">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>. The dialect that is
 used for SQL parsing can be configured with 'spark.sql.dialect'.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sqlText</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="table(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;table(java.lang.String&nbsp;tableName)</pre>
<div class="block">Returns the specified table as a <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="tables()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tables</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;tables()</pre>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the current database.
 The returned DataFrame has two columns, tableName and isTemporary (a Boolean
 indicating if a table is a temporary one or not).
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="tables(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tables</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;tables(java.lang.String&nbsp;databaseName)</pre>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the given database.
 The returned DataFrame has two columns, tableName and isTemporary (a Boolean
 indicating if a table is a temporary one or not).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>databaseName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="streams()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>streams</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql">ContinuousQueryManager</a>&nbsp;streams()</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/ContinuousQueryManager.html" title="class in org.apache.spark.sql"><code>ContinuousQueryManager</code></a> that allows managing all the
 <a href="../../../../org/apache/spark/sql/ContinuousQuery.html" title="interface in org.apache.spark.sql"><code>ContinuousQueries</code></a> active on <code>this</code> context.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="tableNames()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tableNames</h4>
<pre>public&nbsp;java.lang.String[]&nbsp;tableNames()</pre>
<div class="block">Returns the names of tables in the current database as an array.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="tableNames(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tableNames</h4>
<pre>public&nbsp;java.lang.String[]&nbsp;tableNames(java.lang.String&nbsp;databaseName)</pre>
<div class="block">Returns the names of tables in the given database as an array.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>databaseName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>1.3.0</dd></dl>
</li>
</ul>
<a name="parseDataType(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseDataType</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/types/DataType.html" title="class in org.apache.spark.sql.types">DataType</a>&nbsp;parseDataType(java.lang.String&nbsp;dataTypeString)</pre>
<div class="block">Parses the data type in our internal string representation. The data type string should
 have the same format as the one generated by <code>toString</code> in scala.
 It is only used by PySpark.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>dataTypeString</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                                  java.lang.String&nbsp;schemaString)</pre>
<div class="block">Apply a schema defined by the schemaString to an RDD. It is only used by PySpark.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>schemaString</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="applySchemaToPythonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.types.StructType)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>applySchemaToPythonRDD</h4>
<pre>protected&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;applySchemaToPythonRDD(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;java.lang.Object[]&gt;&nbsp;rdd,
                                  <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">Apply a schema defined by the schema to an RDD. It is only used by PySpark.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>rdd</code> - (undocumented)</dd><dd><code>schema</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SparkSession.implicits$.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
