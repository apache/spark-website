<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>spark.streaming.StreamingContext</title>
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link type="text/css" media="screen" rel="stylesheet" href="../../lib/template.css" />
      <script type="text/javascript" src="../../lib/jquery.js"></script>
      <script type="text/javascript" src="../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../lib/template.js"></script>
      <script type="text/javascript" src="../../lib/tools.tooltip.js"></script>
    
        </head>
        <body onload="sh_highlightDocument('../lib/', '.min.js');" class="type">
      <div id="definition">
        <a title="Go to companion" href="StreamingContext$.html"><img src="../../lib/class_to_object_big.png" /></a>
        <p id="owner"><a name="spark" class="extype" href="../package.html">spark</a>.<a name="spark.streaming" class="extype" href="package.html">streaming</a></p>
        <h1><a title="Go to companion" href="StreamingContext$.html">StreamingContext</a></h1>
      </div>

      <h4 class="signature" id="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">StreamingContext</span><span class="result"> extends <span name="spark.Logging" class="extype">Logging</span></span>
      </span>
      </h4>
      
      <div class="fullcommenttop" id="comment"><div class="comment cmt"><p>A StreamingContext is the main entry point for Spark Streaming functionality. Besides the basic
information (such as, cluster URL and job name) to internally create a SparkContext, it provides
methods used to create DStream from various input sources.
</p></div><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span name="spark.Logging" class="extype">Logging</span>, AnyRef, <span name="scala.Any" class="extype">Any</span></div>
        </div></div>
    

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input accesskey="/" type="text" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By inheritance</span></li></ol>
            </div>
        <div id="ancestors">
              <span class="filtertype">Inherited</span>
              <ol><li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li></ol>
              <ol id="linearization"><li name="spark.streaming.StreamingContext" class="in"><span>StreamingContext</span></li><li name="spark.Logging" class="in"><span>Logging</span></li><li name="scala.AnyRef" class="in"><span>AnyRef</span></li><li name="scala.Any" class="in"><span>Any</span></li></ol>
            </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div class="members" id="constructors">
              <h3>Instance Constructors</h3>
              <ol><li visbl="pub" name="spark.streaming.StreamingContext#this" data-isabs="false">
      <a id="this:StreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">StreamingContext</span><span class="params">(<span name="path">path: String</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Re-create a StreamingContext from a checkpoint file.</p><div class="fullcomment"><div class="comment cmt"><p>Re-create a StreamingContext from a checkpoint file.</p></div><dl class="paramcmts block"><dt class="param">path</dt><dd class="cmt"><p>Path either to the directory that was specified as the checkpoint directory, or
            to the checkpoint file 'graph' or 'graph.bk'.
</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#this" data-isabs="false">
      <a id="this:StreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">StreamingContext</span><span class="params">(<span name="master">master: String</span>, <span name="appName">appName: String</span>, <span name="batchDuration">batchDuration: <a name="spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="sparkHome">sparkHome: String = <span class="symbol">null</span></span>, <span name="jars">jars: Seq[String] = <span class="symbol">Nil</span></span>, <span name="environment">environment: <span name="scala.collection.Map" class="extype">Map</span>[String, String] = <span class="symbol"><span class="name"><a href="../../scala/package.html">Map()</a></span></span></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a StreamingContext by providing the details necessary for creating a new SparkContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a StreamingContext by providing the details necessary for creating a new SparkContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Cluster URL to connect to (e.g. mesos://host:port, spark://host:port, local[4]).</p></dd><dt class="param">appName</dt><dd class="cmt"><p>A name for your job, to display on the cluster web UI</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#this" data-isabs="false">
      <a id="this:StreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">StreamingContext</span><span class="params">(<span name="sparkContext">sparkContext: <span name="spark.SparkContext" class="extype">SparkContext</span></span>, <span name="batchDuration">batchDuration: <a name="spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a StreamingContext using an existing SparkContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a StreamingContext using an existing SparkContext.</p></div><dl class="paramcmts block"><dt class="param">sparkContext</dt><dd class="cmt"><p>Existing SparkContext</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li></ol>
            </div>

        

        

        <div class="values members" id="values">
              <h3>Value Members</h3>
              <ol><li visbl="pub" name="scala.AnyRef#!=" data-isabs="false">
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#!=" data-isabs="false">
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef###" data-isabs="false">
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $hash$hash">##</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#==" data-isabs="false">
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#==" data-isabs="false">
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#actorStream" data-isabs="false">
      <a id="actorStream[T](Props,String,StorageLevel,SupervisorStrategy)(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span name="akka.actor.Props" class="extype">Props</span></span>, <span name="name">name: String</span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span> = <span class="symbol"><span class="name"><a href="../package.html">StorageLevel.MEMORY_ONLY_SER_2</a></span></span></span>, <span name="supervisorStrategy">supervisorStrategy: <span name="akka.actor.SupervisorStrategy" class="extype">SupervisorStrategy</span> = <span name='<span class="name"><a href="../package.html">ReceiverSupervisorStrategy.defaultStrategy</a></span>' class="defval">...</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>RDD storage level. Defaults to memory-only.
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li visbl="pub" name="scala.Any#asInstanceOf" data-isabs="false">
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#checkpoint" data-isabs="false">
      <a id="checkpoint(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">checkpoint</span><span class="params">(<span name="directory">directory: String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Set the context to periodically checkpoint the DStream operations for master
fault-tolerance.</p><div class="fullcomment"><div class="comment cmt"><p>Set the context to periodically checkpoint the DStream operations for master
fault-tolerance. The graph will be checkpointed every batch interval.</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS-compatible directory where the checkpoint data will be reliably stored
</p></dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#checkpointDir" data-isabs="false">
      <a id="checkpointDir:String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">var</span>
      </span>
      <span class="symbol">
        <span class="name">checkpointDir</span><span class="result">: String</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#checkpointDuration" data-isabs="false">
      <a id="checkpointDuration:Duration"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">var</span>
      </span>
      <span class="symbol">
        <span class="name">checkpointDuration</span><span class="result">: <a name="spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#clone" data-isabs="false">
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: AnyRef</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#env" data-isabs="false">
      <a id="env:SparkEnv"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">env</span><span class="result">: <span name="spark.SparkEnv" class="extype">SparkEnv</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#eq" data-isabs="false">
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#equals" data-isabs="false">
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#fileStream" data-isabs="false">
      <a id="fileStream[K, V, F&lt;:InputFormat[K, V]](String,(Path) ⇒ Boolean,Boolean)(ClassManifest[K],ClassManifest[V],ClassManifest[F]):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fileStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>, <span name="F">F &lt;: <span name="org.apache.hadoop.mapreduce.InputFormat" class="extype">InputFormat</span>[K, V]</span>]</span><span class="params">(<span name="directory">directory: String</span>, <span name="filter">filter: (<span name="org.apache.hadoop.fs.Path" class="extype">Path</span>) ⇒ <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="newFilesOnly">newFilesOnly: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[K]</span>, <span name="arg1">arg1: ClassManifest[V]</span>, <span name="arg2">arg2: ClassManifest[F]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p></div><dl class="paramcmts block"><dt class="tparam">K</dt><dd class="cmt"><p>Key type for reading HDFS file</p></dd><dt class="tparam">V</dt><dd class="cmt"><p>Value type for reading HDFS file</p></dd><dt class="tparam">F</dt><dd class="cmt"><p>Input format for reading HDFS file
</p></dd><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file</p></dd><dt class="param">filter</dt><dd class="cmt"><p>Function to filter paths to process</p></dd><dt class="param">newFilesOnly</dt><dd class="cmt"><p>Should process only new files and ignore existing files in the directory</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#fileStream" data-isabs="false">
      <a id="fileStream[K, V, F&lt;:InputFormat[K, V]](String)(ClassManifest[K],ClassManifest[V],ClassManifest[F]):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fileStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>, <span name="F">F &lt;: <span name="org.apache.hadoop.mapreduce.InputFormat" class="extype">InputFormat</span>[K, V]</span>]</span><span class="params">(<span name="directory">directory: String</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[K]</span>, <span name="arg1">arg1: ClassManifest[V]</span>, <span name="arg2">arg2: ClassManifest[F]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.
File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="tparam">K</dt><dd class="cmt"><p>Key type for reading HDFS file</p></dd><dt class="tparam">V</dt><dd class="cmt"><p>Value type for reading HDFS file</p></dd><dt class="tparam">F</dt><dd class="cmt"><p>Input format for reading HDFS file
</p></dd><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file</p></dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#finalize" data-isabs="false">
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#flumeStream" data-isabs="false">
      <a id="flumeStream(String,Int,StorageLevel):DStream[SparkFlumeEvent]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flumeStream</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span> = <span class="symbol"><span class="name"><a href="../package.html">StorageLevel.MEMORY_AND_DISK_SER_2</a></span></span></span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[<a name="spark.streaming.dstream.SparkFlumeEvent" class="extype" href="dstream/SparkFlumeEvent.html">SparkFlumeEvent</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from a Flume source.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from a Flume source.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname of the slave machine to which the flume data will be sent</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port of the slave machine to which the flume data will be sent</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#getClass" data-isabs="false">
      <a id="getClass():java.lang.Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: java.lang.Class[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#getNewNetworkStreamId" data-isabs="false">
      <a id="getNewNetworkStreamId():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getNewNetworkStreamId</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#graph" data-isabs="false">
      <a id="graph:DStreamGraph"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">graph</span><span class="result">: <span name="spark.streaming.DStreamGraph" class="extype">DStreamGraph</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#hashCode" data-isabs="false">
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#initLogging" data-isabs="false">
      <a id="initLogging():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">initLogging</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#initialCheckpoint" data-isabs="false">
      <a id="initialCheckpoint:Checkpoint"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">initialCheckpoint</span><span class="result">: <span name="spark.streaming.Checkpoint" class="extype">Checkpoint</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#isCheckpointPresent" data-isabs="false">
      <a id="isCheckpointPresent:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">isCheckpointPresent</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="scala.Any#isInstanceOf" data-isabs="false">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#kafkaStream" data-isabs="false">
      <a id="kafkaStream[T](String,String,Map[String, Int],Map[KafkaPartitionKey, Long],StorageLevel)(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">kafkaStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="zkQuorum">zkQuorum: String</span>, <span name="groupId">groupId: String</span>, <span name="topics">topics: <span name="scala.collection.Map" class="extype">Map</span>[String, <span name="scala.Int" class="extype">Int</span>]</span>, <span name="initialOffsets">initialOffsets: <span name="scala.collection.Map" class="extype">Map</span>[<a name="spark.streaming.dstream.KafkaPartitionKey" class="extype" href="dstream/KafkaPartitionKey.html">KafkaPartitionKey</a>, <span name="scala.Long" class="extype">Long</span>] = <span class="symbol"><span class="name"><a href="../../scala/package.html">Map[KafkaPartitionKey, Long]()</a></span></span></span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span> = <span class="symbol"><span class="name"><a href="../package.html">StorageLevel.MEMORY_ONLY_SER_2</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that pulls messages form a Kafka Broker.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that pulls messages form a Kafka Broker.</p></div><dl class="paramcmts block"><dt class="param">zkQuorum</dt><dd class="cmt"><p>Zookeper quorum (hostname:port,hostname:port,..).</p></dd><dt class="param">groupId</dt><dd class="cmt"><p>The group id for this consumer.</p></dd><dt class="param">topics</dt><dd class="cmt"><p>Map of (topic_name -&gt; numPartitions) to consume. Each partition is consumed
in its own thread.</p></dd><dt class="param">initialOffsets</dt><dd class="cmt"><p>Optional initial offsets for each of the partitions to consume.
By default the value is pulled from zookeper.</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
                     (default: StorageLevel.MEMORY_AND_DISK_SER_2)
</p></dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#log" data-isabs="false">
      <a id="log:Logger"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">log</span><span class="result">: <span name="org.slf4j.Logger" class="extype">Logger</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logDebug" data-isabs="false">
      <a id="logDebug(⇒ String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logDebug</span><span class="params">(<span name="msg">msg: ⇒ String</span>, <span name="throwable">throwable: Throwable</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logDebug" data-isabs="false">
      <a id="logDebug(⇒ String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logDebug</span><span class="params">(<span name="msg">msg: ⇒ String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logError" data-isabs="false">
      <a id="logError(⇒ String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logError</span><span class="params">(<span name="msg">msg: ⇒ String</span>, <span name="throwable">throwable: Throwable</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logError" data-isabs="false">
      <a id="logError(⇒ String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logError</span><span class="params">(<span name="msg">msg: ⇒ String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logInfo" data-isabs="false">
      <a id="logInfo(⇒ String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logInfo</span><span class="params">(<span name="msg">msg: ⇒ String</span>, <span name="throwable">throwable: Throwable</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logInfo" data-isabs="false">
      <a id="logInfo(⇒ String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logInfo</span><span class="params">(<span name="msg">msg: ⇒ String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logTrace" data-isabs="false">
      <a id="logTrace(⇒ String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logTrace</span><span class="params">(<span name="msg">msg: ⇒ String</span>, <span name="throwable">throwable: Throwable</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logTrace" data-isabs="false">
      <a id="logTrace(⇒ String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logTrace</span><span class="params">(<span name="msg">msg: ⇒ String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logWarning" data-isabs="false">
      <a id="logWarning(⇒ String,Throwable):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logWarning</span><span class="params">(<span name="msg">msg: ⇒ String</span>, <span name="throwable">throwable: Throwable</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="prt" name="spark.Logging#logWarning" data-isabs="false">
      <a id="logWarning(⇒ String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">logWarning</span><span class="params">(<span name="msg">msg: ⇒ String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd><dt>Definition Classes</dt><dd>Logging</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#ne" data-isabs="false">
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#networkInputTracker" data-isabs="false">
      <a id="networkInputTracker:NetworkInputTracker"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">var</span>
      </span>
      <span class="symbol">
        <span class="name">networkInputTracker</span><span class="result">: <span name="spark.streaming.NetworkInputTracker" class="extype">NetworkInputTracker</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#networkStream" data-isabs="false">
      <a id="networkStream[T](NetworkReceiver[T])(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">networkStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="receiver">receiver: <a name="spark.streaming.dstream.NetworkReceiver" class="extype" href="dstream/NetworkReceiver.html">NetworkReceiver</a>[T]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented network receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented network receiver.</p></div><dl class="paramcmts block"><dt class="param">receiver</dt><dd class="cmt"><p>Custom implementation of NetworkReceiver
</p></dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#nextNetworkInputStreamId" data-isabs="false">
      <a id="nextNetworkInputStreamId:AtomicInteger"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">nextNetworkInputStreamId</span><span class="result">: <span name="java.util.concurrent.atomic.AtomicInteger" class="extype">AtomicInteger</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notify" data-isabs="false">
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notifyAll" data-isabs="false">
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#queueStream" data-isabs="false">
      <a id="queueStream[T](Queue[RDD[T]],Boolean,RDD[T])(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span name="scala.collection.mutable.Queue" class="extype">Queue</span>[<span name="spark.RDD" class="extype">RDD</span>[T]]</span>, <span name="oneAtATime">oneAtATime: <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="defaultRDD">defaultRDD: <span name="spark.RDD" class="extype">RDD</span>[T]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from a queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from a queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd><dt class="param">oneAtATime</dt><dd class="cmt"><p>Whether only one RDD should be consumed from the queue in every interval</p></dd><dt class="param">defaultRDD</dt><dd class="cmt"><p>Default RDD is returned by the DStream when the queue is empty. Set as null if no RDD should be returned when empty</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#queueStream" data-isabs="false">
      <a id="queueStream[T](Queue[RDD[T]],Boolean)(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span name="scala.collection.mutable.Queue" class="extype">Queue</span>[<span name="spark.RDD" class="extype">RDD</span>[T]]</span>, <span name="oneAtATime">oneAtATime: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from a queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from a queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd><dt class="param">oneAtATime</dt><dd class="cmt"><p>Whether only one RDD should be consumed from the queue in every interval</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#rawSocketStream" data-isabs="false">
      <a id="rawSocketStream[T](String,Int,StorageLevel)(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rawSocketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span> = <span class="symbol"><span class="name"><a href="../package.html">StorageLevel.MEMORY_AND_DISK_SER_2</a></span></span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them. This is the most efficient
way to receive data.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects in the received blocks
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects</p></dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#receiverJobThread" data-isabs="false">
      <a id="receiverJobThread:Thread"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">var</span>
      </span>
      <span class="symbol">
        <span class="name">receiverJobThread</span><span class="result">: <span name="java.lang.Thread" class="extype">Thread</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#registerInputStream" data-isabs="false">
      <a id="registerInputStream(spark.streaming.dstream.InputDStream[_]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">registerInputStream</span><span class="params">(<span name="inputStream">inputStream: spark.streaming.dstream.InputDStream[_]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Register an input stream that will be started (InputDStream.</p><div class="fullcomment"><div class="comment cmt"><p>Register an input stream that will be started (InputDStream.start() called) to get the
input data.
</p></div></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#registerOutputStream" data-isabs="false">
      <a id="registerOutputStream(spark.streaming.DStream[_]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">registerOutputStream</span><span class="params">(<span name="outputStream">outputStream: spark.streaming.DStream[_]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Register an output stream that will be computed every interval
</p>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#remember" data-isabs="false">
      <a id="remember(Duration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">remember</span><span class="params">(<span name="duration">duration: <a name="spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Set each DStreams in this context to remember RDDs it generated in the last given duration.</p><div class="fullcomment"><div class="comment cmt"><p>Set each DStreams in this context to remember RDDs it generated in the last given duration.
DStreams remember RDDs only for a limited duration of time and releases them for garbage
collection. This method allows the developer to specify how to long to remember the RDDs (
if the developer wishes to query old data outside the DStream computation).</p></div><dl class="paramcmts block"><dt class="param">duration</dt><dd class="cmt"><p>Minimum duration that each DStream should remember its RDDs
</p></dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#sc" data-isabs="false">
      <a id="sc:SparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sc</span><span class="result">: <span name="spark.SparkContext" class="extype">SparkContext</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#scheduler" data-isabs="false">
      <a id="scheduler:Scheduler"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">var</span>
      </span>
      <span class="symbol">
        <span class="name">scheduler</span><span class="result">: <span name="spark.streaming.Scheduler" class="extype">Scheduler</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="spark.streaming" class="extype" href="package.html">streaming</a>] </dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#socketStream" data-isabs="false">
      <a id="socketStream[T](String,Int,(InputStream) ⇒ Iterator[T],StorageLevel)(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="converter">converter: (<span name="java.io.InputStream" class="extype">InputStream</span>) ⇒ Iterator[T]</span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from TCP source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from TCP source hostname:port. Data is received using
a TCP socket and the receive bytes it interepreted as object using the given
converter.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects received (after converting bytes to objects)
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">converter</dt><dd class="cmt"><p>Function to convert the byte stream to objects</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#socketTextStream" data-isabs="false">
      <a id="socketTextStream(String,Int,StorageLevel):DStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketTextStream</span><span class="params">(<span name="hostname">hostname: String</span>, <span name="port">port: <span name="scala.Int" class="extype">Int</span></span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span> = <span class="symbol"><span class="name"><a href="../package.html">StorageLevel.MEMORY_AND_DISK_SER_2</a></span></span></span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream from TCP source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream from TCP source hostname:port. Data is received using
a TCP socket and the receive bytes is interpreted as UTF8 encoded <code>\n</code> delimited
lines.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
                     (default: StorageLevel.MEMORY_AND_DISK_SER_2)
</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#sparkContext" data-isabs="false">
      <a id="sparkContext:SparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sparkContext</span><span class="result">: <span name="spark.SparkContext" class="extype">SparkContext</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the associated Spark context
</p>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#start" data-isabs="false">
      <a id="start():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">start</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Start the execution of the streams.</p>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#stop" data-isabs="false">
      <a id="stop():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">stop</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Stop the execution of the streams.</p>
    </li><li visbl="pub" name="scala.AnyRef#synchronized" data-isabs="false">
      <a id="synchronized[T0](⇒ T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ T0</span>)</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#textFileStream" data-isabs="false">
      <a id="textFileStream(String):DStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">textFileStream</span><span class="params">(<span name="directory">directory: String</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as text files (using key as LongWritable, value
as Text and input format as TextInputFormat).</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as text files (using key as LongWritable, value
as Text and input format as TextInputFormat). File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#toString" data-isabs="false">
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span name="java.lang.String" class="extype">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#twitterStream" data-isabs="false">
      <a id="twitterStream(String,String,Seq[String],StorageLevel):DStream[Status]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">twitterStream</span><span class="params">(<span name="username">username: String</span>, <span name="password">password: String</span>, <span name="filters">filters: Seq[String] = <span class="symbol">Nil</span></span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span> = <span class="symbol"><span class="name"><a href="../package.html">StorageLevel.MEMORY_AND_DISK_SER_2</a></span></span></span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[<span name="twitter4j.Status" class="extype">Status</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a input stream that returns tweets received from Twitter.</p><div class="fullcomment"><div class="comment cmt"><p>Create a input stream that returns tweets received from Twitter.</p></div><dl class="paramcmts block"><dt class="param">username</dt><dd class="cmt"><p>Twitter username</p></dd><dt class="param">password</dt><dd class="cmt"><p>Twitter password</p></dd><dt class="param">filters</dt><dd class="cmt"><p>Set of filter strings to get only those tweets that match them</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#union" data-isabs="false">
      <a id="union[T](Seq[DStream[T]])(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="streams">streams: Seq[<a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a unified DStream from multiple DStreams of the same type and same interval
</p>
    </li><li visbl="prt" name="spark.streaming.StreamingContext#validate" data-isabs="false">
      <a id="validate():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">validate</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="spark.streaming.StreamingContext#zeroMQStream" data-isabs="false">
      <a id="zeroMQStream[T](String,Subscribe,(Seq[Seq[Byte]]) ⇒ Iterator[T],StorageLevel,SupervisorStrategy)(ClassManifest[T]):DStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">zeroMQStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="publisherUrl">publisherUrl: String</span>, <span name="subscribe">subscribe: <span name="akka.zeromq.Subscribe" class="extype">Subscribe</span></span>, <span name="bytesToObjects">bytesToObjects: (Seq[Seq[<span name="scala.Byte" class="extype">Byte</span>]]) ⇒ Iterator[T]</span>, <span name="storageLevel">storageLevel: <span name="spark.storage.StorageLevel" class="extype">StorageLevel</span></span>, <span name="supervisorStrategy">supervisorStrategy: <span name="akka.actor.SupervisorStrategy" class="extype">SupervisorStrategy</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[T]</span>)</span><span class="result">: <a name="spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[T]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that receives messages pushed by a zeromq publisher.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that receives messages pushed by a zeromq publisher.</p></div><dl class="paramcmts block"><dt class="param">publisherUrl</dt><dd class="cmt"><p>Url of remote zeromq publisher</p></dd><dt class="param">subscribe</dt><dd class="cmt"><p>topic to subscribe to</p></dd><dt class="param">bytesToObjects</dt><dd class="cmt"><p>A zeroMQ stream publishes sequence of frames for each topic and each frame has sequence
                      of byte thus it needs the converter(which might be deserializer of bytes)
                      to translate from sequence of sequence of bytes, where sequence refer to a frame
                      and sub sequence refer to its payload.</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>RDD storage level. Defaults to memory-only.
</p></dd></dl></div>
    </li></ol>
            </div>

        
        </div>

        <div id="inheritedMembers">
        <div name="spark.Logging" class="parent">
              <h3>Inherited from <span name="spark.Logging" class="extype">Logging</span></h3>
            </div><div name="scala.AnyRef" class="parent">
              <h3>Inherited from AnyRef</h3>
            </div><div name="scala.Any" class="parent">
              <h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3>
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>