
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>Pipeline &#8212; PySpark 3.3.3 documentation</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="PipelineModel" href="pyspark.ml.PipelineModel.html" />
    <link rel="prev" title="PredictionModel" href="pyspark.ml.PredictionModel.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../index.html">
    
      <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../user_guide/index.html">User Guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../development/index.html">Development</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../migration_guide/index.html">Migration Guide</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="../pyspark.sql/index.html">Spark SQL</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.pandas/index.html">Pandas API on Spark</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.ss/index.html">Structured Streaming</a>
                </li>
            
          
            
                <li class="active">
                    <a href="../pyspark.ml.html">MLlib (DataFrame-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.streaming.html">Spark Streaming</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.mllib.html">MLlib (RDD-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.html">Spark Core</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.resource.html">Resource Management</a>
                </li>
            
          
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="pipeline">
<h1>Pipeline<a class="headerlink" href="#pipeline" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="pyspark.ml.Pipeline">
<em class="property">class </em><code class="sig-prename descclassname">pyspark.ml.</code><code class="sig-name descname">Pipeline</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">stages</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>PipelineStage<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple pipeline, which acts as an estimator. A Pipeline consists
of a sequence of stages, each of which is either an
<a class="reference internal" href="pyspark.ml.Estimator.html#pyspark.ml.Estimator" title="pyspark.ml.Estimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">Estimator</span></code></a> or a <a class="reference internal" href="pyspark.ml.Transformer.html#pyspark.ml.Transformer" title="pyspark.ml.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a>. When
<a class="reference internal" href="#pyspark.ml.Pipeline.fit" title="pyspark.ml.Pipeline.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Pipeline.fit()</span></code></a> is called, the stages are executed in
order. If a stage is an <a class="reference internal" href="pyspark.ml.Estimator.html#pyspark.ml.Estimator" title="pyspark.ml.Estimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">Estimator</span></code></a>, its
<a class="reference internal" href="pyspark.ml.Estimator.html#pyspark.ml.Estimator.fit" title="pyspark.ml.Estimator.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Estimator.fit()</span></code></a> method will be called on the input
dataset to fit a model. Then the model, which is a transformer,
will be used to transform the dataset as the input to the next
stage. If a stage is a <a class="reference internal" href="pyspark.ml.Transformer.html#pyspark.ml.Transformer" title="pyspark.ml.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a>, its
<a class="reference internal" href="pyspark.ml.Transformer.html#pyspark.ml.Transformer.transform" title="pyspark.ml.Transformer.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Transformer.transform()</span></code></a> method will be called to produce
the dataset for the next stage. The fitted model from a
<a class="reference internal" href="#pyspark.ml.Pipeline" title="pyspark.ml.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a> is a <a class="reference internal" href="pyspark.ml.PipelineModel.html#pyspark.ml.PipelineModel" title="pyspark.ml.PipelineModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">PipelineModel</span></code></a>, which
consists of fitted models and transformers, corresponding to the
pipeline stages. If stages is an empty list, the pipeline acts as an
identity transformer.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.clear" title="pyspark.ml.Pipeline.clear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clear</span></code></a>(param)</p></td>
<td><p>Clears a param from the param map if it has been explicitly set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.copy" title="pyspark.ml.Pipeline.copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">copy</span></code></a>([extra])</p></td>
<td><p>Creates a copy of this instance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.explainParam" title="pyspark.ml.Pipeline.explainParam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explainParam</span></code></a>(param)</p></td>
<td><p>Explains a single param and returns its name, doc, and optional default value and user-supplied value in a string.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.explainParams" title="pyspark.ml.Pipeline.explainParams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explainParams</span></code></a>()</p></td>
<td><p>Returns the documentation of all params with their optionally default values and user-supplied values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.extractParamMap" title="pyspark.ml.Pipeline.extractParamMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extractParamMap</span></code></a>([extra])</p></td>
<td><p>Extracts the embedded default param values and user-supplied values, and then merges them with extra values from input into a flat param map, where the latter value is used if there exist conflicts, i.e., with ordering: default param values &lt; user-supplied values &lt; extra.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.fit" title="pyspark.ml.Pipeline.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(dataset[, params])</p></td>
<td><p>Fits a model to the input dataset with optional parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.fitMultiple" title="pyspark.ml.Pipeline.fitMultiple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fitMultiple</span></code></a>(dataset, paramMaps)</p></td>
<td><p>Fits a model to the input dataset for each param map in <cite>paramMaps</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.getOrDefault" title="pyspark.ml.Pipeline.getOrDefault"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getOrDefault</span></code></a>(param)</p></td>
<td><p>Gets the value of a param in the user-supplied param map or its default value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.getParam" title="pyspark.ml.Pipeline.getParam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getParam</span></code></a>(paramName)</p></td>
<td><p>Gets a param by its name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.getStages" title="pyspark.ml.Pipeline.getStages"><code class="xref py py-obj docutils literal notranslate"><span class="pre">getStages</span></code></a>()</p></td>
<td><p>Get pipeline stages.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.hasDefault" title="pyspark.ml.Pipeline.hasDefault"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hasDefault</span></code></a>(param)</p></td>
<td><p>Checks whether a param has a default value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.hasParam" title="pyspark.ml.Pipeline.hasParam"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hasParam</span></code></a>(paramName)</p></td>
<td><p>Tests whether this instance contains a param with a given (string) name.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.isDefined" title="pyspark.ml.Pipeline.isDefined"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isDefined</span></code></a>(param)</p></td>
<td><p>Checks whether a param is explicitly set by user or has a default value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.isSet" title="pyspark.ml.Pipeline.isSet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isSet</span></code></a>(param)</p></td>
<td><p>Checks whether a param is explicitly set by user.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.load" title="pyspark.ml.Pipeline.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(path)</p></td>
<td><p>Reads an ML instance from the input path, a shortcut of <cite>read().load(path)</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.read" title="pyspark.ml.Pipeline.read"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read</span></code></a>()</p></td>
<td><p>Returns an MLReader instance for this class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.save" title="pyspark.ml.Pipeline.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(path)</p></td>
<td><p>Save this ML instance to the given path, a shortcut of ‘write().save(path)’.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.set" title="pyspark.ml.Pipeline.set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set</span></code></a>(param, value)</p></td>
<td><p>Sets a parameter in the embedded param map.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.setParams" title="pyspark.ml.Pipeline.setParams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setParams</span></code></a>(self, \*[, stages])</p></td>
<td><p>Sets params for Pipeline.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.setStages" title="pyspark.ml.Pipeline.setStages"><code class="xref py py-obj docutils literal notranslate"><span class="pre">setStages</span></code></a>(value)</p></td>
<td><p>Set pipeline stages.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.write" title="pyspark.ml.Pipeline.write"><code class="xref py py-obj docutils literal notranslate"><span class="pre">write</span></code></a>()</p></td>
<td><p>Returns an MLWriter instance for this ML instance.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.params" title="pyspark.ml.Pipeline.params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">params</span></code></a></p></td>
<td><p>Returns all params ordered by name.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pyspark.ml.Pipeline.stages" title="pyspark.ml.Pipeline.stages"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stages</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p class="rubric">Methods Documentation</p>
<dl class="py method">
<dt id="pyspark.ml.Pipeline.clear">
<code class="sig-name descname">clear</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n"><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a></span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pyspark.ml.Pipeline.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears a param from the param map if it has been explicitly set.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.copy">
<code class="sig-name descname">copy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">extra</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>ParamMap<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; Pipeline<a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline.copy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a copy of this instance.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.4.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>extra</strong><span class="classifier">dict, optional</span></dt><dd><p>extra parameters</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#pyspark.ml.Pipeline" title="pyspark.ml.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a></dt><dd><p>new instance</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.explainParam">
<code class="sig-name descname">explainParam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#pyspark.ml.Pipeline.explainParam" title="Permalink to this definition">¶</a></dt>
<dd><p>Explains a single param and returns its name, doc, and optional
default value and user-supplied value in a string.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.explainParams">
<code class="sig-name descname">explainParams</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#pyspark.ml.Pipeline.explainParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the documentation of all params with their optionally
default values and user-supplied values.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.extractParamMap">
<code class="sig-name descname">extractParamMap</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">extra</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>ParamMap<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; ParamMap<a class="headerlink" href="#pyspark.ml.Pipeline.extractParamMap" title="Permalink to this definition">¶</a></dt>
<dd><p>Extracts the embedded default param values and user-supplied
values, and then merges them with extra values from input into
a flat param map, where the latter value is used if there exist
conflicts, i.e., with ordering: default param values &lt;
user-supplied values &lt; extra.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>extra</strong><span class="classifier">dict, optional</span></dt><dd><p>extra param values</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>dict</dt><dd><p>merged param map</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span><span class="p">:</span> <span class="n">pyspark.sql.dataframe.DataFrame</span></em>, <em class="sig-param"><span class="n">params</span><span class="p">:</span> <span class="n">Union[ParamMap, List[ParamMap], Tuple[ParamMap], None]</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>M<span class="p">, </span>List<span class="p">[</span>M<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#pyspark.ml.Pipeline.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fits a model to the input dataset with optional parameters.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>dataset</strong><span class="classifier"><a class="reference internal" href="../pyspark.sql/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.DataFrame</span></code></a></span></dt><dd><p>input dataset.</p>
</dd>
<dt><strong>params</strong><span class="classifier">dict or list or tuple, optional</span></dt><dd><p>an optional param map that overrides embedded params. If a list/tuple of
param maps is given, this calls fit on each param map and returns a list of
models.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="pyspark.ml.Transformer.html#pyspark.ml.Transformer" title="pyspark.ml.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a> or a list of <a class="reference internal" href="pyspark.ml.Transformer.html#pyspark.ml.Transformer" title="pyspark.ml.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code></a></dt><dd><p>fitted model(s)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.fitMultiple">
<code class="sig-name descname">fitMultiple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span><span class="p">:</span> <span class="n">pyspark.sql.dataframe.DataFrame</span></em>, <em class="sig-param"><span class="n">paramMaps</span><span class="p">:</span> <span class="n">Sequence<span class="p">[</span>ParamMap<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Iterator<span class="p">[</span>Tuple<span class="p">[</span>int<span class="p">, </span>M<span class="p">]</span><span class="p">]</span><a class="headerlink" href="#pyspark.ml.Pipeline.fitMultiple" title="Permalink to this definition">¶</a></dt>
<dd><p>Fits a model to the input dataset for each param map in <cite>paramMaps</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.3.0.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>dataset</strong><span class="classifier"><a class="reference internal" href="../pyspark.sql/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.sql.DataFrame</span></code></a></span></dt><dd><p>input dataset.</p>
</dd>
<dt><strong>paramMaps</strong><span class="classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">collections.abc.Sequence</span></code></span></dt><dd><p>A Sequence of param maps.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">_FitMultipleIterator</span></code></dt><dd><p>A thread safe iterable which contains one model for each param map. Each
call to <cite>next(modelIterator)</cite> will return <cite>(index, model)</cite> where model was fit
using <cite>paramMaps[index]</cite>. <cite>index</cite> values may not be sequential.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.getOrDefault">
<code class="sig-name descname">getOrDefault</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a><span class="p">[</span>T<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>Any<span class="p">, </span>T<span class="p">]</span><a class="headerlink" href="#pyspark.ml.Pipeline.getOrDefault" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the value of a param in the user-supplied param map or its
default value. Raises an error if neither is set.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.getParam">
<code class="sig-name descname">getParam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">paramName</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a><a class="headerlink" href="#pyspark.ml.Pipeline.getParam" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a param by its name.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.getStages">
<code class="sig-name descname">getStages</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>PipelineStage<span class="p">]</span><a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline.getStages"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline.getStages" title="Permalink to this definition">¶</a></dt>
<dd><p>Get pipeline stages.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.hasDefault">
<code class="sig-name descname">hasDefault</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a><span class="p">[</span>Any<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pyspark.ml.Pipeline.hasDefault" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether a param has a default value.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.hasParam">
<code class="sig-name descname">hasParam</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">paramName</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pyspark.ml.Pipeline.hasParam" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests whether this instance contains a param with a given
(string) name.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.isDefined">
<code class="sig-name descname">isDefined</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a><span class="p">[</span>Any<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pyspark.ml.Pipeline.isDefined" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether a param is explicitly set by user or has
a default value.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.isSet">
<code class="sig-name descname">isSet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>str<span class="p">, </span><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a><span class="p">[</span>Any<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#pyspark.ml.Pipeline.isSet" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether a param is explicitly set by user.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.load">
<em class="property">classmethod </em><code class="sig-name descname">load</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; RL<a class="headerlink" href="#pyspark.ml.Pipeline.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads an ML instance from the input path, a shortcut of <cite>read().load(path)</cite>.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.read">
<em class="property">classmethod </em><code class="sig-name descname">read</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; pyspark.ml.pipeline.PipelineReader<a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline.read"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline.read" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an MLReader instance for this class.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.0.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">path</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pyspark.ml.Pipeline.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save this ML instance to the given path, a shortcut of ‘write().save(path)’.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.set">
<code class="sig-name descname">set</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">param</span><span class="p">:</span> <span class="n"><a class="reference internal" href="pyspark.ml.param.Param.html#pyspark.ml.param.Param" title="pyspark.ml.param.Param">pyspark.ml.param.Param</a></span></em>, <em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">Any</span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pyspark.ml.Pipeline.set" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets a parameter in the embedded param map.</p>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.setParams">
<code class="sig-name descname">setParams</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">\*</em>, <em class="sig-param">stages=None</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline.setParams"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline.setParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets params for Pipeline.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.setStages">
<code class="sig-name descname">setStages</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">value</span><span class="p">:</span> <span class="n">List<span class="p">[</span>PipelineStage<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Pipeline<a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline.setStages"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline.setStages" title="Permalink to this definition">¶</a></dt>
<dd><p>Set pipeline stages.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 1.3.0.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">list</span></dt><dd><p>of <a class="reference internal" href="pyspark.ml.Transformer.html#pyspark.ml.Transformer" title="pyspark.ml.Transformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.ml.Transformer</span></code></a>
or <a class="reference internal" href="pyspark.ml.Estimator.html#pyspark.ml.Estimator" title="pyspark.ml.Estimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">pyspark.ml.Estimator</span></code></a></p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#pyspark.ml.Pipeline" title="pyspark.ml.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a></dt><dd><p>the pipeline instance</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pyspark.ml.Pipeline.write">
<code class="sig-name descname">write</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="pyspark.ml.util.MLWriter.html#pyspark.ml.util.MLWriter" title="pyspark.ml.util.MLWriter">pyspark.ml.util.MLWriter</a><a class="reference internal" href="../../_modules/pyspark/ml/pipeline.html#Pipeline.write"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.ml.Pipeline.write" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an MLWriter instance for this ML instance.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 2.0.0.</span></p>
</div>
</dd></dl>

<p class="rubric">Attributes Documentation</p>
<dl class="py attribute">
<dt id="pyspark.ml.Pipeline.params">
<code class="sig-name descname">params</code><a class="headerlink" href="#pyspark.ml.Pipeline.params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns all params ordered by name. The default implementation
uses <code class="xref py py-func docutils literal notranslate"><span class="pre">dir()</span></code> to get all attributes of type
<code class="xref py py-class docutils literal notranslate"><span class="pre">Param</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="pyspark.ml.Pipeline.stages">
<code class="sig-name descname">stages</code><em class="property">: pyspark.ml.param.Param[List[PipelineStage]]</em><em class="property"> = Param(parent='undefined', name='stages', doc='a list of pipeline stages')</em><a class="headerlink" href="#pyspark.ml.Pipeline.stages" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="pyspark.ml.PredictionModel.html" title="previous page">PredictionModel</a>
    <a class='right-next' id="next-link" href="pyspark.ml.PipelineModel.html" title="next page">PipelineModel</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright .<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>