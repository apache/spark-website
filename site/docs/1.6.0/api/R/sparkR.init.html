<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Initialize a new Spark Context.</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for sparkR.init {SparkR}"><tr><td>sparkR.init {SparkR}</td><td align="right">R Documentation</td></tr></table>

<h2>Initialize a new Spark Context.</h2>

<h3>Description</h3>

<p>This function initializes a new SparkContext. For details on how to initialize
and use SparkR, refer to SparkR programming guide at
<a href="http://spark.apache.org/docs/latest/sparkr.html#starting-up-sparkcontext-sqlcontext">http://spark.apache.org/docs/latest/sparkr.html#starting-up-sparkcontext-sqlcontext</a>.
</p>


<h3>Usage</h3>

<pre>
sparkR.init(master = "", appName = "SparkR",
  sparkHome = Sys.getenv("SPARK_HOME"), sparkEnvir = list(),
  sparkExecutorEnv = list(), sparkJars = "", sparkPackages = "")
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>master</code></td>
<td>
<p>The Spark master URL</p>
</td></tr>
<tr valign="top"><td><code>appName</code></td>
<td>
<p>Application name to register with cluster manager</p>
</td></tr>
<tr valign="top"><td><code>sparkHome</code></td>
<td>
<p>Spark Home directory</p>
</td></tr>
<tr valign="top"><td><code>sparkEnvir</code></td>
<td>
<p>Named list of environment variables to set on worker nodes</p>
</td></tr>
<tr valign="top"><td><code>sparkExecutorEnv</code></td>
<td>
<p>Named list of environment variables to be used when launching executors</p>
</td></tr>
<tr valign="top"><td><code>sparkJars</code></td>
<td>
<p>Character vector of jar files to pass to the worker nodes</p>
</td></tr>
<tr valign="top"><td><code>sparkPackages</code></td>
<td>
<p>Character vector of packages from spark-packages.org</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D sc &lt;- sparkR.init(&quot;local[2]&quot;, &quot;SparkR&quot;, &quot;/home/spark&quot;)
##D sc &lt;- sparkR.init(&quot;local[2]&quot;, &quot;SparkR&quot;, &quot;/home/spark&quot;,
##D                  list(spark.executor.memory=&quot;1g&quot;))
##D sc &lt;- sparkR.init(&quot;yarn-client&quot;, &quot;SparkR&quot;, &quot;/home/spark&quot;,
##D                  list(spark.executor.memory=&quot;4g&quot;),
##D                  list(LD_LIBRARY_PATH=&quot;/directory of JVM libraries (libjvm.so) on workers/&quot;),
##D                  c(&quot;one.jar&quot;, &quot;two.jar&quot;, &quot;three.jar&quot;),
##D                  c(&quot;com.databricks:spark-avro_2.10:2.0.1&quot;,
##D                    &quot;com.databricks:spark-csv_2.10:1.3.0&quot;))
## End(Not run)
</code></pre>


<hr><div align="center">[Package <em>SparkR</em> version 1.6.0 <a href="00Index.html">Index</a>]</div>
</body></html>
