<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_80) on Tue Jun 26 17:20:47 UTC 2018 -->
<title>DataStreamWriter (Spark 2.1.3 JavaDoc)</title>
<meta name="date" content="2018-06-26">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="DataStreamWriter (Spark 2.1.3 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/streaming/DataStreamReader.html" title="class in org.apache.spark.sql.streaming"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/streaming/OutputMode.html" title="class in org.apache.spark.sql.streaming"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/streaming/DataStreamWriter.html" target="_top">Frames</a></li>
<li><a href="DataStreamWriter.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.streaming</div>
<h2 title="Class DataStreamWriter" class="title">Class DataStreamWriter&lt;T&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.streaming.DataStreamWriter&lt;T&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public final class <span class="strong">DataStreamWriter&lt;T&gt;</span>
extends Object</pre>
<div class="block">:: Experimental ::
 Interface used to write a streaming <code>Dataset</code> to external storage systems (e.g. file systems,
 key-value stores, etc). Use <code>Dataset.writeStream</code> to access this.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreach(org.apache.spark.sql.ForeachWriter)">foreach</a></strong>(<a href="../../../../../org/apache/spark/sql/ForeachWriter.html" title="class in org.apache.spark.sql">ForeachWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;writer)</code>
<div class="block">Starts the execution of the streaming query, which will continually send results to the given
 <code>ForeachWriter</code> as as new data arrives.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#format(java.lang.String)">format</a></strong>(String&nbsp;source)</code>
<div class="block">Specifies the underlying output data source.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(java.lang.String,%20boolean)">option</a></strong>(String&nbsp;key,
      boolean&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(java.lang.String,%20double)">option</a></strong>(String&nbsp;key,
      double&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(java.lang.String,%20long)">option</a></strong>(String&nbsp;key,
      long&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(java.lang.String,%20java.lang.String)">option</a></strong>(String&nbsp;key,
      String&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#options(scala.collection.Map)">options</a></strong>(scala.collection.Map&lt;String,String&gt;&nbsp;options)</code>
<div class="block">(Scala-specific) Adds output options for the underlying data source.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#options(java.util.Map)">options</a></strong>(java.util.Map&lt;String,String&gt;&nbsp;options)</code>
<div class="block">Adds output options for the underlying data source.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#outputMode(org.apache.spark.sql.streaming.OutputMode)">outputMode</a></strong>(<a href="../../../../../org/apache/spark/sql/streaming/OutputMode.html" title="class in org.apache.spark.sql.streaming">OutputMode</a>&nbsp;outputMode)</code>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#outputMode(java.lang.String)">outputMode</a></strong>(String&nbsp;outputMode)</code>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#partitionBy(scala.collection.Seq)">partitionBy</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;colNames)</code>
<div class="block">Partitions the output by the given columns on the file system.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#partitionBy(java.lang.String...)">partitionBy</a></strong>(String...&nbsp;colNames)</code>
<div class="block">Partitions the output by the given columns on the file system.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#queryName(java.lang.String)">queryName</a></strong>(String&nbsp;queryName)</code>
<div class="block">Specifies the name of the <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> that can be started with <code>start()</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#start()">start</a></strong>()</code>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a></code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#start(java.lang.String)">start</a></strong>(String&nbsp;path)</code>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#trigger(org.apache.spark.sql.streaming.Trigger)">trigger</a></strong>(<a href="../../../../../org/apache/spark/sql/streaming/Trigger.html" title="interface in org.apache.spark.sql.streaming">Trigger</a>&nbsp;trigger)</code>
<div class="block">Set the trigger for the stream query.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="partitionBy(java.lang.String...)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionBy</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;partitionBy(String...&nbsp;colNames)</pre>
<div class="block">Partitions the output by the given columns on the file system. If specified, the output is
 laid out on the file system similar to Hive's partitioning scheme. As an example, when we
 partition a dataset by year and then month, the directory layout would look like:
 <p>
   - year=2016/month=01/
   - year=2016/month=02/
 <p>
 Partitioning is one of the most widely used techniques to optimize physical data layout.
 It provides a coarse-grained index for skipping unnecessary data reads when queries have
 predicates on the partitioned columns. In order for partitioning to work well, the number
 of distinct values in each column should typically be less than tens of thousands.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>colNames</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="outputMode(org.apache.spark.sql.streaming.OutputMode)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>outputMode</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;outputMode(<a href="../../../../../org/apache/spark/sql/streaming/OutputMode.html" title="class in org.apache.spark.sql.streaming">OutputMode</a>&nbsp;outputMode)</pre>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.
   - <code>OutputMode.Append()</code>: only the new rows in the streaming DataFrame/Dataset will be
                            written to the sink
   - <code>OutputMode.Complete()</code>: all the rows in the streaming DataFrame/Dataset will be written
                              to the sink every time these is some updates
   - <code>OutputMode.Update()</code>: only the rows that were updated in the streaming DataFrame/Dataset
                            will be written to the sink every time there are some updates. If
                            the query doesn't contain aggregations, it will be equivalent to
                            <code>OutputMode.Append()</code> mode.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>outputMode</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="outputMode(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>outputMode</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;outputMode(String&nbsp;outputMode)</pre>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.
   - <code>append</code>:   only the new rows in the streaming DataFrame/Dataset will be written to
                 the sink
   - <code>complete</code>: all the rows in the streaming DataFrame/Dataset will be written to the sink
                 every time these is some updates
   - <code>update</code>:   only the rows that were updated in the streaming DataFrame/Dataset will
                 be written to the sink every time there are some updates. If the query doesn't
                 contain aggregations, it will be equivalent to <code>append</code> mode.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>outputMode</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="trigger(org.apache.spark.sql.streaming.Trigger)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>trigger</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;trigger(<a href="../../../../../org/apache/spark/sql/streaming/Trigger.html" title="interface in org.apache.spark.sql.streaming">Trigger</a>&nbsp;trigger)</pre>
<div class="block">Set the trigger for the stream query. The default value is <code>ProcessingTime(0)</code> and it will run
 the query as fast as possible.
 <p>
 Scala Example:
 <pre><code>
   df.writeStream.trigger(ProcessingTime("10 seconds"))

   import scala.concurrent.duration._
   df.writeStream.trigger(ProcessingTime(10.seconds))
 </code></pre>
 <p>
 Java Example:
 <pre><code>
   df.writeStream().trigger(ProcessingTime.create("10 seconds"))

   import java.util.concurrent.TimeUnit
   df.writeStream().trigger(ProcessingTime.create(10, TimeUnit.SECONDS))
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>trigger</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="queryName(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>queryName</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;queryName(String&nbsp;queryName)</pre>
<div class="block">Specifies the name of the <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> that can be started with <code>start()</code>.
 This name must be unique among all the currently active queries in the associated SQLContext.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>queryName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="format(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>format</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;format(String&nbsp;source)</pre>
<div class="block">Specifies the underlying output data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>source</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="partitionBy(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionBy</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;partitionBy(scala.collection.Seq&lt;String&gt;&nbsp;colNames)</pre>
<div class="block">Partitions the output by the given columns on the file system. If specified, the output is
 laid out on the file system similar to Hive's partitioning scheme. As an example, when we
 partition a dataset by year and then month, the directory layout would look like:
 <p>
   - year=2016/month=01/
   - year=2016/month=02/
 <p>
 Partitioning is one of the most widely used techniques to optimize physical data layout.
 It provides a coarse-grained index for skipping unnecessary data reads when queries have
 predicates on the partitioned columns. In order for partitioning to work well, the number
 of distinct values in each column should typically be less than tens of thousands.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>colNames</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="option(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                         String&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="option(java.lang.String, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                         boolean&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="option(java.lang.String, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                         long&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="option(java.lang.String, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                         double&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>key</code> - (undocumented)</dd><dd><code>value</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="options(scala.collection.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>options</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;options(scala.collection.Map&lt;String,String&gt;&nbsp;options)</pre>
<div class="block">(Scala-specific) Adds output options for the underlying data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="options(java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>options</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;options(java.util.Map&lt;String,String&gt;&nbsp;options)</pre>
<div class="block">Adds output options for the underlying data source.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>options</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="start(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>start</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a>&nbsp;start(String&nbsp;path)</pre>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives. The returned <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> object can be used to interact with
 the stream.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="start()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>start</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a>&nbsp;start()</pre>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives. The returned <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> object can be used to interact with
 the stream.
 <p></div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="foreach(org.apache.spark.sql.ForeachWriter)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>foreach</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;foreach(<a href="../../../../../org/apache/spark/sql/ForeachWriter.html" title="class in org.apache.spark.sql">ForeachWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;writer)</pre>
<div class="block">Starts the execution of the streaming query, which will continually send results to the given
 <code>ForeachWriter</code> as as new data arrives. The <code>ForeachWriter</code> can be used to send the data
 generated by the <code>DataFrame</code>/<code>Dataset</code> to an external system.
 <p>
 Scala example:
 <pre><code>
   datasetOfString.writeStream.foreach(new ForeachWriter[String] {

     def open(partitionId: Long, version: Long): Boolean = {
       // open connection
     }

     def process(record: String) = {
       // write string to connection
     }

     def close(errorOrNull: Throwable): Unit = {
       // close the connection
     }
   }).start()
 </code></pre>
 <p>
 Java example:
 <pre><code>
  datasetOfString.writeStream().foreach(new ForeachWriter&lt;String&gt;() {

    &#64;Override
    public boolean open(long partitionId, long version) {
      // open connection
    }

    &#64;Override
    public void process(String value) {
      // write string to connection
    }

    &#64;Override
    public void close(Throwable errorOrNull) {
      // close the connection
    }
  }).start();
 </code></pre>
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>writer</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/streaming/DataStreamReader.html" title="class in org.apache.spark.sql.streaming"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/streaming/OutputMode.html" title="class in org.apache.spark.sql.streaming"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/streaming/DataStreamWriter.html" target="_top">Frames</a></li>
<li><a href="DataStreamWriter.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
