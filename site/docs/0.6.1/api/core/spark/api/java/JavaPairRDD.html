<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>spark.api.java.JavaPairRDD</title>
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link type="text/css" media="screen" rel="stylesheet" href="../../../lib/template.css" />
      <script type="text/javascript" src="../../../lib/jquery.js"></script>
      <script type="text/javascript" src="../../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../../lib/template.js"></script>
      <script type="text/javascript" src="../../../lib/tools.tooltip.js"></script>
    
        </head>
        <body onload="sh_highlightDocument('../lib/', '.min.js');" class="type">
      <div id="definition">
        <a title="Go to companion" href="JavaPairRDD$.html"><img src="../../../lib/class_to_object_big.png" /></a>
        <p id="owner"><a name="spark" class="extype" href="../../package.html">spark</a>.<a name="spark.api" class="extype" href="../package.html">api</a>.<a name="spark.api.java" class="extype" href="package.html">java</a></p>
        <h1><a title="Go to companion" href="JavaPairRDD$.html">JavaPairRDD</a></h1>
      </div>

      <h4 class="signature" id="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">JavaPairRDD</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a>[(K, V), <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]]</span>
      </span>
      </h4>
      
      <div class="fullcommenttop" id="comment"><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a>[(K, V), <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]], <span name="scala.Serializable" class="extype">Serializable</span>, <span name="java.io.Serializable" class="extype">Serializable</span>, AnyRef, <span name="scala.Any" class="extype">Any</span></div>
        </div></div>
    

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input accesskey="/" type="text" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By inheritance</span></li></ol>
            </div>
        <div id="ancestors">
              <span class="filtertype">Inherited</span>
              <ol><li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li></ol>
              <ol id="linearization"><li name="spark.api.java.JavaPairRDD" class="in"><span>JavaPairRDD</span></li><li name="spark.api.java.JavaRDDLike" class="in"><span>JavaRDDLike</span></li><li name="scala.Serializable" class="in"><span>Serializable</span></li><li name="java.io.Serializable" class="in"><span>Serializable</span></li><li name="scala.AnyRef" class="in"><span>AnyRef</span></li><li name="scala.Any" class="in"><span>Any</span></li></ol>
            </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div class="members" id="constructors">
              <h3>Instance Constructors</h3>
              <ol><li visbl="pub" name="spark.api.java.JavaPairRDD#this" data-isabs="false">
      <a id="this:JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaPairRDD</span><span class="params">(<span name="rdd">rdd: <a name="spark.RDD" class="extype" href="../../RDD.html">RDD</a>[(K, V)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="kManifest">kManifest: ClassManifest[K]</span>, <span name="vManifest">vManifest: ClassManifest[V]</span>)</span>
      </span>
      </h4>
      
    </li></ol>
            </div>

        

        

        <div class="values members" id="values">
              <h3>Value Members</h3>
              <ol><li visbl="pub" name="scala.AnyRef#!=" data-isabs="false">
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#!=" data-isabs="false">
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef###" data-isabs="false">
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $hash$hash">##</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#==" data-isabs="false">
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#==" data-isabs="false">
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#aggregate" data-isabs="false">
      <a id="aggregate[U](U)(Function2[U, (K, V), U],Function2[U, U, U]):U"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">aggregate</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="zeroValue">zeroValue: U</span>)</span><span class="params">(<span name="seqOp">seqOp: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[U, (K, V), U]</span>, <span name="combOp">combOp: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[U, U, U]</span>)</span><span class="result">: U</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Aggregate the elements of each partition, and then the results for all the partitions, using
given combine functions and a neutral &quot;zero value&quot;.</p><div class="fullcomment"><div class="comment cmt"><p>Aggregate the elements of each partition, and then the results for all the partitions, using
given combine functions and a neutral &quot;zero value&quot;. This function can return a different result
type, U, than the type of this RDD, T. Thus, we need one operation for merging a T into an U
and one operation for merging two U's, as in scala.TraversableOnce. Both of these functions are
allowed to modify and return their first argument instead of creating a new U to avoid memory
allocation.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.Any#asInstanceOf" data-isabs="false">
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cache" data-isabs="false">
      <a id="cache():JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cache</span><span class="params">()</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Persist this RDD with the default storage level (<code>MEMORY_ONLY</code>).</p>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#cartesian" data-isabs="false">
      <a id="cartesian[U](spark.api.java.JavaRDDLike[U, _]):JavaPairRDD[(K, V), U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cartesian</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="other">other: spark.api.java.JavaRDDLike[U, _]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[(K, V), U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#classManifest" data-isabs="false">
      <a id="classManifest:ClassManifest[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">classManifest</span><span class="result">: ClassManifest[(K, V)]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a> → <a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#clone" data-isabs="false">
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: AnyRef</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cogroup" data-isabs="false">
      <a id="cogroup[W1, W2](JavaPairRDD[K, W1],JavaPairRDD[K, W2],Int):JavaPairRDD[K, (List[V], List[W1], List[W2])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W1">W1</span>, <span name="W2">W2</span>]</span><span class="params">(<span name="other1">other1: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W1]</span>, <span name="other2">other2: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W2]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W1], <span name="java.util.List" class="extype">List</span>[W2])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cogroup" data-isabs="false">
      <a id="cogroup[W](JavaPairRDD[K, W],Int):JavaPairRDD[K, (List[V], List[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
list of values for that key in <code>this</code> as well as <code>other</code>.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cogroup" data-isabs="false">
      <a id="cogroup[W1, W2](JavaPairRDD[K, W1],JavaPairRDD[K, W2]):JavaPairRDD[K, (List[V], List[W1], List[W2])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W1">W1</span>, <span name="W2">W2</span>]</span><span class="params">(<span name="other1">other1: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W1]</span>, <span name="other2">other2: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W2]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W1], <span name="java.util.List" class="extype">List</span>[W2])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cogroup" data-isabs="false">
      <a id="cogroup[W](JavaPairRDD[K, W]):JavaPairRDD[K, (List[V], List[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
list of values for that key in <code>this</code> as well as <code>other</code>.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cogroup" data-isabs="false">
      <a id="cogroup[W1, W2](JavaPairRDD[K, W1],JavaPairRDD[K, W2],Partitioner):JavaPairRDD[K, (List[V], List[W1], List[W2])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W1">W1</span>, <span name="W2">W2</span>]</span><span class="params">(<span name="other1">other1: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W1]</span>, <span name="other2">other2: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W2]</span>, <span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W1], <span name="java.util.List" class="extype">List</span>[W2])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#cogroup" data-isabs="false">
      <a id="cogroup[W](JavaPairRDD[K, W],Partitioner):JavaPairRDD[K, (List[V], List[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
list of values for that key in <code>this</code> as well as <code>other</code>.</p>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#collect" data-isabs="false">
      <a id="collect():List[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">collect</span><span class="params">()</span><span class="result">: <span name="java.util.List" class="extype">List</span>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an array that contains all of the elements in this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return an array that contains all of the elements in this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#collectAsMap" data-isabs="false">
      <a id="collectAsMap():Map[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">collectAsMap</span><span class="params">()</span><span class="result">: <span name="java.util.Map" class="extype">Map</span>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the key-value pairs in this RDD to the master as a Map.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#combineByKey" data-isabs="false">
      <a id="combineByKey[C](Function[V, C],Function2[C, V, C],Function2[C, C, C]):JavaPairRDD[K, C]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: <a name="spark.api.java.function.Function" class="extype" href="function/Function.html">Function</a>[V, C]</span>, <span name="mergeValue">mergeValue: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[C, V, C]</span>, <span name="mergeCombiners">mergeCombiners: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[C, C, C]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, C]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Simplified version of combineByKey that hash-partitions the resulting RDD using the default
parallelism level.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#combineByKey" data-isabs="false">
      <a id="combineByKey[C](Function[V, C],Function2[C, V, C],Function2[C, C, C],Int):JavaPairRDD[K, C]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: <a name="spark.api.java.function.Function" class="extype" href="function/Function.html">Function</a>[V, C]</span>, <span name="mergeValue">mergeValue: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[C, V, C]</span>, <span name="mergeCombiners">mergeCombiners: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[C, C, C]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, C]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Simplified version of combineByKey that hash-partitions the output RDD.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#combineByKey" data-isabs="false">
      <a id="combineByKey[C]((V) ⇒ C,Function2[C, V, C],Function2[C, C, C],Partitioner):JavaPairRDD[K, C]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: (V) ⇒ C</span>, <span name="mergeValue">mergeValue: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[C, V, C]</span>, <span name="mergeCombiners">mergeCombiners: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[C, C, C]</span>, <span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, C]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Generic function to combine the elements for each key using a custom set of aggregation
functions.</p><div class="fullcomment"><div class="comment cmt"><p>Generic function to combine the elements for each key using a custom set of aggregation
functions. Turns a JavaPairRDD[(K, V)] into a result of type JavaPairRDD[(K, C)], for a
&quot;combined type&quot; C * Note that V and C can be different -- for example, one might group an
RDD of type (Int, Int) into an RDD of type (Int, List[Int]). Users provide three
functions:</p><p>- <code>createCombiner</code>, which turns a V into a C (e.g., creates a one-element list)
- <code>mergeValue</code>, to merge a V into a C (e.g., adds it to the end of a list)
- <code>mergeCombiners</code>, to combine two C's into a single one.</p><p>In addition, users can control the partitioning of the output RDD, and whether to perform
map-side aggregation (if a mapper can produce multiple items with the same key).
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#context" data-isabs="false">
      <a id="context:SparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">context</span><span class="result">: <a name="spark.SparkContext" class="extype" href="../../SparkContext.html">SparkContext</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">The <a name="spark.SparkContext" class="extype" href="../../SparkContext.html">SparkContext</a> that this RDD was created on.</p><div class="fullcomment"><div class="comment cmt"><p>The <a name="spark.SparkContext" class="extype" href="../../SparkContext.html">SparkContext</a> that this RDD was created on.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#count" data-isabs="false">
      <a id="count():Long"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">count</span><span class="params">()</span><span class="result">: <span name="scala.Long" class="extype">Long</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the number of elements in the RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return the number of elements in the RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#countApprox" data-isabs="false">
      <a id="countApprox(Long):PartialResult[BoundedDouble]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countApprox</span><span class="params">(<span name="timeout">timeout: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a name="spark.partial.PartialResult" class="extype" href="../../partial/PartialResult.html">PartialResult</a>[<a name="spark.partial.BoundedDouble" class="extype" href="../../partial/BoundedDouble.html">BoundedDouble</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Experimental) Approximate version of count() that returns a potentially incomplete result
within a timeout, even if not all tasks have finished.</p><div class="fullcomment"><div class="comment cmt"><p>(Experimental) Approximate version of count() that returns a potentially incomplete result
within a timeout, even if not all tasks have finished.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#countApprox" data-isabs="false">
      <a id="countApprox(Long,Double):PartialResult[BoundedDouble]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countApprox</span><span class="params">(<span name="timeout">timeout: <span name="scala.Long" class="extype">Long</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a name="spark.partial.PartialResult" class="extype" href="../../partial/PartialResult.html">PartialResult</a>[<a name="spark.partial.BoundedDouble" class="extype" href="../../partial/BoundedDouble.html">BoundedDouble</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Experimental) Approximate version of count() that returns a potentially incomplete result
within a timeout, even if not all tasks have finished.</p><div class="fullcomment"><div class="comment cmt"><p>(Experimental) Approximate version of count() that returns a potentially incomplete result
within a timeout, even if not all tasks have finished.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#countByKey" data-isabs="false">
      <a id="countByKey():Map[K, Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByKey</span><span class="params">()</span><span class="result">: <span name="java.util.Map" class="extype">Map</span>[K, <span name="scala.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Count the number of elements for each key, and return the result to the master as a Map.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#countByKeyApprox" data-isabs="false">
      <a id="countByKeyApprox(Long,Double):PartialResult[Map[K, BoundedDouble]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByKeyApprox</span><span class="params">(<span name="timeout">timeout: <span name="scala.Long" class="extype">Long</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span> = <span class="symbol">0.95</span></span>)</span><span class="result">: <a name="spark.partial.PartialResult" class="extype" href="../../partial/PartialResult.html">PartialResult</a>[<span name="java.util.Map" class="extype">Map</span>[K, <a name="spark.partial.BoundedDouble" class="extype" href="../../partial/BoundedDouble.html">BoundedDouble</a>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Experimental) Approximate version of countByKey that can return a partial result if it does
not finish within a timeout.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#countByKeyApprox" data-isabs="false">
      <a id="countByKeyApprox(Long):PartialResult[Map[K, BoundedDouble]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByKeyApprox</span><span class="params">(<span name="timeout">timeout: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a name="spark.partial.PartialResult" class="extype" href="../../partial/PartialResult.html">PartialResult</a>[<span name="java.util.Map" class="extype">Map</span>[K, <a name="spark.partial.BoundedDouble" class="extype" href="../../partial/BoundedDouble.html">BoundedDouble</a>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Experimental) Approximate version of countByKey that can return a partial result if it does
not finish within a timeout.</p>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#countByValue" data-isabs="false">
      <a id="countByValue():Map[(K, V), Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValue</span><span class="params">()</span><span class="result">: <span name="java.util.Map" class="extype">Map</span>[(K, V), <span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the count of each unique value in this RDD as a map of (value, count) pairs.</p><div class="fullcomment"><div class="comment cmt"><p>Return the count of each unique value in this RDD as a map of (value, count) pairs. The final
combine step happens locally on the master, equivalent to running a single reduce task.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#countByValueApprox" data-isabs="false">
      <a id="countByValueApprox(Long):PartialResult[Map[(K, V), BoundedDouble]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValueApprox</span><span class="params">(<span name="timeout">timeout: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a name="spark.partial.PartialResult" class="extype" href="../../partial/PartialResult.html">PartialResult</a>[<span name="java.util.Map" class="extype">Map</span>[(K, V), <a name="spark.partial.BoundedDouble" class="extype" href="../../partial/BoundedDouble.html">BoundedDouble</a>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Experimental) Approximate version of countByValue().</p><div class="fullcomment"><div class="comment cmt"><p>(Experimental) Approximate version of countByValue().
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#countByValueApprox" data-isabs="false">
      <a id="countByValueApprox(Long,Double):PartialResult[Map[(K, V), BoundedDouble]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValueApprox</span><span class="params">(<span name="timeout">timeout: <span name="scala.Long" class="extype">Long</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a name="spark.partial.PartialResult" class="extype" href="../../partial/PartialResult.html">PartialResult</a>[<span name="java.util.Map" class="extype">Map</span>[(K, V), <a name="spark.partial.BoundedDouble" class="extype" href="../../partial/BoundedDouble.html">BoundedDouble</a>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Experimental) Approximate version of countByValue().</p><div class="fullcomment"><div class="comment cmt"><p>(Experimental) Approximate version of countByValue().
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#distinct" data-isabs="false">
      <a id="distinct(Int):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">distinct</span><span class="params">(<span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD containing the distinct elements in this RDD.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#distinct" data-isabs="false">
      <a id="distinct():JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">distinct</span><span class="params">()</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD containing the distinct elements in this RDD.</p>
    </li><li visbl="pub" name="scala.AnyRef#eq" data-isabs="false">
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#equals" data-isabs="false">
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#filter" data-isabs="false">
      <a id="filter(((K, V)) ⇒ Boolean):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filter</span><span class="params">(<span name="f">f: ((K, V)) ⇒ <span name="java.lang.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD containing only the elements that satisfy a predicate.</p>
    </li><li visbl="prt" name="scala.AnyRef#finalize" data-isabs="false">
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#first" data-isabs="false">
      <a id="first():(K, V)"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">first</span><span class="params">()</span><span class="result">: (K, V)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the first element in this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return the first element in this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a> → <a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#flatMap" data-isabs="false">
      <a id="flatMap[K, V](PairFlatMapFunction[(K, V), K, V]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.PairFlatMapFunction" class="extype" href="function/PairFlatMapFunction.html">PairFlatMapFunction</a>[(K, V), K, V]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt"> Return a new RDD by first applying a function to all elements of this
 RDD, and then flattening the results.</p><div class="fullcomment"><div class="comment cmt"><p> Return a new RDD by first applying a function to all elements of this
 RDD, and then flattening the results.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#flatMap" data-isabs="false">
      <a id="flatMap(DoubleFlatMapFunction[(K, V)]):JavaDoubleRDD"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.DoubleFlatMapFunction" class="extype" href="function/DoubleFlatMapFunction.html">DoubleFlatMapFunction</a>[(K, V)]</span>)</span><span class="result">: <a name="spark.api.java.JavaDoubleRDD" class="extype" href="JavaDoubleRDD.html">JavaDoubleRDD</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt"> Return a new RDD by first applying a function to all elements of this
 RDD, and then flattening the results.</p><div class="fullcomment"><div class="comment cmt"><p> Return a new RDD by first applying a function to all elements of this
 RDD, and then flattening the results.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#flatMap" data-isabs="false">
      <a id="flatMap[U](FlatMapFunction[(K, V), U]):JavaRDD[U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.FlatMapFunction" class="extype" href="function/FlatMapFunction.html">FlatMapFunction</a>[(K, V), U]</span>)</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt"> Return a new RDD by first applying a function to all elements of this
 RDD, and then flattening the results.</p><div class="fullcomment"><div class="comment cmt"><p> Return a new RDD by first applying a function to all elements of this
 RDD, and then flattening the results.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#flatMapValues" data-isabs="false">
      <a id="flatMapValues[U](Function[V, Iterable[U]]):JavaPairRDD[K, U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.Function" class="extype" href="function/Function.html">Function</a>[V, <span name="java.lang.Iterable" class="extype">Iterable</span>[U]]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Pass each value in the key-value pair RDD through a flatMap function without changing the
keys; this also retains the original RDD's partitioning.</p>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#fold" data-isabs="false">
      <a id="fold((K, V))(Function2[(K, V), (K, V), (K, V)]):(K, V)"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fold</span><span class="params">(<span name="zeroValue">zeroValue: (K, V)</span>)</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[(K, V), (K, V), (K, V)]</span>)</span><span class="result">: (K, V)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Aggregate the elements of each partition, and then the results for all the partitions, using a
given associative function and a neutral &quot;zero value&quot;.</p><div class="fullcomment"><div class="comment cmt"><p>Aggregate the elements of each partition, and then the results for all the partitions, using a
given associative function and a neutral &quot;zero value&quot;. The function op(t1, t2) is allowed to
modify t1 and return it as its result value to avoid object allocation; however, it should not
modify t2.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#foreach" data-isabs="false">
      <a id="foreach(VoidFunction[(K, V)]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreach</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.VoidFunction" class="extype" href="function/VoidFunction.html">VoidFunction</a>[(K, V)]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Applies a function f to all elements of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a function f to all elements of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#getClass" data-isabs="false">
      <a id="getClass():java.lang.Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: java.lang.Class[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#getStorageLevel" data-isabs="false">
      <a id="getStorageLevel:StorageLevel"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getStorageLevel</span><span class="result">: <a name="spark.storage.StorageLevel" class="extype" href="../../storage/StorageLevel.html">StorageLevel</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Get the RDD's current storage level, or StorageLevel.</p><div class="fullcomment"><div class="comment cmt"><p>Get the RDD's current storage level, or StorageLevel.NONE if none is set.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#glom" data-isabs="false">
      <a id="glom():JavaRDD[List[(K, V)]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">glom</span><span class="params">()</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[<span name="java.util.List" class="extype">List</span>[(K, V)]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD created by coalescing all elements within each partition into an array.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD created by coalescing all elements within each partition into an array.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#groupBy" data-isabs="false">
      <a id="groupBy[K](Function[(K, V), K],Int):JavaPairRDD[K, List[(K, V)]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupBy</span><span class="tparams">[<span name="K">K</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.Function" class="extype" href="function/Function.html">Function</a>[(K, V), K]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, <span name="java.util.List" class="extype">List</span>[(K, V)]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD of grouped elements.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD of grouped elements. Each group consists of a key and a sequence of elements
mapping to that key.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#groupBy" data-isabs="false">
      <a id="groupBy[K](Function[(K, V), K]):JavaPairRDD[K, List[(K, V)]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupBy</span><span class="tparams">[<span name="K">K</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.Function" class="extype" href="function/Function.html">Function</a>[(K, V), K]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, <span name="java.util.List" class="extype">List</span>[(K, V)]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD of grouped elements.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD of grouped elements. Each group consists of a key and a sequence of elements
mapping to that key.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#groupByKey" data-isabs="false">
      <a id="groupByKey():JavaPairRDD[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">()</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Group the values for each key in the RDD into a single sequence.</p><div class="fullcomment"><div class="comment cmt"><p>Group the values for each key in the RDD into a single sequence. Hash-partitions the
resulting RDD with the default parallelism level.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#groupByKey" data-isabs="false">
      <a id="groupByKey(Int):JavaPairRDD[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Group the values for each key in the RDD into a single sequence.</p><div class="fullcomment"><div class="comment cmt"><p>Group the values for each key in the RDD into a single sequence. Hash-partitions the
resulting RDD with into <code>numSplits</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#groupByKey" data-isabs="false">
      <a id="groupByKey(Partitioner):JavaPairRDD[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Group the values for each key in the RDD into a single sequence.</p><div class="fullcomment"><div class="comment cmt"><p>Group the values for each key in the RDD into a single sequence. Allows controlling the
partitioning of the resulting key-value pair RDD by passing a Partitioner.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#groupWith" data-isabs="false">
      <a id="groupWith[W1, W2](JavaPairRDD[K, W1],JavaPairRDD[K, W2]):JavaPairRDD[K, (List[V], List[W1], List[W2])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupWith</span><span class="tparams">[<span name="W1">W1</span>, <span name="W2">W2</span>]</span><span class="params">(<span name="other1">other1: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W1]</span>, <span name="other2">other2: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W2]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W1], <span name="java.util.List" class="extype">List</span>[W2])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Alias for cogroup.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#groupWith" data-isabs="false">
      <a id="groupWith[W](JavaPairRDD[K, W]):JavaPairRDD[K, (List[V], List[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupWith</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Alias for cogroup.</p>
    </li><li visbl="pub" name="scala.AnyRef#hashCode" data-isabs="false">
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#id" data-isabs="false">
      <a id="id:Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">id</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">A unique ID for this RDD (within its SparkContext).</p><div class="fullcomment"><div class="comment cmt"><p>A unique ID for this RDD (within its SparkContext).</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.Any#isInstanceOf" data-isabs="false">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#iterator" data-isabs="false">
      <a id="iterator(Split):Iterator[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">iterator</span><span class="params">(<span name="split">split: <a name="spark.Split" class="extype" href="../../Split.html">Split</a></span>)</span><span class="result">: <span name="java.util.Iterator" class="extype">Iterator</span>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Internal method to this RDD; will read from cache if applicable, or otherwise compute it.</p><div class="fullcomment"><div class="comment cmt"><p>Internal method to this RDD; will read from cache if applicable, or otherwise compute it.
This should <i>not</i> be called by users directly, but is available for implementors of custom
subclasses of RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#join" data-isabs="false">
      <a id="join[W](JavaPairRDD[K, W],Int):JavaPairRDD[K, (V, W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (V, W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>. Each
pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in <code>this</code> and
(k, v2) is in <code>other</code>. Performs a hash join across the cluster.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#join" data-isabs="false">
      <a id="join[W](JavaPairRDD[K, W]):JavaPairRDD[K, (V, W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (V, W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>. Each
pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in <code>this</code> and
(k, v2) is in <code>other</code>. Performs a hash join across the cluster.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#join" data-isabs="false">
      <a id="join[W](JavaPairRDD[K, W],Partitioner):JavaPairRDD[K, (V, W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (V, W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Merge the values for each key using an associative reduce function.</p><div class="fullcomment"><div class="comment cmt"><p>Merge the values for each key using an associative reduce function. This will also perform
the merging locally on each mapper before sending results to a reducer, similarly to a
&quot;combiner&quot; in MapReduce.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#kManifest" data-isabs="false">
      <a id="kManifest:ClassManifest[K]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">implicit </span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">kManifest</span><span class="result">: ClassManifest[K]</span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#leftOuterJoin" data-isabs="false">
      <a id="leftOuterJoin[W](JavaPairRDD[K, W],Int):JavaPairRDD[K, (V, Option[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (V, <span name="scala.Option" class="extype">Option</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Perform a left outer join of <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Perform a left outer join of <code>this</code> and <code>other</code>. For each element (k, v) in <code>this</code>, the
resulting RDD will either contain all pairs (k, (v, Some(w))) for w in <code>other</code>, or the
pair (k, (v, None)) if no elements in <code>other</code> have key k. Hash-partitions the output
into <code>numSplits</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#leftOuterJoin" data-isabs="false">
      <a id="leftOuterJoin[W](JavaPairRDD[K, W]):JavaPairRDD[K, (V, Option[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (V, <span name="scala.Option" class="extype">Option</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Perform a left outer join of <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Perform a left outer join of <code>this</code> and <code>other</code>. For each element (k, v) in <code>this</code>, the
resulting RDD will either contain all pairs (k, (v, Some(w))) for w in <code>other</code>, or the
pair (k, (v, None)) if no elements in <code>other</code> have key k. Hash-partitions the output
using the default level of parallelism.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#leftOuterJoin" data-isabs="false">
      <a id="leftOuterJoin[W](JavaPairRDD[K, W],Partitioner):JavaPairRDD[K, (V, Option[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (V, <span name="scala.Option" class="extype">Option</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Perform a left outer join of <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Perform a left outer join of <code>this</code> and <code>other</code>. For each element (k, v) in <code>this</code>, the
resulting RDD will either contain all pairs (k, (v, Some(w))) for w in <code>other</code>, or the
pair (k, (v, None)) if no elements in <code>other</code> have key k. Uses the given Partitioner to
partition the output RDD.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#lookup" data-isabs="false">
      <a id="lookup(K):List[V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">lookup</span><span class="params">(<span name="key">key: K</span>)</span><span class="result">: <span name="java.util.List" class="extype">List</span>[V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the list of values in the RDD for key <code>key</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Return the list of values in the RDD for key <code>key</code>. This operation is done efficiently if the
RDD has a known partitioner by only searching the partition that the key maps to.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#map" data-isabs="false">
      <a id="map[K2, V2](PairFunction[(K, V), K2, V2]):JavaPairRDD[K2, V2]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="K2">K2</span>, <span name="V2">V2</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.PairFunction" class="extype" href="function/PairFunction.html">PairFunction</a>[(K, V), K2, V2]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K2, V2]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD by applying a function to all elements of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new RDD by applying a function to all elements of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#map" data-isabs="false">
      <a id="map[R](DoubleFunction[(K, V)]):JavaDoubleRDD"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.DoubleFunction" class="extype" href="function/DoubleFunction.html">DoubleFunction</a>[(K, V)]</span>)</span><span class="result">: <a name="spark.api.java.JavaDoubleRDD" class="extype" href="JavaDoubleRDD.html">JavaDoubleRDD</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD by applying a function to all elements of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new RDD by applying a function to all elements of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#map" data-isabs="false">
      <a id="map[R](Function[(K, V), R]):JavaRDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.Function" class="extype" href="function/Function.html">Function</a>[(K, V), R]</span>)</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[R]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD by applying a function to all elements of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new RDD by applying a function to all elements of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#mapPartitions" data-isabs="false">
      <a id="mapPartitions[K, V](PairFlatMapFunction[Iterator[(K, V)], K, V]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.PairFlatMapFunction" class="extype" href="function/PairFlatMapFunction.html">PairFlatMapFunction</a>[<span name="java.util.Iterator" class="extype">Iterator</span>[(K, V)], K, V]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD by applying a function to each partition of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new RDD by applying a function to each partition of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#mapPartitions" data-isabs="false">
      <a id="mapPartitions(DoubleFlatMapFunction[Iterator[(K, V)]]):JavaDoubleRDD"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.DoubleFlatMapFunction" class="extype" href="function/DoubleFlatMapFunction.html">DoubleFlatMapFunction</a>[<span name="java.util.Iterator" class="extype">Iterator</span>[(K, V)]]</span>)</span><span class="result">: <a name="spark.api.java.JavaDoubleRDD" class="extype" href="JavaDoubleRDD.html">JavaDoubleRDD</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD by applying a function to each partition of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new RDD by applying a function to each partition of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#mapPartitions" data-isabs="false">
      <a id="mapPartitions[U](FlatMapFunction[Iterator[(K, V)], U]):JavaRDD[U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.FlatMapFunction" class="extype" href="function/FlatMapFunction.html">FlatMapFunction</a>[<span name="java.util.Iterator" class="extype">Iterator</span>[(K, V)], U]</span>)</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new RDD by applying a function to each partition of this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new RDD by applying a function to each partition of this RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#mapValues" data-isabs="false">
      <a id="mapValues[U]((V) ⇒ U):JavaPairRDD[K, U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: (V) ⇒ U</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Pass each value in the key-value pair RDD through a map function without changing the keys;
this also retains the original RDD's partitioning.</p>
    </li><li visbl="pub" name="scala.AnyRef#ne" data-isabs="false">
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notify" data-isabs="false">
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notifyAll" data-isabs="false">
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#partitionBy" data-isabs="false">
      <a id="partitionBy(Partitioner):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">partitionBy</span><span class="params">(<span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a copy of the RDD partitioned using the specified partitioner.</p><div class="fullcomment"><div class="comment cmt"><p>Return a copy of the RDD partitioned using the specified partitioner. If <code>mapSideCombine</code>
is true, Spark will group values of the same key together on the map side before the
repartitioning, to only send each key over the network once. If a large number of
duplicated keys are expected, and the size of the keys are large, <code>mapSideCombine</code> should
be set to true.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#persist" data-isabs="false">
      <a id="persist(StorageLevel):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">(<span name="newLevel">newLevel: <a name="spark.storage.StorageLevel" class="extype" href="../../storage/StorageLevel.html">StorageLevel</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Set this RDD's storage level to persist its values across operations after the first time
it is computed.</p><div class="fullcomment"><div class="comment cmt"><p>Set this RDD's storage level to persist its values across operations after the first time
it is computed. Can only be called once on each RDD.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#pipe" data-isabs="false">
      <a id="pipe(List[String],Map[String, String]):JavaRDD[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">pipe</span><span class="params">(<span name="command">command: <span name="java.util.List" class="extype">List</span>[String]</span>, <span name="env">env: <span name="java.util.Map" class="extype">Map</span>[String, String]</span>)</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD created by piping elements to a forked external process.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD created by piping elements to a forked external process.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#pipe" data-isabs="false">
      <a id="pipe(List[String]):JavaRDD[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">pipe</span><span class="params">(<span name="command">command: <span name="java.util.List" class="extype">List</span>[String]</span>)</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD created by piping elements to a forked external process.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD created by piping elements to a forked external process.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#pipe" data-isabs="false">
      <a id="pipe(String):JavaRDD[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">pipe</span><span class="params">(<span name="command">command: String</span>)</span><span class="result">: <a name="spark.api.java.JavaRDD" class="extype" href="JavaRDD.html">JavaRDD</a>[String]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return an RDD created by piping elements to a forked external process.</p><div class="fullcomment"><div class="comment cmt"><p>Return an RDD created by piping elements to a forked external process.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#rdd" data-isabs="false">
      <a id="rdd:RDD[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">rdd</span><span class="result">: <a name="spark.RDD" class="extype" href="../../RDD.html">RDD</a>[(K, V)]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a> → <a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#reduce" data-isabs="false">
      <a id="reduce(Function2[(K, V), (K, V), (K, V)]):(K, V)"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduce</span><span class="params">(<span name="f">f: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[(K, V), (K, V), (K, V)]</span>)</span><span class="result">: (K, V)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Reduces the elements of this RDD using the specified associative binary operator.</p><div class="fullcomment"><div class="comment cmt"><p>Reduces the elements of this RDD using the specified associative binary operator.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#reduceByKey" data-isabs="false">
      <a id="reduceByKey(Function2[V, V, V]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="func">func: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[V, V, V]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Merge the values for each key using an associative reduce function.</p><div class="fullcomment"><div class="comment cmt"><p>Merge the values for each key using an associative reduce function. This will also perform
the merging locally on each mapper before sending results to a reducer, similarly to a
&quot;combiner&quot; in MapReduce. Output will be hash-partitioned with the default parallelism level.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#reduceByKey" data-isabs="false">
      <a id="reduceByKey(Function2[V, V, V],Int):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="func">func: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[V, V, V]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Merge the values for each key using an associative reduce function.</p><div class="fullcomment"><div class="comment cmt"><p>Merge the values for each key using an associative reduce function. This will also perform
the merging locally on each mapper before sending results to a reducer, similarly to a
&quot;combiner&quot; in MapReduce. Output will be hash-partitioned with numSplits splits.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#reduceByKey" data-isabs="false">
      <a id="reduceByKey(Partitioner,Function2[V, V, V]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>, <span name="func">func: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[V, V, V]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Merge the values for each key using an associative reduce function.</p><div class="fullcomment"><div class="comment cmt"><p>Merge the values for each key using an associative reduce function. This will also perform
the merging locally on each mapper before sending results to a reducer, similarly to a
&quot;combiner&quot; in MapReduce.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#reduceByKeyLocally" data-isabs="false">
      <a id="reduceByKeyLocally(Function2[V, V, V]):Map[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyLocally</span><span class="params">(<span name="func">func: <a name="spark.api.java.function.Function2" class="extype" href="function/Function2.html">Function2</a>[V, V, V]</span>)</span><span class="result">: <span name="java.util.Map" class="extype">Map</span>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Merge the values for each key using an associative reduce function, but return the results
immediately to the master as a Map.</p><div class="fullcomment"><div class="comment cmt"><p>Merge the values for each key using an associative reduce function, but return the results
immediately to the master as a Map. This will also perform the merging locally on each mapper
before sending results to a reducer, similarly to a &quot;combiner&quot; in MapReduce.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#rightOuterJoin" data-isabs="false">
      <a id="rightOuterJoin[W](JavaPairRDD[K, W],Int):JavaPairRDD[K, (Option[V], W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="numSplits">numSplits: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="scala.Option" class="extype">Option</span>[V], W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Perform a right outer join of <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Perform a right outer join of <code>this</code> and <code>other</code>. For each element (k, w) in <code>other</code>, the
resulting RDD will either contain all pairs (k, (Some(v), w)) for v in <code>this</code>, or the
pair (k, (None, w)) if no elements in <code>this</code> have key k. Hash-partitions the resulting
RDD into the given number of partitions.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#rightOuterJoin" data-isabs="false">
      <a id="rightOuterJoin[W](JavaPairRDD[K, W]):JavaPairRDD[K, (Option[V], W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="scala.Option" class="extype">Option</span>[V], W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Perform a right outer join of <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Perform a right outer join of <code>this</code> and <code>other</code>. For each element (k, w) in <code>other</code>, the
resulting RDD will either contain all pairs (k, (Some(v), w)) for v in <code>this</code>, or the
pair (k, (None, w)) if no elements in <code>this</code> have key k. Hash-partitions the resulting
RDD using the default parallelism level.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#rightOuterJoin" data-isabs="false">
      <a id="rightOuterJoin[W](JavaPairRDD[K, W],Partitioner):JavaPairRDD[K, (Option[V], W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, W]</span>, <span name="partitioner">partitioner: <a name="spark.Partitioner" class="extype" href="../../Partitioner.html">Partitioner</a></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, (<span name="scala.Option" class="extype">Option</span>[V], W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Perform a right outer join of <code>this</code> and <code>other</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Perform a right outer join of <code>this</code> and <code>other</code>. For each element (k, w) in <code>other</code>, the
resulting RDD will either contain all pairs (k, (Some(v), w)) for v in <code>this</code>, or the
pair (k, (None, w)) if no elements in <code>this</code> have key k. Uses the given Partitioner to
partition the output RDD.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#sample" data-isabs="false">
      <a id="sample(Boolean,Double,Int):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sample</span><span class="params">(<span name="withReplacement">withReplacement: <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="fraction">fraction: <span name="scala.Double" class="extype">Double</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a sampled subset of this RDD.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#saveAsHadoopDataset" data-isabs="false">
      <a id="saveAsHadoopDataset(JobConf):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopDataset</span><span class="params">(<span name="conf">conf: <span name="org.apache.hadoop.mapred.JobConf" class="extype">JobConf</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
that storage system.</p><div class="fullcomment"><div class="comment cmt"><p>Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
that storage system. The JobConf should set an OutputFormat and any output paths required
(e.g. a table name to write to) in the same way as it would be configured for a Hadoop
MapReduce job.
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#saveAsHadoopFile" data-isabs="false">
      <a id="saveAsHadoopFile[F&lt;:org.apache.hadoop.mapred.OutputFormat[_, _]](String,Class[_],Class[_],Class[F]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFile</span><span class="tparams">[<span name="F">F &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]</span>]</span><span class="params">(<span name="path">path: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[F]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Output the RDD to any Hadoop-supported file system.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#saveAsHadoopFile" data-isabs="false">
      <a id="saveAsHadoopFile[F&lt;:org.apache.hadoop.mapred.OutputFormat[_, _]](String,Class[_],Class[_],Class[F],JobConf):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFile</span><span class="tparams">[<span name="F">F &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]</span>]</span><span class="params">(<span name="path">path: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[F]</span>, <span name="conf">conf: <span name="org.apache.hadoop.mapred.JobConf" class="extype">JobConf</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Output the RDD to any Hadoop-supported file system.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#saveAsNewAPIHadoopFile" data-isabs="false">
      <a id="saveAsNewAPIHadoopFile[F&lt;:org.apache.hadoop.mapreduce.OutputFormat[_, _]](String,Class[_],Class[_],Class[F]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFile</span><span class="tparams">[<span name="F">F &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]</span>]</span><span class="params">(<span name="path">path: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[F]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Output the RDD to any Hadoop-supported file system.</p>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#saveAsNewAPIHadoopFile" data-isabs="false">
      <a id="saveAsNewAPIHadoopFile[F&lt;:org.apache.hadoop.mapreduce.OutputFormat[_, _]](String,Class[_],Class[_],Class[F],Configuration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFile</span><span class="tparams">[<span name="F">F &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]</span>]</span><span class="params">(<span name="path">path: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[F]</span>, <span name="conf">conf: <span name="org.apache.hadoop.conf.Configuration" class="extype">Configuration</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Output the RDD to any Hadoop-supported file system.</p>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#saveAsObjectFile" data-isabs="false">
      <a id="saveAsObjectFile(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsObjectFile</span><span class="params">(<span name="path">path: String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save this RDD as a SequenceFile of serialized objects.</p><div class="fullcomment"><div class="comment cmt"><p>Save this RDD as a SequenceFile of serialized objects.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#saveAsTextFile" data-isabs="false">
      <a id="saveAsTextFile(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTextFile</span><span class="params">(<span name="path">path: String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save this RDD as a text file, using string representations of elements.</p><div class="fullcomment"><div class="comment cmt"><p>Save this RDD as a text file, using string representations of elements.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#sortByKey" data-isabs="false">
      <a id="sortByKey(Comparator[K],Boolean):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sortByKey</span><span class="params">(<span name="comp">comp: <span name="java.util.Comparator" class="extype">Comparator</span>[K]</span>, <span name="ascending">ascending: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sort the RDD by key, so that each partition contains a sorted range of the elements.</p><div class="fullcomment"><div class="comment cmt"><p>Sort the RDD by key, so that each partition contains a sorted range of the elements. Calling
<code>collect</code> or <code>save</code> on the resulting RDD will return or output an ordered list of records
(in the <code>save</code> case, they will be written to multiple <code>part-X</code> files in the filesystem, in
order of the keys).
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#sortByKey" data-isabs="false">
      <a id="sortByKey(Comparator[K]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sortByKey</span><span class="params">(<span name="comp">comp: <span name="java.util.Comparator" class="extype">Comparator</span>[K]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sort the RDD by key, so that each partition contains a sorted range of the elements.</p><div class="fullcomment"><div class="comment cmt"><p>Sort the RDD by key, so that each partition contains a sorted range of the elements. Calling
<code>collect</code> or <code>save</code> on the resulting RDD will return or output an ordered list of records
(in the <code>save</code> case, they will be written to multiple <code>part-X</code> files in the filesystem, in
order of the keys).
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#sortByKey" data-isabs="false">
      <a id="sortByKey(Boolean):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sortByKey</span><span class="params">(<span name="ascending">ascending: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sort the RDD by key, so that each partition contains a sorted range of the elements.</p><div class="fullcomment"><div class="comment cmt"><p>Sort the RDD by key, so that each partition contains a sorted range of the elements. Calling
<code>collect</code> or <code>save</code> on the resulting RDD will return or output an ordered list of records
(in the <code>save</code> case, they will be written to multiple <code>part-X</code> files in the filesystem, in
order of the keys).
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#sortByKey" data-isabs="false">
      <a id="sortByKey():JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sortByKey</span><span class="params">()</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sort the RDD by key, so that each partition contains a sorted range of the elements in
ascending order.</p><div class="fullcomment"><div class="comment cmt"><p>Sort the RDD by key, so that each partition contains a sorted range of the elements in
ascending order. Calling <code>collect</code> or <code>save</code> on the resulting RDD will return or output an
ordered list of records (in the <code>save</code> case, they will be written to multiple <code>part-X</code> files
in the filesystem, in order of the keys).
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#splits" data-isabs="false">
      <a id="splits:List[Split]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">splits</span><span class="result">: <span name="java.util.List" class="extype">List</span>[<a name="spark.Split" class="extype" href="../../Split.html">Split</a>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Set of partitions in this RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Set of partitions in this RDD.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#synchronized" data-isabs="false">
      <a id="synchronized[T0](⇒ T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ T0</span>)</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#take" data-isabs="false">
      <a id="take(Int):List[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">take</span><span class="params">(<span name="num">num: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="java.util.List" class="extype">List</span>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Take the first num elements of the RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Take the first num elements of the RDD. This currently scans the partitions *one by one*, so
it will be slow if a lot of partitions are required. In that case, use collect() to get the
whole RDD instead.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaRDDLike#takeSample" data-isabs="false">
      <a id="takeSample(Boolean,Int,Int):List[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">takeSample</span><span class="params">(<span name="withReplacement">withReplacement: <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="num">num: <span name="scala.Int" class="extype">Int</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="java.util.List" class="extype">List</span>[(K, V)]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#toString" data-isabs="false">
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span name="java.lang.String" class="extype">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#union" data-isabs="false">
      <a id="union(JavaPairRDD[K, V]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="params">(<span name="other">other: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the union of this RDD and another one.</p><div class="fullcomment"><div class="comment cmt"><p>Return the union of this RDD and another one. Any identical elements will appear multiple
times (use <code>.distinct()</code> to eliminate them).
</p></div></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#vManifest" data-isabs="false">
      <a id="vManifest:ClassManifest[V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">implicit </span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">vManifest</span><span class="result">: ClassManifest[V]</span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="spark.api.java.JavaPairRDD#wrapRDD" data-isabs="false">
      <a id="wrapRDD(RDD[(K, V)]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wrapRDD</span><span class="params">(<span name="rdd">rdd: <a name="spark.RDD" class="extype" href="../../RDD.html">RDD</a>[(K, V)]</span>)</span><span class="result">: <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a> → <a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a></dd></dl></div>
    </li></ol>
            </div>

        
        </div>

        <div id="inheritedMembers">
        <div name="spark.api.java.JavaRDDLike" class="parent">
              <h3>Inherited from <a name="spark.api.java.JavaRDDLike" class="extype" href="JavaRDDLike.html">JavaRDDLike</a>[(K, V), <a name="spark.api.java.JavaPairRDD" class="extype" href="">JavaPairRDD</a>[K, V]]</h3>
            </div><div name="scala.Serializable" class="parent">
              <h3>Inherited from <span name="scala.Serializable" class="extype">Serializable</span></h3>
            </div><div name="java.io.Serializable" class="parent">
              <h3>Inherited from <span name="java.io.Serializable" class="extype">Serializable</span></h3>
            </div><div name="scala.AnyRef" class="parent">
              <h3>Inherited from AnyRef</h3>
            </div><div name="scala.Any" class="parent">
              <h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3>
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>