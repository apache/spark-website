<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>org.apache.spark.streaming.api.java.JavaPairDStream</title>
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link type="text/css" media="screen" rel="stylesheet" href="../../../../../../lib/template.css" />
      <script type="text/javascript" src="../../../../../../lib/jquery.js"></script>
      <script type="text/javascript" src="../../../../../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../../../../../lib/template.js"></script>
      <script type="text/javascript" src="../../../../../../lib/tools.tooltip.js"></script>
    
        </head>
        <body onload="sh_highlightDocument('../lib/', '.min.js');" class="type">
      <div id="definition">
        <a title="Go to companion" href="JavaPairDStream$.html"><img src="../../../../../../lib/class_to_object_big.png" /></a>
        <p id="owner"><a name="org" class="extype" href="../../../../../package.html">org</a>.<a name="org.apache" class="extype" href="../../../../package.html">apache</a>.<a name="org.apache.spark" class="extype" href="../../../package.html">spark</a>.<a name="org.apache.spark.streaming" class="extype" href="../../package.html">streaming</a>.<a name="org.apache.spark.streaming.api" class="extype" href="../package.html">api</a>.<a name="org.apache.spark.streaming.api.java" class="extype" href="package.html">java</a></p>
        <h1><a title="Go to companion" href="JavaPairDStream$.html">JavaPairDStream</a></h1>
      </div>

      <h4 class="signature" id="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">JavaPairDStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a>[(K, V), <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V], <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]]</span>
      </span>
      </h4>
      
      <div class="fullcommenttop" id="comment"><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a>[(K, V), <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V], <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]], <span name="scala.Serializable" class="extype">Serializable</span>, <span name="java.io.Serializable" class="extype">Serializable</span>, AnyRef, <span name="scala.Any" class="extype">Any</span></div>
        </div></div>
    

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input accesskey="/" type="text" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By inheritance</span></li></ol>
            </div>
        <div id="ancestors">
              <span class="filtertype">Inherited</span>
              <ol><li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li></ol>
              <ol id="linearization"><li name="org.apache.spark.streaming.api.java.JavaPairDStream" class="in"><span>JavaPairDStream</span></li><li name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="in"><span>JavaDStreamLike</span></li><li name="scala.Serializable" class="in"><span>Serializable</span></li><li name="java.io.Serializable" class="in"><span>Serializable</span></li><li name="scala.AnyRef" class="in"><span>AnyRef</span></li><li name="scala.Any" class="in"><span>Any</span></li></ol>
            </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div class="members" id="constructors">
              <h3>Instance Constructors</h3>
              <ol><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#this" data-isabs="false">
      <a id="this:JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaPairDStream</span><span class="params">(<span name="dstream">dstream: <a name="org.apache.spark.streaming.DStream" class="extype" href="../../DStream.html">DStream</a>[(K, V)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="kManifiest">kManifiest: ClassManifest[K]</span>, <span name="vManifest">vManifest: ClassManifest[V]</span>)</span>
      </span>
      </h4>
      
    </li></ol>
            </div>

        

        

        <div class="values members" id="values">
              <h3>Value Members</h3>
              <ol><li visbl="pub" name="scala.AnyRef#!=" data-isabs="false">
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#!=" data-isabs="false">
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef###" data-isabs="false">
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $hash$hash">##</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#==" data-isabs="false">
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#==" data-isabs="false">
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#asInstanceOf" data-isabs="false">
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#cache" data-isabs="false">
      <a id="cache():JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cache</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#checkpoint" data-isabs="false">
      <a id="checkpoint(Duration):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">checkpoint</span><span class="params">(<span name="interval">interval: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="../../DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Enable periodic checkpointing of RDDs of this DStream</p><div class="fullcomment"><div class="comment cmt"><p>Enable periodic checkpointing of RDDs of this DStream</p></div><dl class="paramcmts block"><dt class="param">interval</dt><dd class="cmt"><p>Time interval after which generated RDD will be checkpointed
</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#classManifest" data-isabs="false">
      <a id="classManifest:ClassManifest[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">classManifest</span><span class="result">: ClassManifest[(K, V)]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a> → <a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#clone" data-isabs="false">
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: AnyRef</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#cogroup" data-isabs="false">
      <a id="cogroup[W](JavaPairDStream[K, W],Partitioner):JavaPairDStream[K, (List[V], List[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, W]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Cogroup <code>this</code> DStream with <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Cogroup <code>this</code> DStream with <code>other</code> DStream. For each key k in corresponding RDDs of <code>this</code>
or <code>other</code> DStreams, the generated RDD will contains a tuple with the list of values for that
key in both RDDs. Partitioner is used to partition each generated RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#cogroup" data-isabs="false">
      <a id="cogroup[W](JavaPairDStream[K, W]):JavaPairDStream[K, (List[V], List[W])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, (<span name="java.util.List" class="extype">List</span>[V], <span name="java.util.List" class="extype">List</span>[W])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Cogroup <code>this</code> DStream with <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Cogroup <code>this</code> DStream with <code>other</code> DStream. For each key k in corresponding RDDs of <code>this</code>
or <code>other</code> DStreams, the generated RDD will contains a tuple with the list of values for that
key in both RDDs. HashPartitioner is used to partition each generated RDD into default number
of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#combineByKey" data-isabs="false">
      <a id="combineByKey[C](Function[V, C],Function2[C, V, C],Function2[C, C, C],Partitioner):JavaPairDStream[K, C]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[V, C]</span>, <span name="mergeValue">mergeValue: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[C, V, C]</span>, <span name="mergeCombiners">mergeCombiners: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[C, C, C]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, C]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Combine elements of each key in DStream's RDDs using custom function.</p><div class="fullcomment"><div class="comment cmt"><p>Combine elements of each key in DStream's RDDs using custom function. This is similar to the
combineByKey for RDDs. Please refer to combineByKey in PairRDDFunctions for more
information.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#compute" data-isabs="false">
      <a id="compute(Time):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">compute</span><span class="params">(<span name="validTime">validTime: <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a></span>)</span><span class="result">: <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Method that generates a RDD for the given Duration</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#context" data-isabs="false">
      <a id="context():StreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">context</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.StreamingContext" class="extype" href="../../StreamingContext.html">StreamingContext</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return the StreamingContext associated with this DStream</p><div class="fullcomment"><div class="comment cmt"><p>Return the StreamingContext associated with this DStream</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#count" data-isabs="false">
      <a id="count():JavaDStream[Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">count</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD has a single element generated by counting each RDD
of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD has a single element generated by counting each RDD
of this DStream.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#countByValue" data-isabs="false">
      <a id="countByValue(Int):JavaPairDStream[(K, V), Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValue</span><span class="params">(<span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[(K, V), <span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD contains the counts of each distinct value in
each RDD of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD contains the counts of each distinct value in
each RDD of this DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.</p></div><dl class="paramcmts block"><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream.
</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#countByValue" data-isabs="false">
      <a id="countByValue():JavaPairDStream[(K, V), Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValue</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[(K, V), <span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD contains the counts of each distinct value in
each RDD of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD contains the counts of each distinct value in
each RDD of this DStream.  Hash partitioning is used to generate the RDDs with
Spark's default number of partitions.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#countByValueAndWindow" data-isabs="false">
      <a id="countByValueAndWindow(Duration,Duration,Int):JavaPairDStream[(K, V), Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValueAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[(K, V), <span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD contains the count of distinct elements in
RDDs in a sliding window over this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD contains the count of distinct elements in
RDDs in a sliding window over this DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream.
</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#countByValueAndWindow" data-isabs="false">
      <a id="countByValueAndWindow(Duration,Duration):JavaPairDStream[(K, V), Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByValueAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[(K, V), <span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD contains the count of distinct elements in
RDDs in a sliding window over this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD contains the count of distinct elements in
RDDs in a sliding window over this DStream. Hash partitioning is used to generate the RDDs with
Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#countByWindow" data-isabs="false">
      <a id="countByWindow(Duration,Duration):JavaDStream[Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">countByWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD has a single element generated by counting the number
of elements in a window over this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD has a single element generated by counting the number
of elements in a window over this DStream. windowDuration and slideDuration are as defined in the
window() operation. This is equivalent to window(windowDuration, slideDuration).count()
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#dstream" data-isabs="false">
      <a id="dstream:DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">dstream</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="../../DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a> → <a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#eq" data-isabs="false">
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#equals" data-isabs="false">
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#filter" data-isabs="false">
      <a id="filter(Function[(K, V), Boolean]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filter</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[(K, V), <span name="java.lang.Boolean" class="extype">Boolean</span>]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream containing only the elements that satisfy a predicate.</p>
    </li><li visbl="prt" name="scala.AnyRef#finalize" data-isabs="false">
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#flatMap" data-isabs="false">
      <a id="flatMap[K2, V2](PairFlatMapFunction[(K, V), K2, V2]):JavaPairDStream[K2, V2]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="tparams">[<span name="K2">K2</span>, <span name="V2">V2</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.PairFlatMapFunction" class="extype">PairFlatMapFunction</span>[(K, V), K2, V2]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K2, V2]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a function to all elements of this DStream,
and then flattening the results
</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying a function to all elements of this DStream,
and then flattening the results
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#flatMap" data-isabs="false">
      <a id="flatMap[U](FlatMapFunction[(K, V), U]):JavaDStream[U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.FlatMapFunction" class="extype">FlatMapFunction</span>[(K, V), U]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a function to all elements of this DStream,
and then flattening the results
</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying a function to all elements of this DStream,
and then flattening the results
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#flatMapValues" data-isabs="false">
      <a id="flatMapValues[U](Function[V, Iterable[U]]):JavaPairDStream[K, U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[V, <span name="java.lang.Iterable" class="extype">Iterable</span>[U]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, U]</span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#foreach" data-isabs="false">
      <a id="foreach(Function2[JavaPairRDD[K, V], Time, Void]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreach</span><span class="params">(<span name="foreachFunc">foreachFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V], <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a>, <span name="java.lang.Void" class="extype">Void</span>]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Apply a function to each RDD in this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Apply a function to each RDD in this DStream. This is an output operator, so
this DStream will be registered as an output stream and therefore materialized.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#foreach" data-isabs="false">
      <a id="foreach(Function[JavaPairRDD[K, V], Void]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreach</span><span class="params">(<span name="foreachFunc">foreachFunc: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V], <span name="java.lang.Void" class="extype">Void</span>]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Apply a function to each RDD in this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Apply a function to each RDD in this DStream. This is an output operator, so
this DStream will be registered as an output stream and therefore materialized.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#getClass" data-isabs="false">
      <a id="getClass():java.lang.Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: java.lang.Class[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#glom" data-isabs="false">
      <a id="glom():JavaDStream[List[(K, V)]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">glom</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="java.util.List" class="extype">List</span>[(K, V)]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying glom() to each RDD of
this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying glom() to each RDD of
this DStream. Applying glom() to an RDD coalesces all elements within each partition into
an array.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKey" data-isabs="false">
      <a id="groupByKey(Partitioner):JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> on each RDD of <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> on each RDD of <code>this</code> DStream.
Therefore, the values for each key in <code>this</code> DStream's RDDs are grouped into a
single sequence to generate the RDDs of the new DStream. org.apache.spark.Partitioner
is used to control the partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKey" data-isabs="false">
      <a id="groupByKey(Int):JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKey" data-isabs="false">
      <a id="groupByKey():JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration,Duration,Partitioner):JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration,Duration,Int):JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>Number of partitions of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration,Duration):JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
<code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration):JavaPairDStream[K, List[V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, <span name="java.util.List" class="extype">List</span>[V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
<code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#hashCode" data-isabs="false">
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#isInstanceOf" data-isabs="false">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#join" data-isabs="false">
      <a id="join[W](JavaPairDStream[K, W],Partitioner):JavaPairDStream[K, (V, W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, W]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, (V, W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Join <code>this</code> DStream with <code>other</code> DStream, that is, each RDD of the new DStream will
be generated by joining RDDs from <code>this</code> and other DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Join <code>this</code> DStream with <code>other</code> DStream, that is, each RDD of the new DStream will
be generated by joining RDDs from <code>this</code> and other DStream. Uses the given
Partitioner to partition each generated RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#join" data-isabs="false">
      <a id="join[W](JavaPairDStream[K, W]):JavaPairDStream[K, (V, W)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, (V, W)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Join <code>this</code> DStream with <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Join <code>this</code> DStream with <code>other</code> DStream. HashPartitioner is used
to partition each generated RDD into default number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#kManifiest" data-isabs="false">
      <a id="kManifiest:ClassManifest[K]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">implicit </span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">kManifiest</span><span class="result">: ClassManifest[K]</span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#map" data-isabs="false">
      <a id="map[K2, V2](PairFunction[(K, V), K2, V2]):JavaPairDStream[K2, V2]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="K2">K2</span>, <span name="V2">V2</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.PairFunction" class="extype">PairFunction</span>[(K, V), K2, V2]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K2, V2]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a function to all elements of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying a function to all elements of this DStream.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#map" data-isabs="false">
      <a id="map[R](Function[(K, V), R]):JavaDStream[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[(K, V), R]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[R]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a function to all elements of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying a function to all elements of this DStream.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#mapPartitions" data-isabs="false">
      <a id="mapPartitions[K2, V2](PairFlatMapFunction[Iterator[(K, V)], K2, V2]):JavaPairDStream[K2, V2]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="tparams">[<span name="K2">K2</span>, <span name="V2">V2</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.PairFlatMapFunction" class="extype">PairFlatMapFunction</span>[<span name="java.util.Iterator" class="extype">Iterator</span>[(K, V)], K2, V2]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K2, V2]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
of this DStream. Applying mapPartitions() to an RDD applies a function to each partition
of the RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#mapPartitions" data-isabs="false">
      <a id="mapPartitions[U](FlatMapFunction[Iterator[(K, V)], U]):JavaDStream[U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.FlatMapFunction" class="extype">FlatMapFunction</span>[<span name="java.util.Iterator" class="extype">Iterator</span>[(K, V)], U]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
of this DStream. Applying mapPartitions() to an RDD applies a function to each partition
of the RDD.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#mapValues" data-isabs="false">
      <a id="mapValues[U](Function[V, U]):JavaPairDStream[K, U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[V, U]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, U]</span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="scala.AnyRef#ne" data-isabs="false">
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notify" data-isabs="false">
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notifyAll" data-isabs="false">
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#persist" data-isabs="false">
      <a id="persist(StorageLevel):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">(<span name="storageLevel">storageLevel: <span name="org.apache.spark.storage.StorageLevel" class="extype">StorageLevel</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Persist the RDDs of this DStream with the given storage level</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#persist" data-isabs="false">
      <a id="persist():JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</p>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#print" data-isabs="false">
      <a id="print():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">print</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Print the first ten elements of each RDD generated in this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Print the first ten elements of each RDD generated in this DStream. This is an output
operator, so this DStream will be registered as an output stream and there materialized.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#reduce" data-isabs="false">
      <a id="reduce(Function2[(K, V), (K, V), (K, V)]):JavaDStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduce</span><span class="params">(<span name="f">f: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[(K, V), (K, V), (K, V)]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD has a single element generated by reducing each RDD
of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD has a single element generated by reducing each RDD
of this DStream.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKey" data-isabs="false">
      <a id="reduceByKey(Function2[V, V, V],Partitioner):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="func">func: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[V, V, V]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. org.apache.spark.Partitioner is used to control the
partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKey" data-isabs="false">
      <a id="reduceByKey(Function2[V, V, V],Int):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="func">func: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[V, V, V]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKey" data-isabs="false">
      <a id="reduceByKey(Function2[V, V, V]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="func">func: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[V, V, V]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the associative reduce function. Hash partitioning is used to generate the RDDs
with Spark's default number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,(V, V) ⇒ V,Duration,Duration,Partitioner,Function[(K, V), Boolean]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="invReduceFunc">invReduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>, <span name="filterFunc">filterFunc: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[(K, V), <span name="java.lang.Boolean" class="extype">Boolean</span>]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduce value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)
This is more efficient that reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new DStream.</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained
                      set this to null if you do not want to filter
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,(V, V) ⇒ V,Duration,Duration,Int,Function[(K, V), Boolean]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="invReduceFunc">invReduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>, <span name="filterFunc">filterFunc: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[(K, V), <span name="java.lang.Boolean" class="extype">Boolean</span>]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduce value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)
This is more efficient that reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream.</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained
                      set this to null if you do not want to filter
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,(V, V) ⇒ V,Duration,Duration):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="invReduceFunc">invReduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by reducing over a using incremental computation.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by reducing over a using incremental computation.
The reduced value of over a new window is calculated using the old window's reduce value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)
This is more efficient that reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration,Duration,Partitioner):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
<code>DStream.reduceByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration,Duration,Int):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>Number of partitions of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration,Duration):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#reduceByWindow" data-isabs="false">
      <a id="reduceByWindow(Function2[(K, V), (K, V), (K, V)],Function2[(K, V), (K, V), (K, V)],Duration,Duration):JavaDStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[(K, V), (K, V), (K, V)]</span>, <span name="invReduceFunc">invReduceFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[(K, V), (K, V), (K, V)]</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD has a single element generated by reducing all
elements in a sliding window over this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD has a single element generated by reducing all
elements in a sliding window over this DStream. However, the reduction is done incrementally
using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)
 This is more efficient than reduceByWindow without &quot;inverse reduce&quot; function.
 However, it is applicable to only &quot;invertible reduce functions&quot;.</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#reduceByWindow" data-isabs="false">
      <a id="reduceByWindow(((K, V), (K, V)) ⇒ (K, V),Duration,Duration):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: ((K, V), (K, V)) ⇒ (K, V)</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="../../DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD has a single element generated by reducing all
elements in a sliding window over this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD has a single element generated by reducing all
elements in a sliding window over this DStream.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#saveAsHadoopFiles" data-isabs="false">
      <a id="saveAsHadoopFiles(String,String,Class[_],Class[_],Class[_ &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]],JobConf):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[_ &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]]</span>, <span name="conf">conf: <span name="org.apache.hadoop.mapred.JobConf" class="extype">JobConf</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#saveAsHadoopFiles" data-isabs="false">
      <a id="saveAsHadoopFiles(String,String,Class[_],Class[_],Class[_ &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[_ &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#saveAsHadoopFiles" data-isabs="false">
      <a id="saveAsHadoopFiles[F&lt;:OutputFormat[K, V]](String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span name="org.apache.hadoop.mapred.OutputFormat" class="extype">OutputFormat</span>[K, V]</span>]</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#saveAsNewAPIHadoopFiles" data-isabs="false">
      <a id="saveAsNewAPIHadoopFiles(String,String,Class[_],Class[_],Class[_ &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]],Configuration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[_ &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]]</span>, <span name="conf">conf: <span name="org.apache.hadoop.conf.Configuration" class="extype">Configuration</span> = <span class="symbol"><span class="name"><a href="../../../../../package.html">new Configuration</a></span></span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#saveAsNewAPIHadoopFiles" data-isabs="false">
      <a id="saveAsNewAPIHadoopFiles(String,String,Class[_],Class[_],Class[_ &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[_ &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#saveAsNewAPIHadoopFiles" data-isabs="false">
      <a id="saveAsNewAPIHadoopFiles[F&lt;:OutputFormat[K, V]](String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span name="org.apache.hadoop.mapreduce.OutputFormat" class="extype">OutputFormat</span>[K, V]</span>]</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#scalaIntToJavaLong" data-isabs="false">
      <a id="scalaIntToJavaLong(DStream[Long]):JavaDStream[Long]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">implicit </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">scalaIntToJavaLong</span><span class="params">(<span name="in">in: <a name="org.apache.spark.streaming.DStream" class="extype" href="../../DStream.html">DStream</a>[<span name="scala.Long" class="extype">Long</span>]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[<span name="java.lang.Long" class="extype">Long</span>]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#slice" data-isabs="false">
      <a id="slice(Time,Time):List[JavaPairRDD[K, V]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">slice</span><span class="params">(<span name="fromTime">fromTime: <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a></span>, <span name="toTime">toTime: <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a></span>)</span><span class="result">: <span name="java.util.List" class="extype">List</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return all the RDDs between 'fromDuration' to 'toDuration' (both included)
</p><div class="fullcomment"><div class="comment cmt"><p>Return all the RDDs between 'fromDuration' to 'toDuration' (both included)
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#synchronized" data-isabs="false">
      <a id="synchronized[T0](⇒ T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ T0</span>)</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#toString" data-isabs="false">
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span name="java.lang.String" class="extype">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#transform" data-isabs="false">
      <a id="transform[K2, V2](Function2[JavaPairRDD[K, V], Time, JavaPairRDD[K2, V2]]):JavaPairDStream[K2, V2]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="K2">K2</span>, <span name="V2">V2</span>]</span><span class="params">(<span name="transformFunc">transformFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V], <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a>, <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K2, V2]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K2, V2]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#transform" data-isabs="false">
      <a id="transform[K2, V2](Function[JavaPairRDD[K, V], JavaPairRDD[K2, V2]]):JavaPairDStream[K2, V2]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="K2">K2</span>, <span name="V2">V2</span>]</span><span class="params">(<span name="transformFunc">transformFunc: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V], <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K2, V2]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K2, V2]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#transform" data-isabs="false">
      <a id="transform[U](Function2[JavaPairRDD[K, V], Time, JavaRDD[U]]):JavaDStream[U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="transformFunc">transformFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V], <a name="org.apache.spark.streaming.Time" class="extype" href="../../Time.html">Time</a>, <span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[U]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaDStreamLike#transform" data-isabs="false">
      <a id="transform[U](Function[JavaPairRDD[K, V], JavaRDD[U]]):JavaDStream[U]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="transformFunc">transformFunc: <span name="org.apache.spark.api.java.function.Function" class="extype">Function</span>[<span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V], <span name="org.apache.spark.api.java.JavaRDD" class="extype">JavaRDD</span>[U]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaDStream" class="extype" href="JavaDStream.html">JavaDStream</a>[U]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream in which each RDD is generated by applying a function
on each RDD of this DStream.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#union" data-isabs="false">
      <a id="union(JavaPairDStream[K, V]):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="params">(<span name="that">that: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by unifying data of another DStream with this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by unifying data of another DStream with this DStream.</p></div><dl class="paramcmts block"><dt class="param">that</dt><dd class="cmt"><p>Another DStream having the same interval (i.e., slideDuration) as this DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S](Function2[List[V], Optional[S], Optional[S]],Partitioner)(ClassManifest[S]):JavaPairDStream[K, S]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="java.util.List" class="extype">List</span>[V], <span name="com.google.common.base.Optional" class="extype">Optional</span>[S], <span name="com.google.common.base.Optional" class="extype">Optional</span>[S]]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[S]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, S]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new DStream.</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S](Function2[List[V], Optional[S], Optional[S]],Int)(ClassManifest[S]):JavaPairDStream[K, S]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="java.util.List" class="extype">List</span>[V], <span name="com.google.common.base.Optional" class="extype">Optional</span>[S], <span name="com.google.common.base.Optional" class="extype">Optional</span>[S]]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[S]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, S]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>Number of partitions of each RDD in the new DStream.</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S](Function2[List[V], Optional[S], Optional[S]]):JavaPairDStream[K, S]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: <span name="org.apache.spark.api.java.function.Function2" class="extype">Function2</span>[<span name="java.util.List" class="extype">List</span>[V], <span name="com.google.common.base.Optional" class="extype">Optional</span>[S], <span name="com.google.common.base.Optional" class="extype">Optional</span>[S]]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, S]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#vManifest" data-isabs="false">
      <a id="vManifest:ClassManifest[V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">implicit </span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">vManifest</span><span class="result">: ClassManifest[V]</span>
      </span>
      </h4>
      
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#window" data-isabs="false">
      <a id="window(Duration,Duration):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">window</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream which is computed based on windowed batches of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream which is computed based on windowed batches of this DStream.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>duration (i.e., width) of the window;
                  must be a multiple of this DStream's interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                  the new DStream will generate RDDs); must be a multiple of this
                  DStream's interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#window" data-isabs="false">
      <a id="window(Duration):JavaPairDStream[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">window</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="../../Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream which is computed based on windowed batches of this DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream which is computed based on windowed batches of this DStream.
The new DStream generates RDDs with the same interval as this DStream.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's interval.
@return
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.api.java.JavaPairDStream#wrapRDD" data-isabs="false">
      <a id="wrapRDD(RDD[(K, V)]):JavaPairRDD[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wrapRDD</span><span class="params">(<span name="rdd">rdd: <span name="org.apache.spark.rdd.RDD" class="extype">RDD</span>[(K, V)]</span>)</span><span class="result">: <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a> → <a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a></dd></dl></div>
    </li></ol>
            </div>

        
        </div>

        <div id="inheritedMembers">
        <div name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="parent">
              <h3>Inherited from <a name="org.apache.spark.streaming.api.java.JavaDStreamLike" class="extype" href="JavaDStreamLike.html">JavaDStreamLike</a>[(K, V), <a name="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype" href="">JavaPairDStream</a>[K, V], <span name="org.apache.spark.api.java.JavaPairRDD" class="extype">JavaPairRDD</span>[K, V]]</h3>
            </div><div name="scala.Serializable" class="parent">
              <h3>Inherited from <span name="scala.Serializable" class="extype">Serializable</span></h3>
            </div><div name="java.io.Serializable" class="parent">
              <h3>Inherited from <span name="java.io.Serializable" class="extype">Serializable</span></h3>
            </div><div name="scala.AnyRef" class="parent">
              <h3>Inherited from AnyRef</h3>
            </div><div name="scala.Any" class="parent">
              <h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3>
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>