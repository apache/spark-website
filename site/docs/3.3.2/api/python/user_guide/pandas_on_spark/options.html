
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>Options and settings &#8212; PySpark 3.3.2 documentation</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/options.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="From/to pandas and PySpark DataFrames" href="pandas_pyspark.html" />
    <link rel="prev" title="Pandas API on Spark" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    <!-- Matomo -->
    <script type="text/javascript">
        var _paq = window._paq = window._paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(["disableCookies"]);
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
            var u="https://analytics.apache.org/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '40']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
        })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../index.html">
    
      <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">User Guide</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../reference/index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../development/index.html">Development</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../migration_guide/index.html">Migration Guide</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
          
            
                <li class="">
                    <a href="../python_packaging.html">Python Package Management</a>
                </li>
            
          
            
                <li class="">
                    <a href="../sql/index.html">Spark SQL</a>
                </li>
            
          
            
  
                <li class="active">
                    <a href="index.html">Pandas API on Spark</a>
                    <ul>
                    
                        <li class="active">
                            <a href="">Options and settings</a>
                        </li>
                    
                        <li class="">
                            <a href="pandas_pyspark.html">From/to pandas and PySpark DataFrames</a>
                        </li>
                    
                        <li class="">
                            <a href="transform_apply.html">Transform and apply a function</a>
                        </li>
                    
                        <li class="">
                            <a href="types.html">Type Support in Pandas API on Spark</a>
                        </li>
                    
                        <li class="">
                            <a href="typehints.html">Type Hints in Pandas API on Spark</a>
                        </li>
                    
                        <li class="">
                            <a href="from_to_dbms.html">From/to other DBMSes</a>
                        </li>
                    
                        <li class="">
                            <a href="best_practices.html">Best Practices</a>
                        </li>
                    
                        <li class="">
                            <a href="supported_pandas_api.html">Supported pandas API</a>
                        </li>
                    
                        <li class="">
                            <a href="faq.html">FAQ</a>
                        </li>
                    
                    </ul>
                </li>
            
          
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#getting-and-setting-options" class="nav-link">Getting and setting options</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#operations-on-different-dataframes" class="nav-link">Operations on different DataFrames</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#default-index-type" class="nav-link">Default Index type</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#available-options" class="nav-link">Available options</a>
        </li>
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="options-and-settings">
<h1>Options and settings<a class="headerlink" href="#options-and-settings" title="Permalink to this headline">¶</a></h1>
<p>Pandas API on Spark has an options system that lets you customize some aspects of its behaviour,
display-related options being those the user is most likely to adjust.</p>
<p>Options have a full “dotted-style”, case-insensitive name (e.g. <code class="docutils literal notranslate"><span class="pre">display.max_rows</span></code>).
You can get/set options directly as attributes of the top-level <code class="docutils literal notranslate"><span class="pre">options</span></code> attribute:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span>
<span class="go">10</span>
</pre></div>
</div>
<p>The API is composed of 3 relevant functions, available directly from the <code class="docutils literal notranslate"><span class="pre">pandas_on_spark</span></code>
namespace:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.get_option.html#pyspark.pandas.get_option" title="pyspark.pandas.get_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_option()</span></code></a> / <a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.set_option.html#pyspark.pandas.set_option" title="pyspark.pandas.set_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_option()</span></code></a> - get/set the value of a single option.</p></li>
<li><p><a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.reset_option.html#pyspark.pandas.reset_option" title="pyspark.pandas.reset_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">reset_option()</span></code></a> - reset one or more options to their default value.</p></li>
</ul>
<p><strong>Note:</strong> Developers can check out <a class="reference external" href="https://github.com/apache/spark/blob/master/python/pyspark/pandas/config.py">pyspark.pandas/config.py</a> for more information.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">101</span>
</pre></div>
</div>
<div class="section" id="getting-and-setting-options">
<h2>Getting and setting options<a class="headerlink" href="#getting-and-setting-options" title="Permalink to this headline">¶</a></h2>
<p>As described above, <a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.get_option.html#pyspark.pandas.get_option" title="pyspark.pandas.get_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_option()</span></code></a> and <a class="reference internal" href="../../reference/pyspark.pandas/api/pyspark.pandas.set_option.html#pyspark.pandas.set_option" title="pyspark.pandas.set_option"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_option()</span></code></a>
are available from the <code class="docutils literal notranslate"><span class="pre">pandas_on_spark</span></code> namespace.  To change an option, call
<code class="docutils literal notranslate"><span class="pre">set_option('option</span> <span class="pre">name',</span> <span class="pre">new_value)</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s1">&#39;compute.max_rows&#39;</span><span class="p">)</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.max_rows&#39;</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s1">&#39;compute.max_rows&#39;</span><span class="p">)</span>
<span class="go">2000</span>
</pre></div>
</div>
<p>All options also have a default value, and you can use <code class="docutils literal notranslate"><span class="pre">reset_option</span></code> to do just that:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">999</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">999</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">)</span>
<span class="go">1000</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">option_context</span></code> context manager has been exposed through
the top-level API, allowing you to execute code with given option values. Option values
are restored automatically when you exit the <cite>with</cite> block:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">ps</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;compute.max_rows&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">))</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;compute.max_rows&quot;</span><span class="p">))</span>
<span class="go">10</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;display.max_rows&quot;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ps</span><span class="o">.</span><span class="n">get_option</span><span class="p">(</span><span class="s2">&quot;compute.max_rows&quot;</span><span class="p">))</span>
<span class="go">1000</span>
<span class="go">1000</span>
</pre></div>
</div>
</div>
<div class="section" id="operations-on-different-dataframes">
<h2>Operations on different DataFrames<a class="headerlink" href="#operations-on-different-dataframes" title="Permalink to this headline">¶</a></h2>
<p>Pandas API on Spark disallows the operations on different DataFrames (or Series) by default to prevent expensive
operations. It internally performs a join operation which can be expensive in general.</p>
<p>This can be enabled by setting <cite>compute.ops_on_diff_frames</cite> to <cite>True</cite> to allow such cases.
See the examples below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf1</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf2</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">psdf1</span> <span class="o">-</span> <span class="n">psdf2</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="go">    id</span>
<span class="go">0 -5.0</span>
<span class="go">1 -3.0</span>
<span class="go">2 -1.0</span>
<span class="go">3  NaN</span>
<span class="go">4  NaN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psser_a</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># &#39;psser_a&#39; is not from &#39;psdf&#39; DataFrame. So it is considered as a Series not from &#39;psdf&#39;.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;new_col&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psser_a</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span>
<span class="go">   id  new_col</span>
<span class="go">0   0      1.0</span>
<span class="go">1   1      2.0</span>
<span class="go">3   3      4.0</span>
<span class="go">2   2      3.0</span>
<span class="go">4   4      NaN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.ops_on_diff_frames&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="default-index-type">
<h2>Default Index type<a class="headerlink" href="#default-index-type" title="Permalink to this headline">¶</a></h2>
<p>In pandas API on Spark, the default index is used in several cases, for instance,
when Spark DataFrame is converted into pandas-on-Spark DataFrame. In this case, internally pandas API on Spark attaches a
default index into pandas-on-Spark DataFrame.</p>
<p>There are several types of the default index that can be configured by <cite>compute.default_index_type</cite> as below:</p>
<p><strong>sequence</strong>: It implements a sequence that increases one by one, by PySpark’s Window function without
specifying partition. Therefore, it can end up with whole partition in single node.
This index type should be avoided when the data is large. See the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;sequence&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="o">.</span><span class="n">index</span>
<span class="go">Int64Index([0, 1, 2], dtype=&#39;int64&#39;)</span>
</pre></div>
</div>
<p>This is conceptually equivalent to the PySpark example as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">Window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sequential_index</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">row_number</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span>
<span class="gp">... </span>   <span class="n">Window</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">monotonically_increasing_id</span><span class="p">()</span><span class="o">.</span><span class="n">asc</span><span class="p">()))</span> <span class="o">-</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">sequential_index</span><span class="p">)</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[0, 1, 2]</span>
</pre></div>
</div>
<p><strong>distributed-sequence</strong> (default): It implements a sequence that increases one by one, by group-by and
group-map approach in a distributed manner. It still generates the sequential index globally.
If the default index must be the sequence in a large dataset, this
index has to be used. See the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;distributed-sequence&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="o">.</span><span class="n">index</span>
<span class="go">Int64Index([0, 1, 2], dtype=&#39;int64&#39;)</span>
</pre></div>
</div>
<p>This is conceptually equivalent to the PySpark example as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="p">()</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[0, 1, 2]</span>
</pre></div>
</div>
<p><strong>distributed</strong>: It implements a monotonically increasing sequence simply by using
PySpark’s <cite>monotonically_increasing_id</cite> function in a fully distributed manner. The
values are indeterministic. If the index does not have to be a sequence that increases
one by one, this index should be used. Performance-wise, this index almost does not
have any penalty comparing to other index types. See the example below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">,</span> <span class="s1">&#39;distributed&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">reset_option</span><span class="p">(</span><span class="s1">&#39;compute.default_index_type&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">psdf</span><span class="o">.</span><span class="n">index</span>
<span class="go">Int64Index([25769803776, 60129542144, 94489280512], dtype=&#39;int64&#39;)</span>
</pre></div>
</div>
<p>This is conceptually equivalent to the PySpark example as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pyspark.pandas</span> <span class="k">as</span> <span class="nn">ps</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spark_df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">monotonically_increasing_id</span><span class="p">())</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="go">[25769803776, 60129542144, 94489280512]</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is very unlikely for this type of index to be used for computing two
different dataframes because it is not guaranteed to have the same indexes in two dataframes.
If you use this default index and turn on <cite>compute.ops_on_diff_frames</cite>, the result
from the operations between two different DataFrames will likely be an unexpected
output due to the indeterministic index values.</p>
</div>
</div>
<div class="section" id="available-options">
<h2>Available options<a class="headerlink" href="#available-options" title="Permalink to this headline">¶</a></h2>
<table class="table">
<colgroup>
<col style="width: 29%" />
<col style="width: 21%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Option</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>display.max_rows</p></td>
<td><p>1000</p></td>
<td><p>This sets the maximum number of rows pandas-on-Spark
should output when printing out various output. For
example, this value determines the number of rows to
be shown at the repr() in a dataframe. Set <cite>None</cite> to
unlimit the input length. Default is 1000.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.max_rows</p></td>
<td><p>1000</p></td>
<td><p>‘compute.max_rows’ sets the limit of the current
pandas-on-Spark DataFrame. Set <cite>None</cite> to unlimit the
input length. When the limit is set, it is executed
by the shortcut by collecting the data into the
driver, and then using the pandas API. If the limit
is unset, the operation is executed by PySpark.
Default is 1000.</p></td>
</tr>
<tr class="row-even"><td><p>compute.shortcut_limit</p></td>
<td><p>1000</p></td>
<td><p>‘compute.shortcut_limit’ sets the limit for a
shortcut. It computes specified number of rows and
use its schema. When the dataframe length is larger
than this limit, pandas-on-Spark uses PySpark to
compute.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.ops_on_diff_frames</p></td>
<td><p>False</p></td>
<td><p>This determines whether or not to operate between two
different dataframes. For example, ‘combine_frames’
function internally performs a join operation which
can be expensive in general. So, if
<cite>compute.ops_on_diff_frames</cite> variable is not True,
that method throws an exception.</p></td>
</tr>
<tr class="row-even"><td><p>compute.default_index_type</p></td>
<td><p>‘distributed-sequence’</p></td>
<td><p>This sets the default index type: sequence,
distributed and distributed-sequence.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.ordered_head</p></td>
<td><p>False</p></td>
<td><p>‘compute.ordered_head’ sets whether or not to operate
head with natural ordering. pandas-on-Spark does not
guarantee the row ordering so <cite>head</cite> could return
some rows from distributed partitions. If
‘compute.ordered_head’ is set to True, pandas-on-
Spark performs natural ordering beforehand, but it
will cause a performance overhead.</p></td>
</tr>
<tr class="row-even"><td><p>compute.eager_check</p></td>
<td><p>True</p></td>
<td><p>‘compute.eager_check’ sets whether or not to launch
some Spark jobs just for the sake of validation. If
‘compute.eager_check’ is set to True, pandas-on-Spark
performs the validation beforehand, but it will cause
a performance overhead. Otherwise, pandas-on-Spark
skip the validation and will be slightly different
from pandas. Affected APIs: <cite>Series.dot</cite>,
<cite>Series.asof</cite>, <cite>Series.compare</cite>,
<cite>FractionalExtensionOps.astype</cite>,
<cite>IntegralExtensionOps.astype</cite>,
<cite>FractionalOps.astype</cite>, <cite>DecimalOps.astype</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p>compute.isin_limit</p></td>
<td><p>80</p></td>
<td><p>‘compute.isin_limit’ sets the limit for filtering by
‘Column.isin(list)’. If the length of the ‘list’ is
above the limit, broadcast join is used instead for
better performance.</p></td>
</tr>
<tr class="row-even"><td><p>plotting.max_rows</p></td>
<td><p>1000</p></td>
<td><p>‘plotting.max_rows’ sets the visual limit on top-n-
based plots such as <cite>plot.bar</cite> and <cite>plot.pie</cite>. If it
is set to 1000, the first 1000 data points will be
used for plotting. Default is 1000.</p></td>
</tr>
<tr class="row-odd"><td><p>plotting.sample_ratio</p></td>
<td><p>None</p></td>
<td><p>‘plotting.sample_ratio’ sets the proportion of data
that will be plotted for sample-based plots such as
<cite>plot.line</cite> and <cite>plot.area</cite>. This option defaults to
‘plotting.max_rows’ option.</p></td>
</tr>
<tr class="row-even"><td><p>plotting.backend</p></td>
<td><p>‘plotly’</p></td>
<td><p>Backend to use for plotting. Default is plotly.
Supports any package that has a top-level <cite>.plot</cite>
method. Known options are: [matplotlib, plotly].</p></td>
</tr>
</tbody>
</table>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Pandas API on Spark</a>
    <a class='right-next' id="next-link" href="pandas_pyspark.html" title="next page">From/to pandas and PySpark DataFrames</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright .<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>