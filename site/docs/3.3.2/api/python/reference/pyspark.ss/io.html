
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>Input/Output &#8212; PySpark 3.3.2 documentation</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.ss/io.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="pyspark.sql.streaming.DataStreamReader.csv" href="api/pyspark.sql.streaming.DataStreamReader.csv.html" />
    <link rel="prev" title="pyspark.sql.streaming.StreamingQueryManager" href="api/pyspark.sql.streaming.StreamingQueryManager.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../index.html">
    
      <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../user_guide/index.html">User Guide</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../development/index.html">Development</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../migration_guide/index.html">Migration Guide</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="../pyspark.sql/index.html">Spark SQL</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.pandas/index.html">Pandas API on Spark</a>
                </li>
            
          
            
  
                <li class="active">
                    <a href="index.html">Structured Streaming</a>
                    <ul>
                    
                        <li class="">
                            <a href="core_classes.html">Core Classes</a>
                        </li>
                    
                        <li class="active">
                            <a href="">Input/Output</a>
                        </li>
                    
                        <li class="">
                            <a href="query_management.html">Query Management</a>
                        </li>
                    
                    </ul>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.ml.html">MLlib (DataFrame-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.streaming.html">Spark Streaming</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.mllib.html">MLlib (RDD-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.html">Spark Core</a>
                </li>
            
          
            
                <li class="">
                    <a href="../pyspark.resource.html">Resource Management</a>
                </li>
            
          
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="input-output">
<h1>Input/Output<a class="headerlink" href="#input-output" title="Permalink to this headline">¶</a></h1>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.csv.html#pyspark.sql.streaming.DataStreamReader.csv" title="pyspark.sql.streaming.DataStreamReader.csv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.csv</span></code></a>(path[, schema, sep, …])</p></td>
<td><p>Loads a CSV file stream and returns the result as a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.format.html#pyspark.sql.streaming.DataStreamReader.format" title="pyspark.sql.streaming.DataStreamReader.format"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.format</span></code></a>(source)</p></td>
<td><p>Specifies the input data source format.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.json.html#pyspark.sql.streaming.DataStreamReader.json" title="pyspark.sql.streaming.DataStreamReader.json"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.json</span></code></a>(path[, schema, …])</p></td>
<td><p>Loads a JSON file stream and returns the results as a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.load.html#pyspark.sql.streaming.DataStreamReader.load" title="pyspark.sql.streaming.DataStreamReader.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.load</span></code></a>([path, format, schema])</p></td>
<td><p>Loads a data stream from a data source and returns it as a <a class="reference internal" href="../pyspark.sql/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame" title="pyspark.sql.DataFrame"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.option.html#pyspark.sql.streaming.DataStreamReader.option" title="pyspark.sql.streaming.DataStreamReader.option"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.option</span></code></a>(key, value)</p></td>
<td><p>Adds an input option for the underlying data source.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.options.html#pyspark.sql.streaming.DataStreamReader.options" title="pyspark.sql.streaming.DataStreamReader.options"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.options</span></code></a>(**options)</p></td>
<td><p>Adds input options for the underlying data source.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.orc.html#pyspark.sql.streaming.DataStreamReader.orc" title="pyspark.sql.streaming.DataStreamReader.orc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.orc</span></code></a>(path[, mergeSchema, …])</p></td>
<td><p>Loads a ORC file stream, returning the result as a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.parquet.html#pyspark.sql.streaming.DataStreamReader.parquet" title="pyspark.sql.streaming.DataStreamReader.parquet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.parquet</span></code></a>(path[, …])</p></td>
<td><p>Loads a Parquet file stream, returning the result as a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.schema.html#pyspark.sql.streaming.DataStreamReader.schema" title="pyspark.sql.streaming.DataStreamReader.schema"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.schema</span></code></a>(schema)</p></td>
<td><p>Specifies the input schema.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.table.html#pyspark.sql.streaming.DataStreamReader.table" title="pyspark.sql.streaming.DataStreamReader.table"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.table</span></code></a>(tableName)</p></td>
<td><p>Define a Streaming DataFrame on a Table.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamReader.text.html#pyspark.sql.streaming.DataStreamReader.text" title="pyspark.sql.streaming.DataStreamReader.text"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamReader.text</span></code></a>(path[, wholetext, …])</p></td>
<td><p>Loads a text file stream and returns a <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code> whose schema starts with a string column named “value”, and followed by partitioned columns if there are any.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.foreach.html#pyspark.sql.streaming.DataStreamWriter.foreach" title="pyspark.sql.streaming.DataStreamWriter.foreach"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.foreach</span></code></a>(f)</p></td>
<td><p>Sets the output of the streaming query to be processed using the provided writer <code class="docutils literal notranslate"><span class="pre">f</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.foreachBatch.html#pyspark.sql.streaming.DataStreamWriter.foreachBatch" title="pyspark.sql.streaming.DataStreamWriter.foreachBatch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.foreachBatch</span></code></a>(func)</p></td>
<td><p>Sets the output of the streaming query to be processed using the provided function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.format.html#pyspark.sql.streaming.DataStreamWriter.format" title="pyspark.sql.streaming.DataStreamWriter.format"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.format</span></code></a>(source)</p></td>
<td><p>Specifies the underlying output data source.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.option.html#pyspark.sql.streaming.DataStreamWriter.option" title="pyspark.sql.streaming.DataStreamWriter.option"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.option</span></code></a>(key, value)</p></td>
<td><p>Adds an output option for the underlying data source.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.options.html#pyspark.sql.streaming.DataStreamWriter.options" title="pyspark.sql.streaming.DataStreamWriter.options"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.options</span></code></a>(**options)</p></td>
<td><p>Adds output options for the underlying data source.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.outputMode.html#pyspark.sql.streaming.DataStreamWriter.outputMode" title="pyspark.sql.streaming.DataStreamWriter.outputMode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.outputMode</span></code></a>(outputMode)</p></td>
<td><p>Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.partitionBy.html#pyspark.sql.streaming.DataStreamWriter.partitionBy" title="pyspark.sql.streaming.DataStreamWriter.partitionBy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.partitionBy</span></code></a>(*cols)</p></td>
<td><p>Partitions the output by the given columns on the file system.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.queryName.html#pyspark.sql.streaming.DataStreamWriter.queryName" title="pyspark.sql.streaming.DataStreamWriter.queryName"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.queryName</span></code></a>(queryName)</p></td>
<td><p>Specifies the name of the <a class="reference internal" href="api/pyspark.sql.streaming.StreamingQuery.html#pyspark.sql.streaming.StreamingQuery" title="pyspark.sql.streaming.StreamingQuery"><code class="xref py py-class docutils literal notranslate"><span class="pre">StreamingQuery</span></code></a> that can be started with <code class="xref py py-func docutils literal notranslate"><span class="pre">start()</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.start.html#pyspark.sql.streaming.DataStreamWriter.start" title="pyspark.sql.streaming.DataStreamWriter.start"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.start</span></code></a>([path, format, …])</p></td>
<td><p>Streams the contents of the <code class="xref py py-class docutils literal notranslate"><span class="pre">DataFrame</span></code> to a data source.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.toTable.html#pyspark.sql.streaming.DataStreamWriter.toTable" title="pyspark.sql.streaming.DataStreamWriter.toTable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.toTable</span></code></a>(tableName[, …])</p></td>
<td><p>Starts the execution of the streaming query, which will continually output results to the given table as new data arrives.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="api/pyspark.sql.streaming.DataStreamWriter.trigger.html#pyspark.sql.streaming.DataStreamWriter.trigger" title="pyspark.sql.streaming.DataStreamWriter.trigger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataStreamWriter.trigger</span></code></a>(*[, …])</p></td>
<td><p>Set the trigger for the stream query.</p></td>
</tr>
</tbody>
</table>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="api/pyspark.sql.streaming.StreamingQueryManager.html" title="previous page">pyspark.sql.streaming.StreamingQueryManager</a>
    <a class='right-next' id="next-link" href="api/pyspark.sql.streaming.DataStreamReader.csv.html" title="next page">pyspark.sql.streaming.DataStreamReader.csv</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright .<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>