<!DOCTYPE html >
<html>
        <head>
          <meta http-equiv="X-UA-Compatible" content="IE=edge" />
          <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
          <title>Spark 3.1.3 ScalaDoc  - org.apache.spark.sql</title>
          <meta name="description" content="Spark 3.1.3 ScalaDoc - org.apache.spark.sql" />
          <meta name="keywords" content="Spark 3.1.3 ScalaDoc org.apache.spark.sql" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      
      <link href="../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../../../lib/jquery.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.panzoom.min.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery.mousewheel.min.js"></script>
      <script type="text/javascript" src="../../../../lib/index.js"></script>
      <script type="text/javascript" src="../../../../index.js"></script>
      <script type="text/javascript" src="../../../../lib/scheduler.js"></script>
      <script type="text/javascript" src="../../../../lib/template.js"></script>
      
      <script type="text/javascript">
        /* this variable can be used by the JS to determine the path to the root document */
        var toRoot = '../../../../';
      </script>
    
    <!-- Matomo -->
    <script type="text/javascript">
        var _paq = window._paq = window._paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(["disableCookies"]);
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
            var u="https://analytics.apache.org/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '40']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
        })();
    </script>
    <!-- End Matomo Code -->
        </head>
        <body>
      <div id="search">
        <span id="doc-title">Spark 3.1.3 ScalaDoc<span id="doc-version"></span></span>
        <span class="close-results"><span class="left">&lt;</span> Back</span>
        <div id="textfilter">
          <span class="input">
            <input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/" />
            <i class="clear material-icons"></i>
            <i id="search-icon" class="material-icons"></i>
          </span>
        </div>
    </div>
      <div id="search-results">
        <div id="search-progress">
          <div id="progress-fill"></div>
        </div>
        <div id="results-content">
          <div id="entity-results"></div>
          <div id="member-results"></div>
        </div>
      </div>
      <div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;">
        <div id="content-container" style="-webkit-overflow-scrolling: touch;">
          <div id="subpackage-spacer">
            <div id="packages">
              <h1>Packages</h1>
              <ul>
                <li name="_root_.root" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="_root_"></a><a id="root:_root_"></a>
      <span class="permalink">
      <a href="../../../../index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../../index.html"><span class="name">root</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="_root_.org" visbl="pub" class="indented1 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="org"></a><a id="org:org"></a>
      <span class="permalink">
      <a href="../../../../org/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../index.html"><span class="name">org</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="org.apache" visbl="pub" class="indented2 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="apache"></a><a id="apache:apache"></a>
      <span class="permalink">
      <a href="../../../../org/apache/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../index.html"><span class="name">apache</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../index.html" class="extype" name="org">org</a></dd></dl></div>
    </li><li name="org.apache.spark" visbl="pub" class="indented3 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="spark"></a><a id="spark:spark"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Core Spark functionality." href="../index.html"><span class="name">spark</span></a>
      </span>
      
      <p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../SparkContext.html" class="extype" name="org.apache.spark.SparkContext">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../rdd/PairRDDFunctions.html" class="extype" name="org.apache.spark.rdd.PairRDDFunctions">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../rdd/DoubleRDDFunctions.html" class="extype" name="org.apache.spark.rdd.DoubleRDDFunctions">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../rdd/SequenceFileRDDFunctions.html" class="extype" name="org.apache.spark.rdd.SequenceFileRDDFunctions">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../api/java/index.html" class="extype" name="org.apache.spark.api.java">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../index.html" class="extype" name="org.apache">apache</a></dd></dl></div>
    </li><li name="org.apache.spark.api" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="api"></a><a id="api:api"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/api/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../api/index.html"><span class="name">api</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.broadcast" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="broadcast"></a><a id="broadcast:broadcast"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/broadcast/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Spark's broadcast variables, used to broadcast immutable datasets to all nodes." href="../broadcast/index.html"><span class="name">broadcast</span></a>
      </span>
      
      <p class="shortcomment cmt">Spark's broadcast variables, used to broadcast immutable datasets to all nodes.</p><div class="fullcomment"><div class="comment cmt"><p>Spark's broadcast variables, used to broadcast immutable datasets to all nodes.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.graphx" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="graphx"></a><a id="graphx:graphx"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/graphx/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="ALPHA COMPONENT GraphX is a graph processing framework built on top of Spark." href="../graphx/index.html"><span class="name">graphx</span></a>
      </span>
      
      <p class="shortcomment cmt"><span class="badge" style="float: right;">ALPHA COMPONENT</span>
GraphX is a graph processing framework built on top of Spark.</p><div class="fullcomment"><div class="comment cmt"><p><span class="badge" style="float: right;">ALPHA COMPONENT</span>
GraphX is a graph processing framework built on top of Spark.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.input" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="input"></a><a id="input:input"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/input/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../input/index.html"><span class="name">input</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.io" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="io"></a><a id="io:io"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/io/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="IO codecs used for compression." href="../io/index.html"><span class="name">io</span></a>
      </span>
      
      <p class="shortcomment cmt">IO codecs used for compression.</p><div class="fullcomment"><div class="comment cmt"><p>IO codecs used for compression. See <a href="../io/CompressionCodec.html" class="extype" name="org.apache.spark.io.CompressionCodec">org.apache.spark.io.CompressionCodec</a>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.launcher" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="launcher"></a><a id="launcher:launcher"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/launcher/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../launcher/index.html"><span class="name">launcher</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.mapred" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="mapred"></a><a id="mapred:mapred"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/mapred/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../mapred/index.html"><span class="name">mapred</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.metrics" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="metrics"></a><a id="metrics:metrics"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/metrics/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../metrics/index.html"><span class="name">metrics</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.ml" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ml"></a><a id="ml:ml"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/ml/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="DataFrame-based machine learning APIs to let users quickly assemble and configure practical machine learning pipelines." href="../ml/index.html"><span class="name">ml</span></a>
      </span>
      
      <p class="shortcomment cmt">DataFrame-based machine learning APIs to let users quickly assemble and configure practical
machine learning pipelines.</p><div class="fullcomment"><div class="comment cmt"><p>DataFrame-based machine learning APIs to let users quickly assemble and configure practical
machine learning pipelines.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.mllib" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="mllib"></a><a id="mllib:mllib"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/mllib/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="RDD-based machine learning APIs (in maintenance mode)." href="../mllib/index.html"><span class="name">mllib</span></a>
      </span>
      
      <p class="shortcomment cmt">RDD-based machine learning APIs (in maintenance mode).</p><div class="fullcomment"><div class="comment cmt"><p>RDD-based machine learning APIs (in maintenance mode).</p><p>The <code>spark.mllib</code> package is in maintenance mode as of the Spark 2.0.0 release to encourage
migration to the DataFrame-based APIs under the <a href="../ml/index.html" class="extype" name="org.apache.spark.ml">org.apache.spark.ml</a> package.
While in maintenance mode,</p><ul><li>no new features in the RDD-based <code>spark.mllib</code> package will be accepted, unless they block
   implementing new features in the DataFrame-based <code>spark.ml</code> package;</li><li>bug fixes in the RDD-based APIs will still be accepted.</li></ul><p>The developers will continue adding more features to the DataFrame-based APIs in the 2.x series
to reach feature parity with the RDD-based APIs.
And once we reach feature parity, this package will be deprecated.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd><dt>See also</dt><dd><span class="cmt"><p><a href="https://issues.apache.org/jira/browse/SPARK-4591">SPARK-4591</a> to track
the progress of feature parity</p></span></dd></dl></div>
    </li><li name="org.apache.spark.partial" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="partial"></a><a id="partial:partial"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/partial/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Support for approximate results." href="../partial/index.html"><span class="name">partial</span></a>
      </span>
      
      <p class="shortcomment cmt">Support for approximate results.</p><div class="fullcomment"><div class="comment cmt"><p>Support for approximate results. This provides convenient api and also implementation for
approximate calculation.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd><dt>See also</dt><dd><span class="cmt"><p><a href="../rdd/RDD.html#countApprox(timeout:Long,confidence:Double):org.apache.spark.partial.PartialResult[org.apache.spark.partial.BoundedDouble]" class="extmbr" name="org.apache.spark.rdd.RDD#countApprox">org.apache.spark.rdd.RDD.countApprox</a></p></span></dd></dl></div>
    </li><li name="org.apache.spark.rdd" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="rdd"></a><a id="rdd:rdd"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/rdd/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Provides several RDD implementations." href="../rdd/index.html"><span class="name">rdd</span></a>
      </span>
      
      <p class="shortcomment cmt">Provides several RDD implementations.</p><div class="fullcomment"><div class="comment cmt"><p>Provides several RDD implementations. See <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">org.apache.spark.rdd.RDD</a>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.resource" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="resource"></a><a id="resource:resource"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/resource/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../resource/index.html"><span class="name">resource</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.scheduler" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="scheduler"></a><a id="scheduler:scheduler"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/scheduler/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Spark's scheduling components." href="../scheduler/index.html"><span class="name">scheduler</span></a>
      </span>
      
      <p class="shortcomment cmt">Spark's scheduling components.</p><div class="fullcomment"><div class="comment cmt"><p>Spark's scheduling components. This includes the <code>org.apache.spark.scheduler.DAGScheduler</code> and
lower level <code>org.apache.spark.scheduler.TaskScheduler</code>.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.security" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="security"></a><a id="security:security"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/security/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../security/index.html"><span class="name">security</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.serializer" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="serializer"></a><a id="serializer:serializer"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/serializer/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Pluggable serializers for RDD and shuffle data." href="../serializer/index.html"><span class="name">serializer</span></a>
      </span>
      
      <p class="shortcomment cmt">Pluggable serializers for RDD and shuffle data.</p><div class="fullcomment"><div class="comment cmt"><p>Pluggable serializers for RDD and shuffle data.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd><dt>See also</dt><dd><span class="cmt"><p><a href="../serializer/Serializer.html" class="extype" name="org.apache.spark.serializer.Serializer">org.apache.spark.serializer.Serializer</a></p></span></dd></dl></div>
    </li><li name="org.apache.spark.shuffle" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="shuffle"></a><a id="shuffle:shuffle"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/shuffle/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../shuffle/index.html"><span class="name">shuffle</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.sql" visbl="pub" class="indented4 current" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sql"></a><a id="sql:sql"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">sql</span>
      </span>
      
      <p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.sql.api" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="api"></a><a id="api:api"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/api/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Contains API classes that are specific to a single language (i.e." href="api/index.html"><span class="name">api</span></a>
      </span>
      
      <p class="shortcomment cmt">Contains API classes that are specific to a single language (i.e.</p><div class="fullcomment"><div class="comment cmt"><p>Contains API classes that are specific to a single language (i.e. Java).
</p></div></div>
    </li><li name="org.apache.spark.sql.avro" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="avro"></a><a id="avro:avro"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/avro/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="avro/index.html"><span class="name">avro</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.catalog" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="catalog"></a><a id="catalog:catalog"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/catalog/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="catalog/index.html"><span class="name">catalog</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.columnar" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="columnar"></a><a id="columnar:columnar"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/columnar/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="columnar/index.html"><span class="name">columnar</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.connector" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="connector"></a><a id="connector:connector"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/connector/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="connector/index.html"><span class="name">connector</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.expressions" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="expressions"></a><a id="expressions:expressions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/expressions/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="expressions/index.html"><span class="name">expressions</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.jdbc" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="jdbc"></a><a id="jdbc:jdbc"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/jdbc/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="jdbc/index.html"><span class="name">jdbc</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.sources" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="sources"></a><a id="sources:sources"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/sources/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="A set of APIs for adding data sources to Spark SQL." href="sources/index.html"><span class="name">sources</span></a>
      </span>
      
      <p class="shortcomment cmt">A set of APIs for adding data sources to Spark SQL.</p>
    </li><li name="org.apache.spark.sql.streaming" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="streaming"></a><a id="streaming:streaming"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/streaming/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="streaming/index.html"><span class="name">streaming</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.types" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="types"></a><a id="types:types"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/types/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Contains a type system for attributes produced by relations, including complex types like structs, arrays and maps." href="types/index.html"><span class="name">types</span></a>
      </span>
      
      <p class="shortcomment cmt">Contains a type system for attributes produced by relations, including complex types like
structs, arrays and maps.</p>
    </li><li name="org.apache.spark.sql.util" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="util"></a><a id="util:util"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/util/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="util/index.html"><span class="name">util</span></a>
      </span>
      
      
    </li><li name="org.apache.spark.sql.vectorized" visbl="pub" class="indented5 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="vectorized"></a><a id="vectorized:vectorized"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/vectorized/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="vectorized/index.html"><span class="name">vectorized</span></a>
      </span>
      
      
    </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="AnalysisException.html" title="Thrown when a query fails to analyze, usually because the query itself is invalid."></a>
                        <a href="AnalysisException.html" title="Thrown when a query fails to analyze, usually because the query itself is invalid.">AnalysisException</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="Column.html" title="A column that will be computed based on the data in a DataFrame."></a>
                        <a href="Column.html" title="A column that will be computed based on the data in a DataFrame.">Column</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ColumnName.html" title="A convenient class used for constructing schema."></a>
                        <a href="ColumnName.html" title="A convenient class used for constructing schema.">ColumnName</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="CreateTableWriter.html" title="Trait to restrict calls to create and replace operations."></a>
                        <a href="CreateTableWriter.html" title="Trait to restrict calls to create and replace operations.">CreateTableWriter</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames."></a>
                        <a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames.">DataFrameNaFunctions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g."></a>
                        <a href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g.">DataFrameReader</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameStatFunctions.html" title="Statistic functions for DataFrames."></a>
                        <a href="DataFrameStatFunctions.html" title="Statistic functions for DataFrames.">DataFrameStatFunctions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameWriter.html" title="Interface used to write a Dataset to external storage systems (e.g."></a>
                        <a href="DataFrameWriter.html" title="Interface used to write a Dataset to external storage systems (e.g.">DataFrameWriter</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DataFrameWriterV2.html" title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API."></a>
                        <a href="DataFrameWriterV2.html" title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API.">DataFrameWriterV2</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations."></a>
                        <a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations.">Dataset</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="DatasetHolder.html" title="A container for a Dataset, used for implicit conversions in Scala."></a>
                        <a href="DatasetHolder.html" title="A container for a Dataset, used for implicit conversions in Scala.">DatasetHolder</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="Encoder.html" title="Used to convert a JVM object of type T to and from the internal Spark SQL representation."></a>
                        <a href="Encoder.html" title="Used to convert a JVM object of type T to and from the internal Spark SQL representation.">Encoder</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="object" href="Encoders$.html" title="Methods for creating an Encoder."></a>
                        <a href="Encoders$.html" title="Methods for creating an Encoder.">Encoders</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ExperimentalMethods.html" title=":: Experimental :: Holder for experimental methods for the bravest."></a>
                        <a href="ExperimentalMethods.html" title=":: Experimental :: Holder for experimental methods for the bravest.">ExperimentalMethods</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="ForeachWriter.html" title="The abstract class for writing custom logic to process data generated by a query."></a>
                        <a href="ForeachWriter.html" title="The abstract class for writing custom logic to process data generated by a query.">ForeachWriter</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key."></a>
                        <a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key.">KeyValueGroupedDataset</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="LowPrioritySQLImplicits.html" title="Lower priority implicit methods for converting Scala objects into Datasets."></a>
                        <a href="LowPrioritySQLImplicits.html" title="Lower priority implicit methods for converting Scala objects into Datasets.">LowPrioritySQLImplicits</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)."></a>
                        <a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot).">RelationalGroupedDataset</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="Row$.html" title=""></a>
                        <a class="trait" href="Row.html" title="Represents one row of output from a relational operator."></a>
                        <a href="Row.html" title="Represents one row of output from a relational operator.">Row</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="RowFactory.html" title=""></a>
                        <a href="RowFactory.html" title="">RowFactory</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="RuntimeConfig.html" title="Runtime configuration interface for Spark."></a>
                        <a href="RuntimeConfig.html" title="Runtime configuration interface for Spark.">RuntimeConfig</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="SQLContext$.html" title="This SQLContext object contains utility functions to create a singleton SQLContext instance, or to get the created SQLContext instance."></a>
                        <a class="class" href="SQLContext.html" title="The entry point for working with structured data (rows and columns) in Spark 1.x."></a>
                        <a href="SQLContext.html" title="The entry point for working with structured data (rows and columns) in Spark 1.x.">SQLContext</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="SQLImplicits.html" title="A collection of implicit methods for converting common Scala objects into Datasets."></a>
                        <a href="SQLImplicits.html" title="A collection of implicit methods for converting common Scala objects into Datasets.">SQLImplicits</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="SaveMode.html" title=""></a>
                        <a href="SaveMode.html" title="">SaveMode</a>
                      </li><li class="current-entities indented4">
                        <a class="object" href="SparkSession$.html" title=""></a>
                        <a class="class" href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API."></a>
                        <a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API.">SparkSession</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="SparkSessionExtensions.html" title=":: Experimental :: Holder for injection points to the SparkSession."></a>
                        <a href="SparkSessionExtensions.html" title=":: Experimental :: Holder for injection points to the SparkSession.">SparkSessionExtensions</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="TypedColumn.html" title="A Column where an Encoder has been given for the expected input and return type."></a>
                        <a href="TypedColumn.html" title="A Column where an Encoder has been given for the expected input and return type.">TypedColumn</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="class" href="UDFRegistration.html" title="Functions for registering user-defined functions."></a>
                        <a href="UDFRegistration.html" title="Functions for registering user-defined functions.">UDFRegistration</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="trait" href="WriteConfigMethods.html" title="Configuration methods common to create/replace operations and insert/overwrite operations."></a>
                        <a href="WriteConfigMethods.html" title="Configuration methods common to create/replace operations and insert/overwrite operations.">WriteConfigMethods</a>
                      </li><li class="current-entities indented4">
                        <span class="separator"></span>
                        <a class="object" href="functions$.html" title="Commonly used functions available for DataFrame operations."></a>
                        <a href="functions$.html" title="Commonly used functions available for DataFrame operations.">functions</a>
                      </li><li name="org.apache.spark.status" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="status"></a><a id="status:status"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/status/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../status/index.html"><span class="name">status</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.storage" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="storage"></a><a id="storage:storage"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/storage/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../storage/index.html"><span class="name">storage</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.streaming" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="streaming"></a><a id="streaming:streaming"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/streaming/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Spark Streaming functionality." href="../streaming/index.html"><span class="name">streaming</span></a>
      </span>
      
      <p class="shortcomment cmt">Spark Streaming functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Spark Streaming functionality. <a href="../streaming/StreamingContext.html" class="extype" name="org.apache.spark.streaming.StreamingContext">org.apache.spark.streaming.StreamingContext</a> serves as the main
entry point to Spark Streaming, while <a href="../streaming/dstream/DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">org.apache.spark.streaming.dstream.DStream</a> is the data
type representing a continuous sequence of RDDs, representing a continuous stream of data.</p><p>In addition, <a href="../streaming/dstream/PairDStreamFunctions.html" class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions">org.apache.spark.streaming.dstream.PairDStreamFunctions</a> contains operations
available only on DStreams
of key-value pairs, such as <code>groupByKey</code> and <code>reduceByKey</code>. These operations are automatically
available on any DStream of the right type (e.g. DStream[(Int, Int)] through implicit
conversions.</p><p>For the Java API of Spark Streaming, take a look at the
<a href="../streaming/api/java/JavaStreamingContext.html" class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext">org.apache.spark.streaming.api.java.JavaStreamingContext</a> which serves as the entry point, and
the <a href="../streaming/api/java/JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">org.apache.spark.streaming.api.java.JavaDStream</a> and the
<a href="../streaming/api/java/JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">org.apache.spark.streaming.api.java.JavaPairDStream</a> which have the DStream functionality.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.unsafe" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="unsafe"></a><a id="unsafe:unsafe"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/unsafe/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../unsafe/index.html"><span class="name">unsafe</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li><li name="org.apache.spark.util" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="util"></a><a id="util:util"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/util/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="Spark utilities." href="../util/index.html"><span class="name">util</span></a>
      </span>
      
      <p class="shortcomment cmt">Spark utilities.</p><div class="fullcomment"><div class="comment cmt"><p>Spark utilities.
</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="org.apache.spark">spark</a></dd></dl></div>
    </li>
              </ul>
            </div>
          </div>
          <div id="content">
            <body class="package value">
      <div id="definition">
        <div class="big-circle package">p</div>
        <p id="owner"><a href="../../../index.html" class="extype" name="org">org</a>.<a href="../../index.html" class="extype" name="org.apache">apache</a>.<a href="../index.html" class="extype" name="org.apache.spark">spark</a></p>
        <h1>sql<span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span></h1>
        
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">sql</span>
      </span>
      </h4>

      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"> <dt>Source</dt><dd><a href="https://github.com/apache/spark/tree/v3.1.3/sql/core/src/main/scala/org/apache/spark/sql/package.scala" target="_blank">package.scala</a></dd></dl><div class="toggleContainer block">
          <span class="toggle">
            Linear Supertypes
          </span>
          <div class="superTypes hiddenContent"><a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div class="toggle"></div>
        <div id="memberfilter">
          <i class="material-icons arrow"></i>
          <span class="input">
            <input id="mbrsel-input" placeholder="Filter all members" type="text" accesskey="/" />
          </span>
          <i class="clear material-icons"></i>
        </div>
        <div id="filterby">
          <div id="order">
            <span class="filtertype">Ordering</span>
            <ol>
              
              <li class="alpha in"><span>Alphabetic</span></li>
              <li class="inherit out"><span>By Inheritance</span></li>
            </ol>
          </div>
          <div class="ancestors">
                  <span class="filtertype">Inherited<br />
                  </span>
                  <ol id="linearization">
                    <li class="in" name="org.apache.spark.sql"><span>sql</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                  </ol>
                </div><div class="ancestors">
              <span class="filtertype"></span>
              <ol>
                <li class="hideall out"><span>Hide All</span></li>
                <li class="showall in"><span>Show All</span></li>
              </ol>
            </div>
          <div id="visbl">
              <span class="filtertype">Visibility</span>
              <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
            </div>
        </div>
      </div>

      <div id="template">
        <div id="allMembers">
        

        <div id="types" class="types members">
              <h3>Type Members</h3>
              <ol><li name="org.apache.spark.sql.AnalysisException" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="AnalysisExceptionextendsExceptionwithSerializable"></a><a id="AnalysisException:AnalysisException"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/AnalysisException.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Thrown when a query fails to analyze, usually because the query itself is invalid." href="AnalysisException.html"><span class="name">AnalysisException</span></a><span class="result"> extends <a href="../../../../scala/index.html#Exception=Exception" class="extmbr" name="scala.Exception">Exception</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Thrown when a query fails to analyze, usually because the query itself is invalid.</p><div class="fullcomment"><div class="comment cmt"><p>Thrown when a query fails to analyze, usually because the query itself is invalid.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.Column" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ColumnextendsLogging"></a><a id="Column:Column"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Column.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A column that will be computed based on the data in a DataFrame." href="Column.html"><span class="name">Column</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">A column that will be computed based on the data in a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>A column that will be computed based on the data in a <code>DataFrame</code>.</p><p>A new column can be constructed based on the input columns present in a DataFrame:</p><pre>df(<span class="lit">"columnName"</span>)            <span class="cmt">// On a specific `df` DataFrame.</span>
col(<span class="lit">"columnName"</span>)           <span class="cmt">// A generic column not yet associated with a DataFrame.</span>
col(<span class="lit">"columnName.field"</span>)     <span class="cmt">// Extracting a struct field</span>
col(<span class="lit">"`a.column.with.dots`"</span>) <span class="cmt">// Escape `.` in column names.</span>
$<span class="lit">"columnName"</span>               <span class="cmt">// Scala short hand for a named column.</span></pre><p><a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> objects can be composed to form complex expressions:</p><pre>$<span class="lit">"a"</span> + <span class="num">1</span>
$<span class="lit">"a"</span> === $<span class="lit">"b"</span></pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>The internal Catalyst expression can be accessed via <a href="Column.html#expr:org.apache.spark.sql.catalyst.expressions.Expression" class="extmbr" name="org.apache.spark.sql.Column#expr">expr</a>, but this method is for
debugging purposes only and can change in any future Spark releases.</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.ColumnName" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ColumnNameextendsColumn"></a><a id="ColumnName:ColumnName"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/ColumnName.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A convenient class used for constructing schema." href="ColumnName.html"><span class="name">ColumnName</span></a><span class="result"> extends <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      
      <p class="shortcomment cmt">A convenient class used for constructing schema.</p><div class="fullcomment"><div class="comment cmt"><p>A convenient class used for constructing schema.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.CreateTableWriter" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="CreateTableWriter[T]extendsWriteConfigMethods[org.apache.spark.sql.CreateTableWriter[T]]"></a><a id="CreateTableWriter[T]:CreateTableWriter[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/CreateTableWriter.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Trait to restrict calls to create and replace operations." href="CreateTableWriter.html"><span class="name">CreateTableWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="WriteConfigMethods.html" class="extype" name="org.apache.spark.sql.WriteConfigMethods">WriteConfigMethods</a>[<a href="CreateTableWriter.html" class="extype" name="org.apache.spark.sql.CreateTableWriter">CreateTableWriter</a>[<span class="extype" name="org.apache.spark.sql.CreateTableWriter.T">T</span>]]</span>
      </span>
      
      <p class="shortcomment cmt">Trait to restrict calls to create and replace operations.</p><div class="fullcomment"><div class="comment cmt"><p>Trait to restrict calls to create and replace operations.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>3.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]"></a><a id="DataFrame:DataFrame"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">type</span>
      </span>
      <span class="symbol">
        <span class="name">DataFrame</span><span class="result alias"> = <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>[<a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>]</span>
      </span>
      
      
    </li><li name="org.apache.spark.sql.DataFrameNaFunctions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameNaFunctionsextendsAnyRef"></a><a id="DataFrameNaFunctions:DataFrameNaFunctions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameNaFunctions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Functionality for working with missing data in DataFrames." href="DataFrameNaFunctions.html"><span class="name">DataFrameNaFunctions</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">Functionality for working with missing data in <code>DataFrame</code>s.</p><div class="fullcomment"><div class="comment cmt"><p>Functionality for working with missing data in <code>DataFrame</code>s.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.1</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameReader" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameReaderextendsLogging"></a><a id="DataFrameReader:DataFrameReader"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Interface used to load a Dataset from external storage systems (e.g." href="DataFrameReader.html"><span class="name">DataFrameReader</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">Interface used to load a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from external storage systems (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>Interface used to load a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> from external storage systems (e.g. file systems,
key-value stores, etc). Use <code>SparkSession.read</code> to access this.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameStatFunctions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameStatFunctionsextendsAnyRef"></a><a id="DataFrameStatFunctions:DataFrameStatFunctions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Statistic functions for DataFrames." href="DataFrameStatFunctions.html"><span class="name">DataFrameStatFunctions</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">Statistic functions for <code>DataFrame</code>s.</p><div class="fullcomment"><div class="comment cmt"><p>Statistic functions for <code>DataFrame</code>s.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameWriter" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameWriter[T]extendsAnyRef"></a><a id="DataFrameWriter[T]:DataFrameWriter[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Interface used to write a Dataset to external storage systems (e.g." href="DataFrameWriter.html"><span class="name">DataFrameWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> to external storage systems (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> to external storage systems (e.g. file systems,
key-value stores, etc). Use <code>Dataset.write</code> to access this.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrameWriterV2" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DataFrameWriterV2[T]extendsCreateTableWriter[T]"></a><a id="DataFrameWriterV2[T]:DataFrameWriterV2[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DataFrameWriterV2.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API." href="DataFrameWriterV2.html"><span class="name">DataFrameWriterV2</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="CreateTableWriter.html" class="extype" name="org.apache.spark.sql.CreateTableWriter">CreateTableWriter</a>[<span class="extype" name="org.apache.spark.sql.DataFrameWriterV2.T">T</span>]</span>
      </span>
      
      <p class="shortcomment cmt">Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">org.apache.spark.sql.Dataset</a> to external storage using the v2 API.</p><div class="fullcomment"><div class="comment cmt"><p>Interface used to write a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">org.apache.spark.sql.Dataset</a> to external storage using the v2 API.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Experimental</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.Dataset" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Dataset[T]extendsSerializable"></a><a id="Dataset[T]:Dataset[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Dataset.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations." href="Dataset.html"><span class="name">Dataset</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A Dataset is a strongly typed collection of domain-specific objects that can be transformed
in parallel using functional or relational operations.</p><div class="fullcomment"><div class="comment cmt"><p>A Dataset is a strongly typed collection of domain-specific objects that can be transformed
in parallel using functional or relational operations. Each Dataset also has an untyped view
called a <code>DataFrame</code>, which is a Dataset of <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a>.</p><p>Operations available on Datasets are divided into transformations and actions. Transformations
are the ones that produce new Datasets, and actions are the ones that trigger computation and
return results. Example transformations include map, filter, select, and aggregate (<code>groupBy</code>).
Example actions count, show, or writing data out to file systems.</p><p>Datasets are &quot;lazy&quot;, i.e. computations are only triggered when an action is invoked. Internally,
a Dataset represents a logical plan that describes the computation required to produce the data.
When an action is invoked, Spark's query optimizer optimizes the logical plan and generates a
physical plan for efficient execution in a parallel and distributed manner. To explore the
logical plan as well as optimized physical plan, use the <code>explain</code> function.</p><p>To efficiently support domain-specific objects, an <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a> is required. The encoder maps
the domain specific type <code>T</code> to Spark's internal type system. For example, given a class <code>Person</code>
with two fields, <code>name</code> (string) and <code>age</code> (int), an encoder is used to tell Spark to generate
code at runtime to serialize the <code>Person</code> object into a binary structure. This binary structure
often has much lower memory footprint as well as are optimized for efficiency in data processing
(e.g. in a columnar format). To understand the internal binary representation for data, use the
<code>schema</code> function.</p><p>There are typically two ways to create a Dataset. The most common way is by pointing Spark
to some files on storage systems, using the <code>read</code> function available on a <code>SparkSession</code>.</p><pre><span class="kw">val</span> people = spark.read.parquet(<span class="lit">"..."</span>).as[Person]  <span class="cmt">// Scala</span>
Dataset&lt;Person&gt; people = spark.read().parquet(<span class="lit">"..."</span>).as(Encoders.bean(Person.<span class="kw">class</span>)); <span class="cmt">// Java</span></pre><p>Datasets can also be created through transformations available on existing Datasets. For example,
the following creates a new Dataset by applying a filter on the existing one:</p><pre><span class="kw">val</span> names = people.map(_.name)  <span class="cmt">// in Scala; names is a Dataset[String]</span>
Dataset&lt;<span class="std">String</span>&gt; names = people.map((Person p) -&gt; p.name, Encoders.STRING));</pre><p>Dataset operations can also be untyped, through various domain-specific-language (DSL)
functions defined in: Dataset (this class), <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>, and <a href="functions$.html" class="extype" name="org.apache.spark.sql.functions">functions</a>. These operations
are very similar to the operations available in the data frame abstraction in R or Python.</p><p>To select a column from the Dataset, use <code>apply</code> method in Scala and <code>col</code> in Java.</p><pre><span class="kw">val</span> ageCol = people(<span class="lit">"age"</span>)  <span class="cmt">// in Scala</span>
Column ageCol = people.col(<span class="lit">"age"</span>); <span class="cmt">// in Java</span></pre><p>Note that the <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> type can also be manipulated through its various functions.</p><pre><span class="cmt">// The following creates a new column that increases everybody's age by 10.</span>
people(<span class="lit">"age"</span>) + <span class="num">10</span>  <span class="cmt">// in Scala</span>
people.col(<span class="lit">"age"</span>).plus(<span class="num">10</span>);  <span class="cmt">// in Java</span></pre><p>A more concrete example in Scala:</p><pre><span class="cmt">// To create Dataset[Row] using SparkSession</span>
<span class="kw">val</span> people = spark.read.parquet(<span class="lit">"..."</span>)
<span class="kw">val</span> department = spark.read.parquet(<span class="lit">"..."</span>)

people.filter(<span class="lit">"age &gt; 30"</span>)
  .join(department, people(<span class="lit">"deptId"</span>) === department(<span class="lit">"id"</span>))
  .groupBy(department(<span class="lit">"name"</span>), people(<span class="lit">"gender"</span>))
  .agg(avg(people(<span class="lit">"salary"</span>)), max(people(<span class="lit">"age"</span>)))</pre><p>and in Java:</p><pre><span class="cmt">// To create Dataset&lt;Row&gt; using SparkSession</span>
Dataset&lt;Row&gt; people = spark.read().parquet(<span class="lit">"..."</span>);
Dataset&lt;Row&gt; department = spark.read().parquet(<span class="lit">"..."</span>);

people.filter(people.col(<span class="lit">"age"</span>).gt(<span class="num">30</span>))
  .join(department, people.col(<span class="lit">"deptId"</span>).equalTo(department.col(<span class="lit">"id"</span>)))
  .groupBy(department.col(<span class="lit">"name"</span>), people.col(<span class="lit">"gender"</span>))
  .agg(avg(people.col(<span class="lit">"salary"</span>)), max(people.col(<span class="lit">"age"</span>)));</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DatasetHolder" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="DatasetHolder[T]extendsProductwithSerializable"></a><a id="DatasetHolder[T]:DatasetHolder[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/DatasetHolder.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">case class</span>
      </span>
      <span class="symbol">
        <a title="A container for a Dataset, used for implicit conversions in Scala." href="DatasetHolder.html"><span class="name">DatasetHolder</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Product">Product</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A container for a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>, used for implicit conversions in Scala.</p><div class="fullcomment"><div class="comment cmt"><p>A container for a <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>, used for implicit conversions in Scala.</p><p>To use this, import implicit conversions in SQL:</p><pre><span class="kw">val</span> spark: SparkSession = ...
<span class="kw">import</span> spark.implicits._</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.Encoder" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="Encoder[T]extendsSerializable"></a><a id="Encoder[T]:Encoder[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Encoder.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Used to convert a JVM object of type T to and from the internal Spark SQL representation." href="Encoder.html"><span class="name">Encoder</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Used to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation.</p><div class="fullcomment"><div class="comment cmt"><p>Used to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation.</p><h4> Scala </h4><p>Encoders are generally created automatically through implicits from a <code>SparkSession</code>, or can be
explicitly created by calling static methods on <a href="Encoders$.html" class="extype" name="org.apache.spark.sql.Encoders">Encoders</a>.</p><pre><span class="kw">import</span> spark.implicits._

<span class="kw">val</span> ds = <span class="std">Seq</span>(<span class="num">1</span>, <span class="num">2</span>, <span class="num">3</span>).toDS() <span class="cmt">// implicitly provided (spark.implicits.newIntEncoder)</span></pre><h4> Java </h4><p>Encoders are specified by calling static methods on <a href="Encoders$.html" class="extype" name="org.apache.spark.sql.Encoders">Encoders</a>.</p><pre><span class="std">List</span>&lt;<span class="std">String</span>&gt; data = Arrays.asList(<span class="lit">"abc"</span>, <span class="lit">"abc"</span>, <span class="lit">"xyz"</span>);
Dataset&lt;<span class="std">String</span>&gt; ds = context.createDataset(data, Encoders.STRING());</pre><p>Encoders can be composed into tuples:</p><pre>Encoder&lt;Tuple2&lt;Integer, <span class="std">String</span>&gt;&gt; encoder2 = Encoders.tuple(Encoders.INT(), Encoders.STRING());
<span class="std">List</span>&lt;Tuple2&lt;Integer, <span class="std">String</span>&gt;&gt; data2 = Arrays.asList(<span class="kw">new</span> scala.Tuple2(<span class="num">1</span>, <span class="lit">"a"</span>);
Dataset&lt;Tuple2&lt;Integer, <span class="std">String</span>&gt;&gt; ds2 = context.createDataset(data2, encoder2);</pre><p>Or constructed from Java Beans:</p><pre>Encoders.bean(MyClass.<span class="kw">class</span>);</pre><h4> Implementation </h4><ul><li>Encoders should be thread-safe.
</li></ul></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@implicitNotFound</span><span class="args">(<span>
      
      <span class="defval" name="&quot;Unable to find encoder for type ${T}. An implicit Encoder[${T}] is needed to &quot; +<br/>  &quot;store ${T} instances in a Dataset. Primitive types (Int, String, etc) and Product types (case &quot; +<br/>  &quot;classes) are supported by importing spark.implicits._  Support for serializing other types &quot; +<br/>  &quot;will be added in future releases.&quot;">...</span>
    </span>)</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.ExperimentalMethods" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ExperimentalMethodsextendsAnyRef"></a><a id="ExperimentalMethods:ExperimentalMethods"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title=":: Experimental :: Holder for experimental methods for the bravest." href="ExperimentalMethods.html"><span class="name">ExperimentalMethods</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">:: Experimental ::
Holder for experimental methods for the bravest.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Holder for experimental methods for the bravest. We make NO guarantee about the stability
regarding binary compatibility and source compatibility of methods here.</p><pre>spark.experimental.extraStrategies += ...</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Experimental</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.ForeachWriter" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="ForeachWriter[T]extendsSerializable"></a><a id="ForeachWriter[T]:ForeachWriter[T]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/ForeachWriter.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">abstract </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="The abstract class for writing custom logic to process data generated by a query." href="ForeachWriter.html"><span class="name">ForeachWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">The abstract class for writing custom logic to process data generated by a query.</p><div class="fullcomment"><div class="comment cmt"><p>The abstract class for writing custom logic to process data generated by a query.
This is often used to write the output of a streaming query to arbitrary storage systems.
Any implementation of this base class will be used by Spark in the following way.</p><ul><li>A single instance of this class is responsible of all the data generated by a single task
    in a query. In other words, one instance is responsible for processing one partition of the
    data generated in a distributed manner.</li><li>Any implementation of this class must be serializable because each task will get a fresh
    serialized-deserialized copy of the provided object. Hence, it is strongly recommended that
    any initialization for writing data (e.g. opening a connection or starting a transaction)
    is done after the <code>open(...)</code> method has been called, which signifies that the task is
    ready to generate data.</li><li>The lifecycle of the methods are as follows.</li></ul><p><pre>
  For each partition with `partitionId`:
      For each batch/epoch of streaming data (if its streaming query) with `epochId`:
          Method `open(partitionId, epochId)` is called.
          If `open` returns true:
               For each row in the partition and batch/epoch, method `process(row)` is called.
          Method `close(errorOrNull)` is called with error (if any) seen while processing rows.
</pre></p><p>Important points to note:</p><ul><li>Spark doesn't guarantee same output for (partitionId, epochId), so deduplication
    cannot be achieved with (partitionId, epochId). e.g. source provides different number of
    partitions for some reason, Spark optimization changes number of partitions, etc.
    Refer SPARK-28650 for more details. If you need deduplication on output, try out
    <code>foreachBatch</code> instead.</li><li>The <code>close()</code> method will be called if <code>open()</code> method returns successfully (irrespective
    of the return value), except if the JVM crashes in the middle.</li></ul><p>Scala example:</p><pre>datasetOfString.writeStream.foreach(<span class="kw">new</span> ForeachWriter[<span class="std">String</span>] {

  <span class="kw">def</span> open(partitionId: <span class="std">Long</span>, version: <span class="std">Long</span>): <span class="std">Boolean</span> = {
    <span class="cmt">// open connection</span>
  }

  <span class="kw">def</span> process(record: <span class="std">String</span>) = {
    <span class="cmt">// write string to connection</span>
  }

  <span class="kw">def</span> close(errorOrNull: Throwable): <span class="std">Unit</span> = {
    <span class="cmt">// close the connection</span>
  }
})</pre><p>Java example:</p><pre>datasetOfString.writeStream().foreach(<span class="kw">new</span> ForeachWriter&lt;<span class="std">String</span>&gt;() {

  @Override
  public boolean open(long partitionId, long version) {
    <span class="cmt">// open connection</span>
  }

  @Override
  public void process(<span class="std">String</span> value) {
    <span class="cmt">// write string to connection</span>
  }

  @Override
  public void close(Throwable errorOrNull) {
    <span class="cmt">// close the connection</span>
  }
});</pre></div><dl class="attributes block"> <dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.KeyValueGroupedDataset" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="KeyValueGroupedDataset[K,V]extendsSerializable"></a><a id="KeyValueGroupedDataset[K,V]:KeyValueGroupedDataset[K,V]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/KeyValueGroupedDataset.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A Dataset has been logically grouped by a user specified grouping key." href="KeyValueGroupedDataset.html"><span class="name">KeyValueGroupedDataset</span></a><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> has been logically grouped by a user specified grouping key.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a> has been logically grouped by a user specified grouping key.  Users should not
construct a <a href="KeyValueGroupedDataset.html" class="extype" name="org.apache.spark.sql.KeyValueGroupedDataset">KeyValueGroupedDataset</a> directly, but should instead call <code>groupByKey</code> on
an existing <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.LowPrioritySQLImplicits" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="LowPrioritySQLImplicitsextendsAnyRef"></a><a id="LowPrioritySQLImplicits:LowPrioritySQLImplicits"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/LowPrioritySQLImplicits.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Lower priority implicit methods for converting Scala objects into Datasets." href="LowPrioritySQLImplicits.html"><span class="name">LowPrioritySQLImplicits</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">Lower priority implicit methods for converting Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>Lower priority implicit methods for converting Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.
Conflicting implicits are placed here to disambiguate resolution.</p><p>Reasons for including specific implicits:
newProductEncoder - to disambiguate for <code>List</code>s which are both <code>Seq</code> and <code>Product</code>
</p></div></div>
    </li><li name="org.apache.spark.sql.RelationalGroupedDataset" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="RelationalGroupedDatasetextendsAnyRef"></a><a id="RelationalGroupedDataset:RelationalGroupedDataset"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/RelationalGroupedDataset.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)." href="RelationalGroupedDataset.html"><span class="name">RelationalGroupedDataset</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">A set of methods for aggregations on a <code>DataFrame</code>, created by <a href="Dataset.html#groupBy(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#groupBy">groupBy</a>,
<a href="Dataset.html#cube(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#cube">cube</a> or <a href="Dataset.html#rollup(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#rollup">rollup</a> (and also <code>pivot</code>).</p><div class="fullcomment"><div class="comment cmt"><p>A set of methods for aggregations on a <code>DataFrame</code>, created by <a href="Dataset.html#groupBy(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#groupBy">groupBy</a>,
<a href="Dataset.html#cube(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#cube">cube</a> or <a href="Dataset.html#rollup(col1:String,cols:String*):org.apache.spark.sql.RelationalGroupedDataset" class="extmbr" name="org.apache.spark.sql.Dataset#rollup">rollup</a> (and also <code>pivot</code>).</p><p>The main method is the <code>agg</code> function, which has multiple variants. This class also contains
some first-order statistics such as <code>mean</code>, <code>sum</code> for convenience.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>This class was named <code>GroupedData</code> in Spark 1.x.</p></span></dd></dl></div>
    </li><li name="org.apache.spark.sql.Row" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="RowextendsSerializable"></a><a id="Row:Row"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Row.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Represents one row of output from a relational operator." href="Row.html"><span class="name">Row</span></a><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">Represents one row of output from a relational operator.</p><div class="fullcomment"><div class="comment cmt"><p>Represents one row of output from a relational operator.  Allows both generic access by ordinal,
which will incur boxing overhead for primitives, as well as native primitive access.</p><p>It is invalid to use the native primitive interface to retrieve a value that is null, instead a
user must check <code>isNullAt</code> before attempting to retrieve a value that might be null.</p><p>To create a new Row, use <code>RowFactory.create()</code> in Java or <code>Row.apply()</code> in Scala.</p><p>A <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a> object can be constructed by providing field values. Example:</p><pre><span class="kw">import</span> org.apache.spark.sql._

<span class="cmt">// Create a Row from values.</span>
Row(value1, value2, value3, ...)
<span class="cmt">// Create a Row from a Seq of values.</span>
Row.fromSeq(<span class="std">Seq</span>(value1, value2, ...))</pre><p>A value of a row can be accessed through both generic access by ordinal,
which will incur boxing overhead for primitives, as well as native primitive access.
An example of generic access by ordinal:</p><pre><span class="kw">import</span> org.apache.spark.sql._

<span class="kw">val</span> row = Row(<span class="num">1</span>, <span class="kw">true</span>, <span class="lit">"a string"</span>, <span class="kw">null</span>)
<span class="cmt">// row: Row = [1,true,a string,null]</span>
<span class="kw">val</span> firstValue = row(<span class="num">0</span>)
<span class="cmt">// firstValue: Any = 1</span>
<span class="kw">val</span> fourthValue = row(<span class="num">3</span>)
<span class="cmt">// fourthValue: Any = null</span></pre><p>For native primitive access, it is invalid to use the native primitive interface to retrieve
a value that is null, instead a user must check <code>isNullAt</code> before attempting to retrieve a
value that might be null.
An example of native primitive access:</p><pre><span class="cmt">// using the row from the previous example.</span>
<span class="kw">val</span> firstValue = row.getInt(<span class="num">0</span>)
<span class="cmt">// firstValue: Int = 1</span>
<span class="kw">val</span> isNull = row.isNullAt(<span class="num">3</span>)
<span class="cmt">// isNull: Boolean = true</span></pre><p>In Scala, fields in a <a href="Row.html" class="extype" name="org.apache.spark.sql.Row">Row</a> object can be extracted in a pattern match. Example:</p><pre><span class="kw">import</span> org.apache.spark.sql._

<span class="kw">val</span> pairs = sql(<span class="lit">"SELECT key, value FROM src"</span>).rdd.map {
  <span class="kw">case</span> Row(key: <span class="std">Int</span>, value: <span class="std">String</span>) <span class="kw">=&gt;</span>
    key -&gt; value
}</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.RowFactory" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="RowFactoryextendsObject"></a><a id="RowFactory:RowFactory"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/RowFactory.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="" href="RowFactory.html"><span class="name">RowFactory</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      
    </li><li name="org.apache.spark.sql.RuntimeConfig" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="RuntimeConfigextendsAnyRef"></a><a id="RuntimeConfig:RuntimeConfig"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/RuntimeConfig.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Runtime configuration interface for Spark." href="RuntimeConfig.html"><span class="name">RuntimeConfig</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">Runtime configuration interface for Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Runtime configuration interface for Spark. To access this, use <code>SparkSession.conf</code>.</p><p>Options set here are automatically propagated to the Hadoop configuration during I/O.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SQLContextextendsLoggingwithSerializable"></a><a id="SQLContext:SQLContext"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SQLContext.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="The entry point for working with structured data (rows and columns) in Spark 1.x." href="SQLContext.html"><span class="name">SQLContext</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">The entry point for working with structured data (rows and columns) in Spark 1.x.</p><div class="fullcomment"><div class="comment cmt"><p>The entry point for working with structured data (rows and columns) in Spark 1.x.</p><p>As of Spark 2.0, this is replaced by <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a>. However, we are keeping the class
here for backward compatibility.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.0.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLImplicits" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="SQLImplicitsextendsLowPrioritySQLImplicits"></a><a id="SQLImplicits:SQLImplicits"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SQLImplicits.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">abstract </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A collection of implicit methods for converting common Scala objects into Datasets." href="SQLImplicits.html"><span class="name">SQLImplicits</span></a><span class="result"> extends <a href="LowPrioritySQLImplicits.html" class="extype" name="org.apache.spark.sql.LowPrioritySQLImplicits">LowPrioritySQLImplicits</a></span>
      </span>
      
      <p class="shortcomment cmt">A collection of implicit methods for converting common Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.</p><div class="fullcomment"><div class="comment cmt"><p>A collection of implicit methods for converting common Scala objects into <a href="Dataset.html" class="extype" name="org.apache.spark.sql.Dataset">Dataset</a>s.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SaveMode" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="SaveModeextendsEnum[org.apache.spark.sql.SaveMode]"></a><a id="SaveMode:SaveMode"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SaveMode.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier">sealed abstract final </span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="" href="SaveMode.html"><span class="name">SaveMode</span></a><span class="result"> extends <span class="extype" name="java.lang.Enum">Enum</span>[<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a>]</span>
      </span>
      
      
    </li><li name="org.apache.spark.sql.SparkSession" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SparkSessionextendsSerializablewithCloseablewithLogging"></a><a id="SparkSession:SparkSession"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSession.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="The entry point to programming Spark with the Dataset and DataFrame API." href="SparkSession.html"><span class="name">SparkSession</span></a><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span> with <span class="extype" name="java.io.Closeable">Closeable</span> with <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">The entry point to programming Spark with the Dataset and DataFrame API.</p><div class="fullcomment"><div class="comment cmt"><p>The entry point to programming Spark with the Dataset and DataFrame API.</p><p>In environments that this has been created upfront (e.g. REPL, notebooks), use the builder
to get an existing session:</p><pre>SparkSession.builder().getOrCreate()</pre><p>The builder can also be used to create a new session:</p><pre>SparkSession.builder
  .master(<span class="lit">"local"</span>)
  .appName(<span class="lit">"Word Count"</span>)
  .config(<span class="lit">"spark.some.config.option"</span>, <span class="lit">"some-value"</span>)
  .getOrCreate()</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.SparkSessionExtensions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SparkSessionExtensionsextendsAnyRef"></a><a id="SparkSessionExtensions:SparkSessionExtensions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSessionExtensions.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title=":: Experimental :: Holder for injection points to the SparkSession." href="SparkSessionExtensions.html"><span class="name">SparkSessionExtensions</span></a><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">:: Experimental ::
Holder for injection points to the <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a>.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Holder for injection points to the <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a>. We make NO guarantee about the stability
regarding binary compatibility and source compatibility of methods here.</p><p>This current provides the following extension points:</p><ul><li>Analyzer Rules.</li><li>Check Analysis Rules.</li><li>Optimizer Rules.</li><li>Pre CBO Rules.</li><li>Planning Strategies.</li><li>Customized Parser.</li><li>(External) Catalog listeners.</li><li>Columnar Rules.</li><li>Adaptive Query Stage Preparation Rules.</li></ul><p>The extensions can be used by calling <code>withExtensions</code> on the <a href="SparkSession$$Builder.html" class="extype" name="org.apache.spark.sql.SparkSession.Builder">SparkSession.Builder</a>, for
example:</p><pre>SparkSession.builder()
  .master(<span class="lit">"..."</span>)
  .config(<span class="lit">"..."</span>, <span class="kw">true</span>)
  .withExtensions { extensions <span class="kw">=&gt;</span>
    extensions.injectResolutionRule { session <span class="kw">=&gt;</span>
      ...
    }
    extensions.injectParser { (session, parser) <span class="kw">=&gt;</span>
      ...
    }
  }
  .getOrCreate()</pre><p>The extensions can also be used by setting the Spark SQL configuration property
<code>spark.sql.extensions</code>. Multiple extensions can be set using a comma-separated list. For example:</p><pre>SparkSession.builder()
  .master(<span class="lit">"..."</span>)
  .config(<span class="lit">"spark.sql.extensions"</span>, <span class="lit">"org.example.MyExtensions"</span>)
  .getOrCreate()

<span class="kw">class</span> MyExtensions <span class="kw">extends</span> Function1[SparkSessionExtensions, <span class="std">Unit</span>] {
  <span class="kw">override</span> <span class="kw">def</span> apply(extensions: SparkSessionExtensions): <span class="std">Unit</span> = {
    extensions.injectResolutionRule { session <span class="kw">=&gt;</span>
      ...
    }
    extensions.injectParser { (session, parser) <span class="kw">=&gt;</span>
      ...
    }
  }
}</pre><p>Note that none of the injected builders should assume that the <a href="SparkSession.html" class="extype" name="org.apache.spark.sql.SparkSession">SparkSession</a> is fully
initialized and should not touch the session's internals (e.g. the SessionState).
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
                <span class="name">@Experimental</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.Strategy" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Strategy=org.apache.spark.sql.execution.SparkStrategy"></a><a id="Strategy:Strategy"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/index.html#Strategy=org.apache.spark.sql.execution.SparkStrategy" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">type</span>
      </span>
      <span class="symbol">
        <span class="name">Strategy</span><span class="result alias"> = <span class="extype" name="org.apache.spark.sql.execution.SparkStrategy">SparkStrategy</span></span>
      </span>
      
      <p class="shortcomment cmt">Converts a logical plan into zero or more SparkPlans.</p><div class="fullcomment"><div class="comment cmt"><p>Converts a logical plan into zero or more SparkPlans.  This API is exposed for experimenting
with the query planner and is not designed to be stable across spark releases.  Developers
writing libraries should instead consider using the stable APIs provided in
<a href="sources/index.html" class="extype" name="org.apache.spark.sql.sources">org.apache.spark.sql.sources</a>
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@DeveloperApi</span><span class="args">()</span>
              
                <span class="name">@Unstable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.TypedColumn" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="TypedColumn[-T,U]extendsColumn"></a><a id="TypedColumn[-T,U]:TypedColumn[T,U]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/TypedColumn.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="A Column where an Encoder has been given for the expected input and return type." href="TypedColumn.html"><span class="name">TypedColumn</span></a><span class="tparams">[<span name="T">-T</span>, <span name="U">U</span>]</span><span class="result"> extends <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      
      <p class="shortcomment cmt">A <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> where an <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a> has been given for the expected input and return type.</p><div class="fullcomment"><div class="comment cmt"><p>A <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> where an <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a> has been given for the expected input and return type.
To create a <a href="TypedColumn.html" class="extype" name="org.apache.spark.sql.TypedColumn">TypedColumn</a>, use the <code>as</code> function on a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.
</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>The input type expected for this expression.  Can be <code>Any</code> if the expression is type
          checked by the analyzer instead of the compiler (i.e. <code>expr(&quot;sum(...)&quot;)</code>).</p></dd><dt class="tparam">U</dt><dd class="cmt"><p>The output type of this column.</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.UDFRegistration" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="UDFRegistrationextendsLogging"></a><a id="UDFRegistration:UDFRegistration"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Functions for registering user-defined functions." href="UDFRegistration.html"><span class="name">UDFRegistration</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span></span>
      </span>
      
      <p class="shortcomment cmt">Functions for registering user-defined functions.</p><div class="fullcomment"><div class="comment cmt"><p>Functions for registering user-defined functions. Use <code>SparkSession.udf</code> to access this:</p><pre>spark.udf</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.WriteConfigMethods" visbl="pub" class="indented0 " data-isabs="true" fullComment="yes" group="Ungrouped">
      <a id="WriteConfigMethods[R]extendsAnyRef"></a><a id="WriteConfigMethods[R]:WriteConfigMethods[R]"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/WriteConfigMethods.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="Configuration methods common to create/replace operations and insert/overwrite operations." href="WriteConfigMethods.html"><span class="name">WriteConfigMethods</span></a><span class="tparams">[<span name="R">R</span>]</span><span class="result"> extends <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      <p class="shortcomment cmt">Configuration methods common to create/replace operations and insert/overwrite operations.</p><div class="fullcomment"><div class="comment cmt"><p>Configuration methods common to create/replace operations and insert/overwrite operations.</p></div><dl class="paramcmts block"><dt class="tparam">R</dt><dd class="cmt"><p>builder type to return</p></dd></dl><dl class="attributes block"> <dt>Since</dt><dd><p>3.0.0</p></dd></dl></div>
    </li></ol>
            </div>

        

        <div class="values members">
              <h3>Value Members</h3>
              <ol>
                <li name="org.apache.spark.sql.Encoders" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Encoders"></a><a id="Encoders:Encoders"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Encoders$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="Methods for creating an Encoder." href="Encoders$.html"><span class="name">Encoders</span></a>
      </span>
      
      <p class="shortcomment cmt">Methods for creating an <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Methods for creating an <a href="Encoder.html" class="extype" name="org.apache.spark.sql.Encoder">Encoder</a>.
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>1.6.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.Row" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Row"></a><a id="Row:Row"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/Row$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="Row$.html"><span class="name">Row</span></a><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.SQLContext" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SQLContext"></a><a id="SQLContext:SQLContext"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SQLContext$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="This SQLContext object contains utility functions to create a singleton SQLContext instance, or to get the created SQLContext instance." href="SQLContext$.html"><span class="name">SQLContext</span></a><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">This SQLContext object contains utility functions to create a singleton SQLContext instance,
or to get the created SQLContext instance.</p><div class="fullcomment"><div class="comment cmt"><p>This SQLContext object contains utility functions to create a singleton SQLContext instance,
or to get the created SQLContext instance.</p><p>It also provides utility functions to support preference for threads in multiple sessions
scenario, setActive could set a SQLContext for current thread, which will be returned by
getOrCreate instead of the global one.
</p></div></div>
    </li><li name="org.apache.spark.sql.SparkSession" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="SparkSession"></a><a id="SparkSession:SparkSession"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/SparkSession$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="SparkSession$.html"><span class="name">SparkSession</span></a><span class="result"> extends <span class="extype" name="org.apache.spark.internal.Logging">Logging</span> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.functions" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="functions"></a><a id="functions:functions"></a>
      <span class="permalink">
      <a href="../../../../org/apache/spark/sql/functions$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="Commonly used functions available for DataFrame operations." href="functions$.html"><span class="name">functions</span></a>
      </span>
      
      <p class="shortcomment cmt">Commonly used functions available for DataFrame operations.</p><div class="fullcomment"><div class="comment cmt"><p>Commonly used functions available for DataFrame operations. Using functions defined here provides
a little bit more compile-time safety to make sure the function exists.</p><p>Spark also includes more built-in functions that are less common and are not defined here.
You can still access them (and all the functions defined here) using the <code>functions.expr()</code> API
and calling them through a SQL expression string. You can find the entire list of functions
at SQL API documentation.</p><p>As an example, <code>isnan</code> is a function that is defined here. You can use <code>isnan(col(&quot;myCol&quot;))</code>
to invoke the <code>isnan</code> function. This way the programming language's compiler ensures <code>isnan</code>
exists and is of the proper form. You can also use <code>expr(&quot;isnan(myCol)&quot;)</code> function to invoke the
same function. In this case, Spark itself will ensure <code>isnan</code> exists when it analyzes the query.</p><p><code>regr_count</code> is an example of a function that is built-in but not defined here, because it is
less commonly used. To invoke it, use <code>expr(&quot;regr_count(yCol, xCol)&quot;)</code>.</p><p>This function APIs usually have methods with <code>Column</code> signature only because it can support not
only <code>Column</code> but also other types such as a native string. The other variants currently exist
for historical reasons.
</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@Stable</span><span class="args">()</span>
              
        </dd><dt>Since</dt><dd><p>1.3.0</p></dd></dl></div>
    </li>
              </ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.AnyRef">
              <h3>Inherited from <a href="../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
    </body>
          </div>
        </div>
      </div>
    </body>
      </html>
