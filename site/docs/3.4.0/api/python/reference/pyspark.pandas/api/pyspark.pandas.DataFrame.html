
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>pyspark.pandas.DataFrame &#8212; PySpark 3.4.0 documentation</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/pyspark.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="pyspark.pandas.DataFrame.index" href="pyspark.pandas.DataFrame.index.html" />
    <link rel="prev" title="DataFrame" href="../frame.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    <!-- Matomo -->
    <script type="text/javascript">
        var _paq = window._paq = window._paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(["disableCookies"]);
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
            var u="https://analytics.apache.org/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '40']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
        })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../../index.html">
    
      <img src="../../../_static/spark-logo-reverse.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../index.html">Overview</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../getting_started/index.html">Getting Started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../user_guide/index.html">User Guides</a>
        </li>
        
        <li class="nav-item active">
            <a class="nav-link" href="../../index.html">API Reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../development/index.html">Development</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../migration_guide/index.html">Migration Guides</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
          
            
                <li class="">
                    <a href="../../pyspark.sql/index.html">Spark SQL</a>
                </li>
            
          
            
  
                <li class="active">
                    <a href="../index.html">Pandas API on Spark</a>
                    <ul>
                    
                        <li class="">
                            <a href="../io.html">Input/Output</a>
                        </li>
                    
                        <li class="">
                            <a href="../general_functions.html">General functions</a>
                        </li>
                    
                        <li class="">
                            <a href="../series.html">Series</a>
                        </li>
                    
                        <li class="active">
                            <a href="../frame.html">DataFrame</a>
                        </li>
                    
                        <li class="">
                            <a href="../indexing.html">Index objects</a>
                        </li>
                    
                        <li class="">
                            <a href="../window.html">Window</a>
                        </li>
                    
                        <li class="">
                            <a href="../groupby.html">GroupBy</a>
                        </li>
                    
                        <li class="">
                            <a href="../resampling.html">Resampling</a>
                        </li>
                    
                        <li class="">
                            <a href="../ml.html">Machine Learning utilities</a>
                        </li>
                    
                        <li class="">
                            <a href="../extensions.html">Extensions</a>
                        </li>
                    
                    </ul>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.ss/index.html">Structured Streaming</a>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.ml.html">MLlib (DataFrame-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.streaming.html">Spark Streaming (Legacy)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.mllib.html">MLlib (RDD-based)</a>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.html">Spark Core</a>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.resource.html">Resource Management</a>
                </li>
            
          
            
                <li class="">
                    <a href="../../pyspark.errors.html">Errors</a>
                </li>
            
          
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="pyspark-pandas-dataframe">
<h1>pyspark.pandas.DataFrame<a class="headerlink" href="#pyspark-pandas-dataframe" title="Permalink to this headline">Â¶</a></h1>
<dl class="py class">
<dt id="pyspark.pandas.DataFrame">
<em class="property">class </em><code class="sig-prename descclassname">pyspark.pandas.</code><code class="sig-name descname">DataFrame</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">index</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">columns</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">copy</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/pyspark/pandas/frame.html#DataFrame"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyspark.pandas.DataFrame" title="Permalink to this definition">Â¶</a></dt>
<dd><p>pandas-on-Spark DataFrame that corresponds to pandas DataFrame logically. This holds Spark
DataFrame internally.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><p><strong>_internal</strong> â an internal immutable Frame to manage metadata.</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>data</strong><span class="classifier">numpy ndarray (structured or homogeneous), dict, pandas DataFrame,</span></dt><dd><p>Spark DataFrame, pandas-on-Spark DataFrame or pandas-on-Spark Series.
Dict can contain Series, arrays, constants, or list-like objects</p>
</dd>
<dt><strong>index</strong><span class="classifier">Index or array-like</span></dt><dd><p>Index to use for the resulting frame. Will default to RangeIndex if
no indexing information part of input data and no index provided</p>
</dd>
<dt><strong>columns</strong><span class="classifier">Index or array-like</span></dt><dd><p>Column labels to use for the resulting frame. Will default to
RangeIndex (0, 1, 2, â¦, n) if no column labels are provided</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">dtype, default None</span></dt><dd><p>Data type to force. Only a single dtype is allowed. If None, infer</p>
</dd>
<dt><strong>copy</strong><span class="classifier">boolean, default False</span></dt><dd><p>Copy data from inputs. Only affects DataFrame / 2d ndarray input</p>
</dd>
<dt><strong>.. versionchanged:: 3.4.0</strong></dt><dd><p>Since 3.4.0, it deals with <cite>data</cite> and <cite>index</cite> in this approach:
1, when <cite>data</cite> is a distributed dataset (Internal DataFrame/Spark DataFrame/
pandas-on-Spark DataFrame/pandas-on-Spark Series), it will first parallelize
the <cite>index</cite> if necessary, and then try to combine the <cite>data</cite> and <cite>index</cite>;
Note that if <cite>data</cite> and <cite>index</cite> doesnât have the same anchor, then
<cite>compute.ops_on_diff_frames</cite> should be turned on;
2, when <cite>data</cite> is a local dataset (Pandas DataFrame/numpy ndarray/list/etc),
it will first collect the <cite>index</cite> to driver if necessary, and then apply
the <cite>Pandas.DataFrame(â¦)</cite> creation internally;</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Constructing DataFrame from a dictionary.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;col1&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;col2&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">,</span> <span class="s1">&#39;col2&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span>
<span class="go">   col1  col2</span>
<span class="go">0     1     3</span>
<span class="go">1     2     4</span>
</pre></div>
</div>
<p>Constructing DataFrame from pandas DataFrame</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">,</span> <span class="s1">&#39;col2&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span>
<span class="go">   col1  col2</span>
<span class="go">0     1     3</span>
<span class="go">1     2     4</span>
</pre></div>
</div>
<p>Notice that the inferred dtype is int64.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
<span class="go">col1    int64</span>
<span class="go">col2    int64</span>
<span class="go">dtype: object</span>
</pre></div>
</div>
<p>To enforce a single dtype:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">df</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">df</span><span class="o">.</span><span class="n">dtypes</span>
<span class="go">col1    int8</span>
<span class="go">col2    int8</span>
<span class="go">dtype: object</span>
</pre></div>
</div>
<p>Constructing DataFrame from numpy ndarray:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
<span class="gp">... </span>    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">])</span>
<span class="go">   a  b  c  d  e</span>
<span class="go">0  1  2  3  4  5</span>
<span class="go">1  6  7  8  9  0</span>
</pre></div>
</div>
<p>Constructing DataFrame from numpy ndarray with Pandas index:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
<span class="gp">... </span>    <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">])</span>
<span class="go">   a  b  c  d  e</span>
<span class="go">1  1  2  3  4  5</span>
<span class="go">4  6  7  8  9  0</span>
</pre></div>
</div>
<p>Constructing DataFrame from numpy ndarray with pandas-on-Spark index:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
<span class="gp">... </span>    <span class="n">index</span><span class="o">=</span><span class="n">ps</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">])</span>
<span class="go">   a  b  c  d  e</span>
<span class="go">1  1  2  3  4  5</span>
<span class="go">4  6  7  8  9  0</span>
</pre></div>
</div>
<p>Constructing DataFrame from Pandas DataFrame with Pandas index:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
<span class="gp">... </span>    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pdf</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
<span class="go">     a    b    c    d    e</span>
<span class="go">1  6.0  7.0  8.0  9.0  0.0</span>
<span class="go">4  NaN  NaN  NaN  NaN  NaN</span>
</pre></div>
</div>
<p>Constructing DataFrame from Pandas DataFrame with pandas-on-Spark index:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
<span class="gp">... </span>    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pdf</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">ps</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
<span class="go">     a    b    c    d    e</span>
<span class="go">1  6.0  7.0  8.0  9.0  0.0</span>
<span class="go">4  NaN  NaN  NaN  NaN  NaN</span>
</pre></div>
</div>
<p>Constructing DataFrame from Spark DataFrame with Pandas index:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="s2">&quot;Data&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Bricks&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sdf</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">ValueError</span>: <span class="n">Cannot combine the series or dataframe...&#39;compute.ops_on_diff_frames&#39; option.</span>
</pre></div>
</div>
<p>Enable âcompute.ops_on_diff_framesâ to combine SparkDataFrame and Pandas index</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">ps</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;compute.ops_on_diff_frames&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sdf</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="go">        x    y</span>
<span class="go">0    Data  1.0</span>
<span class="go">1  Bricks  2.0</span>
<span class="go">2    None  NaN</span>
</pre></div>
</div>
<p>Constructing DataFrame from Spark DataFrame with pandas-on-Spark index:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([(</span><span class="s2">&quot;Data&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Bricks&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sdf</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">ps</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="w">  </span><span class="c">...</span>
<span class="gr">ValueError</span>: <span class="n">Cannot combine the series or dataframe...&#39;compute.ops_on_diff_frames&#39; option.</span>
</pre></div>
</div>
<p>Enable âcompute.ops_on_diff_framesâ to combine Spark DataFrame and pandas-on-Spark index</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">ps</span><span class="o">.</span><span class="n">option_context</span><span class="p">(</span><span class="s2">&quot;compute.ops_on_diff_frames&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">sdf</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">ps</span><span class="o">.</span><span class="n">Index</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="go">        x    y</span>
<span class="go">0    Data  1.0</span>
<span class="go">1  Bricks  2.0</span>
<span class="go">2    None  NaN</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.abs.html#pyspark.pandas.DataFrame.abs" title="pyspark.pandas.DataFrame.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code></a>()</p></td>
<td><p>Return a Series/DataFrame with absolute numeric value of each element.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.add.html#pyspark.pandas.DataFrame.add" title="pyspark.pandas.DataFrame.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a>(other)</p></td>
<td><p>Get Addition of dataframe and other, element-wise (binary operator <cite>+</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.add_prefix.html#pyspark.pandas.DataFrame.add_prefix" title="pyspark.pandas.DataFrame.add_prefix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_prefix</span></code></a>(prefix)</p></td>
<td><p>Prefix labels with string <cite>prefix</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.add_suffix.html#pyspark.pandas.DataFrame.add_suffix" title="pyspark.pandas.DataFrame.add_suffix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_suffix</span></code></a>(suffix)</p></td>
<td><p>Suffix labels with string <cite>suffix</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.agg.html#pyspark.pandas.DataFrame.agg" title="pyspark.pandas.DataFrame.agg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">agg</span></code></a>(func)</p></td>
<td><p>Aggregate using one or more operations over the specified axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.aggregate.html#pyspark.pandas.DataFrame.aggregate" title="pyspark.pandas.DataFrame.aggregate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">aggregate</span></code></a>(func)</p></td>
<td><p>Aggregate using one or more operations over the specified axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.align.html#pyspark.pandas.DataFrame.align" title="pyspark.pandas.DataFrame.align"><code class="xref py py-obj docutils literal notranslate"><span class="pre">align</span></code></a>(other[,Â join,Â axis,Â copy])</p></td>
<td><p>Align two objects on their axes with the specified join method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.all.html#pyspark.pandas.DataFrame.all" title="pyspark.pandas.DataFrame.all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all</span></code></a>([axis,Â bool_only,Â skipna])</p></td>
<td><p>Return whether all elements are True.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.any.html#pyspark.pandas.DataFrame.any" title="pyspark.pandas.DataFrame.any"><code class="xref py py-obj docutils literal notranslate"><span class="pre">any</span></code></a>([axis,Â bool_only])</p></td>
<td><p>Return whether any element is True.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.append.html#pyspark.pandas.DataFrame.append" title="pyspark.pandas.DataFrame.append"><code class="xref py py-obj docutils literal notranslate"><span class="pre">append</span></code></a>(other[,Â ignore_index,Â â¦])</p></td>
<td><p>Append rows of other to the end of caller, returning a new object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.apply.html#pyspark.pandas.DataFrame.apply" title="pyspark.pandas.DataFrame.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a>(func[,Â axis,Â args])</p></td>
<td><p>Apply a function along an axis of the DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.applymap.html#pyspark.pandas.DataFrame.applymap" title="pyspark.pandas.DataFrame.applymap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">applymap</span></code></a>(func)</p></td>
<td><p>Apply a function to a Dataframe elementwise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.assign.html#pyspark.pandas.DataFrame.assign" title="pyspark.pandas.DataFrame.assign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">assign</span></code></a>(**kwargs)</p></td>
<td><p>Assign new columns to a DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.astype.html#pyspark.pandas.DataFrame.astype" title="pyspark.pandas.DataFrame.astype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">astype</span></code></a>(dtype)</p></td>
<td><p>Cast a pandas-on-Spark object to a specified dtype <code class="docutils literal notranslate"><span class="pre">dtype</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.at_time.html#pyspark.pandas.DataFrame.at_time" title="pyspark.pandas.DataFrame.at_time"><code class="xref py py-obj docutils literal notranslate"><span class="pre">at_time</span></code></a>(time[,Â asof,Â axis])</p></td>
<td><p>Select values at particular time of day (example: 9:30AM).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.backfill.html#pyspark.pandas.DataFrame.backfill" title="pyspark.pandas.DataFrame.backfill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">backfill</span></code></a>([axis,Â inplace,Â limit])</p></td>
<td><p>Synonym for <cite>DataFrame.fillna()</cite> or <cite>Series.fillna()</cite> with <code class="docutils literal notranslate"><span class="pre">method=`bfill`</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.between_time.html#pyspark.pandas.DataFrame.between_time" title="pyspark.pandas.DataFrame.between_time"><code class="xref py py-obj docutils literal notranslate"><span class="pre">between_time</span></code></a>(start_time,Â end_time[,Â â¦])</p></td>
<td><p>Select values between particular times of the day (example: 9:00-9:30 AM).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.bfill.html#pyspark.pandas.DataFrame.bfill" title="pyspark.pandas.DataFrame.bfill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfill</span></code></a>([axis,Â inplace,Â limit])</p></td>
<td><p>Synonym for <cite>DataFrame.fillna()</cite> or <cite>Series.fillna()</cite> with <code class="docutils literal notranslate"><span class="pre">method=`bfill`</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.bool.html#pyspark.pandas.DataFrame.bool" title="pyspark.pandas.DataFrame.bool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>()</p></td>
<td><p>Return the bool of a single element in the current object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.boxplot.html#pyspark.pandas.DataFrame.boxplot" title="pyspark.pandas.DataFrame.boxplot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">boxplot</span></code></a>(**kwds)</p></td>
<td><p>Make a box plot of the Series columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.clip.html#pyspark.pandas.DataFrame.clip" title="pyspark.pandas.DataFrame.clip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clip</span></code></a>([lower,Â upper])</p></td>
<td><p>Trim values at input threshold(s).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.combine_first.html#pyspark.pandas.DataFrame.combine_first" title="pyspark.pandas.DataFrame.combine_first"><code class="xref py py-obj docutils literal notranslate"><span class="pre">combine_first</span></code></a>(other)</p></td>
<td><p>Update null elements with value in the same location in <cite>other</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.copy.html#pyspark.pandas.DataFrame.copy" title="pyspark.pandas.DataFrame.copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">copy</span></code></a>([deep])</p></td>
<td><p>Make a copy of this objectâs indices and data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.corr.html#pyspark.pandas.DataFrame.corr" title="pyspark.pandas.DataFrame.corr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">corr</span></code></a>([method,Â min_periods])</p></td>
<td><p>Compute pairwise correlation of columns, excluding NA/null values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.corrwith.html#pyspark.pandas.DataFrame.corrwith" title="pyspark.pandas.DataFrame.corrwith"><code class="xref py py-obj docutils literal notranslate"><span class="pre">corrwith</span></code></a>(other[,Â axis,Â drop,Â method])</p></td>
<td><p>Compute pairwise correlation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.count.html#pyspark.pandas.DataFrame.count" title="pyspark.pandas.DataFrame.count"><code class="xref py py-obj docutils literal notranslate"><span class="pre">count</span></code></a>([axis,Â numeric_only])</p></td>
<td><p>Count non-NA cells for each column.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.cov.html#pyspark.pandas.DataFrame.cov" title="pyspark.pandas.DataFrame.cov"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cov</span></code></a>([min_periods,Â ddof])</p></td>
<td><p>Compute pairwise covariance of columns, excluding NA/null values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.cummax.html#pyspark.pandas.DataFrame.cummax" title="pyspark.pandas.DataFrame.cummax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cummax</span></code></a>([skipna])</p></td>
<td><p>Return cumulative maximum over a DataFrame or Series axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.cummin.html#pyspark.pandas.DataFrame.cummin" title="pyspark.pandas.DataFrame.cummin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cummin</span></code></a>([skipna])</p></td>
<td><p>Return cumulative minimum over a DataFrame or Series axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.cumprod.html#pyspark.pandas.DataFrame.cumprod" title="pyspark.pandas.DataFrame.cumprod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cumprod</span></code></a>([skipna])</p></td>
<td><p>Return cumulative product over a DataFrame or Series axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.cumsum.html#pyspark.pandas.DataFrame.cumsum" title="pyspark.pandas.DataFrame.cumsum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cumsum</span></code></a>([skipna])</p></td>
<td><p>Return cumulative sum over a DataFrame or Series axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.describe.html#pyspark.pandas.DataFrame.describe" title="pyspark.pandas.DataFrame.describe"><code class="xref py py-obj docutils literal notranslate"><span class="pre">describe</span></code></a>([percentiles])</p></td>
<td><p>Generate descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâs distribution, excluding <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.diff.html#pyspark.pandas.DataFrame.diff" title="pyspark.pandas.DataFrame.diff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diff</span></code></a>([periods,Â axis])</p></td>
<td><p>First discrete difference of element.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.div.html#pyspark.pandas.DataFrame.div" title="pyspark.pandas.DataFrame.div"><code class="xref py py-obj docutils literal notranslate"><span class="pre">div</span></code></a>(other)</p></td>
<td><p>Get Floating division of dataframe and other, element-wise (binary operator <cite>/</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">divide</span></code>(other)</p></td>
<td><p>Get Floating division of dataframe and other, element-wise (binary operator <cite>/</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.dot.html#pyspark.pandas.DataFrame.dot" title="pyspark.pandas.DataFrame.dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dot</span></code></a>(other)</p></td>
<td><p>Compute the matrix multiplication between the DataFrame and others.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.drop.html#pyspark.pandas.DataFrame.drop" title="pyspark.pandas.DataFrame.drop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">drop</span></code></a>([labels,Â axis,Â index,Â columns])</p></td>
<td><p>Drop specified labels from columns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.drop_duplicates.html#pyspark.pandas.DataFrame.drop_duplicates" title="pyspark.pandas.DataFrame.drop_duplicates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">drop_duplicates</span></code></a>([subset,Â keep,Â inplace,Â â¦])</p></td>
<td><p>Return DataFrame with duplicate rows removed, optionally only considering certain columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.droplevel.html#pyspark.pandas.DataFrame.droplevel" title="pyspark.pandas.DataFrame.droplevel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">droplevel</span></code></a>(level[,Â axis])</p></td>
<td><p>Return DataFrame with requested index / column level(s) removed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.dropna.html#pyspark.pandas.DataFrame.dropna" title="pyspark.pandas.DataFrame.dropna"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dropna</span></code></a>([axis,Â how,Â thresh,Â subset,Â inplace])</p></td>
<td><p>Remove missing values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.duplicated.html#pyspark.pandas.DataFrame.duplicated" title="pyspark.pandas.DataFrame.duplicated"><code class="xref py py-obj docutils literal notranslate"><span class="pre">duplicated</span></code></a>([subset,Â keep])</p></td>
<td><p>Return boolean Series denoting duplicate rows, optionally only considering certain columns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.eq.html#pyspark.pandas.DataFrame.eq" title="pyspark.pandas.DataFrame.eq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eq</span></code></a>(other)</p></td>
<td><p>Compare if the current value is equal to the other.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.equals.html#pyspark.pandas.DataFrame.equals" title="pyspark.pandas.DataFrame.equals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">equals</span></code></a>(other)</p></td>
<td><p>Compare if the current value is equal to the other.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.eval.html#pyspark.pandas.DataFrame.eval" title="pyspark.pandas.DataFrame.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a>(expr[,Â inplace])</p></td>
<td><p>Evaluate a string describing operations on DataFrame columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.ewm.html#pyspark.pandas.DataFrame.ewm" title="pyspark.pandas.DataFrame.ewm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ewm</span></code></a>([com,Â span,Â halflife,Â alpha,Â â¦])</p></td>
<td><p>Provide exponentially weighted window transformations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.expanding.html#pyspark.pandas.DataFrame.expanding" title="pyspark.pandas.DataFrame.expanding"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expanding</span></code></a>([min_periods])</p></td>
<td><p>Provide expanding transformations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.explode.html#pyspark.pandas.DataFrame.explode" title="pyspark.pandas.DataFrame.explode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explode</span></code></a>(column[,Â ignore_index])</p></td>
<td><p>Transform each element of a list-like to a row, replicating index values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.ffill.html#pyspark.pandas.DataFrame.ffill" title="pyspark.pandas.DataFrame.ffill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ffill</span></code></a>([axis,Â inplace,Â limit])</p></td>
<td><p>Synonym for <cite>DataFrame.fillna()</cite> or <cite>Series.fillna()</cite> with <code class="docutils literal notranslate"><span class="pre">method=`ffill`</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.fillna.html#pyspark.pandas.DataFrame.fillna" title="pyspark.pandas.DataFrame.fillna"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fillna</span></code></a>([value,Â method,Â axis,Â inplace,Â limit])</p></td>
<td><p>Fill NA/NaN values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.filter.html#pyspark.pandas.DataFrame.filter" title="pyspark.pandas.DataFrame.filter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filter</span></code></a>([items,Â like,Â regex,Â axis])</p></td>
<td><p>Subset rows or columns of dataframe according to labels in the specified index.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.first.html#pyspark.pandas.DataFrame.first" title="pyspark.pandas.DataFrame.first"><code class="xref py py-obj docutils literal notranslate"><span class="pre">first</span></code></a>(offset)</p></td>
<td><p>Select first periods of time series data based on a date offset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.first_valid_index.html#pyspark.pandas.DataFrame.first_valid_index" title="pyspark.pandas.DataFrame.first_valid_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">first_valid_index</span></code></a>()</p></td>
<td><p>Retrieves the index of the first valid value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.floordiv.html#pyspark.pandas.DataFrame.floordiv" title="pyspark.pandas.DataFrame.floordiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floordiv</span></code></a>(other)</p></td>
<td><p>Get Integer division of dataframe and other, element-wise (binary operator <cite>//</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_dict</span></code>(data[,Â orient,Â dtype,Â columns])</p></td>
<td><p>Construct DataFrame from dict of array-like or dicts.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.from_records.html#pyspark.pandas.DataFrame.from_records" title="pyspark.pandas.DataFrame.from_records"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_records</span></code></a>(data[,Â index,Â exclude,Â â¦])</p></td>
<td><p>Convert structured or recorded ndarray to DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.ge.html#pyspark.pandas.DataFrame.ge" title="pyspark.pandas.DataFrame.ge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ge</span></code></a>(other)</p></td>
<td><p>Compare if the current value is greater than or equal to the other.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.get.html#pyspark.pandas.DataFrame.get" title="pyspark.pandas.DataFrame.get"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get</span></code></a>(key[,Â default])</p></td>
<td><p>Get item from object for given key (DataFrame column, Panel slice, etc.).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_dtype_counts</span></code>()</p></td>
<td><p>Return counts of unique dtypes in this object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.groupby.html#pyspark.pandas.DataFrame.groupby" title="pyspark.pandas.DataFrame.groupby"><code class="xref py py-obj docutils literal notranslate"><span class="pre">groupby</span></code></a>(by[,Â axis,Â as_index,Â dropna])</p></td>
<td><p>Group DataFrame or Series using one or more columns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.gt.html#pyspark.pandas.DataFrame.gt" title="pyspark.pandas.DataFrame.gt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gt</span></code></a>(other)</p></td>
<td><p>Compare if the current value is greater than the other.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.head.html#pyspark.pandas.DataFrame.head" title="pyspark.pandas.DataFrame.head"><code class="xref py py-obj docutils literal notranslate"><span class="pre">head</span></code></a>([n])</p></td>
<td><p>Return the first <cite>n</cite> rows.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.hist.html#pyspark.pandas.DataFrame.hist" title="pyspark.pandas.DataFrame.hist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hist</span></code></a>([bins])</p></td>
<td><p>Draw one histogram of the DataFrameâs columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.idxmax.html#pyspark.pandas.DataFrame.idxmax" title="pyspark.pandas.DataFrame.idxmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">idxmax</span></code></a>([axis])</p></td>
<td><p>Return index of first occurrence of maximum over requested axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.idxmin.html#pyspark.pandas.DataFrame.idxmin" title="pyspark.pandas.DataFrame.idxmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">idxmin</span></code></a>([axis])</p></td>
<td><p>Return index of first occurrence of minimum over requested axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.info.html#pyspark.pandas.DataFrame.info" title="pyspark.pandas.DataFrame.info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">info</span></code></a>([verbose,Â buf,Â max_cols,Â null_counts])</p></td>
<td><p>Print a concise summary of a DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.insert.html#pyspark.pandas.DataFrame.insert" title="pyspark.pandas.DataFrame.insert"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert</span></code></a>(loc,Â column,Â value[,Â allow_duplicates])</p></td>
<td><p>Insert column into DataFrame at specified location.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.interpolate.html#pyspark.pandas.DataFrame.interpolate" title="pyspark.pandas.DataFrame.interpolate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">interpolate</span></code></a>([method,Â limit,Â â¦])</p></td>
<td><p>Fill NaN values using an interpolation method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.isin.html#pyspark.pandas.DataFrame.isin" title="pyspark.pandas.DataFrame.isin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isin</span></code></a>(values)</p></td>
<td><p>Whether each element in the DataFrame is contained in values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.isna.html#pyspark.pandas.DataFrame.isna" title="pyspark.pandas.DataFrame.isna"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isna</span></code></a>()</p></td>
<td><p>Detects missing values for items in the current Dataframe.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.isnull.html#pyspark.pandas.DataFrame.isnull" title="pyspark.pandas.DataFrame.isnull"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isnull</span></code></a>()</p></td>
<td><p>Detects missing values for items in the current Dataframe.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.items.html#pyspark.pandas.DataFrame.items" title="pyspark.pandas.DataFrame.items"><code class="xref py py-obj docutils literal notranslate"><span class="pre">items</span></code></a>()</p></td>
<td><p>Iterator over (column name, Series) pairs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.iteritems.html#pyspark.pandas.DataFrame.iteritems" title="pyspark.pandas.DataFrame.iteritems"><code class="xref py py-obj docutils literal notranslate"><span class="pre">iteritems</span></code></a>()</p></td>
<td><p>This is an alias of <code class="docutils literal notranslate"><span class="pre">items</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.iterrows.html#pyspark.pandas.DataFrame.iterrows" title="pyspark.pandas.DataFrame.iterrows"><code class="xref py py-obj docutils literal notranslate"><span class="pre">iterrows</span></code></a>()</p></td>
<td><p>Iterate over DataFrame rows as (index, Series) pairs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.itertuples.html#pyspark.pandas.DataFrame.itertuples" title="pyspark.pandas.DataFrame.itertuples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">itertuples</span></code></a>([index,Â name])</p></td>
<td><p>Iterate over DataFrame rows as namedtuples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.join.html#pyspark.pandas.DataFrame.join" title="pyspark.pandas.DataFrame.join"><code class="xref py py-obj docutils literal notranslate"><span class="pre">join</span></code></a>(right[,Â on,Â how,Â lsuffix,Â rsuffix])</p></td>
<td><p>Join columns of another DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.kde.html#pyspark.pandas.DataFrame.kde" title="pyspark.pandas.DataFrame.kde"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kde</span></code></a>([bw_method,Â ind])</p></td>
<td><p>Generate Kernel Density Estimate plot using Gaussian kernels.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.keys.html#pyspark.pandas.DataFrame.keys" title="pyspark.pandas.DataFrame.keys"><code class="xref py py-obj docutils literal notranslate"><span class="pre">keys</span></code></a>()</p></td>
<td><p>Return alias for columns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.kurt.html#pyspark.pandas.DataFrame.kurt" title="pyspark.pandas.DataFrame.kurt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kurt</span></code></a>([axis,Â skipna,Â numeric_only])</p></td>
<td><p>Return unbiased kurtosis using Fisherâs definition of kurtosis (kurtosis of normal == 0.0).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.kurtosis.html#pyspark.pandas.DataFrame.kurtosis" title="pyspark.pandas.DataFrame.kurtosis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kurtosis</span></code></a>([axis,Â skipna,Â numeric_only])</p></td>
<td><p>Return unbiased kurtosis using Fisherâs definition of kurtosis (kurtosis of normal == 0.0).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.last.html#pyspark.pandas.DataFrame.last" title="pyspark.pandas.DataFrame.last"><code class="xref py py-obj docutils literal notranslate"><span class="pre">last</span></code></a>(offset)</p></td>
<td><p>Select final periods of time series data based on a date offset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.last_valid_index.html#pyspark.pandas.DataFrame.last_valid_index" title="pyspark.pandas.DataFrame.last_valid_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">last_valid_index</span></code></a>()</p></td>
<td><p>Return index for last non-NA/null value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.le.html#pyspark.pandas.DataFrame.le" title="pyspark.pandas.DataFrame.le"><code class="xref py py-obj docutils literal notranslate"><span class="pre">le</span></code></a>(other)</p></td>
<td><p>Compare if the current value is less than or equal to the other.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.lt.html#pyspark.pandas.DataFrame.lt" title="pyspark.pandas.DataFrame.lt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lt</span></code></a>(other)</p></td>
<td><p>Compare if the current value is less than the other.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.mad.html#pyspark.pandas.DataFrame.mad" title="pyspark.pandas.DataFrame.mad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mad</span></code></a>([axis])</p></td>
<td><p>Return the mean absolute deviation of values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.mask.html#pyspark.pandas.DataFrame.mask" title="pyspark.pandas.DataFrame.mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mask</span></code></a>(cond[,Â other])</p></td>
<td><p>Replace values where the condition is True.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.max.html#pyspark.pandas.DataFrame.max" title="pyspark.pandas.DataFrame.max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max</span></code></a>([axis,Â skipna,Â numeric_only])</p></td>
<td><p>Return the maximum of the values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.mean.html#pyspark.pandas.DataFrame.mean" title="pyspark.pandas.DataFrame.mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mean</span></code></a>([axis,Â skipna,Â numeric_only])</p></td>
<td><p>Return the mean of the values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.median.html#pyspark.pandas.DataFrame.median" title="pyspark.pandas.DataFrame.median"><code class="xref py py-obj docutils literal notranslate"><span class="pre">median</span></code></a>([axis,Â skipna,Â numeric_only,Â accuracy])</p></td>
<td><p>Return the median of the values for the requested axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.melt.html#pyspark.pandas.DataFrame.melt" title="pyspark.pandas.DataFrame.melt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">melt</span></code></a>([id_vars,Â value_vars,Â var_name,Â value_name])</p></td>
<td><p>Unpivot a DataFrame from wide format to long format, optionally leaving identifier variables set.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.merge.html#pyspark.pandas.DataFrame.merge" title="pyspark.pandas.DataFrame.merge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">merge</span></code></a>(right[,Â how,Â on,Â left_on,Â right_on,Â â¦])</p></td>
<td><p>Merge DataFrame objects with a database-style join.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.min.html#pyspark.pandas.DataFrame.min" title="pyspark.pandas.DataFrame.min"><code class="xref py py-obj docutils literal notranslate"><span class="pre">min</span></code></a>([axis,Â skipna,Â numeric_only])</p></td>
<td><p>Return the minimum of the values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.mod.html#pyspark.pandas.DataFrame.mod" title="pyspark.pandas.DataFrame.mod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mod</span></code></a>(other)</p></td>
<td><p>Get Modulo of dataframe and other, element-wise (binary operator <cite>%</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.mode.html#pyspark.pandas.DataFrame.mode" title="pyspark.pandas.DataFrame.mode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code></a>([axis,Â numeric_only,Â dropna])</p></td>
<td><p>Get the mode(s) of each element along the selected axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.mul.html#pyspark.pandas.DataFrame.mul" title="pyspark.pandas.DataFrame.mul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mul</span></code></a>(other)</p></td>
<td><p>Get Multiplication of dataframe and other, element-wise (binary operator <cite>*</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">multiply</span></code>(other)</p></td>
<td><p>Get Multiplication of dataframe and other, element-wise (binary operator <cite>*</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.ne.html#pyspark.pandas.DataFrame.ne" title="pyspark.pandas.DataFrame.ne"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ne</span></code></a>(other)</p></td>
<td><p>Compare if the current value is not equal to the other.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.nlargest.html#pyspark.pandas.DataFrame.nlargest" title="pyspark.pandas.DataFrame.nlargest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nlargest</span></code></a>(n,Â columns[,Â keep])</p></td>
<td><p>Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in descending order.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.notna.html#pyspark.pandas.DataFrame.notna" title="pyspark.pandas.DataFrame.notna"><code class="xref py py-obj docutils literal notranslate"><span class="pre">notna</span></code></a>()</p></td>
<td><p>Detects non-missing values for items in the current Dataframe.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.notnull.html#pyspark.pandas.DataFrame.notnull" title="pyspark.pandas.DataFrame.notnull"><code class="xref py py-obj docutils literal notranslate"><span class="pre">notnull</span></code></a>()</p></td>
<td><p>Detects non-missing values for items in the current Dataframe.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.nsmallest.html#pyspark.pandas.DataFrame.nsmallest" title="pyspark.pandas.DataFrame.nsmallest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nsmallest</span></code></a>(n,Â columns[,Â keep])</p></td>
<td><p>Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in ascending order.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.nunique.html#pyspark.pandas.DataFrame.nunique" title="pyspark.pandas.DataFrame.nunique"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nunique</span></code></a>([axis,Â dropna,Â approx,Â rsd])</p></td>
<td><p>Return number of unique elements in the object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pad.html#pyspark.pandas.DataFrame.pad" title="pyspark.pandas.DataFrame.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code></a>([axis,Â inplace,Â limit])</p></td>
<td><p>Synonym for <cite>DataFrame.fillna()</cite> or <cite>Series.fillna()</cite> with <code class="docutils literal notranslate"><span class="pre">method=`ffill`</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pct_change.html#pyspark.pandas.DataFrame.pct_change" title="pyspark.pandas.DataFrame.pct_change"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pct_change</span></code></a>([periods])</p></td>
<td><p>Percentage change between the current and a prior element.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pipe.html#pyspark.pandas.DataFrame.pipe" title="pyspark.pandas.DataFrame.pipe"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pipe</span></code></a>(func,Â *args,Â **kwargs)</p></td>
<td><p>Apply func(self, *args, **kwargs).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pivot.html#pyspark.pandas.DataFrame.pivot" title="pyspark.pandas.DataFrame.pivot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pivot</span></code></a>([index,Â columns,Â values])</p></td>
<td><p>Return reshaped DataFrame organized by given index / column values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pivot_table.html#pyspark.pandas.DataFrame.pivot_table" title="pyspark.pandas.DataFrame.pivot_table"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pivot_table</span></code></a>([values,Â index,Â columns,Â â¦])</p></td>
<td><p>Create a spreadsheet-style pivot table as a DataFrame.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pop.html#pyspark.pandas.DataFrame.pop" title="pyspark.pandas.DataFrame.pop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pop</span></code></a>(item)</p></td>
<td><p>Return item and drop from frame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.pow.html#pyspark.pandas.DataFrame.pow" title="pyspark.pandas.DataFrame.pow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pow</span></code></a>(other)</p></td>
<td><p>Get Exponential power of series of dataframe and other, element-wise (binary operator <cite>**</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.prod.html#pyspark.pandas.DataFrame.prod" title="pyspark.pandas.DataFrame.prod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prod</span></code></a>([axis,Â skipna,Â numeric_only,Â min_count])</p></td>
<td><p>Return the product of the values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.product.html#pyspark.pandas.DataFrame.product" title="pyspark.pandas.DataFrame.product"><code class="xref py py-obj docutils literal notranslate"><span class="pre">product</span></code></a>([axis,Â skipna,Â numeric_only,Â min_count])</p></td>
<td><p>Return the product of the values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.quantile.html#pyspark.pandas.DataFrame.quantile" title="pyspark.pandas.DataFrame.quantile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantile</span></code></a>([q,Â axis,Â numeric_only,Â accuracy])</p></td>
<td><p>Return value at the given quantile.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.query.html#pyspark.pandas.DataFrame.query" title="pyspark.pandas.DataFrame.query"><code class="xref py py-obj docutils literal notranslate"><span class="pre">query</span></code></a>(expr[,Â inplace])</p></td>
<td><p>Query the columns of a DataFrame with a boolean expression.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.radd.html#pyspark.pandas.DataFrame.radd" title="pyspark.pandas.DataFrame.radd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">radd</span></code></a>(other)</p></td>
<td><p>Get Addition of dataframe and other, element-wise (binary operator <cite>+</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rank.html#pyspark.pandas.DataFrame.rank" title="pyspark.pandas.DataFrame.rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rank</span></code></a>([method,Â ascending,Â numeric_only])</p></td>
<td><p>Compute numerical data ranks (1 through n) along axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rdiv.html#pyspark.pandas.DataFrame.rdiv" title="pyspark.pandas.DataFrame.rdiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rdiv</span></code></a>(other)</p></td>
<td><p>Get Floating division of dataframe and other, element-wise (binary operator <cite>/</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.reindex.html#pyspark.pandas.DataFrame.reindex" title="pyspark.pandas.DataFrame.reindex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reindex</span></code></a>([labels,Â index,Â columns,Â axis,Â â¦])</p></td>
<td><p>Conform DataFrame to new index with optional filling logic, placing NA/NaN in locations having no value in the previous index.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.reindex_like.html#pyspark.pandas.DataFrame.reindex_like" title="pyspark.pandas.DataFrame.reindex_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reindex_like</span></code></a>(other[,Â copy])</p></td>
<td><p>Return a DataFrame with matching indices as other object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rename.html#pyspark.pandas.DataFrame.rename" title="pyspark.pandas.DataFrame.rename"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rename</span></code></a>([mapper,Â index,Â columns,Â axis,Â â¦])</p></td>
<td><p>Alter axes labels.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rename_axis.html#pyspark.pandas.DataFrame.rename_axis" title="pyspark.pandas.DataFrame.rename_axis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rename_axis</span></code></a>([mapper,Â index,Â columns,Â axis,Â â¦])</p></td>
<td><p>Set the name of the axis for the index or columns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.replace.html#pyspark.pandas.DataFrame.replace" title="pyspark.pandas.DataFrame.replace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">replace</span></code></a>([to_replace,Â value,Â inplace,Â limit,Â â¦])</p></td>
<td><p>Returns a new DataFrame replacing a value with another value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.resample.html#pyspark.pandas.DataFrame.resample" title="pyspark.pandas.DataFrame.resample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resample</span></code></a>(rule[,Â closed,Â label,Â on])</p></td>
<td><p>Resample time-series data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.reset_index.html#pyspark.pandas.DataFrame.reset_index" title="pyspark.pandas.DataFrame.reset_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_index</span></code></a>([level,Â drop,Â inplace,Â â¦])</p></td>
<td><p>Reset the index, or a level of it.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rfloordiv.html#pyspark.pandas.DataFrame.rfloordiv" title="pyspark.pandas.DataFrame.rfloordiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rfloordiv</span></code></a>(other)</p></td>
<td><p>Get Integer division of dataframe and other, element-wise (binary operator <cite>//</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rmod.html#pyspark.pandas.DataFrame.rmod" title="pyspark.pandas.DataFrame.rmod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rmod</span></code></a>(other)</p></td>
<td><p>Get Modulo of dataframe and other, element-wise (binary operator <cite>%</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rmul.html#pyspark.pandas.DataFrame.rmul" title="pyspark.pandas.DataFrame.rmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rmul</span></code></a>(other)</p></td>
<td><p>Get Multiplication of dataframe and other, element-wise (binary operator <cite>*</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rolling.html#pyspark.pandas.DataFrame.rolling" title="pyspark.pandas.DataFrame.rolling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rolling</span></code></a>(window[,Â min_periods])</p></td>
<td><p>Provide rolling transformations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.round.html#pyspark.pandas.DataFrame.round" title="pyspark.pandas.DataFrame.round"><code class="xref py py-obj docutils literal notranslate"><span class="pre">round</span></code></a>([decimals])</p></td>
<td><p>Round a DataFrame to a variable number of decimal places.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rpow.html#pyspark.pandas.DataFrame.rpow" title="pyspark.pandas.DataFrame.rpow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rpow</span></code></a>(other)</p></td>
<td><p>Get Exponential power of dataframe and other, element-wise (binary operator <cite>**</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rsub.html#pyspark.pandas.DataFrame.rsub" title="pyspark.pandas.DataFrame.rsub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rsub</span></code></a>(other)</p></td>
<td><p>Get Subtraction of dataframe and other, element-wise (binary operator <cite>-</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.rtruediv.html#pyspark.pandas.DataFrame.rtruediv" title="pyspark.pandas.DataFrame.rtruediv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rtruediv</span></code></a>(other)</p></td>
<td><p>Get Floating division of dataframe and other, element-wise (binary operator <cite>/</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.sample.html#pyspark.pandas.DataFrame.sample" title="pyspark.pandas.DataFrame.sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code></a>([n,Â frac,Â replace,Â random_state,Â â¦])</p></td>
<td><p>Return a random sample of items from an axis of object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.select_dtypes.html#pyspark.pandas.DataFrame.select_dtypes" title="pyspark.pandas.DataFrame.select_dtypes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">select_dtypes</span></code></a>([include,Â exclude])</p></td>
<td><p>Return a subset of the DataFrameâs columns based on the column dtypes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.sem.html#pyspark.pandas.DataFrame.sem" title="pyspark.pandas.DataFrame.sem"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sem</span></code></a>([axis,Â skipna,Â ddof,Â numeric_only])</p></td>
<td><p>Return unbiased standard error of the mean over requested axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.set_index.html#pyspark.pandas.DataFrame.set_index" title="pyspark.pandas.DataFrame.set_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_index</span></code></a>(keys[,Â drop,Â append,Â inplace])</p></td>
<td><p>Set the DataFrame index (row labels) using one or more existing columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.shift.html#pyspark.pandas.DataFrame.shift" title="pyspark.pandas.DataFrame.shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shift</span></code></a>([periods,Â fill_value])</p></td>
<td><p>Shift DataFrame by desired number of periods.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.skew.html#pyspark.pandas.DataFrame.skew" title="pyspark.pandas.DataFrame.skew"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skew</span></code></a>([axis,Â skipna,Â numeric_only])</p></td>
<td><p>Return unbiased skew normalized by N-1.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.sort_index.html#pyspark.pandas.DataFrame.sort_index" title="pyspark.pandas.DataFrame.sort_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sort_index</span></code></a>([axis,Â level,Â ascending,Â â¦])</p></td>
<td><p>Sort object by labels (along an axis)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.sort_values.html#pyspark.pandas.DataFrame.sort_values" title="pyspark.pandas.DataFrame.sort_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sort_values</span></code></a>(by[,Â ascending,Â inplace,Â â¦])</p></td>
<td><p>Sort by the values along either axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.squeeze.html#pyspark.pandas.DataFrame.squeeze" title="pyspark.pandas.DataFrame.squeeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeeze</span></code></a>([axis])</p></td>
<td><p>Squeeze 1 dimensional axis objects into scalars.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.stack.html#pyspark.pandas.DataFrame.stack" title="pyspark.pandas.DataFrame.stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stack</span></code></a>()</p></td>
<td><p>Stack the prescribed level(s) from columns to index.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.std.html#pyspark.pandas.DataFrame.std" title="pyspark.pandas.DataFrame.std"><code class="xref py py-obj docutils literal notranslate"><span class="pre">std</span></code></a>([axis,Â skipna,Â ddof,Â numeric_only])</p></td>
<td><p>Return sample standard deviation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.sub.html#pyspark.pandas.DataFrame.sub" title="pyspark.pandas.DataFrame.sub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sub</span></code></a>(other)</p></td>
<td><p>Get Subtraction of dataframe and other, element-wise (binary operator <cite>-</cite>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">subtract</span></code>(other)</p></td>
<td><p>Get Subtraction of dataframe and other, element-wise (binary operator <cite>-</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.sum.html#pyspark.pandas.DataFrame.sum" title="pyspark.pandas.DataFrame.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code></a>([axis,Â skipna,Â numeric_only,Â min_count])</p></td>
<td><p>Return the sum of the values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.swapaxes.html#pyspark.pandas.DataFrame.swapaxes" title="pyspark.pandas.DataFrame.swapaxes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">swapaxes</span></code></a>(i,Â j[,Â copy])</p></td>
<td><p>Interchange axes and swap values axes appropriately.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.swaplevel.html#pyspark.pandas.DataFrame.swaplevel" title="pyspark.pandas.DataFrame.swaplevel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">swaplevel</span></code></a>([i,Â j,Â axis])</p></td>
<td><p>Swap levels i and j in a MultiIndex on a particular axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.tail.html#pyspark.pandas.DataFrame.tail" title="pyspark.pandas.DataFrame.tail"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tail</span></code></a>([n])</p></td>
<td><p>Return the last <cite>n</cite> rows.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.take.html#pyspark.pandas.DataFrame.take" title="pyspark.pandas.DataFrame.take"><code class="xref py py-obj docutils literal notranslate"><span class="pre">take</span></code></a>(indices[,Â axis])</p></td>
<td><p>Return the elements in the given <em>positional</em> indices along an axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_clipboard.html#pyspark.pandas.DataFrame.to_clipboard" title="pyspark.pandas.DataFrame.to_clipboard"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_clipboard</span></code></a>([excel,Â sep])</p></td>
<td><p>Copy object to the system clipboard.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_csv.html#pyspark.pandas.DataFrame.to_csv" title="pyspark.pandas.DataFrame.to_csv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_csv</span></code></a>([path,Â sep,Â na_rep,Â columns,Â header,Â â¦])</p></td>
<td><p>Write object to a comma-separated values (csv) file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_delta.html#pyspark.pandas.DataFrame.to_delta" title="pyspark.pandas.DataFrame.to_delta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_delta</span></code></a>(path[,Â mode,Â partition_cols,Â index_col])</p></td>
<td><p>Write the DataFrame out as a Delta Lake table.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_dict.html#pyspark.pandas.DataFrame.to_dict" title="pyspark.pandas.DataFrame.to_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_dict</span></code></a>([orient,Â into])</p></td>
<td><p>Convert the DataFrame to a dictionary.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_excel.html#pyspark.pandas.DataFrame.to_excel" title="pyspark.pandas.DataFrame.to_excel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_excel</span></code></a>(excel_writer[,Â sheet_name,Â na_rep,Â â¦])</p></td>
<td><p>Write object to an Excel sheet.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_html.html#pyspark.pandas.DataFrame.to_html" title="pyspark.pandas.DataFrame.to_html"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_html</span></code></a>([buf,Â columns,Â col_space,Â header,Â â¦])</p></td>
<td><p>Render a DataFrame as an HTML table.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_json.html#pyspark.pandas.DataFrame.to_json" title="pyspark.pandas.DataFrame.to_json"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_json</span></code></a>([path,Â compression,Â num_files,Â â¦])</p></td>
<td><p>Convert the object to a JSON string.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_latex.html#pyspark.pandas.DataFrame.to_latex" title="pyspark.pandas.DataFrame.to_latex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_latex</span></code></a>([buf,Â columns,Â col_space,Â header,Â â¦])</p></td>
<td><p>Render an object to a LaTeX tabular environment table.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_markdown.html#pyspark.pandas.DataFrame.to_markdown" title="pyspark.pandas.DataFrame.to_markdown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_markdown</span></code></a>([buf,Â mode])</p></td>
<td><p>Print Series or DataFrame in Markdown-friendly format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_numpy.html#pyspark.pandas.DataFrame.to_numpy" title="pyspark.pandas.DataFrame.to_numpy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_numpy</span></code></a>()</p></td>
<td><p>A NumPy ndarray representing the values in this DataFrame or Series.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_orc.html#pyspark.pandas.DataFrame.to_orc" title="pyspark.pandas.DataFrame.to_orc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_orc</span></code></a>(path[,Â mode,Â partition_cols,Â index_col])</p></td>
<td><p>Write a DataFrame to the ORC format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_pandas.html#pyspark.pandas.DataFrame.to_pandas" title="pyspark.pandas.DataFrame.to_pandas"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_pandas</span></code></a>()</p></td>
<td><p>Return a pandas DataFrame.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_parquet.html#pyspark.pandas.DataFrame.to_parquet" title="pyspark.pandas.DataFrame.to_parquet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_parquet</span></code></a>(path[,Â mode,Â partition_cols,Â â¦])</p></td>
<td><p>Write the DataFrame out as a Parquet file or directory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_records.html#pyspark.pandas.DataFrame.to_records" title="pyspark.pandas.DataFrame.to_records"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_records</span></code></a>([index,Â column_dtypes,Â index_dtypes])</p></td>
<td><p>Convert DataFrame to a NumPy record array.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_spark.html#pyspark.pandas.DataFrame.to_spark" title="pyspark.pandas.DataFrame.to_spark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_spark</span></code></a>([index_col])</p></td>
<td><p>Spark related features.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_spark_io.html#pyspark.pandas.DataFrame.to_spark_io" title="pyspark.pandas.DataFrame.to_spark_io"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_spark_io</span></code></a>([path,Â format,Â mode,Â â¦])</p></td>
<td><p>Write the DataFrame out to a Spark data source.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_string.html#pyspark.pandas.DataFrame.to_string" title="pyspark.pandas.DataFrame.to_string"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_string</span></code></a>([buf,Â columns,Â col_space,Â header,Â â¦])</p></td>
<td><p>Render a DataFrame to a console-friendly tabular output.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.to_table.html#pyspark.pandas.DataFrame.to_table" title="pyspark.pandas.DataFrame.to_table"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_table</span></code></a>(name[,Â format,Â mode,Â â¦])</p></td>
<td><p>Write the DataFrame into a Spark table.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.transform.html#pyspark.pandas.DataFrame.transform" title="pyspark.pandas.DataFrame.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(func[,Â axis])</p></td>
<td><p>Call <code class="docutils literal notranslate"><span class="pre">func</span></code> on self producing a Series with transformed values and that has the same length as its input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.transpose.html#pyspark.pandas.DataFrame.transpose" title="pyspark.pandas.DataFrame.transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transpose</span></code></a>()</p></td>
<td><p>Transpose index and columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.truediv.html#pyspark.pandas.DataFrame.truediv" title="pyspark.pandas.DataFrame.truediv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">truediv</span></code></a>(other)</p></td>
<td><p>Get Floating division of dataframe and other, element-wise (binary operator <cite>/</cite>).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.truncate.html#pyspark.pandas.DataFrame.truncate" title="pyspark.pandas.DataFrame.truncate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">truncate</span></code></a>([before,Â after,Â axis,Â copy])</p></td>
<td><p>Truncate a Series or DataFrame before and after some index value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.unstack.html#pyspark.pandas.DataFrame.unstack" title="pyspark.pandas.DataFrame.unstack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unstack</span></code></a>()</p></td>
<td><p>Pivot the (necessarily hierarchical) index labels.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.update.html#pyspark.pandas.DataFrame.update" title="pyspark.pandas.DataFrame.update"><code class="xref py py-obj docutils literal notranslate"><span class="pre">update</span></code></a>(other[,Â join,Â overwrite])</p></td>
<td><p>Modify in place using non-NA values from another DataFrame.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.var.html#pyspark.pandas.DataFrame.var" title="pyspark.pandas.DataFrame.var"><code class="xref py py-obj docutils literal notranslate"><span class="pre">var</span></code></a>([axis,Â ddof,Â numeric_only])</p></td>
<td><p>Return unbiased variance.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.where.html#pyspark.pandas.DataFrame.where" title="pyspark.pandas.DataFrame.where"><code class="xref py py-obj docutils literal notranslate"><span class="pre">where</span></code></a>(cond[,Â other,Â axis])</p></td>
<td><p>Replace values where the condition is False.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.xs.html#pyspark.pandas.DataFrame.xs" title="pyspark.pandas.DataFrame.xs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xs</span></code></a>(key[,Â axis,Â level])</p></td>
<td><p>Return cross-section from the DataFrame.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.T.html#pyspark.pandas.DataFrame.T" title="pyspark.pandas.DataFrame.T"><code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code></a></p></td>
<td><p>Transpose index and columns.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.at.html#pyspark.pandas.DataFrame.at" title="pyspark.pandas.DataFrame.at"><code class="xref py py-obj docutils literal notranslate"><span class="pre">at</span></code></a></p></td>
<td><p>Access a single value for a row/column label pair.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.axes.html#pyspark.pandas.DataFrame.axes" title="pyspark.pandas.DataFrame.axes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">axes</span></code></a></p></td>
<td><p>Return a list representing the axes of the DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.columns.html#pyspark.pandas.DataFrame.columns" title="pyspark.pandas.DataFrame.columns"><code class="xref py py-obj docutils literal notranslate"><span class="pre">columns</span></code></a></p></td>
<td><p>The column labels of the DataFrame.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.dtypes.html#pyspark.pandas.DataFrame.dtypes" title="pyspark.pandas.DataFrame.dtypes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dtypes</span></code></a></p></td>
<td><p>Return the dtypes in the DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.empty.html#pyspark.pandas.DataFrame.empty" title="pyspark.pandas.DataFrame.empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">empty</span></code></a></p></td>
<td><p>Returns true if the current DataFrame is empty.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.iat.html#pyspark.pandas.DataFrame.iat" title="pyspark.pandas.DataFrame.iat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">iat</span></code></a></p></td>
<td><p>Access a single value for a row/column pair by integer position.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.iloc.html#pyspark.pandas.DataFrame.iloc" title="pyspark.pandas.DataFrame.iloc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">iloc</span></code></a></p></td>
<td><p>Purely integer-location based indexing for selection by position.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.index.html#pyspark.pandas.DataFrame.index" title="pyspark.pandas.DataFrame.index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">index</span></code></a></p></td>
<td><p>The index (row labels) Column of the DataFrame.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.loc.html#pyspark.pandas.DataFrame.loc" title="pyspark.pandas.DataFrame.loc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">loc</span></code></a></p></td>
<td><p>Access a group of rows and columns by label(s) or a boolean Series.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.ndim.html#pyspark.pandas.DataFrame.ndim" title="pyspark.pandas.DataFrame.ndim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ndim</span></code></a></p></td>
<td><p>Return an int representing the number of array dimensions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.shape.html#pyspark.pandas.DataFrame.shape" title="pyspark.pandas.DataFrame.shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shape</span></code></a></p></td>
<td><p>Return a tuple representing the dimensionality of the DataFrame.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.size.html#pyspark.pandas.DataFrame.size" title="pyspark.pandas.DataFrame.size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">size</span></code></a></p></td>
<td><p>Return an int representing the number of elements in this object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.style.html#pyspark.pandas.DataFrame.style" title="pyspark.pandas.DataFrame.style"><code class="xref py py-obj docutils literal notranslate"><span class="pre">style</span></code></a></p></td>
<td><p>Property returning a Styler object containing methods for building a styled HTML representation for the DataFrame.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="pyspark.pandas.DataFrame.values.html#pyspark.pandas.DataFrame.values" title="pyspark.pandas.DataFrame.values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">values</span></code></a></p></td>
<td><p>Return a Numpy representation of the DataFrame or the Series.</p></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="../frame.html" title="previous page">DataFrame</a>
    <a class='right-next' id="next-link" href="pyspark.pandas.DataFrame.index.html" title="next page">pyspark.pandas.DataFrame.index</a>

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.3da636dd464baa7582d2.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright .<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>