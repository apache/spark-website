<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>pyspark.ml.feature &#8212; PySpark 2.1.2 documentation</title>
    
    <link rel="stylesheet" href="../../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pyspark.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '2.1.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../_static/pyspark.js"></script>
    <link rel="top" title="PySpark 2.1.2 documentation" href="../../../index.html" />
    <link rel="up" title="Module code" href="../../index.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
    
        <li class="nav-item nav-item-0"><a href="../../../index.html">PySpark 2.1.2 documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for pyspark.ml.feature</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c1"># contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c1"># this work for additional information regarding copyright ownership.</span>
<span class="c1"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c1"># (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c1"># the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span> <span class="o">&gt;</span> <span class="s1">&#39;3&#39;</span><span class="p">:</span>
    <span class="n">basestring</span> <span class="o">=</span> <span class="nb">str</span>

<span class="kn">from</span> <span class="nn">pyspark</span> <span class="k">import</span> <span class="n">since</span><span class="p">,</span> <span class="n">keyword_only</span>
<span class="kn">from</span> <span class="nn">pyspark.rdd</span> <span class="k">import</span> <span class="n">ignore_unicode_prefix</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="k">import</span> <span class="n">_convert_to_vector</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.param.shared</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.util</span> <span class="k">import</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.wrapper</span> <span class="k">import</span> <span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">_jvm</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.common</span> <span class="k">import</span> <span class="n">inherit_doc</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Binarizer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Bucketizer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;ChiSqSelector&#39;</span><span class="p">,</span> <span class="s1">&#39;ChiSqSelectorModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;CountVectorizer&#39;</span><span class="p">,</span> <span class="s1">&#39;CountVectorizerModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;DCT&#39;</span><span class="p">,</span>
           <span class="s1">&#39;ElementwiseProduct&#39;</span><span class="p">,</span>
           <span class="s1">&#39;HashingTF&#39;</span><span class="p">,</span>
           <span class="s1">&#39;IDF&#39;</span><span class="p">,</span> <span class="s1">&#39;IDFModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;IndexToString&#39;</span><span class="p">,</span>
           <span class="s1">&#39;MaxAbsScaler&#39;</span><span class="p">,</span> <span class="s1">&#39;MaxAbsScalerModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;MinMaxScaler&#39;</span><span class="p">,</span> <span class="s1">&#39;MinMaxScalerModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;NGram&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Normalizer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;OneHotEncoder&#39;</span><span class="p">,</span>
           <span class="s1">&#39;PCA&#39;</span><span class="p">,</span> <span class="s1">&#39;PCAModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;PolynomialExpansion&#39;</span><span class="p">,</span>
           <span class="s1">&#39;QuantileDiscretizer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;RegexTokenizer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;RFormula&#39;</span><span class="p">,</span> <span class="s1">&#39;RFormulaModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;SQLTransformer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StandardScaler&#39;</span><span class="p">,</span> <span class="s1">&#39;StandardScalerModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StopWordsRemover&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StringIndexer&#39;</span><span class="p">,</span> <span class="s1">&#39;StringIndexerModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Tokenizer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;VectorAssembler&#39;</span><span class="p">,</span>
           <span class="s1">&#39;VectorIndexer&#39;</span><span class="p">,</span> <span class="s1">&#39;VectorIndexerModel&#39;</span><span class="p">,</span>
           <span class="s1">&#39;VectorSlicer&#39;</span><span class="p">,</span>
           <span class="s1">&#39;Word2Vec&#39;</span><span class="p">,</span> <span class="s1">&#39;Word2VecModel&#39;</span><span class="p">]</span>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="Binarizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Binarizer">[docs]</a><span class="k">class</span> <span class="nc">Binarizer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Binarize a column of continuous features given a threshold.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(0.5,)], [&quot;values&quot;])</span>
<span class="sd">    &gt;&gt;&gt; binarizer = Binarizer(threshold=1.0, inputCol=&quot;values&quot;, outputCol=&quot;features&quot;)</span>
<span class="sd">    &gt;&gt;&gt; binarizer.transform(df).head().features</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; binarizer.setParams(outputCol=&quot;freqs&quot;).transform(df).head().freqs</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; params = {binarizer.threshold: -0.5, binarizer.outputCol: &quot;vector&quot;}</span>
<span class="sd">    &gt;&gt;&gt; binarizer.transform(df, params).head().vector</span>
<span class="sd">    1.0</span>
<span class="sd">    &gt;&gt;&gt; binarizerPath = temp_path + &quot;/binarizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; binarizer.save(binarizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedBinarizer = Binarizer.load(binarizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedBinarizer.getThreshold() == binarizer.getThreshold()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;threshold in binary classification prediction, in range [0, 1]&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, threshold=0.0, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Binarizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.Binarizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Binarizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Binarizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, threshold=0.0, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this Binarizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Binarizer.setThreshold"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Binarizer.setThreshold">[docs]</a>    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`threshold`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Binarizer.getThreshold"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Binarizer.getThreshold">[docs]</a>    <span class="k">def</span> <span class="nf">getThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of threshold or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="Bucketizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Bucketizer">[docs]</a><span class="k">class</span> <span class="nc">Bucketizer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Maps a column of continuous features to a column of feature buckets.</span>

<span class="sd">    &gt;&gt;&gt; values = [(0.1,), (0.4,), (1.2,), (1.5,), (float(&quot;nan&quot;),), (float(&quot;nan&quot;),)]</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(values, [&quot;values&quot;])</span>
<span class="sd">    &gt;&gt;&gt; bucketizer = Bucketizer(splits=[-float(&quot;inf&quot;), 0.5, 1.4, float(&quot;inf&quot;)],</span>
<span class="sd">    ...     inputCol=&quot;values&quot;, outputCol=&quot;buckets&quot;)</span>
<span class="sd">    &gt;&gt;&gt; bucketed = bucketizer.setHandleInvalid(&quot;keep&quot;).transform(df).collect()</span>
<span class="sd">    &gt;&gt;&gt; len(bucketed)</span>
<span class="sd">    6</span>
<span class="sd">    &gt;&gt;&gt; bucketed[0].buckets</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; bucketed[1].buckets</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; bucketed[2].buckets</span>
<span class="sd">    1.0</span>
<span class="sd">    &gt;&gt;&gt; bucketed[3].buckets</span>
<span class="sd">    2.0</span>
<span class="sd">    &gt;&gt;&gt; bucketizer.setParams(outputCol=&quot;b&quot;).transform(df).head().b</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; bucketizerPath = temp_path + &quot;/bucketizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; bucketizer.save(bucketizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedBucketizer = Bucketizer.load(bucketizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedBucketizer.getSplits() == bucketizer.getSplits()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; bucketed = bucketizer.setHandleInvalid(&quot;skip&quot;).transform(df).collect()</span>
<span class="sd">    &gt;&gt;&gt; len(bucketed)</span>
<span class="sd">    4</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">splits</span> <span class="o">=</span> \
        <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;splits&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Split points for mapping continuous features into buckets. With n+1 splits, &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;there are n buckets. A bucket defined by splits x,y holds values in the &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;range [x,y) except the last bucket, which also includes y. The splits &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;should be of length &gt;= 3 and strictly increasing. Values at -inf, inf must be &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;explicitly provided to cover all Double values; otherwise, values outside the &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;splits specified will be treated as errors.&quot;</span><span class="p">,</span>
              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListFloat</span><span class="p">)</span>

    <span class="n">handleInvalid</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;handleInvalid&quot;</span><span class="p">,</span> <span class="s2">&quot;how to handle invalid entries. &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;Options are &#39;skip&#39; (filter out rows with invalid values), &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;&#39;error&#39; (throw an error), or &#39;keep&#39; (keep invalid values in a special &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;additional bucket).&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, splits=None, inputCol=None, outputCol=None, handleInvalid=&quot;error&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Bucketizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.Bucketizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Bucketizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Bucketizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, splits=None, inputCol=None, outputCol=None, handleInvalid=&quot;error&quot;)</span>
<span class="sd">        Sets params for this Bucketizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Bucketizer.setSplits"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Bucketizer.setSplits">[docs]</a>    <span class="k">def</span> <span class="nf">setSplits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`splits`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splits</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Bucketizer.getSplits"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Bucketizer.getSplits">[docs]</a>    <span class="k">def</span> <span class="nf">getSplits</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of threshold or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">splits</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Bucketizer.setHandleInvalid"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Bucketizer.setHandleInvalid">[docs]</a>    <span class="k">def</span> <span class="nf">setHandleInvalid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`handleInvalid`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">handleInvalid</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Bucketizer.getHandleInvalid"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Bucketizer.getHandleInvalid">[docs]</a>    <span class="k">def</span> <span class="nf">getHandleInvalid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`handleInvalid` or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">handleInvalid</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="CountVectorizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer">[docs]</a><span class="k">class</span> <span class="nc">CountVectorizer</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts a vocabulary from document collections and generates a :py:attr:`CountVectorizerModel`.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(</span>
<span class="sd">    ...    [(0, [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]), (1, [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;])],</span>
<span class="sd">    ...    [&quot;label&quot;, &quot;raw&quot;])</span>
<span class="sd">    &gt;&gt;&gt; cv = CountVectorizer(inputCol=&quot;raw&quot;, outputCol=&quot;vectors&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = cv.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).show(truncate=False)</span>
<span class="sd">    +-----+---------------+-------------------------+</span>
<span class="sd">    |label|raw            |vectors                  |</span>
<span class="sd">    +-----+---------------+-------------------------+</span>
<span class="sd">    |0    |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|</span>
<span class="sd">    |1    |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|</span>
<span class="sd">    +-----+---------------+-------------------------+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; sorted(model.vocabulary) == [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; countVectorizerPath = temp_path + &quot;/count-vectorizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; cv.save(countVectorizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedCv = CountVectorizer.load(countVectorizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedCv.getMinDF() == cv.getMinDF()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedCv.getMinTF() == cv.getMinTF()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedCv.getVocabSize() == cv.getVocabSize()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/count-vectorizer-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = CountVectorizerModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.vocabulary == model.vocabulary</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">minTF</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span>
        <span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minTF&quot;</span><span class="p">,</span> <span class="s2">&quot;Filter to ignore rare words in&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; a document. For each document, terms with frequency/count less than the given&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; threshold are ignored. If this is an integer &gt;= 1, then this specifies a count (of&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; times the term must appear in the document); if this is a double in [0,1), then this &quot;</span> <span class="o">+</span>
        <span class="s2">&quot;specifies a fraction (out of the document&#39;s token count). Note that the parameter is &quot;</span> <span class="o">+</span>
        <span class="s2">&quot;only used in transform of CountVectorizerModel and does not affect fitting. Default 1.0&quot;</span><span class="p">,</span>
        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">minDF</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span>
        <span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minDF&quot;</span><span class="p">,</span> <span class="s2">&quot;Specifies the minimum number of&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; different documents a term must appear in to be included in the vocabulary.&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; If this is an integer &gt;= 1, this specifies the number of documents the term must&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; appear in; if this is a double in [0,1), then this specifies the fraction of documents.&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; Default 1.0&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">vocabSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span>
        <span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;vocabSize&quot;</span><span class="p">,</span> <span class="s2">&quot;max size of the vocabulary. Default 1 &lt;&lt; 18.&quot;</span><span class="p">,</span>
        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">binary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span>
        <span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;Binary toggle to control the output vector values.&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; If True, all nonzero counts (after minTF filter applied) are set to 1. This is useful&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; for discrete probabilistic models that model binary events rather than integer counts.&quot;</span> <span class="o">+</span>
        <span class="s2">&quot; Default False&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minTF</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">minDF</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">vocabSize</span><span class="o">=</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, minTF=1.0, minDF=1.0, vocabSize=1 &lt;&lt; 18, binary=False, inputCol=None,\</span>
<span class="sd">                 outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CountVectorizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.CountVectorizer&quot;</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">minTF</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">minDF</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">vocabSize</span><span class="o">=</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minTF</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">minDF</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">vocabSize</span><span class="o">=</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, minTF=1.0, minDF=1.0, vocabSize=1 &lt;&lt; 18, binary=False, inputCol=None,\</span>
<span class="sd">                  outputCol=None)</span>
<span class="sd">        Set the params for the CountVectorizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.setMinTF"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.setMinTF">[docs]</a>    <span class="k">def</span> <span class="nf">setMinTF</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`minTF`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minTF</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.getMinTF"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.getMinTF">[docs]</a>    <span class="k">def</span> <span class="nf">getMinTF</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of minTF or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minTF</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.setMinDF"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.setMinDF">[docs]</a>    <span class="k">def</span> <span class="nf">setMinDF</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`minDF`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minDF</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.getMinDF"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.getMinDF">[docs]</a>    <span class="k">def</span> <span class="nf">getMinDF</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of minDF or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minDF</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.setVocabSize"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.setVocabSize">[docs]</a>    <span class="k">def</span> <span class="nf">setVocabSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`vocabSize`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">vocabSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.getVocabSize"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.getVocabSize">[docs]</a>    <span class="k">def</span> <span class="nf">getVocabSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of vocabSize or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocabSize</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.setBinary"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.setBinary">[docs]</a>    <span class="k">def</span> <span class="nf">setBinary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`binary`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="CountVectorizer.getBinary"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizer.getBinary">[docs]</a>    <span class="k">def</span> <span class="nf">getBinary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of binary or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">CountVectorizerModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="CountVectorizerModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.CountVectorizerModel">[docs]</a><span class="k">class</span> <span class="nc">CountVectorizerModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`CountVectorizer`.</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">vocabulary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        An array of terms in the vocabulary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;vocabulary&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="DCT"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.DCT">[docs]</a><span class="k">class</span> <span class="nc">DCT</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature transformer that takes the 1D discrete cosine transform</span>
<span class="sd">    of a real vector. No zero padding is performed on the input vector.</span>
<span class="sd">    It returns a real vector of the same length representing the DCT.</span>
<span class="sd">    The return vector is scaled such that the transform matrix is</span>
<span class="sd">    unitary (aka scaled DCT-II).</span>

<span class="sd">    .. seealso:: `More information on Wikipedia \</span>
<span class="sd">    &lt;https://en.wikipedia.org/wiki/Discrete_cosine_transform#DCT-II Wikipedia&gt;`_.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df1 = spark.createDataFrame([(Vectors.dense([5.0, 8.0, 6.0]),)], [&quot;vec&quot;])</span>
<span class="sd">    &gt;&gt;&gt; dct = DCT(inverse=False, inputCol=&quot;vec&quot;, outputCol=&quot;resultVec&quot;)</span>
<span class="sd">    &gt;&gt;&gt; df2 = dct.transform(df1)</span>
<span class="sd">    &gt;&gt;&gt; df2.head().resultVec</span>
<span class="sd">    DenseVector([10.969..., -0.707..., -2.041...])</span>
<span class="sd">    &gt;&gt;&gt; df3 = DCT(inverse=True, inputCol=&quot;resultVec&quot;, outputCol=&quot;origVec&quot;).transform(df2)</span>
<span class="sd">    &gt;&gt;&gt; df3.head().origVec</span>
<span class="sd">    DenseVector([5.0, 8.0, 6.0])</span>
<span class="sd">    &gt;&gt;&gt; dctPath = temp_path + &quot;/dct&quot;</span>
<span class="sd">    &gt;&gt;&gt; dct.save(dctPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedDtc = DCT.load(dctPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedDtc.getInverse()</span>
<span class="sd">    False</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">inverse</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;inverse&quot;</span><span class="p">,</span> <span class="s2">&quot;Set transformer to perform inverse DCT, &quot;</span> <span class="o">+</span>
                    <span class="s2">&quot;default False.&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inverse=False, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DCT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.DCT&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="DCT.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.DCT.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inverse=False, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this DCT.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="DCT.setInverse"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.DCT.setInverse">[docs]</a>    <span class="k">def</span> <span class="nf">setInverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`inverse`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">inverse</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="DCT.getInverse"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.DCT.getInverse">[docs]</a>    <span class="k">def</span> <span class="nf">getInverse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of inverse or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inverse</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="ElementwiseProduct"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct">[docs]</a><span class="k">class</span> <span class="nc">ElementwiseProduct</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span>
                         <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Outputs the Hadamard product (i.e., the element-wise product) of each input vector</span>
<span class="sd">    with a provided &quot;weight&quot; vector. In other words, it scales each column of the dataset</span>
<span class="sd">    by a scalar multiplier.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([2.0, 1.0, 3.0]),)], [&quot;values&quot;])</span>
<span class="sd">    &gt;&gt;&gt; ep = ElementwiseProduct(scalingVec=Vectors.dense([1.0, 2.0, 3.0]),</span>
<span class="sd">    ...     inputCol=&quot;values&quot;, outputCol=&quot;eprod&quot;)</span>
<span class="sd">    &gt;&gt;&gt; ep.transform(df).head().eprod</span>
<span class="sd">    DenseVector([2.0, 2.0, 9.0])</span>
<span class="sd">    &gt;&gt;&gt; ep.setParams(scalingVec=Vectors.dense([2.0, 3.0, 5.0])).transform(df).head().eprod</span>
<span class="sd">    DenseVector([4.0, 3.0, 15.0])</span>
<span class="sd">    &gt;&gt;&gt; elementwiseProductPath = temp_path + &quot;/elementwise-product&quot;</span>
<span class="sd">    &gt;&gt;&gt; ep.save(elementwiseProductPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedEp = ElementwiseProduct.load(elementwiseProductPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedEp.getScalingVec() == ep.getScalingVec()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">scalingVec</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;scalingVec&quot;</span><span class="p">,</span> <span class="s2">&quot;Vector for hadamard product.&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toVector</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scalingVec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, scalingVec=None, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ElementwiseProduct</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.ElementwiseProduct&quot;</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ElementwiseProduct.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scalingVec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, scalingVec=None, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this ElementwiseProduct.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ElementwiseProduct.setScalingVec"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct.setScalingVec">[docs]</a>    <span class="k">def</span> <span class="nf">setScalingVec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`scalingVec`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">scalingVec</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ElementwiseProduct.getScalingVec"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct.getScalingVec">[docs]</a>    <span class="k">def</span> <span class="nf">getScalingVec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of scalingVec or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scalingVec</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="HashingTF"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.HashingTF">[docs]</a><span class="k">class</span> <span class="nc">HashingTF</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">HasNumFeatures</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span>
                <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Maps a sequence of terms to their term frequencies using the hashing trick.</span>
<span class="sd">    Currently we use Austin Appleby&#39;s MurmurHash 3 algorithm (MurmurHash3_x86_32)</span>
<span class="sd">    to calculate the hash code value for the term object.</span>
<span class="sd">    Since a simple modulo is used to transform the hash function to a column index,</span>
<span class="sd">    it is advisable to use a power of two as the numFeatures parameter;</span>
<span class="sd">    otherwise the features will not be mapped evenly to the columns.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],)], [&quot;words&quot;])</span>
<span class="sd">    &gt;&gt;&gt; hashingTF = HashingTF(numFeatures=10, inputCol=&quot;words&quot;, outputCol=&quot;features&quot;)</span>
<span class="sd">    &gt;&gt;&gt; hashingTF.transform(df).head().features</span>
<span class="sd">    SparseVector(10, {0: 1.0, 1: 1.0, 2: 1.0})</span>
<span class="sd">    &gt;&gt;&gt; hashingTF.setParams(outputCol=&quot;freqs&quot;).transform(df).head().freqs</span>
<span class="sd">    SparseVector(10, {0: 1.0, 1: 1.0, 2: 1.0})</span>
<span class="sd">    &gt;&gt;&gt; params = {hashingTF.numFeatures: 5, hashingTF.outputCol: &quot;vector&quot;}</span>
<span class="sd">    &gt;&gt;&gt; hashingTF.transform(df, params).head().vector</span>
<span class="sd">    SparseVector(5, {0: 1.0, 1: 1.0, 2: 1.0})</span>
<span class="sd">    &gt;&gt;&gt; hashingTFPath = temp_path + &quot;/hashing-tf&quot;</span>
<span class="sd">    &gt;&gt;&gt; hashingTF.save(hashingTFPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedHashingTF = HashingTF.load(hashingTFPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedHashingTF.getNumFeatures() == hashingTF.getNumFeatures()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.3.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">binary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;If True, all non zero counts are set to 1. &quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;This is useful for discrete probabilistic models that model binary events &quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;rather than integer counts. Default False.&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numFeatures</span><span class="o">=</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, numFeatures=1 &lt;&lt; 18, binary=False, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HashingTF</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.HashingTF&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">numFeatures</span><span class="o">=</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.3.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="HashingTF.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.HashingTF.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numFeatures</span><span class="o">=</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">18</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, numFeatures=1 &lt;&lt; 18, binary=False, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this HashingTF.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="HashingTF.setBinary"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.HashingTF.setBinary">[docs]</a>    <span class="k">def</span> <span class="nf">setBinary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`binary`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="HashingTF.getBinary"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.HashingTF.getBinary">[docs]</a>    <span class="k">def</span> <span class="nf">getBinary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of binary or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="IDF"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IDF">[docs]</a><span class="k">class</span> <span class="nc">IDF</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Inverse Document Frequency (IDF) given a collection of documents.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import DenseVector</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(DenseVector([1.0, 2.0]),),</span>
<span class="sd">    ...     (DenseVector([0.0, 1.0]),), (DenseVector([3.0, 0.2]),)], [&quot;tf&quot;])</span>
<span class="sd">    &gt;&gt;&gt; idf = IDF(minDocFreq=3, inputCol=&quot;tf&quot;, outputCol=&quot;idf&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = idf.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.idf</span>
<span class="sd">    DenseVector([0.0, 0.0])</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).head().idf</span>
<span class="sd">    DenseVector([0.0, 0.0])</span>
<span class="sd">    &gt;&gt;&gt; idf.setParams(outputCol=&quot;freqs&quot;).fit(df).transform(df).collect()[1].freqs</span>
<span class="sd">    DenseVector([0.0, 0.0])</span>
<span class="sd">    &gt;&gt;&gt; params = {idf.minDocFreq: 1, idf.outputCol: &quot;vector&quot;}</span>
<span class="sd">    &gt;&gt;&gt; idf.fit(df, params).transform(df).head().vector</span>
<span class="sd">    DenseVector([0.2877, 0.0])</span>
<span class="sd">    &gt;&gt;&gt; idfPath = temp_path + &quot;/idf&quot;</span>
<span class="sd">    &gt;&gt;&gt; idf.save(idfPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedIdf = IDF.load(idfPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedIdf.getMinDocFreq() == idf.getMinDocFreq()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/idf-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = IDFModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.transform(df).head().idf == model.transform(df).head().idf</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">minDocFreq</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minDocFreq&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;minimum number of documents in which a term should appear for filtering&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minDocFreq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, minDocFreq=0, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">IDF</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.IDF&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">minDocFreq</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="IDF.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IDF.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minDocFreq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, minDocFreq=0, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this IDF.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="IDF.setMinDocFreq"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IDF.setMinDocFreq">[docs]</a>    <span class="k">def</span> <span class="nf">setMinDocFreq</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`minDocFreq`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minDocFreq</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="IDF.getMinDocFreq"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IDF.getMinDocFreq">[docs]</a>    <span class="k">def</span> <span class="nf">getMinDocFreq</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of minDocFreq or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minDocFreq</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">IDFModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="IDFModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IDFModel">[docs]</a><span class="k">class</span> <span class="nc">IDFModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`IDF`.</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">idf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the IDF vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;idf&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="MaxAbsScaler"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MaxAbsScaler">[docs]</a><span class="k">class</span> <span class="nc">MaxAbsScaler</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rescale each feature individually to range [-1, 1] by dividing through the largest maximum</span>
<span class="sd">    absolute value in each feature. It does not shift/center the data, and thus does not destroy</span>
<span class="sd">    any sparsity.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([1.0]),), (Vectors.dense([2.0]),)], [&quot;a&quot;])</span>
<span class="sd">    &gt;&gt;&gt; maScaler = MaxAbsScaler(inputCol=&quot;a&quot;, outputCol=&quot;scaled&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = maScaler.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).show()</span>
<span class="sd">    +-----+------+</span>
<span class="sd">    |    a|scaled|</span>
<span class="sd">    +-----+------+</span>
<span class="sd">    |[1.0]| [0.5]|</span>
<span class="sd">    |[2.0]| [1.0]|</span>
<span class="sd">    +-----+------+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; scalerPath = temp_path + &quot;/max-abs-scaler&quot;</span>
<span class="sd">    &gt;&gt;&gt; maScaler.save(scalerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedMAScaler = MaxAbsScaler.load(scalerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedMAScaler.getInputCol() == maScaler.getInputCol()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedMAScaler.getOutputCol() == maScaler.getOutputCol()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/max-abs-scaler-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = MaxAbsScalerModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.maxAbs == model.maxAbs</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 2.0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaxAbsScaler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.MaxAbsScaler&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">()</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="MaxAbsScaler.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MaxAbsScaler.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this MaxAbsScaler.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MaxAbsScalerModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="MaxAbsScalerModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MaxAbsScalerModel">[docs]</a><span class="k">class</span> <span class="nc">MaxAbsScalerModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`MaxAbsScaler`.</span>

<span class="sd">    .. versionadded:: 2.0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">maxAbs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Max Abs vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;maxAbs&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="MinMaxScaler"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScaler">[docs]</a><span class="k">class</span> <span class="nc">MinMaxScaler</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rescale each feature individually to a common range [min, max] linearly using column summary</span>
<span class="sd">    statistics, which is also known as min-max normalization or Rescaling. The rescaled value for</span>
<span class="sd">    feature E is calculated as,</span>

<span class="sd">    Rescaled(e_i) = (e_i - E_min) / (E_max - E_min) * (max - min) + min</span>

<span class="sd">    For the case E_max == E_min, Rescaled(e_i) = 0.5 * (max + min)</span>

<span class="sd">    .. note:: Since zero values will probably be transformed to non-zero values, output of the</span>
<span class="sd">        transformer will be DenseVector even for sparse input.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([0.0]),), (Vectors.dense([2.0]),)], [&quot;a&quot;])</span>
<span class="sd">    &gt;&gt;&gt; mmScaler = MinMaxScaler(inputCol=&quot;a&quot;, outputCol=&quot;scaled&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = mmScaler.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.originalMin</span>
<span class="sd">    DenseVector([0.0])</span>
<span class="sd">    &gt;&gt;&gt; model.originalMax</span>
<span class="sd">    DenseVector([2.0])</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).show()</span>
<span class="sd">    +-----+------+</span>
<span class="sd">    |    a|scaled|</span>
<span class="sd">    +-----+------+</span>
<span class="sd">    |[0.0]| [0.0]|</span>
<span class="sd">    |[2.0]| [1.0]|</span>
<span class="sd">    +-----+------+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; minMaxScalerPath = temp_path + &quot;/min-max-scaler&quot;</span>
<span class="sd">    &gt;&gt;&gt; mmScaler.save(minMaxScalerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedMMScaler = MinMaxScaler.load(minMaxScalerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedMMScaler.getMin() == mmScaler.getMin()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedMMScaler.getMax() == mmScaler.getMax()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/min-max-scaler-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = MinMaxScalerModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.originalMin == model.originalMin</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.originalMax == model.originalMax</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">min</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;Lower bound of the output feature range&quot;</span><span class="p">,</span>
                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;Upper bound of the output feature range&quot;</span><span class="p">,</span>
                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, min=0.0, max=1.0, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.MinMaxScaler&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="MinMaxScaler.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScaler.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, min=0.0, max=1.0, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this MinMaxScaler.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="MinMaxScaler.setMin"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScaler.setMin">[docs]</a>    <span class="k">def</span> <span class="nf">setMin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`min`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="MinMaxScaler.getMin"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScaler.getMin">[docs]</a>    <span class="k">def</span> <span class="nf">getMin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of min or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="MinMaxScaler.setMax"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScaler.setMax">[docs]</a>    <span class="k">def</span> <span class="nf">setMax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`max`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="MinMaxScaler.getMax"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScaler.getMax">[docs]</a>    <span class="k">def</span> <span class="nf">getMax</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of max or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MinMaxScalerModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="MinMaxScalerModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.MinMaxScalerModel">[docs]</a><span class="k">class</span> <span class="nc">MinMaxScalerModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`MinMaxScaler`.</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">originalMin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Min value for each original column during fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;originalMin&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">originalMax</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Max value for each original column during fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;originalMax&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<span class="nd">@ignore_unicode_prefix</span>
<div class="viewcode-block" id="NGram"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.NGram">[docs]</a><span class="k">class</span> <span class="nc">NGram</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature transformer that converts the input array of strings into an array of n-grams. Null</span>
<span class="sd">    values in the input array are ignored.</span>
<span class="sd">    It returns an array of n-grams where each n-gram is represented by a space-separated string of</span>
<span class="sd">    words.</span>
<span class="sd">    When the input is empty, an empty array is returned.</span>
<span class="sd">    When the input array length is less than n (number of elements per n-gram), no n-grams are</span>
<span class="sd">    returned.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([Row(inputTokens=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;])])</span>
<span class="sd">    &gt;&gt;&gt; ngram = NGram(n=2, inputCol=&quot;inputTokens&quot;, outputCol=&quot;nGrams&quot;)</span>
<span class="sd">    &gt;&gt;&gt; ngram.transform(df).head()</span>
<span class="sd">    Row(inputTokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;, u&#39;d&#39;, u&#39;e&#39;], nGrams=[u&#39;a b&#39;, u&#39;b c&#39;, u&#39;c d&#39;, u&#39;d e&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Change n-gram length</span>
<span class="sd">    &gt;&gt;&gt; ngram.setParams(n=4).transform(df).head()</span>
<span class="sd">    Row(inputTokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;, u&#39;d&#39;, u&#39;e&#39;], nGrams=[u&#39;a b c d&#39;, u&#39;b c d e&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Temporarily modify output column.</span>
<span class="sd">    &gt;&gt;&gt; ngram.transform(df, {ngram.outputCol: &quot;output&quot;}).head()</span>
<span class="sd">    Row(inputTokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;, u&#39;d&#39;, u&#39;e&#39;], output=[u&#39;a b c d&#39;, u&#39;b c d e&#39;])</span>
<span class="sd">    &gt;&gt;&gt; ngram.transform(df).head()</span>
<span class="sd">    Row(inputTokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;, u&#39;d&#39;, u&#39;e&#39;], nGrams=[u&#39;a b c d&#39;, u&#39;b c d e&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Must use keyword arguments to specify params.</span>
<span class="sd">    &gt;&gt;&gt; ngram.setParams(&quot;text&quot;)</span>
<span class="sd">    Traceback (most recent call last):</span>
<span class="sd">        ...</span>
<span class="sd">    TypeError: Method setParams forces keyword arguments.</span>
<span class="sd">    &gt;&gt;&gt; ngramPath = temp_path + &quot;/ngram&quot;</span>
<span class="sd">    &gt;&gt;&gt; ngram.save(ngramPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedNGram = NGram.load(ngramPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedNGram.getN() == ngram.getN()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="s2">&quot;number of elements per n-gram (&gt;=1)&quot;</span><span class="p">,</span>
              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, n=2, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NGram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.NGram&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="NGram.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.NGram.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, n=2, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this NGram.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="NGram.setN"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.NGram.setN">[docs]</a>    <span class="k">def</span> <span class="nf">setN</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`n`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="NGram.getN"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.NGram.getN">[docs]</a>    <span class="k">def</span> <span class="nf">getN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of n or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="Normalizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Normalizer">[docs]</a><span class="k">class</span> <span class="nc">Normalizer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">     Normalize a vector to have unit norm using the given p-norm.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; svec = Vectors.sparse(4, {1: 4.0, 3: 3.0})</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([3.0, -4.0]), svec)], [&quot;dense&quot;, &quot;sparse&quot;])</span>
<span class="sd">    &gt;&gt;&gt; normalizer = Normalizer(p=2.0, inputCol=&quot;dense&quot;, outputCol=&quot;features&quot;)</span>
<span class="sd">    &gt;&gt;&gt; normalizer.transform(df).head().features</span>
<span class="sd">    DenseVector([0.6, -0.8])</span>
<span class="sd">    &gt;&gt;&gt; normalizer.setParams(inputCol=&quot;sparse&quot;, outputCol=&quot;freqs&quot;).transform(df).head().freqs</span>
<span class="sd">    SparseVector(4, {1: 0.8, 3: 0.6})</span>
<span class="sd">    &gt;&gt;&gt; params = {normalizer.p: 1.0, normalizer.inputCol: &quot;dense&quot;, normalizer.outputCol: &quot;vector&quot;}</span>
<span class="sd">    &gt;&gt;&gt; normalizer.transform(df, params).head().vector</span>
<span class="sd">    DenseVector([0.4286, -0.5714])</span>
<span class="sd">    &gt;&gt;&gt; normalizerPath = temp_path + &quot;/normalizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; normalizer.save(normalizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedNormalizer = Normalizer.load(normalizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedNormalizer.getP() == normalizer.getP()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="s2">&quot;the p norm value.&quot;</span><span class="p">,</span>
              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, p=2.0, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Normalizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.Normalizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Normalizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Normalizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, p=2.0, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this Normalizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Normalizer.setP"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Normalizer.setP">[docs]</a>    <span class="k">def</span> <span class="nf">setP</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`p`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Normalizer.getP"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Normalizer.getP">[docs]</a>    <span class="k">def</span> <span class="nf">getP</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of p or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="OneHotEncoder"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.OneHotEncoder">[docs]</a><span class="k">class</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A one-hot encoder that maps a column of category indices to a</span>
<span class="sd">    column of binary vectors, with at most a single one-value per row</span>
<span class="sd">    that indicates the input category index.</span>
<span class="sd">    For example with 5 categories, an input value of 2.0 would map to</span>
<span class="sd">    an output vector of `[0.0, 0.0, 1.0, 0.0]`.</span>
<span class="sd">    The last category is not included by default (configurable via</span>
<span class="sd">    :py:attr:`dropLast`) because it makes the vector entries sum up to</span>
<span class="sd">    one, and hence linearly dependent.</span>
<span class="sd">    So an input value of 4.0 maps to `[0.0, 0.0, 0.0, 0.0]`.</span>

<span class="sd">    .. note:: This is different from scikit-learn&#39;s OneHotEncoder,</span>
<span class="sd">        which keeps all categories. The output vectors are sparse.</span>

<span class="sd">    .. seealso::</span>

<span class="sd">       :py:class:`StringIndexer` for converting categorical values into</span>
<span class="sd">       category indices</span>

<span class="sd">    &gt;&gt;&gt; stringIndexer = StringIndexer(inputCol=&quot;label&quot;, outputCol=&quot;indexed&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = stringIndexer.fit(stringIndDf)</span>
<span class="sd">    &gt;&gt;&gt; td = model.transform(stringIndDf)</span>
<span class="sd">    &gt;&gt;&gt; encoder = OneHotEncoder(inputCol=&quot;indexed&quot;, outputCol=&quot;features&quot;)</span>
<span class="sd">    &gt;&gt;&gt; encoder.transform(td).head().features</span>
<span class="sd">    SparseVector(2, {0: 1.0})</span>
<span class="sd">    &gt;&gt;&gt; encoder.setParams(outputCol=&quot;freqs&quot;).transform(td).head().freqs</span>
<span class="sd">    SparseVector(2, {0: 1.0})</span>
<span class="sd">    &gt;&gt;&gt; params = {encoder.dropLast: False, encoder.outputCol: &quot;test&quot;}</span>
<span class="sd">    &gt;&gt;&gt; encoder.transform(td, params).head().test</span>
<span class="sd">    SparseVector(3, {0: 1.0})</span>
<span class="sd">    &gt;&gt;&gt; onehotEncoderPath = temp_path + &quot;/onehot-encoder&quot;</span>
<span class="sd">    &gt;&gt;&gt; encoder.save(onehotEncoderPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedEncoder = OneHotEncoder.load(onehotEncoderPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedEncoder.getDropLast() == encoder.getDropLast()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">dropLast</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;dropLast&quot;</span><span class="p">,</span> <span class="s2">&quot;whether to drop the last category&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropLast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, includeFirst=True, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OneHotEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.OneHotEncoder&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">dropLast</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="OneHotEncoder.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.OneHotEncoder.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropLast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, dropLast=True, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this OneHotEncoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="OneHotEncoder.setDropLast"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.OneHotEncoder.setDropLast">[docs]</a>    <span class="k">def</span> <span class="nf">setDropLast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`dropLast`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dropLast</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="OneHotEncoder.getDropLast"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.OneHotEncoder.getDropLast">[docs]</a>    <span class="k">def</span> <span class="nf">getDropLast</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of dropLast or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropLast</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="PolynomialExpansion"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion">[docs]</a><span class="k">class</span> <span class="nc">PolynomialExpansion</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span>
                          <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform feature expansion in a polynomial space. As said in `wikipedia of Polynomial Expansion</span>
<span class="sd">    &lt;http://en.wikipedia.org/wiki/Polynomial_expansion&gt;`_, &quot;In mathematics, an</span>
<span class="sd">    expansion of a product of sums expresses it as a sum of products by using the fact that</span>
<span class="sd">    multiplication distributes over addition&quot;. Take a 2-variable feature vector as an example:</span>
<span class="sd">    `(x, y)`, if we want to expand it with degree 2, then we get `(x, x * x, y, x * y, y * y)`.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([0.5, 2.0]),)], [&quot;dense&quot;])</span>
<span class="sd">    &gt;&gt;&gt; px = PolynomialExpansion(degree=2, inputCol=&quot;dense&quot;, outputCol=&quot;expanded&quot;)</span>
<span class="sd">    &gt;&gt;&gt; px.transform(df).head().expanded</span>
<span class="sd">    DenseVector([0.5, 0.25, 2.0, 1.0, 4.0])</span>
<span class="sd">    &gt;&gt;&gt; px.setParams(outputCol=&quot;test&quot;).transform(df).head().test</span>
<span class="sd">    DenseVector([0.5, 0.25, 2.0, 1.0, 4.0])</span>
<span class="sd">    &gt;&gt;&gt; polyExpansionPath = temp_path + &quot;/poly-expansion&quot;</span>
<span class="sd">    &gt;&gt;&gt; px.save(polyExpansionPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedPx = PolynomialExpansion.load(polyExpansionPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedPx.getDegree() == px.getDegree()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">degree</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;degree&quot;</span><span class="p">,</span> <span class="s2">&quot;the polynomial degree to expand (&gt;= 1)&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, degree=2, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PolynomialExpansion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span>
            <span class="s2">&quot;org.apache.spark.ml.feature.PolynomialExpansion&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="PolynomialExpansion.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, degree=2, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this PolynomialExpansion.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="PolynomialExpansion.setDegree"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion.setDegree">[docs]</a>    <span class="k">def</span> <span class="nf">setDegree</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`degree`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="PolynomialExpansion.getDegree"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion.getDegree">[docs]</a>    <span class="k">def</span> <span class="nf">getDegree</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of degree or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="QuantileDiscretizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer">[docs]</a><span class="k">class</span> <span class="nc">QuantileDiscretizer</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note:: Experimental</span>

<span class="sd">    `QuantileDiscretizer` takes a column with continuous features and outputs a column with binned</span>
<span class="sd">    categorical features. The number of bins can be set using the :py:attr:`numBuckets` parameter.</span>
<span class="sd">    The bin ranges are chosen using an approximate algorithm (see the documentation for</span>
<span class="sd">    :py:meth:`~.DataFrameStatFunctions.approxQuantile` for a detailed description).</span>
<span class="sd">    The precision of the approximation can be controlled with the</span>
<span class="sd">    :py:attr:`relativeError` parameter.</span>
<span class="sd">    The lower and upper bin bounds will be `-Infinity` and `+Infinity`, covering all real values.</span>

<span class="sd">    &gt;&gt;&gt; values = [(0.1,), (0.4,), (1.2,), (1.5,), (float(&quot;nan&quot;),), (float(&quot;nan&quot;),)]</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(values, [&quot;values&quot;])</span>
<span class="sd">    &gt;&gt;&gt; qds = QuantileDiscretizer(numBuckets=2,</span>
<span class="sd">    ...     inputCol=&quot;values&quot;, outputCol=&quot;buckets&quot;, relativeError=0.01, handleInvalid=&quot;error&quot;)</span>
<span class="sd">    &gt;&gt;&gt; qds.getRelativeError()</span>
<span class="sd">    0.01</span>
<span class="sd">    &gt;&gt;&gt; bucketizer = qds.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; qds.setHandleInvalid(&quot;keep&quot;).fit(df).transform(df).count()</span>
<span class="sd">    6</span>
<span class="sd">    &gt;&gt;&gt; qds.setHandleInvalid(&quot;skip&quot;).fit(df).transform(df).count()</span>
<span class="sd">    4</span>
<span class="sd">    &gt;&gt;&gt; splits = bucketizer.getSplits()</span>
<span class="sd">    &gt;&gt;&gt; splits[0]</span>
<span class="sd">    -inf</span>
<span class="sd">    &gt;&gt;&gt; print(&quot;%2.1f&quot; % round(splits[1], 1))</span>
<span class="sd">    0.4</span>
<span class="sd">    &gt;&gt;&gt; bucketed = bucketizer.transform(df).head()</span>
<span class="sd">    &gt;&gt;&gt; bucketed.buckets</span>
<span class="sd">    0.0</span>
<span class="sd">    &gt;&gt;&gt; quantileDiscretizerPath = temp_path + &quot;/quantile-discretizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; qds.save(quantileDiscretizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedQds = QuantileDiscretizer.load(quantileDiscretizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedQds.getNumBuckets() == qds.getNumBuckets()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 2.0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">numBuckets</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;numBuckets&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;Maximum number of buckets (quantiles, or &quot;</span> <span class="o">+</span>
                       <span class="s2">&quot;categories) into which data points are grouped. Must be &gt;= 2.&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">relativeError</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;relativeError&quot;</span><span class="p">,</span> <span class="s2">&quot;The relative target precision for &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;the approximate quantile algorithm used to generate buckets. &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;Must be in the range [0, 1].&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">handleInvalid</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;handleInvalid&quot;</span><span class="p">,</span> <span class="s2">&quot;how to handle invalid entries. &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;Options are skip (filter out rows with invalid values), &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;error (throw an error), or keep (keep invalid values in a special &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;additional bucket).&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numBuckets</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">relativeError</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                 <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, numBuckets=2, inputCol=None, outputCol=None, relativeError=0.001, \</span>
<span class="sd">                 handleInvalid=&quot;error&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QuantileDiscretizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.QuantileDiscretizer&quot;</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">numBuckets</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">relativeError</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numBuckets</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">relativeError</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                  <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, numBuckets=2, inputCol=None, outputCol=None, relativeError=0.001, \</span>
<span class="sd">                  handleInvalid=&quot;error&quot;)</span>
<span class="sd">        Set the params for the QuantileDiscretizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.setNumBuckets"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.setNumBuckets">[docs]</a>    <span class="k">def</span> <span class="nf">setNumBuckets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`numBuckets`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">numBuckets</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.getNumBuckets"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.getNumBuckets">[docs]</a>    <span class="k">def</span> <span class="nf">getNumBuckets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of numBuckets or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">numBuckets</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.setRelativeError"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.setRelativeError">[docs]</a>    <span class="k">def</span> <span class="nf">setRelativeError</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`relativeError`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">relativeError</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.getRelativeError"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.getRelativeError">[docs]</a>    <span class="k">def</span> <span class="nf">getRelativeError</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of relativeError or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relativeError</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.setHandleInvalid"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.setHandleInvalid">[docs]</a>    <span class="k">def</span> <span class="nf">setHandleInvalid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`handleInvalid`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">handleInvalid</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="QuantileDiscretizer.getHandleInvalid"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer.getHandleInvalid">[docs]</a>    <span class="k">def</span> <span class="nf">getHandleInvalid</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`handleInvalid` or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">handleInvalid</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Private method to convert the java_model to a Python model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Bucketizer</span><span class="p">(</span><span class="n">splits</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">java_model</span><span class="o">.</span><span class="n">getSplits</span><span class="p">()),</span>
                          <span class="n">inputCol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">getInputCol</span><span class="p">(),</span>
                          <span class="n">outputCol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">(),</span>
                          <span class="n">handleInvalid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">getHandleInvalid</span><span class="p">())</span></div>


<span class="nd">@inherit_doc</span>
<span class="nd">@ignore_unicode_prefix</span>
<div class="viewcode-block" id="RegexTokenizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer">[docs]</a><span class="k">class</span> <span class="nc">RegexTokenizer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A regex based tokenizer that extracts tokens either by using the</span>
<span class="sd">    provided regex pattern (in Java dialect) to split the text</span>
<span class="sd">    (default) or repeatedly matching the regex (if gaps is false).</span>
<span class="sd">    Optional parameters also allow filtering tokens using a minimal</span>
<span class="sd">    length.</span>
<span class="sd">    It returns an array of strings that can be empty.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(&quot;A B  c&quot;,)], [&quot;text&quot;])</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer = RegexTokenizer(inputCol=&quot;text&quot;, outputCol=&quot;words&quot;)</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer.transform(df).head()</span>
<span class="sd">    Row(text=u&#39;A B  c&#39;, words=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Change a parameter.</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer.setParams(outputCol=&quot;tokens&quot;).transform(df).head()</span>
<span class="sd">    Row(text=u&#39;A B  c&#39;, tokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Temporarily modify a parameter.</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer.transform(df, {reTokenizer.outputCol: &quot;words&quot;}).head()</span>
<span class="sd">    Row(text=u&#39;A B  c&#39;, words=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer.transform(df).head()</span>
<span class="sd">    Row(text=u&#39;A B  c&#39;, tokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Must use keyword arguments to specify params.</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer.setParams(&quot;text&quot;)</span>
<span class="sd">    Traceback (most recent call last):</span>
<span class="sd">        ...</span>
<span class="sd">    TypeError: Method setParams forces keyword arguments.</span>
<span class="sd">    &gt;&gt;&gt; regexTokenizerPath = temp_path + &quot;/regex-tokenizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; reTokenizer.save(regexTokenizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedReTokenizer = RegexTokenizer.load(regexTokenizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedReTokenizer.getMinTokenLength() == reTokenizer.getMinTokenLength()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedReTokenizer.getGaps() == reTokenizer.getGaps()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">minTokenLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minTokenLength&quot;</span><span class="p">,</span> <span class="s2">&quot;minimum token length (&gt;= 0)&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">gaps</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;gaps&quot;</span><span class="p">,</span> <span class="s2">&quot;whether regex splits on gaps (True) or matches tokens &quot;</span> <span class="o">+</span>
                 <span class="s2">&quot;(False)&quot;</span><span class="p">)</span>
    <span class="n">pattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;pattern&quot;</span><span class="p">,</span> <span class="s2">&quot;regex pattern (Java dialect) used for tokenizing&quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>
    <span class="n">toLowercase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;toLowercase&quot;</span><span class="p">,</span> <span class="s2">&quot;whether to convert all characters to &quot;</span> <span class="o">+</span>
                        <span class="s2">&quot;lowercase before tokenizing&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minTokenLength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gaps</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">s+&quot;</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">toLowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, minTokenLength=1, gaps=True, pattern=&quot;\\s+&quot;, inputCol=None, \</span>
<span class="sd">                 outputCol=None, toLowercase=True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RegexTokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.RegexTokenizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">minTokenLength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gaps</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">s+&quot;</span><span class="p">,</span> <span class="n">toLowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">minTokenLength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gaps</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">s+&quot;</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">toLowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, minTokenLength=1, gaps=True, pattern=&quot;\\s+&quot;, inputCol=None, \</span>
<span class="sd">                  outputCol=None, toLowercase=True)</span>
<span class="sd">        Sets params for this RegexTokenizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.setMinTokenLength"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.setMinTokenLength">[docs]</a>    <span class="k">def</span> <span class="nf">setMinTokenLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`minTokenLength`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minTokenLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.getMinTokenLength"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.getMinTokenLength">[docs]</a>    <span class="k">def</span> <span class="nf">getMinTokenLength</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of minTokenLength or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minTokenLength</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.setGaps"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.setGaps">[docs]</a>    <span class="k">def</span> <span class="nf">setGaps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`gaps`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">gaps</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.getGaps"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.getGaps">[docs]</a>    <span class="k">def</span> <span class="nf">getGaps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of gaps or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gaps</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.setPattern"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.setPattern">[docs]</a>    <span class="k">def</span> <span class="nf">setPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`pattern`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.getPattern"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.getPattern">[docs]</a>    <span class="k">def</span> <span class="nf">getPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of pattern or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pattern</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.setToLowercase"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.setToLowercase">[docs]</a>    <span class="k">def</span> <span class="nf">setToLowercase</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`toLowercase`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">toLowercase</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RegexTokenizer.getToLowercase"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RegexTokenizer.getToLowercase">[docs]</a>    <span class="k">def</span> <span class="nf">getToLowercase</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of toLowercase or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">toLowercase</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="SQLTransformer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.SQLTransformer">[docs]</a><span class="k">class</span> <span class="nc">SQLTransformer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements the transforms which are defined by SQL statement.</span>
<span class="sd">    Currently we only support SQL syntax like &#39;SELECT ... FROM __THIS__&#39;</span>
<span class="sd">    where &#39;__THIS__&#39; represents the underlying table of the input dataset.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(0, 1.0, 3.0), (2, 2.0, 5.0)], [&quot;id&quot;, &quot;v1&quot;, &quot;v2&quot;])</span>
<span class="sd">    &gt;&gt;&gt; sqlTrans = SQLTransformer(</span>
<span class="sd">    ...     statement=&quot;SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__&quot;)</span>
<span class="sd">    &gt;&gt;&gt; sqlTrans.transform(df).head()</span>
<span class="sd">    Row(id=0, v1=1.0, v2=3.0, v3=4.0, v4=3.0)</span>
<span class="sd">    &gt;&gt;&gt; sqlTransformerPath = temp_path + &quot;/sql-transformer&quot;</span>
<span class="sd">    &gt;&gt;&gt; sqlTrans.save(sqlTransformerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedSqlTrans = SQLTransformer.load(sqlTransformerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedSqlTrans.getStatement() == sqlTrans.getStatement()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">statement</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;statement&quot;</span><span class="p">,</span> <span class="s2">&quot;SQL statement&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">statement</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, statement=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SQLTransformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.SQLTransformer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="SQLTransformer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.SQLTransformer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">statement</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, statement=None)</span>
<span class="sd">        Sets params for this SQLTransformer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="SQLTransformer.setStatement"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.SQLTransformer.setStatement">[docs]</a>    <span class="k">def</span> <span class="nf">setStatement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`statement`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">statement</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="SQLTransformer.getStatement"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.SQLTransformer.getStatement">[docs]</a>    <span class="k">def</span> <span class="nf">getStatement</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of statement or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">statement</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="StandardScaler"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScaler">[docs]</a><span class="k">class</span> <span class="nc">StandardScaler</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Standardizes features by removing the mean and scaling to unit variance using column summary</span>
<span class="sd">    statistics on the samples in the training set.</span>

<span class="sd">    The &quot;unit std&quot; is computed using the `corrected sample standard deviation \</span>
<span class="sd">    &lt;https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation&gt;`_,</span>
<span class="sd">    which is computed as the square root of the unbiased sample variance.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([0.0]),), (Vectors.dense([2.0]),)], [&quot;a&quot;])</span>
<span class="sd">    &gt;&gt;&gt; standardScaler = StandardScaler(inputCol=&quot;a&quot;, outputCol=&quot;scaled&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = standardScaler.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.mean</span>
<span class="sd">    DenseVector([1.0])</span>
<span class="sd">    &gt;&gt;&gt; model.std</span>
<span class="sd">    DenseVector([1.4142])</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).collect()[1].scaled</span>
<span class="sd">    DenseVector([1.4142])</span>
<span class="sd">    &gt;&gt;&gt; standardScalerPath = temp_path + &quot;/standard-scaler&quot;</span>
<span class="sd">    &gt;&gt;&gt; standardScaler.save(standardScalerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedStandardScaler = StandardScaler.load(standardScalerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedStandardScaler.getWithMean() == standardScaler.getWithMean()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedStandardScaler.getWithStd() == standardScaler.getWithStd()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/standard-scaler-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = StandardScalerModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.std == model.std</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.mean == model.mean</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">withMean</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;withMean&quot;</span><span class="p">,</span> <span class="s2">&quot;Center data with mean&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">withStd</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;withStd&quot;</span><span class="p">,</span> <span class="s2">&quot;Scale to unit standard deviation&quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">withMean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">withStd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, withMean=False, withStd=True, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.StandardScaler&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">withMean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">withStd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StandardScaler.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScaler.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">withMean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">withStd</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, withMean=False, withStd=True, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this StandardScaler.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StandardScaler.setWithMean"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScaler.setWithMean">[docs]</a>    <span class="k">def</span> <span class="nf">setWithMean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`withMean`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">withMean</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StandardScaler.getWithMean"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScaler.getWithMean">[docs]</a>    <span class="k">def</span> <span class="nf">getWithMean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of withMean or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">withMean</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StandardScaler.setWithStd"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScaler.setWithStd">[docs]</a>    <span class="k">def</span> <span class="nf">setWithStd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`withStd`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">withStd</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StandardScaler.getWithStd"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScaler.getWithStd">[docs]</a>    <span class="k">def</span> <span class="nf">getWithStd</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of withStd or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">withStd</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">StandardScalerModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="StandardScalerModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StandardScalerModel">[docs]</a><span class="k">class</span> <span class="nc">StandardScalerModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`StandardScaler`.</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Standard deviation of the StandardScalerModel.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;std&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Mean of the StandardScalerModel.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="StringIndexer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StringIndexer">[docs]</a><span class="k">class</span> <span class="nc">StringIndexer</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">HasHandleInvalid</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span>
                    <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A label indexer that maps a string column of labels to an ML column of label indices.</span>
<span class="sd">    If the input column is numeric, we cast it to string and index the string values.</span>
<span class="sd">    The indices are in [0, numLabels), ordered by label frequencies.</span>
<span class="sd">    So the most frequent label gets index 0.</span>

<span class="sd">    &gt;&gt;&gt; stringIndexer = StringIndexer(inputCol=&quot;label&quot;, outputCol=&quot;indexed&quot;, handleInvalid=&#39;error&#39;)</span>
<span class="sd">    &gt;&gt;&gt; model = stringIndexer.fit(stringIndDf)</span>
<span class="sd">    &gt;&gt;&gt; td = model.transform(stringIndDf)</span>
<span class="sd">    &gt;&gt;&gt; sorted(set([(i[0], i[1]) for i in td.select(td.id, td.indexed).collect()]),</span>
<span class="sd">    ...     key=lambda x: x[0])</span>
<span class="sd">    [(0, 0.0), (1, 2.0), (2, 1.0), (3, 0.0), (4, 0.0), (5, 1.0)]</span>
<span class="sd">    &gt;&gt;&gt; inverter = IndexToString(inputCol=&quot;indexed&quot;, outputCol=&quot;label2&quot;, labels=model.labels)</span>
<span class="sd">    &gt;&gt;&gt; itd = inverter.transform(td)</span>
<span class="sd">    &gt;&gt;&gt; sorted(set([(i[0], str(i[1])) for i in itd.select(itd.id, itd.label2).collect()]),</span>
<span class="sd">    ...     key=lambda x: x[0])</span>
<span class="sd">    [(0, &#39;a&#39;), (1, &#39;b&#39;), (2, &#39;c&#39;), (3, &#39;a&#39;), (4, &#39;a&#39;), (5, &#39;c&#39;)]</span>
<span class="sd">    &gt;&gt;&gt; stringIndexerPath = temp_path + &quot;/string-indexer&quot;</span>
<span class="sd">    &gt;&gt;&gt; stringIndexer.save(stringIndexerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedIndexer = StringIndexer.load(stringIndexerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedIndexer.getHandleInvalid() == stringIndexer.getHandleInvalid()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/string-indexer-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = StringIndexerModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.labels == model.labels</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; indexToStringPath = temp_path + &quot;/index-to-string&quot;</span>
<span class="sd">    &gt;&gt;&gt; inverter.save(indexToStringPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedInverter = IndexToString.load(indexToStringPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedInverter.getLabels() == inverter.getLabels()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCol=None, outputCol=None, handleInvalid=&quot;error&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StringIndexer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.StringIndexer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StringIndexer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StringIndexer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCol=None, outputCol=None, handleInvalid=&quot;error&quot;)</span>
<span class="sd">        Sets params for this StringIndexer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">StringIndexerModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="StringIndexerModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StringIndexerModel">[docs]</a><span class="k">class</span> <span class="nc">StringIndexerModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`StringIndexer`.</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Ordered list of labels, corresponding to indices to be assigned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="IndexToString"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IndexToString">[docs]</a><span class="k">class</span> <span class="nc">IndexToString</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A :py:class:`Transformer` that maps a column of indices back to a new column of</span>
<span class="sd">    corresponding string values.</span>
<span class="sd">    The index-string mapping is either from the ML attributes of the input column,</span>
<span class="sd">    or from user-supplied labels (which take precedence over ML attributes).</span>
<span class="sd">    See L{StringIndexer} for converting strings into indices.</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Optional array of labels specifying index-string mapping.&quot;</span> <span class="o">+</span>
                   <span class="s2">&quot; If not provided or if empty, then metadata from inputCol is used instead.&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCol=None, outputCol=None, labels=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">IndexToString</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.IndexToString&quot;</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="IndexToString.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IndexToString.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCol=None, outputCol=None, labels=None)</span>
<span class="sd">        Sets params for this IndexToString.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="IndexToString.setLabels"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IndexToString.setLabels">[docs]</a>    <span class="k">def</span> <span class="nf">setLabels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`labels`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="IndexToString.getLabels"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.IndexToString.getLabels">[docs]</a>    <span class="k">def</span> <span class="nf">getLabels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`labels` or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="StopWordsRemover"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover">[docs]</a><span class="k">class</span> <span class="nc">StopWordsRemover</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature transformer that filters out stop words from input.</span>

<span class="sd">    .. note:: null values from input array are preserved unless adding null to stopWords explicitly.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;],)], [&quot;text&quot;])</span>
<span class="sd">    &gt;&gt;&gt; remover = StopWordsRemover(inputCol=&quot;text&quot;, outputCol=&quot;words&quot;, stopWords=[&quot;b&quot;])</span>
<span class="sd">    &gt;&gt;&gt; remover.transform(df).head().words == [&#39;a&#39;, &#39;c&#39;]</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; stopWordsRemoverPath = temp_path + &quot;/stopwords-remover&quot;</span>
<span class="sd">    &gt;&gt;&gt; remover.save(stopWordsRemoverPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedRemover = StopWordsRemover.load(stopWordsRemoverPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedRemover.getStopWords() == remover.getStopWords()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedRemover.getCaseSensitive() == remover.getCaseSensitive()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stopWords</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;stopWords&quot;</span><span class="p">,</span> <span class="s2">&quot;The words to be filtered out&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">caseSensitive</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;caseSensitive&quot;</span><span class="p">,</span> <span class="s2">&quot;whether to do a case sensitive &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;comparison over the stop words&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stopWords</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCol=None, outputCol=None, stopWords=None, caseSensitive=false)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopWordsRemover</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.StopWordsRemover&quot;</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">stopWords</span><span class="o">=</span><span class="n">StopWordsRemover</span><span class="o">.</span><span class="n">loadDefaultStopWords</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">),</span>
                         <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StopWordsRemover.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stopWords</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCol=None, outputCol=None, stopWords=None, caseSensitive=false)</span>
<span class="sd">        Sets params for this StopWordRemover.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StopWordsRemover.setStopWords"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover.setStopWords">[docs]</a>    <span class="k">def</span> <span class="nf">setStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`stopWords`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">stopWords</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StopWordsRemover.getStopWords"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover.getStopWords">[docs]</a>    <span class="k">def</span> <span class="nf">getStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`stopWords` or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stopWords</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StopWordsRemover.setCaseSensitive"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover.setCaseSensitive">[docs]</a>    <span class="k">def</span> <span class="nf">setCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`caseSensitive`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StopWordsRemover.getCaseSensitive"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover.getCaseSensitive">[docs]</a>    <span class="k">def</span> <span class="nf">getCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`caseSensitive` or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">caseSensitive</span><span class="p">)</span></div>

    <span class="nd">@staticmethod</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="StopWordsRemover.loadDefaultStopWords"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.StopWordsRemover.loadDefaultStopWords">[docs]</a>    <span class="k">def</span> <span class="nf">loadDefaultStopWords</span><span class="p">(</span><span class="n">language</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the default stop words for the given language.</span>
<span class="sd">        Supported languages: danish, dutch, english, finnish, french, german, hungarian,</span>
<span class="sd">        italian, norwegian, portuguese, russian, spanish, swedish, turkish</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stopWordsObj</span> <span class="o">=</span> <span class="n">_jvm</span><span class="p">()</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">ml</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">StopWordsRemover</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">stopWordsObj</span><span class="o">.</span><span class="n">loadDefaultStopWords</span><span class="p">(</span><span class="n">language</span><span class="p">))</span></div></div>


<span class="nd">@inherit_doc</span>
<span class="nd">@ignore_unicode_prefix</span>
<div class="viewcode-block" id="Tokenizer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Tokenizer">[docs]</a><span class="k">class</span> <span class="nc">Tokenizer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A tokenizer that converts the input string to lowercase and then</span>
<span class="sd">    splits it by white spaces.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(&quot;a b c&quot;,)], [&quot;text&quot;])</span>
<span class="sd">    &gt;&gt;&gt; tokenizer = Tokenizer(inputCol=&quot;text&quot;, outputCol=&quot;words&quot;)</span>
<span class="sd">    &gt;&gt;&gt; tokenizer.transform(df).head()</span>
<span class="sd">    Row(text=u&#39;a b c&#39;, words=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Change a parameter.</span>
<span class="sd">    &gt;&gt;&gt; tokenizer.setParams(outputCol=&quot;tokens&quot;).transform(df).head()</span>
<span class="sd">    Row(text=u&#39;a b c&#39;, tokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Temporarily modify a parameter.</span>
<span class="sd">    &gt;&gt;&gt; tokenizer.transform(df, {tokenizer.outputCol: &quot;words&quot;}).head()</span>
<span class="sd">    Row(text=u&#39;a b c&#39;, words=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; tokenizer.transform(df).head()</span>
<span class="sd">    Row(text=u&#39;a b c&#39;, tokens=[u&#39;a&#39;, u&#39;b&#39;, u&#39;c&#39;])</span>
<span class="sd">    &gt;&gt;&gt; # Must use keyword arguments to specify params.</span>
<span class="sd">    &gt;&gt;&gt; tokenizer.setParams(&quot;text&quot;)</span>
<span class="sd">    Traceback (most recent call last):</span>
<span class="sd">        ...</span>
<span class="sd">    TypeError: Method setParams forces keyword arguments.</span>
<span class="sd">    &gt;&gt;&gt; tokenizerPath = temp_path + &quot;/tokenizer&quot;</span>
<span class="sd">    &gt;&gt;&gt; tokenizer.save(tokenizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedTokenizer = Tokenizer.load(tokenizerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedTokenizer.transform(df).head().tokens == tokenizer.transform(df).head().tokens</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.3.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.Tokenizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.3.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Tokenizer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Tokenizer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this Tokenizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="VectorAssembler"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorAssembler">[docs]</a><span class="k">class</span> <span class="nc">VectorAssembler</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCols</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feature transformer that merges multiple columns into a vector column.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(1, 0, 3)], [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])</span>
<span class="sd">    &gt;&gt;&gt; vecAssembler = VectorAssembler(inputCols=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], outputCol=&quot;features&quot;)</span>
<span class="sd">    &gt;&gt;&gt; vecAssembler.transform(df).head().features</span>
<span class="sd">    DenseVector([1.0, 0.0, 3.0])</span>
<span class="sd">    &gt;&gt;&gt; vecAssembler.setParams(outputCol=&quot;freqs&quot;).transform(df).head().freqs</span>
<span class="sd">    DenseVector([1.0, 0.0, 3.0])</span>
<span class="sd">    &gt;&gt;&gt; params = {vecAssembler.inputCols: [&quot;b&quot;, &quot;a&quot;], vecAssembler.outputCol: &quot;vector&quot;}</span>
<span class="sd">    &gt;&gt;&gt; vecAssembler.transform(df, params).head().vector</span>
<span class="sd">    DenseVector([0.0, 1.0])</span>
<span class="sd">    &gt;&gt;&gt; vectorAssemblerPath = temp_path + &quot;/vector-assembler&quot;</span>
<span class="sd">    &gt;&gt;&gt; vecAssembler.save(vectorAssemblerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedAssembler = VectorAssembler.load(vectorAssemblerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedAssembler.transform(df).head().freqs == vecAssembler.transform(df).head().freqs</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCols</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCols=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VectorAssembler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.VectorAssembler&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorAssembler.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorAssembler.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCols</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCols=None, outputCol=None)</span>
<span class="sd">        Sets params for this VectorAssembler.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="VectorIndexer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorIndexer">[docs]</a><span class="k">class</span> <span class="nc">VectorIndexer</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for indexing categorical feature columns in a dataset of `Vector`.</span>

<span class="sd">    This has 2 usage modes:</span>
<span class="sd">      - Automatically identify categorical features (default behavior)</span>
<span class="sd">         - This helps process a dataset of unknown vectors into a dataset with some continuous</span>
<span class="sd">           features and some categorical features. The choice between continuous and categorical</span>
<span class="sd">           is based upon a maxCategories parameter.</span>
<span class="sd">         - Set maxCategories to the maximum number of categorical any categorical feature should</span>
<span class="sd">           have.</span>
<span class="sd">         - E.g.: Feature 0 has unique values {-1.0, 0.0}, and feature 1 values {1.0, 3.0, 5.0}.</span>
<span class="sd">           If maxCategories = 2, then feature 0 will be declared categorical and use indices {0, 1},</span>
<span class="sd">           and feature 1 will be declared continuous.</span>
<span class="sd">      - Index all features, if all features are categorical</span>
<span class="sd">         - If maxCategories is set to be very large, then this will build an index of unique</span>
<span class="sd">           values for all features.</span>
<span class="sd">         - Warning: This can cause problems if features are continuous since this will collect ALL</span>
<span class="sd">           unique values to the driver.</span>
<span class="sd">         - E.g.: Feature 0 has unique values {-1.0, 0.0}, and feature 1 values {1.0, 3.0, 5.0}.</span>
<span class="sd">           If maxCategories &gt;= 3, then both features will be declared categorical.</span>

<span class="sd">     This returns a model which can transform categorical features to use 0-based indices.</span>

<span class="sd">    Index stability:</span>
<span class="sd">      - This is not guaranteed to choose the same category index across multiple runs.</span>
<span class="sd">      - If a categorical feature includes value 0, then this is guaranteed to map value 0 to</span>
<span class="sd">        index 0. This maintains vector sparsity.</span>
<span class="sd">      - More stability may be added in the future.</span>

<span class="sd">     TODO: Future extensions: The following functionality is planned for the future:</span>
<span class="sd">      - Preserve metadata in transform; if a feature&#39;s metadata is already present,</span>
<span class="sd">        do not recompute.</span>
<span class="sd">      - Specify certain features to not index, either via a parameter or via existing metadata.</span>
<span class="sd">      - Add warning if a categorical feature has only 1 category.</span>
<span class="sd">      - Add option for allowing unknown categories.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([(Vectors.dense([-1.0, 0.0]),),</span>
<span class="sd">    ...     (Vectors.dense([0.0, 1.0]),), (Vectors.dense([0.0, 2.0]),)], [&quot;a&quot;])</span>
<span class="sd">    &gt;&gt;&gt; indexer = VectorIndexer(maxCategories=2, inputCol=&quot;a&quot;, outputCol=&quot;indexed&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = indexer.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).head().indexed</span>
<span class="sd">    DenseVector([1.0, 0.0])</span>
<span class="sd">    &gt;&gt;&gt; model.numFeatures</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; model.categoryMaps</span>
<span class="sd">    {0: {0.0: 0, -1.0: 1}}</span>
<span class="sd">    &gt;&gt;&gt; indexer.setParams(outputCol=&quot;test&quot;).fit(df).transform(df).collect()[1].test</span>
<span class="sd">    DenseVector([0.0, 1.0])</span>
<span class="sd">    &gt;&gt;&gt; params = {indexer.maxCategories: 3, indexer.outputCol: &quot;vector&quot;}</span>
<span class="sd">    &gt;&gt;&gt; model2 = indexer.fit(df, params)</span>
<span class="sd">    &gt;&gt;&gt; model2.transform(df).head().vector</span>
<span class="sd">    DenseVector([1.0, 0.0])</span>
<span class="sd">    &gt;&gt;&gt; vectorIndexerPath = temp_path + &quot;/vector-indexer&quot;</span>
<span class="sd">    &gt;&gt;&gt; indexer.save(vectorIndexerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedIndexer = VectorIndexer.load(vectorIndexerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedIndexer.getMaxCategories() == indexer.getMaxCategories()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/vector-indexer-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = VectorIndexerModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.numFeatures == model.numFeatures</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.categoryMaps == model.categoryMaps</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">maxCategories</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxCategories&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;Threshold for the number of values a categorical feature can take &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;(&gt;= 2). If a feature is found to have &gt; maxCategories values, then &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;it is declared continuous.&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maxCategories</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, maxCategories=20, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VectorIndexer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.VectorIndexer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">maxCategories</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorIndexer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorIndexer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">maxCategories</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, maxCategories=20, inputCol=None, outputCol=None)</span>
<span class="sd">        Sets params for this VectorIndexer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorIndexer.setMaxCategories"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorIndexer.setMaxCategories">[docs]</a>    <span class="k">def</span> <span class="nf">setMaxCategories</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`maxCategories`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxCategories</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorIndexer.getMaxCategories"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorIndexer.getMaxCategories">[docs]</a>    <span class="k">def</span> <span class="nf">getMaxCategories</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of maxCategories or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxCategories</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">VectorIndexerModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="VectorIndexerModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorIndexerModel">[docs]</a><span class="k">class</span> <span class="nc">VectorIndexerModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`VectorIndexer`.</span>

<span class="sd">    Transform categorical features to use 0-based indices instead of their original values.</span>
<span class="sd">      - Categorical features are mapped to indices.</span>
<span class="sd">      - Continuous features (columns) are left unchanged.</span>

<span class="sd">    This also appends metadata to the output column, marking features as Numeric (continuous),</span>
<span class="sd">    Nominal (categorical), or Binary (either continuous or categorical).</span>
<span class="sd">    Non-ML metadata is not carried over from the input to the output column.</span>

<span class="sd">    This maintains vector sparsity.</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">numFeatures</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Number of features, i.e., length of Vectors which this transforms.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;numFeatures&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">categoryMaps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Feature value index.  Keys are categorical feature indices (column indices).</span>
<span class="sd">        Values are maps from original features values to 0-based category indices.</span>
<span class="sd">        If a feature is not in this map, it is treated as continuous.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;javaCategoryMaps&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="VectorSlicer"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorSlicer">[docs]</a><span class="k">class</span> <span class="nc">VectorSlicer</span><span class="p">(</span><span class="n">JavaTransformer</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class takes a feature vector and outputs a new feature vector with a subarray</span>
<span class="sd">    of the original features.</span>

<span class="sd">    The subset of features can be specified with either indices (`setIndices()`)</span>
<span class="sd">    or names (`setNames()`).  At least one feature must be selected. Duplicate features</span>
<span class="sd">    are not allowed, so there can be no overlap between selected indices and names.</span>

<span class="sd">    The output vector will order features with the selected indices first (in the order given),</span>
<span class="sd">    followed by the selected names (in the order given).</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([</span>
<span class="sd">    ...     (Vectors.dense([-2.0, 2.3, 0.0, 0.0, 1.0]),),</span>
<span class="sd">    ...     (Vectors.dense([0.0, 0.0, 0.0, 0.0, 0.0]),),</span>
<span class="sd">    ...     (Vectors.dense([0.6, -1.1, -3.0, 4.5, 3.3]),)], [&quot;features&quot;])</span>
<span class="sd">    &gt;&gt;&gt; vs = VectorSlicer(inputCol=&quot;features&quot;, outputCol=&quot;sliced&quot;, indices=[1, 4])</span>
<span class="sd">    &gt;&gt;&gt; vs.transform(df).head().sliced</span>
<span class="sd">    DenseVector([2.3, 1.0])</span>
<span class="sd">    &gt;&gt;&gt; vectorSlicerPath = temp_path + &quot;/vector-slicer&quot;</span>
<span class="sd">    &gt;&gt;&gt; vs.save(vectorSlicerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedVs = VectorSlicer.load(vectorSlicerPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedVs.getIndices() == vs.getIndices()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedVs.getNames() == vs.getNames()</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.6.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;indices&quot;</span><span class="p">,</span> <span class="s2">&quot;An array of indices to select features from &quot;</span> <span class="o">+</span>
                    <span class="s2">&quot;a vector column. There can be no overlap with names.&quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListInt</span><span class="p">)</span>
    <span class="n">names</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;names&quot;</span><span class="p">,</span> <span class="s2">&quot;An array of feature names to select features from &quot;</span> <span class="o">+</span>
                  <span class="s2">&quot;a vector column. These names must be specified by ML &quot;</span> <span class="o">+</span>
                  <span class="s2">&quot;org.apache.spark.ml.attribute.Attribute. There can be no overlap with &quot;</span> <span class="o">+</span>
                  <span class="s2">&quot;indices.&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, inputCol=None, outputCol=None, indices=None, names=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VectorSlicer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.VectorSlicer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[],</span> <span class="n">names</span><span class="o">=</span><span class="p">[])</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorSlicer.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorSlicer.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, inputCol=None, outputCol=None, indices=None, names=None):</span>
<span class="sd">        Sets params for this VectorSlicer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorSlicer.setIndices"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorSlicer.setIndices">[docs]</a>    <span class="k">def</span> <span class="nf">setIndices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`indices`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorSlicer.getIndices"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorSlicer.getIndices">[docs]</a>    <span class="k">def</span> <span class="nf">getIndices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of indices or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorSlicer.setNames"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorSlicer.setNames">[docs]</a>    <span class="k">def</span> <span class="nf">setNames</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`names`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">names</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.6.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="VectorSlicer.getNames"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.VectorSlicer.getNames">[docs]</a>    <span class="k">def</span> <span class="nf">getNames</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of names or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<span class="nd">@ignore_unicode_prefix</span>
<div class="viewcode-block" id="Word2Vec"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec">[docs]</a><span class="k">class</span> <span class="nc">Word2Vec</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasStepSize</span><span class="p">,</span> <span class="n">HasMaxIter</span><span class="p">,</span> <span class="n">HasSeed</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span>
               <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further</span>
<span class="sd">    natural language processing or machine learning process.</span>

<span class="sd">    &gt;&gt;&gt; sent = (&quot;a b &quot; * 100 + &quot;a c &quot; * 10).split(&quot; &quot;)</span>
<span class="sd">    &gt;&gt;&gt; doc = spark.createDataFrame([(sent,), (sent,)], [&quot;sentence&quot;])</span>
<span class="sd">    &gt;&gt;&gt; word2Vec = Word2Vec(vectorSize=5, seed=42, inputCol=&quot;sentence&quot;, outputCol=&quot;model&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = word2Vec.fit(doc)</span>
<span class="sd">    &gt;&gt;&gt; model.getVectors().show()</span>
<span class="sd">    +----+--------------------+</span>
<span class="sd">    |word|              vector|</span>
<span class="sd">    +----+--------------------+</span>
<span class="sd">    |   a|[0.09461779892444...|</span>
<span class="sd">    |   b|[1.15474212169647...|</span>
<span class="sd">    |   c|[-0.3794820010662...|</span>
<span class="sd">    +----+--------------------+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; from pyspark.sql.functions import format_number as fmt</span>
<span class="sd">    &gt;&gt;&gt; model.findSynonyms(&quot;a&quot;, 2).select(&quot;word&quot;, fmt(&quot;similarity&quot;, 5).alias(&quot;similarity&quot;)).show()</span>
<span class="sd">    +----+----------+</span>
<span class="sd">    |word|similarity|</span>
<span class="sd">    +----+----------+</span>
<span class="sd">    |   b|   0.25053|</span>
<span class="sd">    |   c|  -0.69805|</span>
<span class="sd">    +----+----------+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; model.transform(doc).head().model</span>
<span class="sd">    DenseVector([0.5524, -0.4995, -0.3599, 0.0241, 0.3461])</span>
<span class="sd">    &gt;&gt;&gt; word2vecPath = temp_path + &quot;/word2vec&quot;</span>
<span class="sd">    &gt;&gt;&gt; word2Vec.save(word2vecPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedWord2Vec = Word2Vec.load(word2vecPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedWord2Vec.getVectorSize() == word2Vec.getVectorSize()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedWord2Vec.getNumPartitions() == word2Vec.getNumPartitions()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedWord2Vec.getMinCount() == word2Vec.getMinCount()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/word2vec-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = Word2VecModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.getVectors().first().word == model.getVectors().first().word</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.getVectors().first().vector == model.getVectors().first().vector</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">vectorSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;vectorSize&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;the dimension of codes after transforming from words&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">numPartitions</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;numPartitions&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;number of partitions for sentences of words&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">minCount</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minCount&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;the minimum number of times a token must appear to be included in the &quot;</span> <span class="o">+</span>
                     <span class="s2">&quot;word2vec model&#39;s vocabulary&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">windowSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;windowSize&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;the window size (context words from [-window, window]). Default value is 5&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Maximum length (in words) of each sentence in the input data. &quot;</span> <span class="o">+</span>
                              <span class="s2">&quot;Any sentence longer than this threshold will &quot;</span> <span class="o">+</span>
                              <span class="s2">&quot;be divided into chunks up to the size.&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectorSize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">minCount</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">numPartitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stepSize</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">windowSize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, \</span>
<span class="sd">                 seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Word2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.Word2Vec&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">vectorSize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">minCount</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">numPartitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stepSize</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">windowSize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vectorSize</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">minCount</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">numPartitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stepSize</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">windowSize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, \</span>
<span class="sd">                 inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)</span>
<span class="sd">        Sets params for this Word2Vec.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.setVectorSize"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.setVectorSize">[docs]</a>    <span class="k">def</span> <span class="nf">setVectorSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`vectorSize`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">vectorSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.getVectorSize"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.getVectorSize">[docs]</a>    <span class="k">def</span> <span class="nf">getVectorSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of vectorSize or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vectorSize</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.setNumPartitions"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.setNumPartitions">[docs]</a>    <span class="k">def</span> <span class="nf">setNumPartitions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`numPartitions`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">numPartitions</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.getNumPartitions"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.getNumPartitions">[docs]</a>    <span class="k">def</span> <span class="nf">getNumPartitions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of numPartitions or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">numPartitions</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.setMinCount"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.setMinCount">[docs]</a>    <span class="k">def</span> <span class="nf">setMinCount</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`minCount`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minCount</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.4.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.getMinCount"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.getMinCount">[docs]</a>    <span class="k">def</span> <span class="nf">getMinCount</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of minCount or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">minCount</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.setWindowSize"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.setWindowSize">[docs]</a>    <span class="k">def</span> <span class="nf">setWindowSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`windowSize`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">windowSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.getWindowSize"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.getWindowSize">[docs]</a>    <span class="k">def</span> <span class="nf">getWindowSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of windowSize or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">windowSize</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.setMaxSentenceLength"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.setMaxSentenceLength">[docs]</a>    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`maxSentenceLength`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2Vec.getMaxSentenceLength"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2Vec.getMaxSentenceLength">[docs]</a>    <span class="k">def</span> <span class="nf">getMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of maxSentenceLength or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxSentenceLength</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Word2VecModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="Word2VecModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2VecModel">[docs]</a><span class="k">class</span> <span class="nc">Word2VecModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`Word2Vec`.</span>

<span class="sd">    .. versionadded:: 1.4.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2VecModel.getVectors"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2VecModel.getVectors">[docs]</a>    <span class="k">def</span> <span class="nf">getVectors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the vector representation of the words as a dataframe</span>
<span class="sd">        with two fields, word and vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;getVectors&quot;</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="Word2VecModel.findSynonyms"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.Word2VecModel.findSynonyms">[docs]</a>    <span class="k">def</span> <span class="nf">findSynonyms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">num</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Find &quot;num&quot; number of words closest in similarity to &quot;word&quot;.</span>
<span class="sd">        word can be a string or vector representation.</span>
<span class="sd">        Returns a dataframe with two fields word and similarity (which</span>
<span class="sd">        gives the cosine similarity).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">basestring</span><span class="p">):</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">_convert_to_vector</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;findSynonyms&quot;</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span></div></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="PCA"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PCA">[docs]</a><span class="k">class</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasInputCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    PCA trains a model to project vectors to a lower dimensional space of the</span>
<span class="sd">    top :py:attr:`k` principal components.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; data = [(Vectors.sparse(5, [(1, 1.0), (3, 7.0)]),),</span>
<span class="sd">    ...     (Vectors.dense([2.0, 0.0, 3.0, 4.0, 5.0]),),</span>
<span class="sd">    ...     (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),)]</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data,[&quot;features&quot;])</span>
<span class="sd">    &gt;&gt;&gt; pca = PCA(k=2, inputCol=&quot;features&quot;, outputCol=&quot;pca_features&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = pca.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).collect()[0].pca_features</span>
<span class="sd">    DenseVector([1.648..., -4.013...])</span>
<span class="sd">    &gt;&gt;&gt; model.explainedVariance</span>
<span class="sd">    DenseVector([0.794..., 0.205...])</span>
<span class="sd">    &gt;&gt;&gt; pcaPath = temp_path + &quot;/pca&quot;</span>
<span class="sd">    &gt;&gt;&gt; pca.save(pcaPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedPca = PCA.load(pcaPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedPca.getK() == pca.getK()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/pca-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = PCAModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.pc == model.pc</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.explainedVariance == model.explainedVariance</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 1.5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="s2">&quot;the number of principal components&quot;</span><span class="p">,</span>
              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, k=None, inputCol=None, outputCol=None)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PCA</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.PCA&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="PCA.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PCA.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, k=None, inputCol=None, outputCol=None)</span>
<span class="sd">        Set params for this PCA.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="PCA.setK"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PCA.setK">[docs]</a>    <span class="k">def</span> <span class="nf">setK</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`k`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="PCA.getK"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PCA.getK">[docs]</a>    <span class="k">def</span> <span class="nf">getK</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of k or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">PCAModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="PCAModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.PCAModel">[docs]</a><span class="k">class</span> <span class="nc">PCAModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model fitted by :py:class:`PCA`. Transforms vectors to a lower dimensional space.</span>

<span class="sd">    .. versionadded:: 1.5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">pc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a principal components Matrix.</span>
<span class="sd">        Each column is one principal component.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;pc&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">explainedVariance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a vector of proportions of variance</span>
<span class="sd">        explained by each principal component.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;explainedVariance&quot;</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="RFormula"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormula">[docs]</a><span class="k">class</span> <span class="nc">RFormula</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasFeaturesCol</span><span class="p">,</span> <span class="n">HasLabelCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note:: Experimental</span>

<span class="sd">    Implements the transforms required for fitting a dataset against an</span>
<span class="sd">    R model formula. Currently we support a limited subset of the R</span>
<span class="sd">    operators, including &#39;~&#39;, &#39;.&#39;, &#39;:&#39;, &#39;+&#39;, and &#39;-&#39;. Also see the `R formula docs</span>
<span class="sd">    &lt;http://stat.ethz.ch/R-manual/R-patched/library/stats/html/formula.html&gt;`_.</span>

<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame([</span>
<span class="sd">    ...     (1.0, 1.0, &quot;a&quot;),</span>
<span class="sd">    ...     (0.0, 2.0, &quot;b&quot;),</span>
<span class="sd">    ...     (0.0, 0.0, &quot;a&quot;)</span>
<span class="sd">    ... ], [&quot;y&quot;, &quot;x&quot;, &quot;s&quot;])</span>
<span class="sd">    &gt;&gt;&gt; rf = RFormula(formula=&quot;y ~ x + s&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = rf.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).show()</span>
<span class="sd">    +---+---+---+---------+-----+</span>
<span class="sd">    |  y|  x|  s| features|label|</span>
<span class="sd">    +---+---+---+---------+-----+</span>
<span class="sd">    |1.0|1.0|  a|[1.0,1.0]|  1.0|</span>
<span class="sd">    |0.0|2.0|  b|[2.0,0.0]|  0.0|</span>
<span class="sd">    |0.0|0.0|  a|[0.0,1.0]|  0.0|</span>
<span class="sd">    +---+---+---+---------+-----+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; rf.fit(df, {rf.formula: &quot;y ~ . - s&quot;}).transform(df).show()</span>
<span class="sd">    +---+---+---+--------+-----+</span>
<span class="sd">    |  y|  x|  s|features|label|</span>
<span class="sd">    +---+---+---+--------+-----+</span>
<span class="sd">    |1.0|1.0|  a|   [1.0]|  1.0|</span>
<span class="sd">    |0.0|2.0|  b|   [2.0]|  0.0|</span>
<span class="sd">    |0.0|0.0|  a|   [0.0]|  0.0|</span>
<span class="sd">    +---+---+---+--------+-----+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; rFormulaPath = temp_path + &quot;/rFormula&quot;</span>
<span class="sd">    &gt;&gt;&gt; rf.save(rFormulaPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedRF = RFormula.load(rFormulaPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedRF.getFormula() == rf.getFormula()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedRF.getFeaturesCol() == rf.getFeaturesCol()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedRF.getLabelCol() == rf.getLabelCol()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; str(loadedRF)</span>
<span class="sd">    &#39;RFormula(y ~ x + s) (uid=...)&#39;</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/rFormulaModel&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = RFormulaModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.uid == model.uid</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.transform(df).show()</span>
<span class="sd">    +---+---+---+---------+-----+</span>
<span class="sd">    |  y|  x|  s| features|label|</span>
<span class="sd">    +---+---+---+---------+-----+</span>
<span class="sd">    |1.0|1.0|  a|[1.0,1.0]|  1.0|</span>
<span class="sd">    |0.0|2.0|  b|[2.0,0.0]|  0.0|</span>
<span class="sd">    |0.0|0.0|  a|[0.0,1.0]|  0.0|</span>
<span class="sd">    +---+---+---+---------+-----+</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; str(loadedModel)</span>
<span class="sd">    &#39;RFormulaModel(ResolvedRFormula(label=y, terms=[x,s], hasIntercept=true)) (uid=...)&#39;</span>

<span class="sd">    .. versionadded:: 1.5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">formula</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;formula&quot;</span><span class="p">,</span> <span class="s2">&quot;R model formula&quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">forceIndexLabel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;forceIndexLabel&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Force to index label whether it is numeric or string&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">formula</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
                 <span class="n">forceIndexLabel</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, formula=None, featuresCol=&quot;features&quot;, labelCol=&quot;label&quot;, \</span>
<span class="sd">                 forceIndexLabel=False)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RFormula</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.RFormula&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">forceIndexLabel</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RFormula.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormula.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">formula</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
                  <span class="n">forceIndexLabel</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, formula=None, featuresCol=&quot;features&quot;, labelCol=&quot;label&quot;, \</span>
<span class="sd">                  forceIndexLabel=False)</span>
<span class="sd">        Sets params for RFormula.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RFormula.setFormula"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormula.setFormula">[docs]</a>    <span class="k">def</span> <span class="nf">setFormula</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`formula`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;1.5.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RFormula.getFormula"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormula.getFormula">[docs]</a>    <span class="k">def</span> <span class="nf">getFormula</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`formula`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RFormula.setForceIndexLabel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormula.setForceIndexLabel">[docs]</a>    <span class="k">def</span> <span class="nf">setForceIndexLabel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`forceIndexLabel`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">forceIndexLabel</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="RFormula.getForceIndexLabel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormula.getForceIndexLabel">[docs]</a>    <span class="k">def</span> <span class="nf">getForceIndexLabel</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of :py:attr:`forceIndexLabel`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">forceIndexLabel</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">RFormulaModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">formulaStr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getFormula</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">isDefined</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">formula</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;RFormula(</span><span class="si">%s</span><span class="s2">) (uid=</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">formulaStr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span></div>


<div class="viewcode-block" id="RFormulaModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.RFormulaModel">[docs]</a><span class="k">class</span> <span class="nc">RFormulaModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note:: Experimental</span>

<span class="sd">    Model fitted by :py:class:`RFormula`. Fitting is required to determine the</span>
<span class="sd">    factor levels of formula terms.</span>

<span class="sd">    .. versionadded:: 1.5.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">resolvedFormula</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;resolvedFormula&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;RFormulaModel(</span><span class="si">%s</span><span class="s2">) (uid=</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">resolvedFormula</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span></div>


<span class="nd">@inherit_doc</span>
<div class="viewcode-block" id="ChiSqSelector"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector">[docs]</a><span class="k">class</span> <span class="nc">ChiSqSelector</span><span class="p">(</span><span class="n">JavaEstimator</span><span class="p">,</span> <span class="n">HasFeaturesCol</span><span class="p">,</span> <span class="n">HasOutputCol</span><span class="p">,</span> <span class="n">HasLabelCol</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span>
                    <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note:: Experimental</span>

<span class="sd">    Chi-Squared feature selection, which selects categorical features to use for predicting a</span>
<span class="sd">    categorical label.</span>

<span class="sd">    &gt;&gt;&gt; from pyspark.ml.linalg import Vectors</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(</span>
<span class="sd">    ...    [(Vectors.dense([0.0, 0.0, 18.0, 1.0]), 1.0),</span>
<span class="sd">    ...     (Vectors.dense([0.0, 1.0, 12.0, 0.0]), 0.0),</span>
<span class="sd">    ...     (Vectors.dense([1.0, 0.0, 15.0, 0.1]), 0.0)],</span>
<span class="sd">    ...    [&quot;features&quot;, &quot;label&quot;])</span>
<span class="sd">    &gt;&gt;&gt; selector = ChiSqSelector(numTopFeatures=1, outputCol=&quot;selectedFeatures&quot;)</span>
<span class="sd">    &gt;&gt;&gt; model = selector.fit(df)</span>
<span class="sd">    &gt;&gt;&gt; model.transform(df).head().selectedFeatures</span>
<span class="sd">    DenseVector([18.0])</span>
<span class="sd">    &gt;&gt;&gt; model.selectedFeatures</span>
<span class="sd">    [2]</span>
<span class="sd">    &gt;&gt;&gt; chiSqSelectorPath = temp_path + &quot;/chi-sq-selector&quot;</span>
<span class="sd">    &gt;&gt;&gt; selector.save(chiSqSelectorPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedSelector = ChiSqSelector.load(chiSqSelectorPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedSelector.getNumTopFeatures() == selector.getNumTopFeatures()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; modelPath = temp_path + &quot;/chi-sq-selector-model&quot;</span>
<span class="sd">    &gt;&gt;&gt; model.save(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel = ChiSqSelectorModel.load(modelPath)</span>
<span class="sd">    &gt;&gt;&gt; loadedModel.selectedFeatures == model.selectedFeatures</span>
<span class="sd">    True</span>

<span class="sd">    .. versionadded:: 2.0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">selectorType</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;selectorType&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;The selector type of the ChisqSelector. &quot;</span> <span class="o">+</span>
                         <span class="s2">&quot;Supported options: numTopFeatures (default), percentile and fpr.&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">numTopFeatures</span> <span class="o">=</span> \
        <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;numTopFeatures&quot;</span><span class="p">,</span>
              <span class="s2">&quot;Number of features that selector will select, ordered by ascending p-value. &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;If the number of features is &lt; numTopFeatures, then this will select &quot;</span> <span class="o">+</span>
              <span class="s2">&quot;all features.&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">percentile</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;percentile&quot;</span><span class="p">,</span> <span class="s2">&quot;Percentile of features that selector &quot;</span> <span class="o">+</span>
                       <span class="s2">&quot;will select, ordered by ascending p-value.&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">fpr</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;fpr&quot;</span><span class="p">,</span> <span class="s2">&quot;The highest p-value for features to be kept.&quot;</span><span class="p">,</span>
                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numTopFeatures</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">selectorType</span><span class="o">=</span><span class="s2">&quot;numTopFeatures&quot;</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">fpr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        __init__(self, numTopFeatures=50, featuresCol=&quot;features&quot;, outputCol=None, \</span>
<span class="sd">                 labelCol=&quot;label&quot;, selectorType=&quot;numTopFeatures&quot;, percentile=0.1, fpr=0.05)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChiSqSelector</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_new_java_obj</span><span class="p">(</span><span class="s2">&quot;org.apache.spark.ml.feature.ChiSqSelector&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">numTopFeatures</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">selectorType</span><span class="o">=</span><span class="s2">&quot;numTopFeatures&quot;</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                         <span class="n">fpr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setParams</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.setParams"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.setParams">[docs]</a>    <span class="k">def</span> <span class="nf">setParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numTopFeatures</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">featuresCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="n">selectorType</span><span class="o">=</span><span class="s2">&quot;numTopFeatures&quot;</span><span class="p">,</span> <span class="n">percentile</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">fpr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        setParams(self, numTopFeatures=50, featuresCol=&quot;features&quot;, outputCol=None, \</span>
<span class="sd">                  labelCol=&quot;labels&quot;, selectorType=&quot;numTopFeatures&quot;, percentile=0.1, fpr=0.05)</span>
<span class="sd">        Sets params for this ChiSqSelector.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.setSelectorType"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.setSelectorType">[docs]</a>    <span class="k">def</span> <span class="nf">setSelectorType</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`selectorType`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">selectorType</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.getSelectorType"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.getSelectorType">[docs]</a>    <span class="k">def</span> <span class="nf">getSelectorType</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of selectorType or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">selectorType</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.setNumTopFeatures"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.setNumTopFeatures">[docs]</a>    <span class="k">def</span> <span class="nf">setNumTopFeatures</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`numTopFeatures`.</span>
<span class="sd">        Only applicable when selectorType = &quot;numTopFeatures&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">numTopFeatures</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.getNumTopFeatures"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.getNumTopFeatures">[docs]</a>    <span class="k">def</span> <span class="nf">getNumTopFeatures</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of numTopFeatures or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">numTopFeatures</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.setPercentile"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.setPercentile">[docs]</a>    <span class="k">def</span> <span class="nf">setPercentile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`percentile`.</span>
<span class="sd">        Only applicable when selectorType = &quot;percentile&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.getPercentile"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.getPercentile">[docs]</a>    <span class="k">def</span> <span class="nf">getPercentile</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of percentile or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">percentile</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.setFpr"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.setFpr">[docs]</a>    <span class="k">def</span> <span class="nf">setFpr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`fpr`.</span>
<span class="sd">        Only applicable when selectorType = &quot;fpr&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">fpr</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">)</span>
<div class="viewcode-block" id="ChiSqSelector.getFpr"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelector.getFpr">[docs]</a>    <span class="k">def</span> <span class="nf">getFpr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gets the value of fpr or its default value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fpr</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ChiSqSelectorModel</span><span class="p">(</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="ChiSqSelectorModel"><a class="viewcode-back" href="../../../pyspark.ml.html#pyspark.ml.feature.ChiSqSelectorModel">[docs]</a><span class="k">class</span> <span class="nc">ChiSqSelectorModel</span><span class="p">(</span><span class="n">JavaModel</span><span class="p">,</span> <span class="n">JavaMLReadable</span><span class="p">,</span> <span class="n">JavaMLWritable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    .. note:: Experimental</span>

<span class="sd">    Model fitted by :py:class:`ChiSqSelector`.</span>

<span class="sd">    .. versionadded:: 2.0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@since</span><span class="p">(</span><span class="s2">&quot;2.0.0&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">selectedFeatures</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        List of indices to select (filter).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s2">&quot;selectedFeatures&quot;</span><span class="p">)</span></div>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="kn">import</span> <span class="nn">tempfile</span>

    <span class="kn">import</span> <span class="nn">pyspark.ml.feature</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="k">import</span> <span class="n">Row</span><span class="p">,</span> <span class="n">SparkSession</span>

    <span class="n">globs</span> <span class="o">=</span> <span class="nb">globals</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">ml</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">globs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="c1"># The small batch size here ensures that we see multiple batches,</span>
    <span class="c1"># even in these small test examples:</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span>\
        <span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;ml.feature tests&quot;</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
    <span class="n">globs</span><span class="p">[</span><span class="s1">&#39;sc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sc</span>
    <span class="n">globs</span><span class="p">[</span><span class="s1">&#39;spark&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spark</span>
    <span class="n">testData</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">),</span>
                               <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;a&quot;</span><span class="p">),</span>
                               <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;a&quot;</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;c&quot;</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">globs</span><span class="p">[</span><span class="s1">&#39;stringIndDf&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">testData</span><span class="p">)</span>
    <span class="n">temp_path</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
    <span class="n">globs</span><span class="p">[</span><span class="s1">&#39;temp_path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp_path</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="p">(</span><span class="n">failure_count</span><span class="p">,</span> <span class="n">test_count</span><span class="p">)</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="n">globs</span><span class="p">,</span> <span class="n">optionflags</span><span class="o">=</span><span class="n">doctest</span><span class="o">.</span><span class="n">ELLIPSIS</span><span class="p">)</span>
        <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">shutil</span> <span class="k">import</span> <span class="n">rmtree</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">rmtree</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
            <span class="k">pass</span>
    <span class="k">if</span> <span class="n">failure_count</span><span class="p">:</span>
        <span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../index.html">
              <img class="logo" src="../../../_static/spark-logo-hd.png" alt="Logo"/>
            </a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
    
        <li class="nav-item nav-item-0"><a href="../../../index.html">PySpark 2.1.2 documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.6.
    </div>
  </body>
</html>