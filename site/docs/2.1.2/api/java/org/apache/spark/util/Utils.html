<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.7.0_151) on Mon Oct 02 14:47:28 PDT 2017 -->
<title>Utils (Spark 2.1.2 JavaDoc)</title>
<meta name="date" content="2017-10-02">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="Utils (Spark 2.1.2 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/util/ThreadUtils.html" title="class in org.apache.spark.util"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/util/VersionUtils.html" title="class in org.apache.spark.util"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/util/Utils.html" target="_top">Frames</a></li>
<li><a href="Utils.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.util</div>
<h2 title="Class Utils" class="title">Class Utils</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.util.Utils</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public class <span class="strong">Utils</span>
extends Object</pre>
<div class="block">Various utility methods used by Spark.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#Utils()">Utils</a></strong>()</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#BACKUP_STANDALONE_MASTER_PREFIX()">BACKUP_STANDALONE_MASTER_PREFIX</a></strong>()</code>
<div class="block">An identifier that backup masters use in their responses.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#bytesToString(long)">bytesToString</a></strong>(long&nbsp;size)</code>
<div class="block">Convert a quantity in bytes to a human-readable string such as "4.0 MB".</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#byteStringAsBytes(java.lang.String)">byteStringAsBytes</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a passed byte string (e.g.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#byteStringAsGb(java.lang.String)">byteStringAsGb</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a passed byte string (e.g.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#byteStringAsKb(java.lang.String)">byteStringAsKb</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a passed byte string (e.g.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#byteStringAsMb(java.lang.String)">byteStringAsMb</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a passed byte string (e.g.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#checkHost(java.lang.String,%20java.lang.String)">checkHost</a></strong>(String&nbsp;host,
         String&nbsp;message)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#checkHostPort(java.lang.String,%20java.lang.String)">checkHostPort</a></strong>(String&nbsp;hostPort,
             String&nbsp;message)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#chmod700(java.io.File)">chmod700</a></strong>(java.io.File&nbsp;file)</code>
<div class="block">JDK equivalent of <code>chmod 700 file</code>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static Class&lt;?&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#classForName(java.lang.String)">classForName</a></strong>(String&nbsp;className)</code>
<div class="block">Preferred alternative to Class.forName(className)</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#classIsLoadable(java.lang.String)">classIsLoadable</a></strong>(String&nbsp;clazz)</code>
<div class="block">Determines whether the provided class is loadable in the current thread.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#clone(T,%20org.apache.spark.serializer.SerializerInstance,%20scala.reflect.ClassTag)">clone</a></strong>(T&nbsp;value,
     <a href="../../../../org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a>&nbsp;serializer,
     scala.reflect.ClassTag&lt;T&gt;&nbsp;evidence$2)</code>
<div class="block">Clone an object using a Spark serializer.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#configTestLog4j(java.lang.String)">configTestLog4j</a></strong>(String&nbsp;level)</code>
<div class="block">config a log4j properties used for testsuite</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.net.URI</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#constructURIForAuthentication(java.net.URI,%20org.apache.spark.SecurityManager)">constructURIForAuthentication</a></strong>(java.net.URI&nbsp;uri,
                             org.apache.spark.SecurityManager&nbsp;securityMgr)</code>
<div class="block">Construct a URI container information used for authentication.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#copyFileStreamNIO(java.nio.channels.FileChannel,%20java.nio.channels.FileChannel,%20long,%20long)">copyFileStreamNIO</a></strong>(java.nio.channels.FileChannel&nbsp;input,
                 java.nio.channels.FileChannel&nbsp;output,
                 long&nbsp;startPosition,
                 long&nbsp;bytesToCopy)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#copyStream(java.io.InputStream,%20java.io.OutputStream,%20boolean,%20boolean)">copyStream</a></strong>(java.io.InputStream&nbsp;in,
          java.io.OutputStream&nbsp;out,
          boolean&nbsp;closeStreams,
          boolean&nbsp;transferToEnabled)</code>
<div class="block">Copy all data from an InputStream to an OutputStream.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.io.File</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#createDirectory(java.lang.String,%20java.lang.String)">createDirectory</a></strong>(String&nbsp;root,
               String&nbsp;namePrefix)</code>
<div class="block">Create a directory inside the given parent directory.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.io.File</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#createTempDir(java.lang.String,%20java.lang.String)">createTempDir</a></strong>(String&nbsp;root,
             String&nbsp;namePrefix)</code>
<div class="block">Create a temporary directory inside the given parent directory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#decodeFileNameInURI(java.net.URI)">decodeFileNameInURI</a></strong>(java.net.URI&nbsp;uri)</code>
<div class="block">Get the file name from uri's raw path and decode it.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#DEFAULT_DRIVER_MEM_MB()">DEFAULT_DRIVER_MEM_MB</a></strong>()</code>
<div class="block">Define a default value for driver memory here since this value is referenced across the code
 base and nearly all files already use Utils.scala</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#DEFAULT_MAX_TO_STRING_FIELDS()">DEFAULT_MAX_TO_STRING_FIELDS</a></strong>()</code>
<div class="block">The performance overhead of creating and logging strings for wide schemas can be large.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#deleteRecursively(java.io.File)">deleteRecursively</a></strong>(java.io.File&nbsp;file)</code>
<div class="block">Delete a file or directory and its contents recursively.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#deserialize(byte[])">deserialize</a></strong>(byte[]&nbsp;bytes)</code>
<div class="block">Deserialize an object using Java serialization</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#deserialize(byte[],%20java.lang.ClassLoader)">deserialize</a></strong>(byte[]&nbsp;bytes,
           ClassLoader&nbsp;loader)</code>
<div class="block">Deserialize an object using Java serialization and the given ClassLoader</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#deserializeLongValue(byte[])">deserializeLongValue</a></strong>(byte[]&nbsp;bytes)</code>
<div class="block">Deserialize a Long value (used for <code>PythonPartitioner</code>)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#deserializeViaNestedStream(java.io.InputStream,%20org.apache.spark.serializer.SerializerInstance,%20scala.Function1)">deserializeViaNestedStream</a></strong>(java.io.InputStream&nbsp;is,
                          <a href="../../../../org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a>&nbsp;ser,
                          scala.Function1&lt;<a href="../../../../org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</a>,scala.runtime.BoxedUnit&gt;&nbsp;f)</code>
<div class="block">Deserialize via nested stream using specific serializer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#doesDirectoryContainAnyNewFiles(java.io.File,%20long)">doesDirectoryContainAnyNewFiles</a></strong>(java.io.File&nbsp;dir,
                               long&nbsp;cutoff)</code>
<div class="block">Determines if a directory contains any files newer than cutoff seconds.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.immutable.Set&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#EMPTY_USER_GROUPS()">EMPTY_USER_GROUPS</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.json4s.JsonAST.JObject</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#emptyJson()">emptyJson</a></strong>()</code>
<div class="block">Return an empty JSON object</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#encodeFileNameToURIRawPath(java.lang.String)">encodeFileNameToURIRawPath</a></strong>(String&nbsp;fileName)</code>
<div class="block">A file name may contain some invalid URI characters, such as " ".</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#exceptionString(java.lang.Throwable)">exceptionString</a></strong>(Throwable&nbsp;e)</code>
<div class="block">Return a nice string representation of the exception.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#executeAndGetOutput(scala.collection.Seq,%20java.io.File,%20scala.collection.Map,%20boolean)">executeAndGetOutput</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;command,
                   java.io.File&nbsp;workingDir,
                   scala.collection.Map&lt;String,String&gt;&nbsp;extraEnvironment,
                   boolean&nbsp;redirectStderr)</code>
<div class="block">Execute a command and get its output, throwing an exception if it yields a code other than 0.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static Process</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#executeCommand(scala.collection.Seq,%20java.io.File,%20scala.collection.Map,%20boolean)">executeCommand</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;command,
              java.io.File&nbsp;workingDir,
              scala.collection.Map&lt;String,String&gt;&nbsp;extraEnvironment,
              boolean&nbsp;redirectStderr)</code>
<div class="block">Execute a command and return the process running the command.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.Tuple2&lt;String,Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#extractHostPortFromSparkUrl(java.lang.String)">extractHostPortFromSparkUrl</a></strong>(String&nbsp;sparkUrl)</code>
<div class="block">Return a pair of host and port extracted from the <code>sparkUrl</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#fetchFile(java.lang.String,%20java.io.File,%20org.apache.spark.SparkConf,%20org.apache.spark.SecurityManager,%20org.apache.hadoop.conf.Configuration,%20long,%20boolean)">fetchFile</a></strong>(String&nbsp;url,
         java.io.File&nbsp;targetDir,
         <a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
         org.apache.spark.SecurityManager&nbsp;securityMgr,
         org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
         long&nbsp;timestamp,
         boolean&nbsp;useCache)</code>
<div class="block">Download a file or directory to target directory.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.spark.util.CallSite</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getCallSite(scala.Function1)">getCallSite</a></strong>(scala.Function1&lt;String,Object&gt;&nbsp;skipClass)</code>
<div class="block">When called inside a class in the spark package, returns the name of the user code class
 (outside the spark package) that called into Spark, as well as which Spark method they called.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getConfiguredLocalDirs(org.apache.spark.SparkConf)">getConfiguredLocalDirs</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>
<div class="block">Return the configured local directories where Spark can write files.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static ClassLoader</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getContextOrSparkClassLoader()">getContextOrSparkClassLoader</a></strong>()</code>
<div class="block">Get the Context ClassLoader on this thread or, if not present, the ClassLoader that
 loaded Spark.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.immutable.Set&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getCurrentUserGroups(org.apache.spark.SparkConf,%20java.lang.String)">getCurrentUserGroups</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;sparkConf,
                    String&nbsp;username)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getCurrentUserName()">getCurrentUserName</a></strong>()</code>
<div class="block">Returns the current user name.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getDefaultPropertiesFile(scala.collection.Map)">getDefaultPropertiesFile</a></strong>(scala.collection.Map&lt;String,String&gt;&nbsp;env)</code>
<div class="block">Return the path of the default Spark properties file.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getDynamicAllocationInitialExecutors(org.apache.spark.SparkConf)">getDynamicAllocationInitialExecutors</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>
<div class="block">Return the initial number of executors for dynamic allocation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getFileLength(java.io.File,%20org.apache.spark.SparkConf)">getFileLength</a></strong>(java.io.File&nbsp;file,
             <a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;workConf)</code>
<div class="block">Return the file length, if the file is compressed it returns the uncompressed file length.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getFilePath(java.io.File,%20java.lang.String)">getFilePath</a></strong>(java.io.File&nbsp;dir,
           String&nbsp;fileName)</code>
<div class="block">Return the absolute path of a file in the given directory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getFormattedClassName(java.lang.Object)">getFormattedClassName</a></strong>(Object&nbsp;obj)</code>
<div class="block">Return the class name of the given object, removing all dollar signs</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.hadoop.fs.FileSystem</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getHadoopFileSystem(java.lang.String,%20org.apache.hadoop.conf.Configuration)">getHadoopFileSystem</a></strong>(String&nbsp;path,
                   org.apache.hadoop.conf.Configuration&nbsp;conf)</code>
<div class="block">Return a Hadoop FileSystem with the scheme encoded in the given path.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static org.apache.hadoop.fs.FileSystem</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getHadoopFileSystem(java.net.URI,%20org.apache.hadoop.conf.Configuration)">getHadoopFileSystem</a></strong>(java.net.URI&nbsp;path,
                   org.apache.hadoop.conf.Configuration&nbsp;conf)</code>
<div class="block">Return a Hadoop FileSystem with the scheme encoded in the given path.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getIteratorSize(scala.collection.Iterator)">getIteratorSize</a></strong>(scala.collection.Iterator&lt;T&gt;&nbsp;iterator)</code>
<div class="block">Counts the number of elements of an iterator using a while loop rather than calling
 <code>TraversableOnce.size()</code> because it uses a for loop, which is slightly slower
 in the current version of Scala.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;scala.collection.Iterator&lt;scala.Tuple2&lt;T,Object&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getIteratorZipWithIndex(scala.collection.Iterator,%20long)">getIteratorZipWithIndex</a></strong>(scala.collection.Iterator&lt;T&gt;&nbsp;iterator,
                       long&nbsp;startIndex)</code>
<div class="block">Generate a zipWithIndex iterator, avoid index value overflowing problem
 in scala's zipWithIndex</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getLocalDir(org.apache.spark.SparkConf)">getLocalDir</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>
<div class="block">Get the path of a temporary directory.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getMaxResultSize(org.apache.spark.SparkConf)">getMaxResultSize</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getProcessName()">getProcessName</a></strong>()</code>
<div class="block">Returns the name of this JVM process.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getPropertiesFromFile(java.lang.String)">getPropertiesFromFile</a></strong>(String&nbsp;filename)</code>
<div class="block">Load properties present in the given file.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static ClassLoader</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getSparkClassLoader()">getSparkClassLoader</a></strong>()</code>
<div class="block">Get the ClassLoader which loaded Spark.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getSparkOrYarnConfig(org.apache.spark.SparkConf,%20java.lang.String,%20java.lang.String)">getSparkOrYarnConfig</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                    String&nbsp;key,
                    String&nbsp;default_)</code>
<div class="block">Return the value of a config either through the SparkConf or the Hadoop configuration
 if this is Yarn mode.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.Option&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getStderr(java.lang.Process,%20long)">getStderr</a></strong>(Process&nbsp;process,
         long&nbsp;timeoutMs)</code>
<div class="block">Return the stderr of a process after waiting for the process to terminate.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getSystemProperties()">getSystemProperties</a></strong>()</code>
<div class="block">Returns the system properties map that is thread-safe to iterator over.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static org.apache.spark.util.ThreadStackTrace[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getThreadDump()">getThreadDump</a></strong>()</code>
<div class="block">Return a thread dump of all threads' stacktraces.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.Option&lt;org.apache.spark.util.ThreadStackTrace&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getThreadDumpForThread(long)">getThreadDumpForThread</a></strong>(long&nbsp;threadId)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getUsedTimeMs(long)">getUsedTimeMs</a></strong>(long&nbsp;startTimeMs)</code>
<div class="block">Return the string to tell how long has passed in milliseconds.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#getUserJars(org.apache.spark.SparkConf,%20boolean)">getUserJars</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
           boolean&nbsp;isShell)</code>
<div class="block">In YARN mode this method returns a union of the jar files pointed by "spark.jars" and the
 "spark.yarn.dist.jars" properties, while in other modes it returns the jar files pointed by
 only the "spark.jars" property.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#initDaemon(org.slf4j.Logger)">initDaemon</a></strong>(org.slf4j.Logger&nbsp;log)</code>
<div class="block">Utility function that should be called early in <code>main()</code> for daemons to set up some common
 diagnostic state.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#invoke(java.lang.Class,%20java.lang.Object,%20java.lang.String,%20scala.collection.Seq)">invoke</a></strong>(Class&lt;?&gt;&nbsp;clazz,
      Object&nbsp;obj,
      String&nbsp;methodName,
      scala.collection.Seq&lt;scala.Tuple2&lt;Class&lt;?&gt;,Object&gt;&gt;&nbsp;args)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isBindCollision(java.lang.Throwable)">isBindCollision</a></strong>(Throwable&nbsp;exception)</code>
<div class="block">Return whether the exception is caused by an address-port collision when binding.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isDynamicAllocationEnabled(org.apache.spark.SparkConf)">isDynamicAllocationEnabled</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>
<div class="block">Return whether dynamic allocation is enabled in the given conf.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isFatalError(java.lang.Throwable)">isFatalError</a></strong>(Throwable&nbsp;e)</code>
<div class="block">Returns true if the given exception was fatal.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isInDirectory(java.io.File,%20java.io.File)">isInDirectory</a></strong>(java.io.File&nbsp;parent,
             java.io.File&nbsp;child)</code>
<div class="block">Return whether the specified file is a parent directory of the child file.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isLocalMaster(org.apache.spark.SparkConf)">isLocalMaster</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isMac()">isMac</a></strong>()</code>
<div class="block">Whether the underlying operating system is Mac OS X.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isSymlink(java.io.File)">isSymlink</a></strong>(java.io.File&nbsp;file)</code>
<div class="block">Check to see if file is a symbolic link.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isTesting()">isTesting</a></strong>()</code>
<div class="block">Indicates whether Spark is currently running unit tests.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#isWindows()">isWindows</a></strong>()</code>
<div class="block">Whether the underlying operating system is Windows.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.Option&lt;org.json4s.JsonAST.JValue&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#jsonOption(org.json4s.JsonAST.JValue)">jsonOption</a></strong>(org.json4s.JsonAST.JValue&nbsp;json)</code>
<div class="block">Return an option that translates JNothing to None</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#libraryPathEnvName()">libraryPathEnvName</a></strong>()</code>
<div class="block">Return the current system LD_LIBRARY_PATH name</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#libraryPathEnvPrefix(scala.collection.Seq)">libraryPathEnvPrefix</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;libraryPaths)</code>
<div class="block">Return the prefix of a command that appends the given library paths to the
 system-specific library path environment variable.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#loadDefaultSparkProperties(org.apache.spark.SparkConf,%20java.lang.String)">loadDefaultSparkProperties</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                          String&nbsp;filePath)</code>
<div class="block">Load default Spark properties from the given file.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#localHostName()">localHostName</a></strong>()</code>
<div class="block">Get the local machine's hostname.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#localHostNameForURI()">localHostNameForURI</a></strong>()</code>
<div class="block">Get the local machine's URI.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#logUncaughtExceptions(scala.Function0)">logUncaughtExceptions</a></strong>(scala.Function0&lt;T&gt;&nbsp;f)</code>
<div class="block">Execute the given block, logging and re-throwing any uncaught exception.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#megabytesToString(long)">megabytesToString</a></strong>(long&nbsp;megabytes)</code>
<div class="block">Convert a quantity in megabytes to a human-readable string such as "4.0 MB".</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#memoryStringToMb(java.lang.String)">memoryStringToMb</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a Java memory parameter passed to -Xmx (such as 300m or 1g) to a number of mebibytes.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#msDurationToString(long)">msDurationToString</a></strong>(long&nbsp;ms)</code>
<div class="block">Returns a human-readable string representing a duration such as "35ms"</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#nanSafeCompareDoubles(double,%20double)">nanSafeCompareDoubles</a></strong>(double&nbsp;x,
                     double&nbsp;y)</code>
<div class="block">NaN-safe version of <code>java.lang.Double.compare()</code> which allows NaN values to be compared
 according to semantics where NaN == NaN and NaN is greater than any non-NaN double.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#nanSafeCompareFloats(float,%20float)">nanSafeCompareFloats</a></strong>(float&nbsp;x,
                    float&nbsp;y)</code>
<div class="block">NaN-safe version of <code>java.lang.Float.compare()</code> which allows NaN values to be compared
 according to semantics where NaN == NaN and NaN is greater than any non-NaN float.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#nonLocalPaths(java.lang.String,%20boolean)">nonLocalPaths</a></strong>(String&nbsp;paths,
             boolean&nbsp;testWindows)</code>
<div class="block">Return all non-local paths from a comma-separated list of paths.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#nonNegativeHash(java.lang.Object)">nonNegativeHash</a></strong>(Object&nbsp;obj)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#nonNegativeMod(int,%20int)">nonNegativeMod</a></strong>(int&nbsp;x,
              int&nbsp;mod)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#offsetBytes(scala.collection.Seq,%20scala.collection.Seq,%20long,%20long)">offsetBytes</a></strong>(scala.collection.Seq&lt;java.io.File&gt;&nbsp;files,
           scala.collection.Seq&lt;Object&gt;&nbsp;fileLengths,
           long&nbsp;start,
           long&nbsp;end)</code>
<div class="block">Return a string containing data across a set of files.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#offsetBytes(java.lang.String,%20long,%20long,%20long)">offsetBytes</a></strong>(String&nbsp;path,
           long&nbsp;length,
           long&nbsp;start,
           long&nbsp;end)</code>
<div class="block">Return a string containing part of a file from byte 'start' to 'end'.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.Tuple2&lt;String,Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#parseHostPort(java.lang.String)">parseHostPort</a></strong>(String&nbsp;hostPort)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static String[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#parseStandaloneMasterUrls(java.lang.String)">parseStandaloneMasterUrls</a></strong>(String&nbsp;masterUrls)</code>
<div class="block">Split the comma delimited string of master URLs into a list.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#portMaxRetries(org.apache.spark.SparkConf)">portMaxRetries</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</code>
<div class="block">Maximum number of retries when binding to a port before giving up.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static Thread</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#processStreamByLine(java.lang.String,%20java.io.InputStream,%20scala.Function1)">processStreamByLine</a></strong>(String&nbsp;threadName,
                   java.io.InputStream&nbsp;inputStream,
                   scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;&nbsp;processLine)</code>
<div class="block">Return and start a daemon thread that processes the content of the input stream line by line.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.util.Random</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#random()">random</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;scala.collection.Seq&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#randomize(scala.collection.TraversableOnce,%20scala.reflect.ClassTag)">randomize</a></strong>(scala.collection.TraversableOnce&lt;T&gt;&nbsp;seq,
         scala.reflect.ClassTag&lt;T&gt;&nbsp;evidence$1)</code>
<div class="block">Shuffle the elements of a collection into a random order, returning the
 result in a new collection.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;Object</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#randomizeInPlace(java.lang.Object,%20java.util.Random)">randomizeInPlace</a></strong>(Object&nbsp;arr,
                java.util.Random&nbsp;rand)</code>
<div class="block">Shuffle the elements of an array into a random order, modifying the
 original array.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;scala.Tuple2&lt;String,String&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#redact(scala.collection.Map)">redact</a></strong>(scala.collection.Map&lt;String,String&gt;&nbsp;kvs)</code>
<div class="block">Looks up the redaction regex from within the key value pairs and uses it to redact the rest
 of the key value pairs.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;scala.Tuple2&lt;String,String&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#redact(org.apache.spark.SparkConf,%20scala.collection.Seq)">redact</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
      scala.collection.Seq&lt;scala.Tuple2&lt;String,String&gt;&gt;&nbsp;kvs)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static java.net.URI</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#resolveURI(java.lang.String)">resolveURI</a></strong>(String&nbsp;path)</code>
<div class="block">Return a well-formed URI for the file described by a user input string.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#resolveURIs(java.lang.String)">resolveURIs</a></strong>(String&nbsp;paths)</code>
<div class="block">Resolve a comma-separated list of paths.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#responseFromBackup(java.lang.String)">responseFromBackup</a></strong>(String&nbsp;msg)</code>
<div class="block">Return true if the response message is sent from a backup Master on standby.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;byte[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#serialize(T)">serialize</a></strong>(T&nbsp;o)</code>
<div class="block">Serialize an object using Java serialization</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#serializeViaNestedStream(java.io.OutputStream,%20org.apache.spark.serializer.SerializerInstance,%20scala.Function1)">serializeViaNestedStream</a></strong>(java.io.OutputStream&nbsp;os,
                        <a href="../../../../org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a>&nbsp;ser,
                        scala.Function1&lt;<a href="../../../../org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a>,scala.runtime.BoxedUnit&gt;&nbsp;f)</code>
<div class="block">Serialize via nested stream using specific serializer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#setCustomHostname(java.lang.String)">setCustomHostname</a></strong>(String&nbsp;hostname)</code>
<div class="block">Allow setting a custom host name because when we run on Mesos we need to use the same
 hostname it reports to the master.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#setLogLevel(org.apache.log4j.Level)">setLogLevel</a></strong>(org.apache.log4j.Level&nbsp;l)</code>
<div class="block">configure a new log4j level</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.net.URLConnection</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#setupSecureURLConnection(java.net.URLConnection,%20org.apache.spark.SecurityManager)">setupSecureURLConnection</a></strong>(java.net.URLConnection&nbsp;urlConnection,
                        org.apache.spark.SecurityManager&nbsp;sm)</code>
<div class="block">If the given URL connection is HttpsURLConnection, it sets the SSL socket factory and
 the host verifier from the given security manager.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#sparkJavaOpts(org.apache.spark.SparkConf,%20scala.Function1)">sparkJavaOpts</a></strong>(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
             scala.Function1&lt;String,Object&gt;&nbsp;filterKey)</code>
<div class="block">Convert all spark properties set in the given SparkConf to a sequence of java options.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#splitCommandString(java.lang.String)">splitCommandString</a></strong>(String&nbsp;s)</code>
<div class="block">Split a string of potentially quoted arguments from the command line the way that a shell
 would do it to determine arguments to a command.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;scala.Tuple2&lt;T,Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#startServiceOnPort(int,%20scala.Function1,%20org.apache.spark.SparkConf,%20java.lang.String)">startServiceOnPort</a></strong>(int&nbsp;startPort,
                  scala.Function1&lt;Object,scala.Tuple2&lt;T,Object&gt;&gt;&nbsp;startService,
                  <a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                  String&nbsp;serviceName)</code>
<div class="block">Attempt to start a service on the given port, or fail after a number of attempts.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#stripDirectory(java.lang.String)">stripDirectory</a></strong>(String&nbsp;path)</code>
<div class="block">Strip the directory from a path name</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#symlink(java.io.File,%20java.io.File)">symlink</a></strong>(java.io.File&nbsp;src,
       java.io.File&nbsp;dst)</code>
<div class="block">Creates a symlink.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.io.File</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tempFileWith(java.io.File)">tempFileWith</a></strong>(java.io.File&nbsp;path)</code>
<div class="block">Returns a path of temporary file which is in the same directory with <code>path</code>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.Option&lt;Object&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#terminateProcess(java.lang.Process,%20long)">terminateProcess</a></strong>(Process&nbsp;process,
                long&nbsp;timeoutMs)</code>
<div class="block">Terminates a process waiting for at most the specified duration.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#timeIt(int,%20scala.Function0,%20scala.Option)">timeIt</a></strong>(int&nbsp;numIters,
      scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;f,
      scala.Option&lt;scala.Function0&lt;scala.runtime.BoxedUnit&gt;&gt;&nbsp;prepare)</code>
<div class="block">Timing method based on iterations that permit JVM JIT optimization.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#times(int,%20scala.Function0)">times</a></strong>(int&nbsp;numIters,
     scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;f)</code>
<div class="block">Method executed for repeating a task for side effects.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#timeStringAsMs(java.lang.String)">timeStringAsMs</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a time parameter such as (50s, 100ms, or 250us) to microseconds for internal use.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#timeStringAsSeconds(java.lang.String)">timeStringAsSeconds</a></strong>(String&nbsp;str)</code>
<div class="block">Convert a time parameter such as (50s, 100ms, or 250us) to seconds for internal use.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#truncatedString(scala.collection.Seq,%20java.lang.String)">truncatedString</a></strong>(scala.collection.Seq&lt;T&gt;&nbsp;seq,
               String&nbsp;sep)</code>
<div class="block">Shorthand for calling truncatedString() without start or end strings.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;String</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#truncatedString(scala.collection.Seq,%20java.lang.String,%20java.lang.String,%20java.lang.String,%20int)">truncatedString</a></strong>(scala.collection.Seq&lt;T&gt;&nbsp;seq,
               String&nbsp;start,
               String&nbsp;sep,
               String&nbsp;end,
               int&nbsp;maxNumFields)</code>
<div class="block">Format a sequence with semantics similar to calling .mkString().</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;scala.util.Try&lt;T&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryLog(scala.Function0)">tryLog</a></strong>(scala.Function0&lt;T&gt;&nbsp;f)</code>
<div class="block">Executes the given block in a Try, logging any uncaught exceptions.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryLogNonFatalError(scala.Function0)">tryLogNonFatalError</a></strong>(scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;block)</code>
<div class="block">Executes the given block.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryOrExit(scala.Function0)">tryOrExit</a></strong>(scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;block)</code>
<div class="block">Execute a block of code that evaluates to Unit, forwarding any uncaught exceptions to the
 default UncaughtExceptionHandler</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryOrIOException(scala.Function0)">tryOrIOException</a></strong>(scala.Function0&lt;T&gt;&nbsp;block)</code>
<div class="block">Execute a block of code that returns a value, re-throwing any non-fatal uncaught
 exceptions as IOException.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryOrStopSparkContext(org.apache.spark.SparkContext,%20scala.Function0)">tryOrStopSparkContext</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                     scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;block)</code>
<div class="block">Execute a block of code that evaluates to Unit, stop SparkContext if there is any uncaught
 exception</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;R extends java.io.Closeable,T&gt;&nbsp;<br>T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryWithResource(scala.Function0,%20scala.Function1)">tryWithResource</a></strong>(scala.Function0&lt;R&gt;&nbsp;createResource,
               scala.Function1&lt;R,T&gt;&nbsp;f)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryWithSafeFinally(scala.Function0,%20scala.Function0)">tryWithSafeFinally</a></strong>(scala.Function0&lt;T&gt;&nbsp;block,
                  scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;finallyBlock)</code>
<div class="block">Execute a block of code, then a finally block, but if exceptions happen in
 the finally block, do not suppress the original exception.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#tryWithSafeFinallyAndFailureCallbacks(scala.Function0,%20scala.Function0,%20scala.Function0)">tryWithSafeFinallyAndFailureCallbacks</a></strong>(scala.Function0&lt;T&gt;&nbsp;block,
                                     scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;catchBlock,
                                     scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;finallyBlock)</code>
<div class="block">Execute a block of code and call the failure callbacks in the catch block.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static scala.collection.immutable.Set&lt;String&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#unionFileLists(scala.Option,%20scala.Option)">unionFileLists</a></strong>(scala.Option&lt;String&gt;&nbsp;leftList,
              scala.Option&lt;String&gt;&nbsp;rightList)</code>
<div class="block">Unions two comma-separated lists of files and filters out empty strings.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#validateURL(java.net.URI)">validateURL</a></strong>(java.net.URI&nbsp;uri)</code>
<div class="block">Validate that a given URI is actually a valid URL as well.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#waitForProcess(java.lang.Process,%20long)">waitForProcess</a></strong>(Process&nbsp;process,
              long&nbsp;timeoutMs)</code>
<div class="block">Wait for a process to terminate for at most the specified duration.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static scala.util.matching.Regex</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#windowsDrive()">windowsDrive</a></strong>()</code>
<div class="block">Pattern for matching a Windows drive, which contains only a single alphabet character.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static &lt;T&gt;&nbsp;T</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#withDummyCallSite(org.apache.spark.SparkContext,%20scala.Function0)">withDummyCallSite</a></strong>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                 scala.Function0&lt;T&gt;&nbsp;body)</code>
<div class="block">To avoid calling <code>Utils.getCallSite</code> for every single RDD we create in the body,
 set a dummy call site that RDDs use instead.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#writeByteBuffer(java.nio.ByteBuffer,%20java.io.DataOutput)">writeByteBuffer</a></strong>(java.nio.ByteBuffer&nbsp;bb,
               java.io.DataOutput&nbsp;out)</code>
<div class="block">Primitive often used when writing <code>ByteBuffer</code> to <code>DataOutput</code></div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/util/Utils.html#writeByteBuffer(java.nio.ByteBuffer,%20java.io.OutputStream)">writeByteBuffer</a></strong>(java.nio.ByteBuffer&nbsp;bb,
               java.io.OutputStream&nbsp;out)</code>
<div class="block">Primitive often used when writing <code>ByteBuffer</code> to <code>OutputStream</code></div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="Utils()">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>Utils</h4>
<pre>public&nbsp;Utils()</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="random()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>random</h4>
<pre>public static&nbsp;java.util.Random&nbsp;random()</pre>
</li>
</ul>
<a name="DEFAULT_DRIVER_MEM_MB()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DEFAULT_DRIVER_MEM_MB</h4>
<pre>public static&nbsp;int&nbsp;DEFAULT_DRIVER_MEM_MB()</pre>
<div class="block">Define a default value for driver memory here since this value is referenced across the code
 base and nearly all files already use Utils.scala</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="DEFAULT_MAX_TO_STRING_FIELDS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>DEFAULT_MAX_TO_STRING_FIELDS</h4>
<pre>public static&nbsp;int&nbsp;DEFAULT_MAX_TO_STRING_FIELDS()</pre>
<div class="block">The performance overhead of creating and logging strings for wide schemas can be large. To
 limit the impact, we bound the number of fields to include by default. This can be overridden
 by setting the 'spark.debug.maxToStringFields' conf in SparkEnv.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="truncatedString(scala.collection.Seq, java.lang.String, java.lang.String, java.lang.String, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>truncatedString</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;String&nbsp;truncatedString(scala.collection.Seq&lt;T&gt;&nbsp;seq,
                         String&nbsp;start,
                         String&nbsp;sep,
                         String&nbsp;end,
                         int&nbsp;maxNumFields)</pre>
<div class="block">Format a sequence with semantics similar to calling .mkString(). Any elements beyond
 maxNumToStringFields will be dropped and replaced by a "... N more fields" placeholder.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>seq</code> - (undocumented)</dd><dd><code>start</code> - (undocumented)</dd><dd><code>sep</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd><dd><code>maxNumFields</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>the trimmed and formatted string.</dd></dl>
</li>
</ul>
<a name="truncatedString(scala.collection.Seq, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>truncatedString</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;String&nbsp;truncatedString(scala.collection.Seq&lt;T&gt;&nbsp;seq,
                         String&nbsp;sep)</pre>
<div class="block">Shorthand for calling truncatedString() without start or end strings.</div>
</li>
</ul>
<a name="serialize(java.lang.Object)">
<!--   -->
</a><a name="serialize(T)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>serialize</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;byte[]&nbsp;serialize(T&nbsp;o)</pre>
<div class="block">Serialize an object using Java serialization</div>
</li>
</ul>
<a name="deserialize(byte[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deserialize</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;deserialize(byte[]&nbsp;bytes)</pre>
<div class="block">Deserialize an object using Java serialization</div>
</li>
</ul>
<a name="deserialize(byte[], java.lang.ClassLoader)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deserialize</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;deserialize(byte[]&nbsp;bytes,
                ClassLoader&nbsp;loader)</pre>
<div class="block">Deserialize an object using Java serialization and the given ClassLoader</div>
</li>
</ul>
<a name="deserializeLongValue(byte[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deserializeLongValue</h4>
<pre>public static&nbsp;long&nbsp;deserializeLongValue(byte[]&nbsp;bytes)</pre>
<div class="block">Deserialize a Long value (used for <code>PythonPartitioner</code>)</div>
</li>
</ul>
<a name="serializeViaNestedStream(java.io.OutputStream, org.apache.spark.serializer.SerializerInstance, scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>serializeViaNestedStream</h4>
<pre>public static&nbsp;void&nbsp;serializeViaNestedStream(java.io.OutputStream&nbsp;os,
                            <a href="../../../../org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a>&nbsp;ser,
                            scala.Function1&lt;<a href="../../../../org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a>,scala.runtime.BoxedUnit&gt;&nbsp;f)</pre>
<div class="block">Serialize via nested stream using specific serializer</div>
</li>
</ul>
<a name="deserializeViaNestedStream(java.io.InputStream, org.apache.spark.serializer.SerializerInstance, scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deserializeViaNestedStream</h4>
<pre>public static&nbsp;void&nbsp;deserializeViaNestedStream(java.io.InputStream&nbsp;is,
                              <a href="../../../../org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a>&nbsp;ser,
                              scala.Function1&lt;<a href="../../../../org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</a>,scala.runtime.BoxedUnit&gt;&nbsp;f)</pre>
<div class="block">Deserialize via nested stream using specific serializer</div>
</li>
</ul>
<a name="getSparkClassLoader()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSparkClassLoader</h4>
<pre>public static&nbsp;ClassLoader&nbsp;getSparkClassLoader()</pre>
<div class="block">Get the ClassLoader which loaded Spark.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getContextOrSparkClassLoader()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getContextOrSparkClassLoader</h4>
<pre>public static&nbsp;ClassLoader&nbsp;getContextOrSparkClassLoader()</pre>
<div class="block">Get the Context ClassLoader on this thread or, if not present, the ClassLoader that
 loaded Spark.
 <p>
 This should be used whenever passing a ClassLoader to Class.ForName or finding the currently
 active loader when setting up ClassLoader delegation chains.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="classIsLoadable(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>classIsLoadable</h4>
<pre>public static&nbsp;boolean&nbsp;classIsLoadable(String&nbsp;clazz)</pre>
<div class="block">Determines whether the provided class is loadable in the current thread.</div>
</li>
</ul>
<a name="classForName(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>classForName</h4>
<pre>public static&nbsp;Class&lt;?&gt;&nbsp;classForName(String&nbsp;className)</pre>
<div class="block">Preferred alternative to Class.forName(className)</div>
</li>
</ul>
<a name="writeByteBuffer(java.nio.ByteBuffer, java.io.DataOutput)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>writeByteBuffer</h4>
<pre>public static&nbsp;void&nbsp;writeByteBuffer(java.nio.ByteBuffer&nbsp;bb,
                   java.io.DataOutput&nbsp;out)</pre>
<div class="block">Primitive often used when writing <code>ByteBuffer</code> to <code>DataOutput</code></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>bb</code> - (undocumented)</dd><dd><code>out</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="writeByteBuffer(java.nio.ByteBuffer, java.io.OutputStream)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>writeByteBuffer</h4>
<pre>public static&nbsp;void&nbsp;writeByteBuffer(java.nio.ByteBuffer&nbsp;bb,
                   java.io.OutputStream&nbsp;out)</pre>
<div class="block">Primitive often used when writing <code>ByteBuffer</code> to <code>OutputStream</code></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>bb</code> - (undocumented)</dd><dd><code>out</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="chmod700(java.io.File)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>chmod700</h4>
<pre>public static&nbsp;boolean&nbsp;chmod700(java.io.File&nbsp;file)</pre>
<div class="block">JDK equivalent of <code>chmod 700 file</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>file</code> - the file whose permissions will be modified</dd>
<dt><span class="strong">Returns:</span></dt><dd>true if the permissions were successfully changed, false otherwise.</dd></dl>
</li>
</ul>
<a name="createDirectory(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDirectory</h4>
<pre>public static&nbsp;java.io.File&nbsp;createDirectory(String&nbsp;root,
                           String&nbsp;namePrefix)</pre>
<div class="block">Create a directory inside the given parent directory. The directory is guaranteed to be
 newly created, and is not marked for automatic deletion.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>root</code> - (undocumented)</dd><dd><code>namePrefix</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="createTempDir(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createTempDir</h4>
<pre>public static&nbsp;java.io.File&nbsp;createTempDir(String&nbsp;root,
                         String&nbsp;namePrefix)</pre>
<div class="block">Create a temporary directory inside the given parent directory. The directory will be
 automatically deleted when the VM shuts down.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>root</code> - (undocumented)</dd><dd><code>namePrefix</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="copyStream(java.io.InputStream, java.io.OutputStream, boolean, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>copyStream</h4>
<pre>public static&nbsp;long&nbsp;copyStream(java.io.InputStream&nbsp;in,
              java.io.OutputStream&nbsp;out,
              boolean&nbsp;closeStreams,
              boolean&nbsp;transferToEnabled)</pre>
<div class="block">Copy all data from an InputStream to an OutputStream. NIO way of file stream to file stream
 copying is disabled by default unless explicitly set transferToEnabled as true,
 the parameter transferToEnabled should be configured by spark.file.transferTo = [true|false].</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>in</code> - (undocumented)</dd><dd><code>out</code> - (undocumented)</dd><dd><code>closeStreams</code> - (undocumented)</dd><dd><code>transferToEnabled</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="copyFileStreamNIO(java.nio.channels.FileChannel, java.nio.channels.FileChannel, long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>copyFileStreamNIO</h4>
<pre>public static&nbsp;void&nbsp;copyFileStreamNIO(java.nio.channels.FileChannel&nbsp;input,
                     java.nio.channels.FileChannel&nbsp;output,
                     long&nbsp;startPosition,
                     long&nbsp;bytesToCopy)</pre>
</li>
</ul>
<a name="constructURIForAuthentication(java.net.URI, org.apache.spark.SecurityManager)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>constructURIForAuthentication</h4>
<pre>public static&nbsp;java.net.URI&nbsp;constructURIForAuthentication(java.net.URI&nbsp;uri,
                                         org.apache.spark.SecurityManager&nbsp;securityMgr)</pre>
<div class="block">Construct a URI container information used for authentication.
 This also sets the default authenticator to properly negotiation the
 user/password based on the URI.
 <p>
 Note this relies on the Authenticator.setDefault being set properly to decode
 the user name and password. This is currently set in the SecurityManager.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>uri</code> - (undocumented)</dd><dd><code>securityMgr</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="encodeFileNameToURIRawPath(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>encodeFileNameToURIRawPath</h4>
<pre>public static&nbsp;String&nbsp;encodeFileNameToURIRawPath(String&nbsp;fileName)</pre>
<div class="block">A file name may contain some invalid URI characters, such as " ". This method will convert the
 file name to a raw path accepted by <code>java.net.URI(String)</code>.
 <p>
 Note: the file name must not contain "/" or "\"</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>fileName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="decodeFileNameInURI(java.net.URI)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>decodeFileNameInURI</h4>
<pre>public static&nbsp;String&nbsp;decodeFileNameInURI(java.net.URI&nbsp;uri)</pre>
<div class="block">Get the file name from uri's raw path and decode it. If the raw path of uri ends with "/",
 return the name before the last "/".</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>uri</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="fetchFile(java.lang.String, java.io.File, org.apache.spark.SparkConf, org.apache.spark.SecurityManager, org.apache.hadoop.conf.Configuration, long, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fetchFile</h4>
<pre>public static&nbsp;void&nbsp;fetchFile(String&nbsp;url,
             java.io.File&nbsp;targetDir,
             <a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
             org.apache.spark.SecurityManager&nbsp;securityMgr,
             org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
             long&nbsp;timestamp,
             boolean&nbsp;useCache)</pre>
<div class="block">Download a file or directory to target directory. Supports fetching the file in a variety of
 ways, including HTTP, Hadoop-compatible filesystems, and files on a standard filesystem, based
 on the URL parameter. Fetching directories is only supported from Hadoop-compatible
 filesystems.
 <p>
 If <code>useCache</code> is true, first attempts to fetch the file to a local cache that's shared
 across executors running the same application. <code>useCache</code> is used mainly for
 the executors, and not in local mode.
 <p>
 Throws SparkException if the target file already exists and has different contents than
 the requested file.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>url</code> - (undocumented)</dd><dd><code>targetDir</code> - (undocumented)</dd><dd><code>conf</code> - (undocumented)</dd><dd><code>securityMgr</code> - (undocumented)</dd><dd><code>hadoopConf</code> - (undocumented)</dd><dd><code>timestamp</code> - (undocumented)</dd><dd><code>useCache</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="validateURL(java.net.URI)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>validateURL</h4>
<pre>public static&nbsp;void&nbsp;validateURL(java.net.URI&nbsp;uri)
                        throws java.net.MalformedURLException</pre>
<div class="block">Validate that a given URI is actually a valid URL as well.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>uri</code> - The URI to validate</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code>java.net.MalformedURLException</code></dd></dl>
</li>
</ul>
<a name="getLocalDir(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLocalDir</h4>
<pre>public static&nbsp;String&nbsp;getLocalDir(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
<div class="block">Get the path of a temporary directory.  Spark's local directories can be configured through
 multiple settings, which are used with the following precedence:
 <p>
   - If called from inside of a YARN container, this will return a directory chosen by YARN.
   - If the SPARK_LOCAL_DIRS environment variable is set, this will return a directory from it.
   - Otherwise, if the spark.local.dir is set, this will return a directory from it.
   - Otherwise, this will return java.io.tmpdir.
 <p>
 Some of these configuration options might be lists of multiple paths, but this method will
 always return a single directory.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getConfiguredLocalDirs(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConfiguredLocalDirs</h4>
<pre>public static&nbsp;String[]&nbsp;getConfiguredLocalDirs(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
<div class="block">Return the configured local directories where Spark can write files. This
 method does not create any directories on its own, it only encapsulates the
 logic of locating the local directories according to deployment mode.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="randomize(scala.collection.TraversableOnce, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>randomize</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;scala.collection.Seq&lt;T&gt;&nbsp;randomize(scala.collection.TraversableOnce&lt;T&gt;&nbsp;seq,
                                    scala.reflect.ClassTag&lt;T&gt;&nbsp;evidence$1)</pre>
<div class="block">Shuffle the elements of a collection into a random order, returning the
 result in a new collection. Unlike scala.util.Random.shuffle, this method
 uses a local random number generator, avoiding inter-thread contention.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>seq</code> - (undocumented)</dd><dd><code>evidence$1</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="randomizeInPlace(java.lang.Object, java.util.Random)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>randomizeInPlace</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;Object&nbsp;randomizeInPlace(Object&nbsp;arr,
                          java.util.Random&nbsp;rand)</pre>
<div class="block">Shuffle the elements of an array into a random order, modifying the
 original array. Returns the original array.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>arr</code> - (undocumented)</dd><dd><code>rand</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="setCustomHostname(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setCustomHostname</h4>
<pre>public static&nbsp;void&nbsp;setCustomHostname(String&nbsp;hostname)</pre>
<div class="block">Allow setting a custom host name because when we run on Mesos we need to use the same
 hostname it reports to the master.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>hostname</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="localHostName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>localHostName</h4>
<pre>public static&nbsp;String&nbsp;localHostName()</pre>
<div class="block">Get the local machine's hostname.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="localHostNameForURI()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>localHostNameForURI</h4>
<pre>public static&nbsp;String&nbsp;localHostNameForURI()</pre>
<div class="block">Get the local machine's URI.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="checkHost(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>checkHost</h4>
<pre>public static&nbsp;void&nbsp;checkHost(String&nbsp;host,
             String&nbsp;message)</pre>
</li>
</ul>
<a name="checkHostPort(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>checkHostPort</h4>
<pre>public static&nbsp;void&nbsp;checkHostPort(String&nbsp;hostPort,
                 String&nbsp;message)</pre>
</li>
</ul>
<a name="parseHostPort(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseHostPort</h4>
<pre>public static&nbsp;scala.Tuple2&lt;String,Object&gt;&nbsp;parseHostPort(String&nbsp;hostPort)</pre>
</li>
</ul>
<a name="getUsedTimeMs(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getUsedTimeMs</h4>
<pre>public static&nbsp;String&nbsp;getUsedTimeMs(long&nbsp;startTimeMs)</pre>
<div class="block">Return the string to tell how long has passed in milliseconds.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>startTimeMs</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="deleteRecursively(java.io.File)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deleteRecursively</h4>
<pre>public static&nbsp;void&nbsp;deleteRecursively(java.io.File&nbsp;file)</pre>
<div class="block">Delete a file or directory and its contents recursively.
 Don't follow directories if they are symlinks.
 Throws an exception if deletion is unsuccessful.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>file</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="isSymlink(java.io.File)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isSymlink</h4>
<pre>public static&nbsp;boolean&nbsp;isSymlink(java.io.File&nbsp;file)</pre>
<div class="block">Check to see if file is a symbolic link.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>file</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="doesDirectoryContainAnyNewFiles(java.io.File, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doesDirectoryContainAnyNewFiles</h4>
<pre>public static&nbsp;boolean&nbsp;doesDirectoryContainAnyNewFiles(java.io.File&nbsp;dir,
                                      long&nbsp;cutoff)</pre>
<div class="block">Determines if a directory contains any files newer than cutoff seconds.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>dir</code> - must be the path to a directory, or IllegalArgumentException is thrown</dd><dd><code>cutoff</code> - measured in seconds. Returns true if there are any files or directories in the
               given directory whose last modified time is later than this many seconds ago</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="timeStringAsMs(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>timeStringAsMs</h4>
<pre>public static&nbsp;long&nbsp;timeStringAsMs(String&nbsp;str)</pre>
<div class="block">Convert a time parameter such as (50s, 100ms, or 250us) to microseconds for internal use. If
 no suffix is provided, the passed number is assumed to be in ms.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="timeStringAsSeconds(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>timeStringAsSeconds</h4>
<pre>public static&nbsp;long&nbsp;timeStringAsSeconds(String&nbsp;str)</pre>
<div class="block">Convert a time parameter such as (50s, 100ms, or 250us) to seconds for internal use. If
 no suffix is provided, the passed number is assumed to be in seconds.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="byteStringAsBytes(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>byteStringAsBytes</h4>
<pre>public static&nbsp;long&nbsp;byteStringAsBytes(String&nbsp;str)</pre>
<div class="block">Convert a passed byte string (e.g. 50b, 100k, or 250m) to bytes for internal use.
 <p>
 If no suffix is provided, the passed number is assumed to be in bytes.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="byteStringAsKb(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>byteStringAsKb</h4>
<pre>public static&nbsp;long&nbsp;byteStringAsKb(String&nbsp;str)</pre>
<div class="block">Convert a passed byte string (e.g. 50b, 100k, or 250m) to kibibytes for internal use.
 <p>
 If no suffix is provided, the passed number is assumed to be in kibibytes.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="byteStringAsMb(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>byteStringAsMb</h4>
<pre>public static&nbsp;long&nbsp;byteStringAsMb(String&nbsp;str)</pre>
<div class="block">Convert a passed byte string (e.g. 50b, 100k, or 250m) to mebibytes for internal use.
 <p>
 If no suffix is provided, the passed number is assumed to be in mebibytes.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="byteStringAsGb(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>byteStringAsGb</h4>
<pre>public static&nbsp;long&nbsp;byteStringAsGb(String&nbsp;str)</pre>
<div class="block">Convert a passed byte string (e.g. 50b, 100k, or 250m, 500g) to gibibytes for internal use.
 <p>
 If no suffix is provided, the passed number is assumed to be in gibibytes.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="memoryStringToMb(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>memoryStringToMb</h4>
<pre>public static&nbsp;int&nbsp;memoryStringToMb(String&nbsp;str)</pre>
<div class="block">Convert a Java memory parameter passed to -Xmx (such as 300m or 1g) to a number of mebibytes.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>str</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="bytesToString(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bytesToString</h4>
<pre>public static&nbsp;String&nbsp;bytesToString(long&nbsp;size)</pre>
<div class="block">Convert a quantity in bytes to a human-readable string such as "4.0 MB".</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>size</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="msDurationToString(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>msDurationToString</h4>
<pre>public static&nbsp;String&nbsp;msDurationToString(long&nbsp;ms)</pre>
<div class="block">Returns a human-readable string representing a duration such as "35ms"</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>ms</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="megabytesToString(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>megabytesToString</h4>
<pre>public static&nbsp;String&nbsp;megabytesToString(long&nbsp;megabytes)</pre>
<div class="block">Convert a quantity in megabytes to a human-readable string such as "4.0 MB".</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>megabytes</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="executeCommand(scala.collection.Seq, java.io.File, scala.collection.Map, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executeCommand</h4>
<pre>public static&nbsp;Process&nbsp;executeCommand(scala.collection.Seq&lt;String&gt;&nbsp;command,
                     java.io.File&nbsp;workingDir,
                     scala.collection.Map&lt;String,String&gt;&nbsp;extraEnvironment,
                     boolean&nbsp;redirectStderr)</pre>
<div class="block">Execute a command and return the process running the command.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>command</code> - (undocumented)</dd><dd><code>workingDir</code> - (undocumented)</dd><dd><code>extraEnvironment</code> - (undocumented)</dd><dd><code>redirectStderr</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="executeAndGetOutput(scala.collection.Seq, java.io.File, scala.collection.Map, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executeAndGetOutput</h4>
<pre>public static&nbsp;String&nbsp;executeAndGetOutput(scala.collection.Seq&lt;String&gt;&nbsp;command,
                         java.io.File&nbsp;workingDir,
                         scala.collection.Map&lt;String,String&gt;&nbsp;extraEnvironment,
                         boolean&nbsp;redirectStderr)</pre>
<div class="block">Execute a command and get its output, throwing an exception if it yields a code other than 0.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>command</code> - (undocumented)</dd><dd><code>workingDir</code> - (undocumented)</dd><dd><code>extraEnvironment</code> - (undocumented)</dd><dd><code>redirectStderr</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="processStreamByLine(java.lang.String, java.io.InputStream, scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>processStreamByLine</h4>
<pre>public static&nbsp;Thread&nbsp;processStreamByLine(String&nbsp;threadName,
                         java.io.InputStream&nbsp;inputStream,
                         scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;&nbsp;processLine)</pre>
<div class="block">Return and start a daemon thread that processes the content of the input stream line by line.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>threadName</code> - (undocumented)</dd><dd><code>inputStream</code> - (undocumented)</dd><dd><code>processLine</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="tryOrExit(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryOrExit</h4>
<pre>public static&nbsp;void&nbsp;tryOrExit(scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;block)</pre>
<div class="block">Execute a block of code that evaluates to Unit, forwarding any uncaught exceptions to the
 default UncaughtExceptionHandler
 <p>
 NOTE: This method is to be called by the spark-started JVM process.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>block</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="tryOrStopSparkContext(org.apache.spark.SparkContext, scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryOrStopSparkContext</h4>
<pre>public static&nbsp;void&nbsp;tryOrStopSparkContext(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                         scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;block)</pre>
<div class="block">Execute a block of code that evaluates to Unit, stop SparkContext if there is any uncaught
 exception
 <p>
 NOTE: This method is to be called by the driver-side components to avoid stopping the
 user-started JVM process completely; in contrast, tryOrExit is to be called in the
 spark-started JVM process .</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sc</code> - (undocumented)</dd><dd><code>block</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="tryOrIOException(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryOrIOException</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;tryOrIOException(scala.Function0&lt;T&gt;&nbsp;block)</pre>
<div class="block">Execute a block of code that returns a value, re-throwing any non-fatal uncaught
 exceptions as IOException. This is used when implementing Externalizable and Serializable's
 read and write methods, since Java's serializer will not report non-IOExceptions properly;
 see SPARK-4080 for more context.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>block</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="tryLogNonFatalError(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryLogNonFatalError</h4>
<pre>public static&nbsp;void&nbsp;tryLogNonFatalError(scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;block)</pre>
<div class="block">Executes the given block. Log non-fatal errors if any, and only throw fatal errors</div>
</li>
</ul>
<a name="tryWithSafeFinally(scala.Function0, scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryWithSafeFinally</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;tryWithSafeFinally(scala.Function0&lt;T&gt;&nbsp;block,
                       scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;finallyBlock)</pre>
<div class="block">Execute a block of code, then a finally block, but if exceptions happen in
 the finally block, do not suppress the original exception.
 <p>
 This is primarily an issue with <code>finally { out.close() }</code> blocks, where
 close needs to be called to clean up <code>out</code>, but if an exception happened
 in <code>out.write</code>, it's likely <code>out</code> may be corrupted and <code>out.close</code> will
 fail as well. This would then suppress the original/likely more meaningful
 exception from the original <code>out.write</code> call.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>block</code> - (undocumented)</dd><dd><code>finallyBlock</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="tryWithSafeFinallyAndFailureCallbacks(scala.Function0, scala.Function0, scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryWithSafeFinallyAndFailureCallbacks</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;tryWithSafeFinallyAndFailureCallbacks(scala.Function0&lt;T&gt;&nbsp;block,
                                          scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;catchBlock,
                                          scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;finallyBlock)</pre>
<div class="block">Execute a block of code and call the failure callbacks in the catch block. If exceptions occur
 in either the catch or the finally block, they are appended to the list of suppressed
 exceptions in original exception which is then rethrown.
 <p>
 This is primarily an issue with <code>catch { abort() }</code> or <code>finally { out.close() }</code> blocks,
 where the abort/close needs to be called to clean up <code>out</code>, but if an exception happened
 in <code>out.write</code>, it's likely <code>out</code> may be corrupted and <code>abort</code> or <code>out.close</code> will
 fail as well. This would then suppress the original/likely more meaningful
 exception from the original <code>out.write</code> call.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>block</code> - (undocumented)</dd><dd><code>catchBlock</code> - (undocumented)</dd><dd><code>finallyBlock</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getCallSite(scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCallSite</h4>
<pre>public static&nbsp;org.apache.spark.util.CallSite&nbsp;getCallSite(scala.Function1&lt;String,Object&gt;&nbsp;skipClass)</pre>
<div class="block">When called inside a class in the spark package, returns the name of the user code class
 (outside the spark package) that called into Spark, as well as which Spark method they called.
 This is used, for example, to tell users where in their code each RDD got created.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>skipClass</code> - Function that is used to exclude non-user-code classes.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getFileLength(java.io.File, org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFileLength</h4>
<pre>public static&nbsp;long&nbsp;getFileLength(java.io.File&nbsp;file,
                 <a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;workConf)</pre>
<div class="block">Return the file length, if the file is compressed it returns the uncompressed file length.
 It also caches the uncompressed file size to avoid repeated decompression. The cache size is
 read from workerConf.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>file</code> - (undocumented)</dd><dd><code>workConf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="offsetBytes(java.lang.String, long, long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>offsetBytes</h4>
<pre>public static&nbsp;String&nbsp;offsetBytes(String&nbsp;path,
                 long&nbsp;length,
                 long&nbsp;start,
                 long&nbsp;end)</pre>
<div class="block">Return a string containing part of a file from byte 'start' to 'end'.</div>
</li>
</ul>
<a name="offsetBytes(scala.collection.Seq, scala.collection.Seq, long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>offsetBytes</h4>
<pre>public static&nbsp;String&nbsp;offsetBytes(scala.collection.Seq&lt;java.io.File&gt;&nbsp;files,
                 scala.collection.Seq&lt;Object&gt;&nbsp;fileLengths,
                 long&nbsp;start,
                 long&nbsp;end)</pre>
<div class="block">Return a string containing data across a set of files. The <code>startIndex</code>
 and <code>endIndex</code> is based on the cumulative size of all the files take in
 the given order. See figure below for more details.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>files</code> - (undocumented)</dd><dd><code>fileLengths</code> - (undocumented)</dd><dd><code>start</code> - (undocumented)</dd><dd><code>end</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="clone(java.lang.Object,org.apache.spark.serializer.SerializerInstance,scala.reflect.ClassTag)">
<!--   -->
</a><a name="clone(T, org.apache.spark.serializer.SerializerInstance, scala.reflect.ClassTag)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clone</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;clone(T&nbsp;value,
          <a href="../../../../org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a>&nbsp;serializer,
          scala.reflect.ClassTag&lt;T&gt;&nbsp;evidence$2)</pre>
<div class="block">Clone an object using a Spark serializer.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>value</code> - (undocumented)</dd><dd><code>serializer</code> - (undocumented)</dd><dd><code>evidence$2</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="splitCommandString(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>splitCommandString</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;splitCommandString(String&nbsp;s)</pre>
<div class="block">Split a string of potentially quoted arguments from the command line the way that a shell
 would do it to determine arguments to a command. For example, if the string is 'a "b c" d',
 then it would be parsed as three arguments: 'a', 'b c' and 'd'.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>s</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="nonNegativeMod(int, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>nonNegativeMod</h4>
<pre>public static&nbsp;int&nbsp;nonNegativeMod(int&nbsp;x,
                 int&nbsp;mod)</pre>
</li>
</ul>
<a name="nonNegativeHash(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>nonNegativeHash</h4>
<pre>public static&nbsp;int&nbsp;nonNegativeHash(Object&nbsp;obj)</pre>
</li>
</ul>
<a name="nanSafeCompareDoubles(double, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>nanSafeCompareDoubles</h4>
<pre>public static&nbsp;int&nbsp;nanSafeCompareDoubles(double&nbsp;x,
                        double&nbsp;y)</pre>
<div class="block">NaN-safe version of <code>java.lang.Double.compare()</code> which allows NaN values to be compared
 according to semantics where NaN == NaN and NaN is greater than any non-NaN double.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - (undocumented)</dd><dd><code>y</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="nanSafeCompareFloats(float, float)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>nanSafeCompareFloats</h4>
<pre>public static&nbsp;int&nbsp;nanSafeCompareFloats(float&nbsp;x,
                       float&nbsp;y)</pre>
<div class="block">NaN-safe version of <code>java.lang.Float.compare()</code> which allows NaN values to be compared
 according to semantics where NaN == NaN and NaN is greater than any non-NaN float.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - (undocumented)</dd><dd><code>y</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getSystemProperties()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSystemProperties</h4>
<pre>public static&nbsp;scala.collection.Map&lt;String,String&gt;&nbsp;getSystemProperties()</pre>
<div class="block">Returns the system properties map that is thread-safe to iterator over. It gets the
 properties which have been set explicitly, as well as those for which only a default value
 has been defined.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="times(int, scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>times</h4>
<pre>public static&nbsp;void&nbsp;times(int&nbsp;numIters,
         scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;f)</pre>
<div class="block">Method executed for repeating a task for side effects.
 Unlike a for comprehension, it permits JVM JIT optimization</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>numIters</code> - (undocumented)</dd><dd><code>f</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="timeIt(int, scala.Function0, scala.Option)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>timeIt</h4>
<pre>public static&nbsp;long&nbsp;timeIt(int&nbsp;numIters,
          scala.Function0&lt;scala.runtime.BoxedUnit&gt;&nbsp;f,
          scala.Option&lt;scala.Function0&lt;scala.runtime.BoxedUnit&gt;&gt;&nbsp;prepare)</pre>
<div class="block">Timing method based on iterations that permit JVM JIT optimization.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>numIters</code> - number of iterations</dd><dd><code>f</code> - function to be executed. If prepare is not None, the running time of each call to f
          must be an order of magnitude longer than one millisecond for accurate timing.</dd><dd><code>prepare</code> - function to be executed before each call to f. Its running time doesn't count.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the total time across all iterations (not counting preparation time)</dd></dl>
</li>
</ul>
<a name="getIteratorSize(scala.collection.Iterator)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIteratorSize</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;long&nbsp;getIteratorSize(scala.collection.Iterator&lt;T&gt;&nbsp;iterator)</pre>
<div class="block">Counts the number of elements of an iterator using a while loop rather than calling
 <code>TraversableOnce.size()</code> because it uses a for loop, which is slightly slower
 in the current version of Scala.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>iterator</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getIteratorZipWithIndex(scala.collection.Iterator, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIteratorZipWithIndex</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;scala.collection.Iterator&lt;scala.Tuple2&lt;T,Object&gt;&gt;&nbsp;getIteratorZipWithIndex(scala.collection.Iterator&lt;T&gt;&nbsp;iterator,
                                                                            long&nbsp;startIndex)</pre>
<div class="block">Generate a zipWithIndex iterator, avoid index value overflowing problem
 in scala's zipWithIndex</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>iterator</code> - (undocumented)</dd><dd><code>startIndex</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="symlink(java.io.File, java.io.File)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>symlink</h4>
<pre>public static&nbsp;void&nbsp;symlink(java.io.File&nbsp;src,
           java.io.File&nbsp;dst)</pre>
<div class="block">Creates a symlink.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>src</code> - absolute path to the source</dd><dd><code>dst</code> - relative path for the destination</dd></dl>
</li>
</ul>
<a name="getFormattedClassName(java.lang.Object)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFormattedClassName</h4>
<pre>public static&nbsp;String&nbsp;getFormattedClassName(Object&nbsp;obj)</pre>
<div class="block">Return the class name of the given object, removing all dollar signs</div>
</li>
</ul>
<a name="jsonOption(org.json4s.JsonAST.JValue)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jsonOption</h4>
<pre>public static&nbsp;scala.Option&lt;org.json4s.JsonAST.JValue&gt;&nbsp;jsonOption(org.json4s.JsonAST.JValue&nbsp;json)</pre>
<div class="block">Return an option that translates JNothing to None</div>
</li>
</ul>
<a name="emptyJson()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>emptyJson</h4>
<pre>public static&nbsp;org.json4s.JsonAST.JObject&nbsp;emptyJson()</pre>
<div class="block">Return an empty JSON object</div>
</li>
</ul>
<a name="getHadoopFileSystem(java.net.URI, org.apache.hadoop.conf.Configuration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getHadoopFileSystem</h4>
<pre>public static&nbsp;org.apache.hadoop.fs.FileSystem&nbsp;getHadoopFileSystem(java.net.URI&nbsp;path,
                                                  org.apache.hadoop.conf.Configuration&nbsp;conf)</pre>
<div class="block">Return a Hadoop FileSystem with the scheme encoded in the given path.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getHadoopFileSystem(java.lang.String, org.apache.hadoop.conf.Configuration)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getHadoopFileSystem</h4>
<pre>public static&nbsp;org.apache.hadoop.fs.FileSystem&nbsp;getHadoopFileSystem(String&nbsp;path,
                                                  org.apache.hadoop.conf.Configuration&nbsp;conf)</pre>
<div class="block">Return a Hadoop FileSystem with the scheme encoded in the given path.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getFilePath(java.io.File, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFilePath</h4>
<pre>public static&nbsp;org.apache.hadoop.fs.Path&nbsp;getFilePath(java.io.File&nbsp;dir,
                                    String&nbsp;fileName)</pre>
<div class="block">Return the absolute path of a file in the given directory.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>dir</code> - (undocumented)</dd><dd><code>fileName</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="isWindows()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isWindows</h4>
<pre>public static&nbsp;boolean&nbsp;isWindows()</pre>
<div class="block">Whether the underlying operating system is Windows.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="isMac()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isMac</h4>
<pre>public static&nbsp;boolean&nbsp;isMac()</pre>
<div class="block">Whether the underlying operating system is Mac OS X.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="windowsDrive()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>windowsDrive</h4>
<pre>public static&nbsp;scala.util.matching.Regex&nbsp;windowsDrive()</pre>
<div class="block">Pattern for matching a Windows drive, which contains only a single alphabet character.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="isTesting()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isTesting</h4>
<pre>public static&nbsp;boolean&nbsp;isTesting()</pre>
<div class="block">Indicates whether Spark is currently running unit tests.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="stripDirectory(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>stripDirectory</h4>
<pre>public static&nbsp;String&nbsp;stripDirectory(String&nbsp;path)</pre>
<div class="block">Strip the directory from a path name</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="terminateProcess(java.lang.Process, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>terminateProcess</h4>
<pre>public static&nbsp;scala.Option&lt;Object&gt;&nbsp;terminateProcess(Process&nbsp;process,
                                    long&nbsp;timeoutMs)</pre>
<div class="block">Terminates a process waiting for at most the specified duration.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>process</code> - (undocumented)</dd><dd><code>timeoutMs</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>the process exit value if it was successfully terminated, else None</dd></dl>
</li>
</ul>
<a name="waitForProcess(java.lang.Process, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>waitForProcess</h4>
<pre>public static&nbsp;boolean&nbsp;waitForProcess(Process&nbsp;process,
                     long&nbsp;timeoutMs)</pre>
<div class="block">Wait for a process to terminate for at most the specified duration.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>process</code> - (undocumented)</dd><dd><code>timeoutMs</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>whether the process actually terminated before the given timeout.</dd></dl>
</li>
</ul>
<a name="getStderr(java.lang.Process, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStderr</h4>
<pre>public static&nbsp;scala.Option&lt;String&gt;&nbsp;getStderr(Process&nbsp;process,
                             long&nbsp;timeoutMs)</pre>
<div class="block">Return the stderr of a process after waiting for the process to terminate.
 If the process does not terminate within the specified timeout, return None.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>process</code> - (undocumented)</dd><dd><code>timeoutMs</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="logUncaughtExceptions(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>logUncaughtExceptions</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;logUncaughtExceptions(scala.Function0&lt;T&gt;&nbsp;f)</pre>
<div class="block">Execute the given block, logging and re-throwing any uncaught exception.
 This is particularly useful for wrapping code that runs in a thread, to ensure
 that exceptions are printed, and to avoid having to catch Throwable.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>f</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="tryLog(scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryLog</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;scala.util.Try&lt;T&gt;&nbsp;tryLog(scala.Function0&lt;T&gt;&nbsp;f)</pre>
<div class="block">Executes the given block in a Try, logging any uncaught exceptions.</div>
</li>
</ul>
<a name="isFatalError(java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isFatalError</h4>
<pre>public static&nbsp;boolean&nbsp;isFatalError(Throwable&nbsp;e)</pre>
<div class="block">Returns true if the given exception was fatal. See docs for scala.util.control.NonFatal.</div>
</li>
</ul>
<a name="resolveURI(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resolveURI</h4>
<pre>public static&nbsp;java.net.URI&nbsp;resolveURI(String&nbsp;path)</pre>
<div class="block">Return a well-formed URI for the file described by a user input string.
 <p>
 If the supplied path does not contain a scheme, or is a relative path, it will be
 converted into an absolute path with a file:// scheme.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="resolveURIs(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resolveURIs</h4>
<pre>public static&nbsp;String&nbsp;resolveURIs(String&nbsp;paths)</pre>
<div class="block">Resolve a comma-separated list of paths.</div>
</li>
</ul>
<a name="nonLocalPaths(java.lang.String, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>nonLocalPaths</h4>
<pre>public static&nbsp;String[]&nbsp;nonLocalPaths(String&nbsp;paths,
                     boolean&nbsp;testWindows)</pre>
<div class="block">Return all non-local paths from a comma-separated list of paths.</div>
</li>
</ul>
<a name="loadDefaultSparkProperties(org.apache.spark.SparkConf, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>loadDefaultSparkProperties</h4>
<pre>public static&nbsp;String&nbsp;loadDefaultSparkProperties(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                                String&nbsp;filePath)</pre>
<div class="block">Load default Spark properties from the given file. If no file is provided,
 use the common defaults file. This mutates state in the given SparkConf and
 in this JVM's system properties if the config specified in the file is not
 already set. Return the path of the properties file used.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd><dd><code>filePath</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getPropertiesFromFile(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPropertiesFromFile</h4>
<pre>public static&nbsp;scala.collection.Map&lt;String,String&gt;&nbsp;getPropertiesFromFile(String&nbsp;filename)</pre>
<div class="block">Load properties present in the given file.</div>
</li>
</ul>
<a name="getDefaultPropertiesFile(scala.collection.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDefaultPropertiesFile</h4>
<pre>public static&nbsp;String&nbsp;getDefaultPropertiesFile(scala.collection.Map&lt;String,String&gt;&nbsp;env)</pre>
<div class="block">Return the path of the default Spark properties file.</div>
</li>
</ul>
<a name="exceptionString(java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>exceptionString</h4>
<pre>public static&nbsp;String&nbsp;exceptionString(Throwable&nbsp;e)</pre>
<div class="block">Return a nice string representation of the exception. It will call "printStackTrace" to
 recursively generate the stack trace including the exception and its causes.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>e</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getThreadDump()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getThreadDump</h4>
<pre>public static&nbsp;org.apache.spark.util.ThreadStackTrace[]&nbsp;getThreadDump()</pre>
<div class="block">Return a thread dump of all threads' stacktraces.  Used to capture dumps for the web UI</div>
</li>
</ul>
<a name="getThreadDumpForThread(long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getThreadDumpForThread</h4>
<pre>public static&nbsp;scala.Option&lt;org.apache.spark.util.ThreadStackTrace&gt;&nbsp;getThreadDumpForThread(long&nbsp;threadId)</pre>
</li>
</ul>
<a name="sparkJavaOpts(org.apache.spark.SparkConf, scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkJavaOpts</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;sparkJavaOpts(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                                         scala.Function1&lt;String,Object&gt;&nbsp;filterKey)</pre>
<div class="block">Convert all spark properties set in the given SparkConf to a sequence of java options.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd><dd><code>filterKey</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="portMaxRetries(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>portMaxRetries</h4>
<pre>public static&nbsp;int&nbsp;portMaxRetries(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
<div class="block">Maximum number of retries when binding to a port before giving up.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="startServiceOnPort(int, scala.Function1, org.apache.spark.SparkConf, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>startServiceOnPort</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;scala.Tuple2&lt;T,Object&gt;&nbsp;startServiceOnPort(int&nbsp;startPort,
                                            scala.Function1&lt;Object,scala.Tuple2&lt;T,Object&gt;&gt;&nbsp;startService,
                                            <a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                                            String&nbsp;serviceName)</pre>
<div class="block">Attempt to start a service on the given port, or fail after a number of attempts.
 Each subsequent attempt uses 1 + the port used in the previous attempt (unless the port is 0).
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>startPort</code> - The initial port to start the service on.</dd><dd><code>startService</code> - Function to start service on a given port.
                     This is expected to throw java.net.BindException on port collision.</dd><dd><code>conf</code> - A SparkConf used to get the maximum number of retries when binding to a port.</dd><dd><code>serviceName</code> - Name of the service.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(service: T, port: Int)</dd></dl>
</li>
</ul>
<a name="isBindCollision(java.lang.Throwable)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isBindCollision</h4>
<pre>public static&nbsp;boolean&nbsp;isBindCollision(Throwable&nbsp;exception)</pre>
<div class="block">Return whether the exception is caused by an address-port collision when binding.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>exception</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="setLogLevel(org.apache.log4j.Level)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLogLevel</h4>
<pre>public static&nbsp;void&nbsp;setLogLevel(org.apache.log4j.Level&nbsp;l)</pre>
<div class="block">configure a new log4j level</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>l</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="configTestLog4j(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>configTestLog4j</h4>
<pre>public static&nbsp;void&nbsp;configTestLog4j(String&nbsp;level)</pre>
<div class="block">config a log4j properties used for testsuite</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>level</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="setupSecureURLConnection(java.net.URLConnection, org.apache.spark.SecurityManager)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setupSecureURLConnection</h4>
<pre>public static&nbsp;java.net.URLConnection&nbsp;setupSecureURLConnection(java.net.URLConnection&nbsp;urlConnection,
                                              org.apache.spark.SecurityManager&nbsp;sm)</pre>
<div class="block">If the given URL connection is HttpsURLConnection, it sets the SSL socket factory and
 the host verifier from the given security manager.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>urlConnection</code> - (undocumented)</dd><dd><code>sm</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="invoke(java.lang.Class, java.lang.Object, java.lang.String, scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>invoke</h4>
<pre>public static&nbsp;Object&nbsp;invoke(Class&lt;?&gt;&nbsp;clazz,
            Object&nbsp;obj,
            String&nbsp;methodName,
            scala.collection.Seq&lt;scala.Tuple2&lt;Class&lt;?&gt;,Object&gt;&gt;&nbsp;args)</pre>
</li>
</ul>
<a name="getMaxResultSize(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMaxResultSize</h4>
<pre>public static&nbsp;long&nbsp;getMaxResultSize(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
</li>
</ul>
<a name="libraryPathEnvName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>libraryPathEnvName</h4>
<pre>public static&nbsp;String&nbsp;libraryPathEnvName()</pre>
<div class="block">Return the current system LD_LIBRARY_PATH name</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="libraryPathEnvPrefix(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>libraryPathEnvPrefix</h4>
<pre>public static&nbsp;String&nbsp;libraryPathEnvPrefix(scala.collection.Seq&lt;String&gt;&nbsp;libraryPaths)</pre>
<div class="block">Return the prefix of a command that appends the given library paths to the
 system-specific library path environment variable. On Unix, for instance,
 this returns the string LD_LIBRARY_PATH="path1:path2:$LD_LIBRARY_PATH".</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>libraryPaths</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getSparkOrYarnConfig(org.apache.spark.SparkConf, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSparkOrYarnConfig</h4>
<pre>public static&nbsp;String&nbsp;getSparkOrYarnConfig(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                          String&nbsp;key,
                          String&nbsp;default_)</pre>
<div class="block">Return the value of a config either through the SparkConf or the Hadoop configuration
 if this is Yarn mode. In the latter case, this defaults to the value set through SparkConf
 if the key is not set in the Hadoop configuration.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd><dd><code>key</code> - (undocumented)</dd><dd><code>default_</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="extractHostPortFromSparkUrl(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>extractHostPortFromSparkUrl</h4>
<pre>public static&nbsp;scala.Tuple2&lt;String,Object&gt;&nbsp;extractHostPortFromSparkUrl(String&nbsp;sparkUrl)
                                                               throws <a href="../../../../org/apache/spark/SparkException.html" title="class in org.apache.spark">SparkException</a></pre>
<div class="block">Return a pair of host and port extracted from the <code>sparkUrl</code>.
 <p>
 A spark url (<code>spark://host:port</code>) is a special URI that its scheme is <code>spark</code> and only contains
 host and port.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sparkUrl</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd>
<dt><span class="strong">Throws:</span></dt>
<dd><code><a href="../../../../org/apache/spark/SparkException.html" title="class in org.apache.spark">SparkException</a></code> - if sparkUrl is invalid.</dd></dl>
</li>
</ul>
<a name="getCurrentUserName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCurrentUserName</h4>
<pre>public static&nbsp;String&nbsp;getCurrentUserName()</pre>
<div class="block">Returns the current user name. This is the currently logged in user, unless that's been
 overridden by the <code>SPARK_USER</code> environment variable.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="EMPTY_USER_GROUPS()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>EMPTY_USER_GROUPS</h4>
<pre>public static&nbsp;scala.collection.immutable.Set&lt;String&gt;&nbsp;EMPTY_USER_GROUPS()</pre>
</li>
</ul>
<a name="getCurrentUserGroups(org.apache.spark.SparkConf, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCurrentUserGroups</h4>
<pre>public static&nbsp;scala.collection.immutable.Set&lt;String&gt;&nbsp;getCurrentUserGroups(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;sparkConf,
                                                          String&nbsp;username)</pre>
</li>
</ul>
<a name="parseStandaloneMasterUrls(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parseStandaloneMasterUrls</h4>
<pre>public static&nbsp;String[]&nbsp;parseStandaloneMasterUrls(String&nbsp;masterUrls)</pre>
<div class="block">Split the comma delimited string of master URLs into a list.
 For instance, "spark://abc,def" becomes [spark://abc, spark://def].</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>masterUrls</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="BACKUP_STANDALONE_MASTER_PREFIX()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>BACKUP_STANDALONE_MASTER_PREFIX</h4>
<pre>public static&nbsp;String&nbsp;BACKUP_STANDALONE_MASTER_PREFIX()</pre>
<div class="block">An identifier that backup masters use in their responses.</div>
</li>
</ul>
<a name="responseFromBackup(java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>responseFromBackup</h4>
<pre>public static&nbsp;boolean&nbsp;responseFromBackup(String&nbsp;msg)</pre>
<div class="block">Return true if the response message is sent from a backup Master on standby.</div>
</li>
</ul>
<a name="withDummyCallSite(org.apache.spark.SparkContext, scala.Function0)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>withDummyCallSite</h4>
<pre>public static&nbsp;&lt;T&gt;&nbsp;T&nbsp;withDummyCallSite(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                      scala.Function0&lt;T&gt;&nbsp;body)</pre>
<div class="block">To avoid calling <code>Utils.getCallSite</code> for every single RDD we create in the body,
 set a dummy call site that RDDs use instead. This is for performance optimization.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>sc</code> - (undocumented)</dd><dd><code>body</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="isInDirectory(java.io.File, java.io.File)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isInDirectory</h4>
<pre>public static&nbsp;boolean&nbsp;isInDirectory(java.io.File&nbsp;parent,
                    java.io.File&nbsp;child)</pre>
<div class="block">Return whether the specified file is a parent directory of the child file.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>parent</code> - (undocumented)</dd><dd><code>child</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="isLocalMaster(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isLocalMaster</h4>
<pre>public static&nbsp;boolean&nbsp;isLocalMaster(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>whether it is local mode</dd></dl>
</li>
</ul>
<a name="isDynamicAllocationEnabled(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isDynamicAllocationEnabled</h4>
<pre>public static&nbsp;boolean&nbsp;isDynamicAllocationEnabled(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
<div class="block">Return whether dynamic allocation is enabled in the given conf.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getDynamicAllocationInitialExecutors(org.apache.spark.SparkConf)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDynamicAllocationInitialExecutors</h4>
<pre>public static&nbsp;int&nbsp;getDynamicAllocationInitialExecutors(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf)</pre>
<div class="block">Return the initial number of executors for dynamic allocation.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="tryWithResource(scala.Function0, scala.Function1)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tryWithResource</h4>
<pre>public static&nbsp;&lt;R extends java.io.Closeable,T&gt;&nbsp;T&nbsp;tryWithResource(scala.Function0&lt;R&gt;&nbsp;createResource,
                                                scala.Function1&lt;R,T&gt;&nbsp;f)</pre>
</li>
</ul>
<a name="tempFileWith(java.io.File)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tempFileWith</h4>
<pre>public static&nbsp;java.io.File&nbsp;tempFileWith(java.io.File&nbsp;path)</pre>
<div class="block">Returns a path of temporary file which is in the same directory with <code>path</code>.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>path</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getProcessName()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getProcessName</h4>
<pre>public static&nbsp;String&nbsp;getProcessName()</pre>
<div class="block">Returns the name of this JVM process. This is OS dependent but typically (OSX, Linux, Windows),
 this is formatted as PID@hostname.</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="initDaemon(org.slf4j.Logger)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initDaemon</h4>
<pre>public static&nbsp;void&nbsp;initDaemon(org.slf4j.Logger&nbsp;log)</pre>
<div class="block">Utility function that should be called early in <code>main()</code> for daemons to set up some common
 diagnostic state.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>log</code> - (undocumented)</dd></dl>
</li>
</ul>
<a name="unionFileLists(scala.Option, scala.Option)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unionFileLists</h4>
<pre>public static&nbsp;scala.collection.immutable.Set&lt;String&gt;&nbsp;unionFileLists(scala.Option&lt;String&gt;&nbsp;leftList,
                                                    scala.Option&lt;String&gt;&nbsp;rightList)</pre>
<div class="block">Unions two comma-separated lists of files and filters out empty strings.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>leftList</code> - (undocumented)</dd><dd><code>rightList</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="getUserJars(org.apache.spark.SparkConf, boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getUserJars</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;getUserJars(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                                       boolean&nbsp;isShell)</pre>
<div class="block">In YARN mode this method returns a union of the jar files pointed by "spark.jars" and the
 "spark.yarn.dist.jars" properties, while in other modes it returns the jar files pointed by
 only the "spark.jars" property.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>conf</code> - (undocumented)</dd><dd><code>isShell</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
<a name="redact(org.apache.spark.SparkConf, scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>redact</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;scala.Tuple2&lt;String,String&gt;&gt;&nbsp;redact(<a href="../../../../org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a>&nbsp;conf,
                                                       scala.collection.Seq&lt;scala.Tuple2&lt;String,String&gt;&gt;&nbsp;kvs)</pre>
</li>
</ul>
<a name="redact(scala.collection.Map)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>redact</h4>
<pre>public static&nbsp;scala.collection.Seq&lt;scala.Tuple2&lt;String,String&gt;&gt;&nbsp;redact(scala.collection.Map&lt;String,String&gt;&nbsp;kvs)</pre>
<div class="block">Looks up the redaction regex from within the key value pairs and uses it to redact the rest
 of the key value pairs. No care is taken to make sure the redaction property itself is not
 redacted. So theoretically, the property itself could be configured to redact its own value
 when printing.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>kvs</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/util/ThreadUtils.html" title="class in org.apache.spark.util"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/util/VersionUtils.html" title="class in org.apache.spark.util"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/util/Utils.html" target="_top">Frames</a></li>
<li><a href="Utils.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
