<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.7.0_151) on Mon Oct 02 14:47:15 PDT 2017 -->
<title>DataFrameStatFunctions (Spark 2.1.2 JavaDoc)</title>
<meta name="date" content="2017-10-02">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="DataFrameStatFunctions (Spark 2.1.2 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/DataFrameStatFunctions.html" target="_top">Frames</a></li>
<li><a href="DataFrameStatFunctions.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class DataFrameStatFunctions" class="title">Class DataFrameStatFunctions</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.DataFrameStatFunctions</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public final class <span class="strong">DataFrameStatFunctions</span>
extends Object</pre>
<div class="block">Statistic functions for <code>DataFrame</code>s.
 <p></div>
<dl><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double[]</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#approxQuantile(java.lang.String,%20double[],%20double)">approxQuantile</a></strong>(String&nbsp;col,
              double[]&nbsp;probabilities,
              double&nbsp;relativeError)</code>
<div class="block">Calculates the approximate quantiles of a numerical column of a DataFrame.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(org.apache.spark.sql.Column,%20long,%20double)">bloomFilter</a></strong>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
           long&nbsp;expectedNumItems,
           double&nbsp;fpp)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(org.apache.spark.sql.Column,%20long,%20long)">bloomFilter</a></strong>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
           long&nbsp;expectedNumItems,
           long&nbsp;numBits)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(java.lang.String,%20long,%20double)">bloomFilter</a></strong>(String&nbsp;colName,
           long&nbsp;expectedNumItems,
           double&nbsp;fpp)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(java.lang.String,%20long,%20long)">bloomFilter</a></strong>(String&nbsp;colName,
           long&nbsp;expectedNumItems,
           long&nbsp;numBits)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#corr(java.lang.String,%20java.lang.String)">corr</a></strong>(String&nbsp;col1,
    String&nbsp;col2)</code>
<div class="block">Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#corr(java.lang.String,%20java.lang.String,%20java.lang.String)">corr</a></strong>(String&nbsp;col1,
    String&nbsp;col2,
    String&nbsp;method)</code>
<div class="block">Calculates the correlation of two columns of a DataFrame.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(org.apache.spark.sql.Column,%20double,%20double,%20int)">countMinSketch</a></strong>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
              double&nbsp;eps,
              double&nbsp;confidence,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(org.apache.spark.sql.Column,%20int,%20int,%20int)">countMinSketch</a></strong>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
              int&nbsp;depth,
              int&nbsp;width,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(java.lang.String,%20double,%20double,%20int)">countMinSketch</a></strong>(String&nbsp;colName,
              double&nbsp;eps,
              double&nbsp;confidence,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(java.lang.String,%20int,%20int,%20int)">countMinSketch</a></strong>(String&nbsp;colName,
              int&nbsp;depth,
              int&nbsp;width,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#cov(java.lang.String,%20java.lang.String)">cov</a></strong>(String&nbsp;col1,
   String&nbsp;col2)</code>
<div class="block">Calculate the sample covariance of two numerical columns of a DataFrame.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#crosstab(java.lang.String,%20java.lang.String)">crosstab</a></strong>(String&nbsp;col1,
        String&nbsp;col2)</code>
<div class="block">Computes a pair-wise frequency table of the given columns.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(scala.collection.Seq)">freqItems</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;cols)</code>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(scala.collection.Seq,%20double)">freqItems</a></strong>(scala.collection.Seq&lt;String&gt;&nbsp;cols,
         double&nbsp;support)</code>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(java.lang.String[])">freqItems</a></strong>(String[]&nbsp;cols)</code>
<div class="block">Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(java.lang.String[],%20double)">freqItems</a></strong>(String[]&nbsp;cols,
         double&nbsp;support)</code>
<div class="block">Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy(java.lang.String,%20java.util.Map,%20long)">sampleBy</a></strong>(String&nbsp;col,
        java.util.Map&lt;T,Double&gt;&nbsp;fractions,
        long&nbsp;seed)</code>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy(java.lang.String,%20scala.collection.immutable.Map,%20long)">sampleBy</a></strong>(String&nbsp;col,
        scala.collection.immutable.Map&lt;T,Object&gt;&nbsp;fractions,
        long&nbsp;seed)</code>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="approxQuantile(java.lang.String, double[], double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>approxQuantile</h4>
<pre>public&nbsp;double[]&nbsp;approxQuantile(String&nbsp;col,
                      double[]&nbsp;probabilities,
                      double&nbsp;relativeError)</pre>
<div class="block">Calculates the approximate quantiles of a numerical column of a DataFrame.
 <p>
 The result of this algorithm has the following deterministic bound:
 If the DataFrame has N elements and if we request the quantile at probability <code>p</code> up to error
 <code>err</code>, then the algorithm will return a sample <code>x</code> from the DataFrame so that the *exact* rank
 of <code>x</code> is close to (p * N).
 More precisely,
 <p>
 <pre><code>
   floor((p - err) * N) &lt;= rank(x) &lt;= ceil((p + err) * N)
 </code></pre>
 <p>
 This method implements a variation of the Greenwald-Khanna algorithm (with some speed
 optimizations).
 The algorithm was first present in <a href="http://dx.doi.org/10.1145/375663.375670">
 Space-efficient Online Computation of Quantile Summaries</a> by Greenwald and Khanna.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - the name of the numerical column</dd><dd><code>probabilities</code> - a list of quantile probabilities
   Each number must belong to [0, 1].
   For example 0 is the minimum, 0.5 is the median, 1 is the maximum.</dd><dd><code>relativeError</code> - The relative target precision to achieve (greater or equal to 0).
   If set to zero, the exact quantiles are computed, which could be very expensive.
   Note that values greater than 1 are accepted but give the same result as 1.</dd>
<dt><span class="strong">Returns:</span></dt><dd>the approximate quantiles at the given probabilities
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd>
<dt><span class="strong">Note:</span></dt>
  <dd>NaN values will be removed from the numerical column before calculation
 <p></dd></dl>
</li>
</ul>
<a name="cov(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cov</h4>
<pre>public&nbsp;double&nbsp;cov(String&nbsp;col1,
         String&nbsp;col2)</pre>
<div class="block">Calculate the sample covariance of two numerical columns of a DataFrame.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col1</code> - the name of the first column</dd><dd><code>col2</code> - the name of the second column</dd>
<dt><span class="strong">Returns:</span></dt><dd>the covariance of the two columns.
 <p>
 <pre><code>
    val df = sc.parallelize(0 until 10).toDF("id").withColumn("rand1", rand(seed=10))
      .withColumn("rand2", rand(seed=27))
    df.stat.cov("rand1", "rand2")
    res1: Double = 0.065...
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="corr(java.lang.String, java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>corr</h4>
<pre>public&nbsp;double&nbsp;corr(String&nbsp;col1,
          String&nbsp;col2,
          String&nbsp;method)</pre>
<div class="block">Calculates the correlation of two columns of a DataFrame. Currently only supports the Pearson
 Correlation Coefficient. For Spearman Correlation, consider using RDD methods found in
 MLlib's Statistics.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col1</code> - the name of the column</dd><dd><code>col2</code> - the name of the column to calculate the correlation against</dd><dd><code>method</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>The Pearson Correlation Coefficient as a Double.
 <p>
 <pre><code>
    val df = sc.parallelize(0 until 10).toDF("id").withColumn("rand1", rand(seed=10))
      .withColumn("rand2", rand(seed=27))
    df.stat.corr("rand1", "rand2")
    res1: Double = 0.613...
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="corr(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>corr</h4>
<pre>public&nbsp;double&nbsp;corr(String&nbsp;col1,
          String&nbsp;col2)</pre>
<div class="block">Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col1</code> - the name of the column</dd><dd><code>col2</code> - the name of the column to calculate the correlation against</dd>
<dt><span class="strong">Returns:</span></dt><dd>The Pearson Correlation Coefficient as a Double.
 <p>
 <pre><code>
    val df = sc.parallelize(0 until 10).toDF("id").withColumn("rand1", rand(seed=10))
      .withColumn("rand2", rand(seed=27))
    df.stat.corr("rand1", "rand2", "pearson")
    res1: Double = 0.613...
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="crosstab(java.lang.String, java.lang.String)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>crosstab</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;crosstab(String&nbsp;col1,
                    String&nbsp;col2)</pre>
<div class="block">Computes a pair-wise frequency table of the given columns. Also known as a contingency table.
 The number of distinct values for each column should be less than 1e4. At most 1e6 non-zero
 pair frequencies will be returned.
 The first column of each row will be the distinct values of <code>col1</code> and the column names will
 be the distinct values of <code>col2</code>. The name of the first column will be <code>$col1_$col2</code>. Counts
 will be returned as <code>Long</code>s. Pairs that have no occurrences will have zero as their counts.
 Null elements will be replaced by "null", and back ticks will be dropped from elements if they
 exist.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col1</code> - The name of the first column. Distinct items will make the first item of
             each row.</dd><dd><code>col2</code> - The name of the second column. Distinct items will make the column names
             of the DataFrame.</dd>
<dt><span class="strong">Returns:</span></dt><dd>A DataFrame containing for the contingency table.
 <p>
 <pre><code>
    val df = spark.createDataFrame(Seq((1, 1), (1, 2), (2, 1), (2, 1), (2, 3), (3, 2), (3, 3)))
      .toDF("key", "value")
    val ct = df.stat.crosstab("key", "value")
    ct.show()
    +---------+---+---+---+
    |key_value|  1|  2|  3|
    +---------+---+---+---+
    |        2|  2|  0|  1|
    |        1|  1|  1|  0|
    |        3|  0|  1|  1|
    +---------+---+---+---+
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="freqItems(java.lang.String[], double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(String[]&nbsp;cols,
                     double&nbsp;support)</pre>
<div class="block">Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp,
 Schenker, and Papadimitriou.
 The <code>support</code> should be greater than 1e-4.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - the names of the columns to search frequent items in.</dd><dd><code>support</code> - The minimum frequency for an item to be considered <code>frequent</code>. Should be greater
                than 1e-4.</dd>
<dt><span class="strong">Returns:</span></dt><dd>A Local DataFrame with the Array of frequent items for each column.
 <p>
 <pre><code>
    val rows = Seq.tabulate(100) { i =&gt;
      if (i % 2 == 0) (1, -1.0) else (i, i * -1.0)
    }
    val df = spark.createDataFrame(rows).toDF("a", "b")
    // find the items with a frequency greater than 0.4 (observed 40% of the time) for columns
    // "a" and "b"
    val freqSingles = df.stat.freqItems(Array("a", "b"), 0.4)
    freqSingles.show()
    +-----------+-------------+
    |a_freqItems|  b_freqItems|
    +-----------+-------------+
    |    [1, 99]|[-1.0, -99.0]|
    +-----------+-------------+
    // find the pair of items with a frequency greater than 0.1 in columns "a" and "b"
    val pairDf = df.select(struct("a", "b").as("a-b"))
    val freqPairs = pairDf.stat.freqItems(Array("a-b"), 0.1)
    freqPairs.select(explode($"a-b_freqItems").as("freq_ab")).show()
    +----------+
    |   freq_ab|
    +----------+
    |  [1,-1.0]|
    |   ...    |
    +----------+
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="freqItems(java.lang.String[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(String[]&nbsp;cols)</pre>
<div class="block">Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp,
 Schenker, and Papadimitriou.
 Uses a <code>default</code> support of 1%.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - the names of the columns to search frequent items in.</dd>
<dt><span class="strong">Returns:</span></dt><dd>A Local DataFrame with the Array of frequent items for each column.
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="freqItems(scala.collection.Seq, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(scala.collection.Seq&lt;String&gt;&nbsp;cols,
                     double&nbsp;support)</pre>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp, Schenker,
 and Papadimitriou.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - the names of the columns to search frequent items in.</dd><dd><code>support</code> - (undocumented)</dd>
<dt><span class="strong">Returns:</span></dt><dd>A Local DataFrame with the Array of frequent items for each column.
 <p>
 <pre><code>
    val rows = Seq.tabulate(100) { i =&gt;
      if (i % 2 == 0) (1, -1.0) else (i, i * -1.0)
    }
    val df = spark.createDataFrame(rows).toDF("a", "b")
    // find the items with a frequency greater than 0.4 (observed 40% of the time) for columns
    // "a" and "b"
    val freqSingles = df.stat.freqItems(Seq("a", "b"), 0.4)
    freqSingles.show()
    +-----------+-------------+
    |a_freqItems|  b_freqItems|
    +-----------+-------------+
    |    [1, 99]|[-1.0, -99.0]|
    +-----------+-------------+
    // find the pair of items with a frequency greater than 0.1 in columns "a" and "b"
    val pairDf = df.select(struct("a", "b").as("a-b"))
    val freqPairs = pairDf.stat.freqItems(Seq("a-b"), 0.1)
    freqPairs.select(explode($"a-b_freqItems").as("freq_ab")).show()
    +----------+
    |   freq_ab|
    +----------+
    |  [1,-1.0]|
    |   ...    |
    +----------+
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="freqItems(scala.collection.Seq)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(scala.collection.Seq&lt;String&gt;&nbsp;cols)</pre>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp, Schenker,
 and Papadimitriou.
 Uses a <code>default</code> support of 1%.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>cols</code> - the names of the columns to search frequent items in.</dd>
<dt><span class="strong">Returns:</span></dt><dd>A Local DataFrame with the Array of frequent items for each column.
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.4.0</dd></dl>
</li>
</ul>
<a name="sampleBy(java.lang.String, scala.collection.immutable.Map, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sampleBy</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sampleBy(String&nbsp;col,
                        scala.collection.immutable.Map&lt;T,Object&gt;&nbsp;fractions,
                        long&nbsp;seed)</pre>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - column that defines strata</dd><dd><code>fractions</code> - sampling fraction for each stratum. If a stratum is not specified, we treat
                  its fraction as zero.</dd><dd><code>seed</code> - random seed</dd>
<dt><span class="strong">Returns:</span></dt><dd>a new <code>DataFrame</code> that represents the stratified sample
 <p>
 <pre><code>
    val df = spark.createDataFrame(Seq((1, 1), (1, 2), (2, 1), (2, 1), (2, 3), (3, 2),
      (3, 3))).toDF("key", "value")
    val fractions = Map(1 -&gt; 1.0, 3 -&gt; 0.5)
    df.stat.sampleBy("key", fractions, 36L).show()
    +---+-----+
    |key|value|
    +---+-----+
    |  1|    1|
    |  1|    2|
    |  3|    2|
    +---+-----+
 </code></pre>
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.5.0</dd></dl>
</li>
</ul>
<a name="sampleBy(java.lang.String, java.util.Map, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sampleBy</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sampleBy(String&nbsp;col,
                        java.util.Map&lt;T,Double&gt;&nbsp;fractions,
                        long&nbsp;seed)</pre>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - column that defines strata</dd><dd><code>fractions</code> - sampling fraction for each stratum. If a stratum is not specified, we treat
                  its fraction as zero.</dd><dd><code>seed</code> - random seed</dd>
<dt><span class="strong">Returns:</span></dt><dd>a new <code>DataFrame</code> that represents the stratified sample
 <p></dd><dt><span class="strong">Since:</span></dt>
  <dd>1.5.0</dd></dl>
</li>
</ul>
<a name="countMinSketch(java.lang.String, int, int, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(String&nbsp;colName,
                            int&nbsp;depth,
                            int&nbsp;width,
                            int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>colName</code> - name of the column over which the sketch is built</dd><dd><code>depth</code> - depth of the sketch</dd><dd><code>width</code> - width of the sketch</dd><dd><code>seed</code> - random seed</dd>
<dt><span class="strong">Returns:</span></dt><dd>a <code>CountMinSketch</code> over column <code>colName</code></dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="countMinSketch(java.lang.String, double, double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(String&nbsp;colName,
                            double&nbsp;eps,
                            double&nbsp;confidence,
                            int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>colName</code> - name of the column over which the sketch is built</dd><dd><code>eps</code> - relative error of the sketch</dd><dd><code>confidence</code> - confidence of the sketch</dd><dd><code>seed</code> - random seed</dd>
<dt><span class="strong">Returns:</span></dt><dd>a <code>CountMinSketch</code> over column <code>colName</code></dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="countMinSketch(org.apache.spark.sql.Column, int, int, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                            int&nbsp;depth,
                            int&nbsp;width,
                            int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - the column over which the sketch is built</dd><dd><code>depth</code> - depth of the sketch</dd><dd><code>width</code> - width of the sketch</dd><dd><code>seed</code> - random seed</dd>
<dt><span class="strong">Returns:</span></dt><dd>a <code>CountMinSketch</code> over column <code>colName</code></dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="countMinSketch(org.apache.spark.sql.Column, double, double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                            double&nbsp;eps,
                            double&nbsp;confidence,
                            int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - the column over which the sketch is built</dd><dd><code>eps</code> - relative error of the sketch</dd><dd><code>confidence</code> - confidence of the sketch</dd><dd><code>seed</code> - random seed</dd>
<dt><span class="strong">Returns:</span></dt><dd>a <code>CountMinSketch</code> over column <code>colName</code></dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="bloomFilter(java.lang.String, long, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(String&nbsp;colName,
                      long&nbsp;expectedNumItems,
                      double&nbsp;fpp)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>colName</code> - name of the column over which the filter is built</dd><dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd><dd><code>fpp</code> - expected false positive probability of the filter.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="bloomFilter(org.apache.spark.sql.Column, long, double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                      long&nbsp;expectedNumItems,
                      double&nbsp;fpp)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - the column over which the filter is built</dd><dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd><dd><code>fpp</code> - expected false positive probability of the filter.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="bloomFilter(java.lang.String, long, long)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(String&nbsp;colName,
                      long&nbsp;expectedNumItems,
                      long&nbsp;numBits)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>colName</code> - name of the column over which the filter is built</dd><dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd><dd><code>numBits</code> - expected number of bits of the filter.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
<a name="bloomFilter(org.apache.spark.sql.Column, long, long)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                      long&nbsp;expectedNumItems,
                      long&nbsp;numBits)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>col</code> - the column over which the filter is built</dd><dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd><dd><code>numBits</code> - expected number of bits of the filter.</dd>
<dt><span class="strong">Returns:</span></dt><dd>(undocumented)</dd><dt><span class="strong">Since:</span></dt>
  <dd>2.0.0</dd></dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><span class="strong">Prev Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/DataFrameStatFunctions.html" target="_top">Frames</a></li>
<li><a href="DataFrameStatFunctions.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
