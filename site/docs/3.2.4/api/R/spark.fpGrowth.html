<!DOCTYPE html><html><head><title>R: FP-growth</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body><div class="container">

<table style="width: 100%;"><tr><td>spark.fpGrowth {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>FP-growth</h2>

<h3>Description</h3>

<p>A parallel FP-growth algorithm to mine frequent itemsets.
<code>spark.fpGrowth</code> fits a FP-growth model on a SparkDataFrame. Users can
<code>spark.freqItemsets</code> to get frequent itemsets, <code>spark.associationRules</code> to get
association rules, <code>predict</code> to make predictions on new data based on generated association
rules, and <code>write.ml</code>/<code>read.ml</code> to save/load fitted models.
For more details, see
<a href="https://spark.apache.org/docs/latest/mllib-frequent-pattern-mining.html#fp-growth">
FP-growth</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spark.fpGrowth(data, ...)

spark.freqItemsets(object)

spark.associationRules(object)

## S4 method for signature 'SparkDataFrame'
spark.fpGrowth(
  data,
  minSupport = 0.3,
  minConfidence = 0.8,
  itemsCol = "items",
  numPartitions = NULL
)

## S4 method for signature 'FPGrowthModel'
spark.freqItemsets(object)

## S4 method for signature 'FPGrowthModel'
spark.associationRules(object)

## S4 method for signature 'FPGrowthModel'
predict(object, newData)

## S4 method for signature 'FPGrowthModel,character'
write.ml(object, path, overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;"><td><code>data</code></td>
<td>
<p>A SparkDataFrame for training.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>...</code></td>
<td>
<p>additional argument(s) passed to the method.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>object</code></td>
<td>
<p>a fitted FPGrowth model.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>minSupport</code></td>
<td>
<p>Minimal support level.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>minConfidence</code></td>
<td>
<p>Minimal confidence level.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>itemsCol</code></td>
<td>
<p>Features column name.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>numPartitions</code></td>
<td>
<p>Number of partitions used for fitting.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>newData</code></td>
<td>
<p>a SparkDataFrame for testing.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>path</code></td>
<td>
<p>the directory where the model is saved.</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>overwrite</code></td>
<td>
<p>logical value indicating whether to overwrite if the output path
already exists. Default is FALSE which means throw exception
if the output path exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>spark.fpGrowth</code> returns a fitted FPGrowth model.
</p>
<p>A <code>SparkDataFrame</code> with frequent itemsets.
The <code>SparkDataFrame</code> contains two columns:
<code>items</code> (an array of the same type as the input column)
and <code>freq</code> (frequency of the itemset).
</p>
<p>A <code>SparkDataFrame</code> with association rules.
The <code>SparkDataFrame</code> contains five columns:
<code>antecedent</code> (an array of the same type as the input column),
<code>consequent</code> (an array of the same type as the input column),
<code>confidence</code> (confidence for the rule)
<code>lift</code> (lift for the rule)
and <code>support</code> (support for the rule)
</p>
<p><code>predict</code> returns a SparkDataFrame containing predicted values.
</p>


<h3>Note</h3>

<p>spark.fpGrowth since 2.2.0
</p>
<p>spark.freqItemsets(FPGrowthModel) since 2.2.0
</p>
<p>spark.associationRules(FPGrowthModel) since 2.2.0
</p>
<p>predict(FPGrowthModel) since 2.2.0
</p>
<p>write.ml(FPGrowthModel, character) since 2.2.0
</p>


<h3>See Also</h3>

<p><a href="../../SparkR/help/read.ml.html">read.ml</a>
</p>


<h3>Examples</h3>

<pre><code class="r">

## Not run: 
##D raw_data <- read.df(
##D   "data/mllib/sample_fpgrowth.txt",
##D   source = "csv",
##D   schema = structType(structField("raw_items", "string")))
##D 
##D data <- selectExpr(raw_data, "split(raw_items, ' ') as items")
##D model <- spark.fpGrowth(data)
##D 
##D # Show frequent itemsets
##D frequent_itemsets <- spark.freqItemsets(model)
##D showDF(frequent_itemsets)
##D 
##D # Show association rules
##D association_rules <- spark.associationRules(model)
##D showDF(association_rules)
##D 
##D # Predict on new data
##D new_itemsets <- data.frame(items = c("t", "t,s"))
##D new_data <- selectExpr(createDataFrame(new_itemsets), "split(items, ',') as items")
##D predict(model, new_data)
##D 
##D # Save and load model
##D path <- "/path/to/model"
##D write.ml(model, path)
##D read.ml(path)
##D 
##D # Optional arguments
##D baskets_data <- selectExpr(createDataFrame(itemsets), "split(items, ',') as baskets")
##D another_model <- spark.fpGrowth(data, minSupport = 0.1, minConfidence = 0.5,
##D                                 itemsCol = "baskets", numPartitions = 10)
## End(Not run)



</code></pre>

<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 3.2.4 <a href="00Index.html">Index</a>]</div>
</div>
</body></html>
