<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_362) on Sun Apr 09 21:41:43 UTC 2023 -->
<title>DataFrameReader (Spark 3.2.4 JavaDoc)</title>
<meta name="date" content="2023-04-09">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
    <!-- Matomo -->
    <script type="text/javascript">
        var _paq = window._paq = window._paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(["disableCookies"]);
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
            var u="https://analytics.apache.org/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '40']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
        })();
    </script>
    <!-- End Matomo Code -->
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="DataFrameReader (Spark 3.2.4 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":42,"i10":42,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10,"i32":10,"i33":10,"i34":10,"i35":10,"i36":10,"i37":10,"i38":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"],32:["t6","Deprecated Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/DataFrameReader.html" target="_top">Frames</a></li>
<li><a href="DataFrameReader.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class DataFrameReader" class="title">Class DataFrameReader</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.DataFrameReader</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>org.apache.spark.internal.Logging</dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">DataFrameReader</span>
extends Object
implements org.apache.spark.internal.Logging</pre>
<div class="block">Interface used to load a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from external storage systems (e.g. file systems,
 key-value stores, etc). Use <code>SparkSession.read</code> to access this.
 <p></div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t6" class="tableTab"><span><a href="javascript:show(32);">Deprecated Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#csv-org.apache.spark.sql.Dataset-">csv</a></span>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;csvDataset)</code>
<div class="block">Loads an <code>Dataset[String]</code> storing CSV rows and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#csv-scala.collection.Seq-">csv</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads CSV files and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#csv-java.lang.String...-">csv</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads CSV files and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#csv-java.lang.String-">csv</a></span>(String&nbsp;path)</code>
<div class="block">Loads a CSV file and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#format-java.lang.String-">format</a></span>(String&nbsp;source)</code>
<div class="block">Specifies the input data source format.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#jdbc-java.lang.String-java.lang.String-java.util.Properties-">jdbc</a></span>(String&nbsp;url,
    String&nbsp;table,
    java.util.Properties&nbsp;properties)</code>
<div class="block">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
 url named table and connection properties.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#jdbc-java.lang.String-java.lang.String-java.lang.String:A-java.util.Properties-">jdbc</a></span>(String&nbsp;url,
    String&nbsp;table,
    String[]&nbsp;predicates,
    java.util.Properties&nbsp;connectionProperties)</code>
<div class="block">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
 url named table using connection properties.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#jdbc-java.lang.String-java.lang.String-java.lang.String-long-long-int-java.util.Properties-">jdbc</a></span>(String&nbsp;url,
    String&nbsp;table,
    String&nbsp;columnName,
    long&nbsp;lowerBound,
    long&nbsp;upperBound,
    int&nbsp;numPartitions,
    java.util.Properties&nbsp;connectionProperties)</code>
<div class="block">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
 url named table.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#json-org.apache.spark.sql.Dataset-">json</a></span>(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;jsonDataset)</code>
<div class="block">Loads a <code>Dataset[String]</code> storing JSON objects (<a href="http://jsonlines.org/">JSON Lines
 text format or newline-delimited JSON</a>) and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#json-org.apache.spark.api.java.JavaRDD-">json</a></span>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;String&gt;&nbsp;jsonRDD)</code>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;
<div class="block"><span class="deprecationComment">Use json(Dataset[String]) instead. Since 2.2.0.</span></div>
</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#json-org.apache.spark.rdd.RDD-">json</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;jsonRDD)</code>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;
<div class="block"><span class="deprecationComment">Use json(Dataset[String]) instead. Since 2.2.0.</span></div>
</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#json-scala.collection.Seq-">json</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads JSON files and returns the results as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#json-java.lang.String...-">json</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads JSON files and returns the results as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#json-java.lang.String-">json</a></span>(String&nbsp;path)</code>
<div class="block">Loads a JSON file and returns the results as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#load--">load</a></span>()</code>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that don't require a path (e.g.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#load-scala.collection.Seq-">load</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that support multiple paths.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#load-java.lang.String...-">load</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that support multiple paths.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#load-java.lang.String-">load</a></span>(String&nbsp;path)</code>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that require a path (e.g.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-boolean-">option</a></span>(String&nbsp;key,
      boolean&nbsp;value)</code>
<div class="block">Adds an input option for the underlying data source.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-double-">option</a></span>(String&nbsp;key,
      double&nbsp;value)</code>
<div class="block">Adds an input option for the underlying data source.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-long-">option</a></span>(String&nbsp;key,
      long&nbsp;value)</code>
<div class="block">Adds an input option for the underlying data source.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#option-java.lang.String-java.lang.String-">option</a></span>(String&nbsp;key,
      String&nbsp;value)</code>
<div class="block">Adds an input option for the underlying data source.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#options-scala.collection.Map-">options</a></span>(scala.collection.Map&lt;String,String&gt;&nbsp;options)</code>
<div class="block">(Scala-specific) Adds input options for the underlying data source.</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#options-java.util.Map-">options</a></span>(java.util.Map&lt;String,String&gt;&nbsp;options)</code>
<div class="block">Adds input options for the underlying data source.</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#orc-scala.collection.Seq-">orc</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads ORC files and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#orc-java.lang.String...-">orc</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads ORC files and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#orc-java.lang.String-">orc</a></span>(String&nbsp;path)</code>
<div class="block">Loads an ORC file and returns the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#parquet-scala.collection.Seq-">parquet</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads a Parquet file, returning the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#parquet-java.lang.String...-">parquet</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads a Parquet file, returning the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#parquet-java.lang.String-">parquet</a></span>(String&nbsp;path)</code>
<div class="block">Loads a Parquet file, returning the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#schema-java.lang.String-">schema</a></span>(String&nbsp;schemaString)</code>
<div class="block">Specifies the schema by using the input DDL-formatted string.</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#schema-org.apache.spark.sql.types.StructType-">schema</a></span>(<a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">Specifies the input schema.</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#table-java.lang.String-">table</a></span>(String&nbsp;tableName)</code>
<div class="block">Returns the specified table/view as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#text-scala.collection.Seq-">text</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
 "value", and followed by partitioned columns if there are any.</div>
</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#text-java.lang.String...-">text</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
 "value", and followed by partitioned columns if there are any.</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#text-java.lang.String-">text</a></span>(String&nbsp;path)</code>
<div class="block">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
 "value", and followed by partitioned columns if there are any.</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#textFile-scala.collection.Seq-">textFile</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;paths)</code>
<div class="block">Loads text files and returns a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> of String.</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#textFile-java.lang.String...-">textFile</a></span>(String...&nbsp;paths)</code>
<div class="block">Loads text files and returns a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> of String.</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameReader.html#textFile-java.lang.String-">textFile</a></span>(String&nbsp;path)</code>
<div class="block">Loads text files and returns a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> of String.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.internal.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.internal.Logging</h3>
<code>$init$, initializeForcefully, initializeLogIfNecessary, initializeLogIfNecessary, initializeLogIfNecessary$default$2, initLock, isTraceEnabled, log, logDebug, logDebug, logError, logError, logInfo, logInfo, logName, logTrace, logTrace, logWarning, logWarning, org$apache$spark$internal$Logging$$log__$eq, org$apache$spark$internal$Logging$$log_, uninitialize</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="csv-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>csv</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;csv(String...&nbsp;paths)</pre>
<div class="block">Loads CSV files and returns the result as a <code>DataFrame</code>.
 <p>
 This function will go through the input once to determine the input schema if <code>inferSchema</code>
 is enabled. To avoid going through the entire data once, disable <code>inferSchema</code> option or
 specify the schema explicitly using <code>schema</code>.
 <p>
 You can find the CSV-specific options for reading CSV files in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="csv-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>csv</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;csv(String&nbsp;path)</pre>
<div class="block">Loads a CSV file and returns the result as a <code>DataFrame</code>. See the documentation on the
 other overloaded <code>csv()</code> method for more details.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="csv-org.apache.spark.sql.Dataset-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>csv</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;csv(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;csvDataset)</pre>
<div class="block">Loads an <code>Dataset[String]</code> storing CSV rows and returns the result as a <code>DataFrame</code>.
 <p>
 If the schema is not specified using <code>schema</code> function and <code>inferSchema</code> option is enabled,
 this function goes through the input once to determine the input schema.
 <p>
 If the schema is not specified using <code>schema</code> function and <code>inferSchema</code> option is disabled,
 it determines the columns as string types and it reads only the first line to determine the
 names and the number of fields.
 <p>
 If the enforceSchema is set to <code>false</code>, only the CSV header in the first line is checked
 to conform specified or inferred schema.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>csvDataset</code> - input Dataset with one CSV row per record</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.2.0</dd>
<dt><span class="simpleTagLabel">Note:</span></dt>
<dd>if <code>header</code> option is set to <code>true</code> when calling this API, all lines same with
 the header will be removed if exists.
 <p></dd>
</dl>
</li>
</ul>
<a name="csv-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>csv</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;csv(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads CSV files and returns the result as a <code>DataFrame</code>.
 <p>
 This function will go through the input once to determine the input schema if <code>inferSchema</code>
 is enabled. To avoid going through the entire data once, disable <code>inferSchema</code> option or
 specify the schema explicitly using <code>schema</code>.
 <p>
 You can find the CSV-specific options for reading CSV files in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="format-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>format</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;format(String&nbsp;source)</pre>
<div class="block">Specifies the input data source format.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>source</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="jdbc-java.lang.String-java.lang.String-java.util.Properties-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jdbc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;jdbc(String&nbsp;url,
                         String&nbsp;table,
                         java.util.Properties&nbsp;properties)</pre>
<div class="block">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
 url named table and connection properties.
 <p>
 You can find the JDBC-specific option and parameter documentation for reading tables
 via JDBC in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>url</code> - (undocumented)</dd>
<dd><code>table</code> - (undocumented)</dd>
<dd><code>properties</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="jdbc-java.lang.String-java.lang.String-java.lang.String-long-long-int-java.util.Properties-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jdbc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;jdbc(String&nbsp;url,
                         String&nbsp;table,
                         String&nbsp;columnName,
                         long&nbsp;lowerBound,
                         long&nbsp;upperBound,
                         int&nbsp;numPartitions,
                         java.util.Properties&nbsp;connectionProperties)</pre>
<div class="block">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
 url named table. Partitions of the table will be retrieved in parallel based on the parameters
 passed to this function.
 <p>
 Don't create too many partitions in parallel on a large cluster; otherwise Spark might crash
 your external database systems.
 <p>
 You can find the JDBC-specific option and parameter documentation for reading tables via JDBC in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>table</code> - Name of the table in the external database.</dd>
<dd><code>columnName</code> - Alias of <code>partitionColumn</code> option. Refer to <code>partitionColumn</code> in
                   <a href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option">
                     Data Source Option</a> in the version you use.</dd>
<dd><code>connectionProperties</code> - JDBC database connection arguments, a list of arbitrary string
                             tag/value. Normally at least a "user" and "password" property
                             should be included. "fetchsize" can be used to control the
                             number of rows per fetch and "queryTimeout" can be used to wait
                             for a Statement object to execute to the given number of seconds.</dd>
<dd><code>url</code> - (undocumented)</dd>
<dd><code>lowerBound</code> - (undocumented)</dd>
<dd><code>upperBound</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="jdbc-java.lang.String-java.lang.String-java.lang.String:A-java.util.Properties-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>jdbc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;jdbc(String&nbsp;url,
                         String&nbsp;table,
                         String[]&nbsp;predicates,
                         java.util.Properties&nbsp;connectionProperties)</pre>
<div class="block">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL
 url named table using connection properties. The <code>predicates</code> parameter gives a list
 expressions suitable for inclusion in WHERE clauses; each one defines one partition
 of the <code>DataFrame</code>.
 <p>
 Don't create too many partitions in parallel on a large cluster; otherwise Spark might crash
 your external database systems.
 <p>
 You can find the JDBC-specific option and parameter documentation for reading tables
 via JDBC in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>table</code> - Name of the table in the external database.</dd>
<dd><code>predicates</code> - Condition in the where clause for each partition.</dd>
<dd><code>connectionProperties</code> - JDBC database connection arguments, a list of arbitrary string
                             tag/value. Normally at least a "user" and "password" property
                             should be included. "fetchsize" can be used to control the
                             number of rows per fetch.</dd>
<dd><code>url</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="json-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>json</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;json(String...&nbsp;paths)</pre>
<div class="block">Loads JSON files and returns the results as a <code>DataFrame</code>.
 <p>
 <a href="http://jsonlines.org/">JSON Lines</a> (newline-delimited JSON) is supported by
 default. For JSON (one record per file), set the <code>multiLine</code> option to true.
 <p>
 This function goes through the input once to determine the input schema. If you know the
 schema in advance, use the version that specifies the schema to avoid the extra scan.
 <p>
 You can find the JSON-specific options for reading JSON files in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="json-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>json</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;json(String&nbsp;path)</pre>
<div class="block">Loads a JSON file and returns the results as a <code>DataFrame</code>.
 <p>
 See the documentation on the overloaded <code>json()</code> method with varargs for more details.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="json-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>json</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;json(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads JSON files and returns the results as a <code>DataFrame</code>.
 <p>
 <a href="http://jsonlines.org/">JSON Lines</a> (newline-delimited JSON) is supported by
 default. For JSON (one record per file), set the <code>multiLine</code> option to true.
 <p>
 This function goes through the input once to determine the input schema. If you know the
 schema in advance, use the version that specifies the schema to avoid the extra scan.
 <p>
 You can find the JSON-specific options for reading JSON files in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="json-org.apache.spark.api.java.JavaRDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>json</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;json(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;String&gt;&nbsp;jsonRDD)</pre>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;<span class="deprecationComment">Use json(Dataset[String]) instead. Since 2.2.0.</span></div>
<div class="block">Loads a <code>JavaRDD[String]</code> storing JSON objects (<a href="http://jsonlines.org/">JSON
 Lines text format or newline-delimited JSON</a>) and returns the result as
 a <code>DataFrame</code>.
 <p>
 Unless the schema is specified using <code>schema</code> function, this function goes through the
 input once to determine the input schema.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>jsonRDD</code> - input RDD with one JSON object per record</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="json-org.apache.spark.rdd.RDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>json</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;json(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;jsonRDD)</pre>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;<span class="deprecationComment">Use json(Dataset[String]) instead. Since 2.2.0.</span></div>
<div class="block">Loads an <code>RDD[String]</code> storing JSON objects (<a href="http://jsonlines.org/">JSON Lines
 text format or newline-delimited JSON</a>) and returns the result as a <code>DataFrame</code>.
 <p>
 Unless the schema is specified using <code>schema</code> function, this function goes through the
 input once to determine the input schema.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>jsonRDD</code> - input RDD with one JSON object per record</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="json-org.apache.spark.sql.Dataset-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>json</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;json(<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;jsonDataset)</pre>
<div class="block">Loads a <code>Dataset[String]</code> storing JSON objects (<a href="http://jsonlines.org/">JSON Lines
 text format or newline-delimited JSON</a>) and returns the result as a <code>DataFrame</code>.
 <p>
 Unless the schema is specified using <code>schema</code> function, this function goes through the
 input once to determine the input schema.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>jsonDataset</code> - input Dataset with one JSON object per record</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.2.0</dd>
</dl>
</li>
</ul>
<a name="load-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;load(String...&nbsp;paths)</pre>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that support multiple paths.
 Only works if the source is a HadoopFsRelationProvider.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="load--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;load()</pre>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that don't require a path (e.g. external
 key-value stores).
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="load-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;load(String&nbsp;path)</pre>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that require a path (e.g. data backed by
 a local or distributed file system).
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="load-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;load(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads input in as a <code>DataFrame</code>, for data sources that support multiple paths.
 Only works if the source is a HadoopFsRelationProvider.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;option(String&nbsp;key,
                              String&nbsp;value)</pre>
<div class="block">Adds an input option for the underlying data source.
 <p>
 All options are maintained in a case-insensitive way in terms of key names.
 If a new option has the same key case-insensitively, it will override the existing option.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;option(String&nbsp;key,
                              boolean&nbsp;value)</pre>
<div class="block">Adds an input option for the underlying data source.
 <p>
 All options are maintained in a case-insensitive way in terms of key names.
 If a new option has the same key case-insensitively, it will override the existing option.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;option(String&nbsp;key,
                              long&nbsp;value)</pre>
<div class="block">Adds an input option for the underlying data source.
 <p>
 All options are maintained in a case-insensitive way in terms of key names.
 If a new option has the same key case-insensitively, it will override the existing option.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;option(String&nbsp;key,
                              double&nbsp;value)</pre>
<div class="block">Adds an input option for the underlying data source.
 <p>
 All options are maintained in a case-insensitive way in terms of key names.
 If a new option has the same key case-insensitively, it will override the existing option.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="options-scala.collection.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>options</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;options(scala.collection.Map&lt;String,String&gt;&nbsp;options)</pre>
<div class="block">(Scala-specific) Adds input options for the underlying data source.
 <p>
 All options are maintained in a case-insensitive way in terms of key names.
 If a new option has the same key case-insensitively, it will override the existing option.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>options</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="options-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>options</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;options(java.util.Map&lt;String,String&gt;&nbsp;options)</pre>
<div class="block">Adds input options for the underlying data source.
 <p>
 All options are maintained in a case-insensitive way in terms of key names.
 If a new option has the same key case-insensitively, it will override the existing option.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>options</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="orc-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>orc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;orc(String...&nbsp;paths)</pre>
<div class="block">Loads ORC files and returns the result as a <code>DataFrame</code>.
 <p>
 ORC-specific option(s) for reading ORC files can be found in
 <a href=
   "https://spark.apache.org/docs/latest/sql-data-sources-orc.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - input paths</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="orc-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>orc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;orc(String&nbsp;path)</pre>
<div class="block">Loads an ORC file and returns the result as a <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - input path</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.5.0</dd>
</dl>
</li>
</ul>
<a name="orc-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>orc</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;orc(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads ORC files and returns the result as a <code>DataFrame</code>.
 <p>
 ORC-specific option(s) for reading ORC files can be found in
 <a href=
   "https://spark.apache.org/docs/latest/sql-data-sources-orc.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - input paths</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="parquet-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquet</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;parquet(String...&nbsp;paths)</pre>
<div class="block">Loads a Parquet file, returning the result as a <code>DataFrame</code>.
 <p>
 Parquet-specific option(s) for reading Parquet files can be found in
 <a href=
   "https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="parquet-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquet</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;parquet(String&nbsp;path)</pre>
<div class="block">Loads a Parquet file, returning the result as a <code>DataFrame</code>. See the documentation
 on the other overloaded <code>parquet()</code> method for more details.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="parquet-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>parquet</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;parquet(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads a Parquet file, returning the result as a <code>DataFrame</code>.
 <p>
 Parquet-specific option(s) for reading Parquet files can be found in
 <a href=
   "https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="schema-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>schema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;schema(<a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">Specifies the input schema. Some data sources (e.g. JSON) can infer the input schema
 automatically from data. By specifying the schema here, the underlying data source can
 skip the schema inference step, and thus speed up data loading.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>schema</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="schema-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>schema</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;schema(String&nbsp;schemaString)</pre>
<div class="block">Specifies the schema by using the input DDL-formatted string. Some data sources (e.g. JSON) can
 infer the input schema automatically from data. By specifying the schema here, the underlying
 data source can skip the schema inference step, and thus speed up data loading.
 <p>
 <pre><code>
   spark.read.schema("a INT, b STRING, c DOUBLE").csv("test.csv")
 </code></pre>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>schemaString</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.3.0</dd>
</dl>
</li>
</ul>
<a name="table-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;table(String&nbsp;tableName)</pre>
<div class="block">Returns the specified table/view as a <code>DataFrame</code>. If it's a table, it must support batch
 reading and the returned DataFrame is the batch scan query plan of this table. If it's a view,
 the returned DataFrame is simply the query plan of the view, which can either be a batch or
 streaming query plan.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>tableName</code> - is either a qualified or unqualified name that designates a table or view.
                  If a database is specified, it identifies the table/view from the database.
                  Otherwise, it first attempts to find a temporary view with the given name
                  and then match the table/view from the current database.
                  Note that, the global temporary view database is also valid here.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="text-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>text</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;text(String...&nbsp;paths)</pre>
<div class="block">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
 "value", and followed by partitioned columns if there are any.
 The text files must be encoded as UTF-8.
 <p>
 By default, each line in the text files is a new row in the resulting DataFrame. For example:
 <pre><code>
   // Scala:
   spark.read.text("/path/to/spark/README.md")

   // Java:
   spark.read().text("/path/to/spark/README.md")
 </code></pre>
 <p>
 You can find the text-specific options for reading text files in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-text.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - input paths</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="text-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>text</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;text(String&nbsp;path)</pre>
<div class="block">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
 "value", and followed by partitioned columns if there are any. See the documentation on
 the other overloaded <code>text()</code> method for more details.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="text-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>text</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;text(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
 "value", and followed by partitioned columns if there are any.
 The text files must be encoded as UTF-8.
 <p>
 By default, each line in the text files is a new row in the resulting DataFrame. For example:
 <pre><code>
   // Scala:
   spark.read.text("/path/to/spark/README.md")

   // Java:
   spark.read().text("/path/to/spark/README.md")
 </code></pre>
 <p>
 You can find the text-specific options for reading text files in
 <a href="https://spark.apache.org/docs/latest/sql-data-sources-text.html#data-source-option">
   Data Source Option</a> in the version you use.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - input paths</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="textFile-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>textFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;textFile(String...&nbsp;paths)</pre>
<div class="block">Loads text files and returns a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> of String. The underlying schema of the Dataset
 contains a single string column named "value".
 The text files must be encoded as UTF-8.
 <p>
 If the directory structure of the text files contains partitioning information, those are
 ignored in the resulting Dataset. To include partitioning information as columns, use <code>text</code>.
 <p>
 By default, each line in the text files is a new row in the resulting DataFrame. For example:
 <pre><code>
   // Scala:
   spark.read.textFile("/path/to/spark/README.md")

   // Java:
   spark.read().textFile("/path/to/spark/README.md")
 </code></pre>
 <p>
 You can set the text-specific options as specified in <code>DataFrameReader.text</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - input path</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="textFile-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>textFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;textFile(String&nbsp;path)</pre>
<div class="block">Loads text files and returns a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> of String. See the documentation on the
 other overloaded <code>textFile()</code> method for more details.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="textFile-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>textFile</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;String&gt;&nbsp;textFile(scala.collection.Seq&lt;String&gt;&nbsp;paths)</pre>
<div class="block">Loads text files and returns a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> of String. The underlying schema of the Dataset
 contains a single string column named "value".
 The text files must be encoded as UTF-8.
 <p>
 If the directory structure of the text files contains partitioning information, those are
 ignored in the resulting Dataset. To include partitioning information as columns, use <code>text</code>.
 <p>
 By default, each line in the text files is a new row in the resulting DataFrame. For example:
 <pre><code>
   // Scala:
   spark.read.textFile("/path/to/spark/README.md")

   // Java:
   spark.read().textFile("/path/to/spark/README.md")
 </code></pre>
 <p>
 You can set the text-specific options as specified in <code>DataFrameReader.text</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>paths</code> - input path</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameNaFunctions.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/DataFrameReader.html" target="_top">Frames</a></li>
<li><a href="DataFrameReader.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
