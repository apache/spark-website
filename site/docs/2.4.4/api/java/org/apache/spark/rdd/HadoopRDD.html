<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_222) on Tue Aug 27 22:14:25 UTC 2019 -->
<title>HadoopRDD (Spark 2.4.4 JavaDoc)</title>
<meta name="date" content="2019-08-27">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="HadoopRDD (Spark 2.4.4 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":9,"i1":9,"i2":9,"i3":9,"i4":9,"i5":9,"i6":10,"i7":9,"i8":9,"i9":9,"i10":9,"i11":9,"i12":9,"i13":10,"i14":9,"i15":9,"i16":9,"i17":9,"i18":9,"i19":9,"i20":9,"i21":9,"i22":9,"i23":9,"i24":9,"i25":9,"i26":9,"i27":9,"i28":9,"i29":9,"i30":9,"i31":9,"i32":9,"i33":9,"i34":9,"i35":9,"i36":9,"i37":9,"i38":9,"i39":10,"i40":9,"i41":10,"i42":10,"i43":9,"i44":9,"i45":9,"i46":9,"i47":9,"i48":9,"i49":9,"i50":9,"i51":9,"i52":9,"i53":9,"i54":9,"i55":9,"i56":9,"i57":9,"i58":9,"i59":9,"i60":9,"i61":9,"i62":9,"i63":9,"i64":9,"i65":9,"i66":9,"i67":10,"i68":9,"i69":9,"i70":9,"i71":9,"i72":9,"i73":9,"i74":10,"i75":9,"i76":9,"i77":9,"i78":9,"i79":9,"i80":9,"i81":9,"i82":9,"i83":9,"i84":9,"i85":9,"i86":9,"i87":9,"i88":9,"i89":9,"i90":9,"i91":9,"i92":9,"i93":9,"i94":9,"i95":9,"i96":9,"i97":9,"i98":9,"i99":9,"i100":9,"i101":9,"i102":9,"i103":9,"i104":9,"i105":9,"i106":9,"i107":9,"i108":9,"i109":9,"i110":9,"i111":9,"i112":9,"i113":9,"i114":9,"i115":9,"i116":9,"i117":9,"i118":9,"i119":9,"i120":9,"i121":9,"i122":9,"i123":9,"i124":9,"i125":9,"i126":9,"i127":9,"i128":9,"i129":9};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/HadoopRDD.HadoopMapPartitionsWithSplitRDD$.html" title="class in org.apache.spark.rdd"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/HadoopRDD.html" target="_top">Frames</a></li>
<li><a href="HadoopRDD.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.rdd</div>
<h2 title="Class HadoopRDD" class="title">Class HadoopRDD&lt;K,V&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">org.apache.spark.rdd.RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.rdd.HadoopRDD&lt;K,V&gt;</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">HadoopRDD&lt;K,V&gt;</span>
extends <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,V&gt;&gt;
implements <a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></pre>
<div class="block">:: DeveloperApi ::
 An RDD that provides core functionality for reading data stored in Hadoop (e.g., files in HDFS,
 sources in HBase, or S3), using the older MapReduce API (<code>org.apache.hadoop.mapred</code>).
 <p>
 param:  sc The SparkContext to associate the RDD with.
 param:  broadcastedConf A general Hadoop Configuration, or a subclass of it. If the enclosed
   variable references an instance of JobConf, then that JobConf will be used for the Hadoop job.
   Otherwise, a new JobConf will be created on each slave using the enclosed Configuration.
 param:  initLocalJobConfFuncOpt Optional closure used to initialize any JobConf that HadoopRDD
     creates.
 param:  inputFormatClass Storage format of the data to be read.
 param:  keyClass Class of the key associated with the inputFormatClass.
 param:  valueClass Class of the value associated with the inputFormatClass.
 param:  minPartitions Minimum number of HadoopRDD partitions (Hadoop Splits) to generate.
 <p></div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../serialized-form.html#org.apache.spark.rdd.HadoopRDD">Serialized Form</a></dd>
<dt><span class="simpleTagLabel">Note:</span></dt>
<dd>Instantiating this class directly is not recommended, please use
 <code>org.apache.spark.SparkContext.hadoopRDD()</code></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.HadoopMapPartitionsWithSplitRDD$.html" title="class in org.apache.spark.rdd">HadoopRDD.HadoopMapPartitionsWithSplitRDD$</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#HadoopRDD-org.apache.spark.SparkContext-org.apache.spark.broadcast.Broadcast-scala.Option-java.lang.Class-java.lang.Class-java.lang.Class-int-">HadoopRDD</a></span>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
         <a href="../../../../org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a>&lt;org.apache.spark.util.SerializableConfiguration&gt;&nbsp;broadcastedConf,
         scala.Option&lt;scala.Function1&lt;org.apache.hadoop.mapred.JobConf,scala.runtime.BoxedUnit&gt;&gt;&nbsp;initLocalJobConfFuncOpt,
         Class&lt;? extends org.apache.hadoop.mapred.InputFormat&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;&nbsp;inputFormatClass,
         Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>&gt;&nbsp;keyClass,
         Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&nbsp;valueClass,
         int&nbsp;minPartitions)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#HadoopRDD-org.apache.spark.SparkContext-org.apache.hadoop.mapred.JobConf-java.lang.Class-java.lang.Class-java.lang.Class-int-">HadoopRDD</a></span>(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
         org.apache.hadoop.mapred.JobConf&nbsp;conf,
         Class&lt;? extends org.apache.hadoop.mapred.InputFormat&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;&nbsp;inputFormatClass,
         Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>&gt;&nbsp;keyClass,
         Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&nbsp;valueClass,
         int&nbsp;minPartitions)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#Z:Z:Dplus:Dplus-org.apache.spark.rdd.RDD-">$plus$plus</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</code>&nbsp;</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#addLocalConfiguration-java.lang.String-int-int-int-org.apache.hadoop.mapred.JobConf-">addLocalConfiguration</a></span>(String&nbsp;jobTrackerId,
                     int&nbsp;jobId,
                     int&nbsp;splitId,
                     int&nbsp;attemptId,
                     org.apache.hadoop.mapred.JobConf&nbsp;conf)</code>
<div class="block">Add Hadoop configuration specific to a single partition and attempt.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;U</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#aggregate-U-scala.Function2-scala.Function2-scala.reflect.ClassTag-">aggregate</a></span>(U&nbsp;zeroValue,
         scala.Function2&lt;U,T,U&gt;&nbsp;seqOp,
         scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
         scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$30)</code>&nbsp;</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDDBarrier.html" title="class in org.apache.spark.rdd">RDDBarrier</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#barrier--">barrier</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#cache--">cache</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,U&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#cartesian-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">cartesian</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;other,
         scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$5)</code>&nbsp;</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#checkpoint--">checkpoint</a></span>()</code>
<div class="block">Mark this RDD for checkpointing.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#coalesce-int-boolean-scala.Option-scala.math.Ordering-">coalesce</a></span>(int&nbsp;numPartitions,
        boolean&nbsp;shuffle,
        scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PartitionCoalescer.html" title="interface in org.apache.spark.rdd">PartitionCoalescer</a>&gt;&nbsp;partitionCoalescer,
        scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#coalesce:Ddefault:D2--">coalesce$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>static scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PartitionCoalescer.html" title="interface in org.apache.spark.rdd">PartitionCoalescer</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#coalesce:Ddefault:D3--">coalesce$default$3</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#coalesce:Ddefault:D4-int-boolean-scala.Option-">coalesce$default$4</a></span>(int&nbsp;numPartitions,
                  boolean&nbsp;shuffle,
                  scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PartitionCoalescer.html" title="interface in org.apache.spark.rdd">PartitionCoalescer</a>&gt;&nbsp;partitionCoalescer)</code>&nbsp;</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#collect--">collect</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#collect-scala.PartialFunction-scala.reflect.ClassTag-">collect</a></span>(scala.PartialFunction&lt;T,U&gt;&nbsp;f,
       scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$29)</code>&nbsp;</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">compute</a></span>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;theSplit,
       <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</code>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#CONFIGURATION_INSTANTIATION_LOCK--">CONFIGURATION_INSTANTIATION_LOCK</a></span>()</code>
<div class="block">Configuration's constructor is not threadsafe (see SPARK-1097 and HADOOP-10456).</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#context--">context</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#count--">count</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a>&lt;<a href="../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countApprox-long-double-">countApprox</a></span>(long&nbsp;timeout,
           double&nbsp;confidence)</code>&nbsp;</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countApprox:Ddefault:D2--">countApprox$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countApproxDistinct-double-">countApproxDistinct</a></span>(double&nbsp;relativeSD)</code>&nbsp;</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countApproxDistinct-int-int-">countApproxDistinct</a></span>(int&nbsp;p,
                   int&nbsp;sp)</code>&nbsp;</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countApproxDistinct:Ddefault:D1--">countApproxDistinct$default$1</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>static scala.collection.Map&lt;T,Object&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countByValue-scala.math.Ordering-">countByValue</a></span>(scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countByValue:Ddefault:D1--">countByValue$default$1</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a>&lt;scala.collection.Map&lt;T,<a href="../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countByValueApprox-long-double-scala.math.Ordering-">countByValueApprox</a></span>(long&nbsp;timeout,
                  double&nbsp;confidence,
                  scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code>static double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countByValueApprox:Ddefault:D2--">countByValueApprox$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#countByValueApprox:Ddefault:D3-long-double-">countByValueApprox$default$3</a></span>(long&nbsp;timeout,
                            double&nbsp;confidence)</code>&nbsp;</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;<a href="../../../../org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</a>&lt;?&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#dependencies--">dependencies</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#distinct--">distinct</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#distinct-int-scala.math.Ordering-">distinct</a></span>(int&nbsp;numPartitions,
        scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#distinct:Ddefault:D2-int-">distinct$default$2</a></span>(int&nbsp;numPartitions)</code>&nbsp;</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#filter-scala.Function1-">filter</a></span>(scala.Function1&lt;T,Object&gt;&nbsp;f)</code>&nbsp;</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code>static T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#first--">first</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#flatMap-scala.Function1-scala.reflect.ClassTag-">flatMap</a></span>(scala.Function1&lt;T,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;f,
       scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$4)</code>&nbsp;</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code>static T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#fold-T-scala.Function2-">fold</a></span>(T&nbsp;zeroValue,
    scala.Function2&lt;T,T,T&gt;&nbsp;op)</code>&nbsp;</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#foreach-scala.Function1-">foreach</a></span>(scala.Function1&lt;T,scala.runtime.BoxedUnit&gt;&nbsp;f)</code>&nbsp;</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#foreachPartition-scala.Function1-">foreachPartition</a></span>(scala.Function1&lt;scala.collection.Iterator&lt;T&gt;,scala.runtime.BoxedUnit&gt;&nbsp;f)</code>&nbsp;</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getCachedMetadata-java.lang.String-">getCachedMetadata</a></span>(String&nbsp;key)</code>
<div class="block">The three methods below are helpers for accessing the local map, a property of the SparkEnv of
 the local process.</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>static scala.Option&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getCheckpointFile--">getCheckpointFile</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.conf.Configuration</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getConf--">getConf</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getNumPartitions--">getNumPartitions</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getPartitions--">getPartitions</a></span>()</code>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD.</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getPreferredLocations-org.apache.spark.Partition-">getPreferredLocations</a></span>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split)</code>
<div class="block">Optionally overridden by subclasses to specify placement preferences.</div>
</td>
</tr>
<tr id="i43" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#getStorageLevel--">getStorageLevel</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i44" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;Object&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#glom--">glom</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i45" class="rowColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;T&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#groupBy-scala.Function1-scala.reflect.ClassTag-">groupBy</a></span>(scala.Function1&lt;T,K&gt;&nbsp;f,
       scala.reflect.ClassTag&lt;K&gt;&nbsp;kt)</code>&nbsp;</td>
</tr>
<tr id="i46" class="altColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;T&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#groupBy-scala.Function1-int-scala.reflect.ClassTag-">groupBy</a></span>(scala.Function1&lt;T,K&gt;&nbsp;f,
       int&nbsp;numPartitions,
       scala.reflect.ClassTag&lt;K&gt;&nbsp;kt)</code>&nbsp;</td>
</tr>
<tr id="i47" class="rowColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;T&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#groupBy-scala.Function1-org.apache.spark.Partitioner-scala.reflect.ClassTag-scala.math.Ordering-">groupBy</a></span>(scala.Function1&lt;T,K&gt;&nbsp;f,
       <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
       scala.reflect.ClassTag&lt;K&gt;&nbsp;kt,
       scala.math.Ordering&lt;K&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i48" class="altColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;scala.runtime.Null$</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#groupBy:Ddefault:D4-scala.Function1-org.apache.spark.Partitioner-">groupBy$default$4</a></span>(scala.Function1&lt;T,K&gt;&nbsp;f,
                 <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p)</code>&nbsp;</td>
</tr>
<tr id="i49" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#id--">id</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i50" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#intersection-org.apache.spark.rdd.RDD-">intersection</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</code>&nbsp;</td>
</tr>
<tr id="i51" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#intersection-org.apache.spark.rdd.RDD-int-">intersection</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
            int&nbsp;numPartitions)</code>&nbsp;</td>
</tr>
<tr id="i52" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#intersection-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">intersection</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
            <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
            scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i53" class="rowColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#intersection:Ddefault:D3-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-">intersection$default$3</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                      <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>&nbsp;</td>
</tr>
<tr id="i54" class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#isCheckpointed--">isCheckpointed</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i55" class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#isEmpty--">isEmpty</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i56" class="altColor">
<td class="colFirst"><code>static scala.collection.Iterator&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#iterator-org.apache.spark.Partition-org.apache.spark.TaskContext-">iterator</a></span>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split,
        <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</code>&nbsp;</td>
</tr>
<tr id="i57" class="rowColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,T&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#keyBy-scala.Function1-">keyBy</a></span>(scala.Function1&lt;T,K&gt;&nbsp;f)</code>&nbsp;</td>
</tr>
<tr id="i58" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#localCheckpoint--">localCheckpoint</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i59" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#map-scala.Function1-scala.reflect.ClassTag-">map</a></span>(scala.Function1&lt;T,U&gt;&nbsp;f,
   scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$3)</code>&nbsp;</td>
</tr>
<tr id="i60" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitions-scala.Function1-boolean-scala.reflect.ClassTag-">mapPartitions</a></span>(scala.Function1&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
             boolean&nbsp;preservesPartitioning,
             scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$6)</code>&nbsp;</td>
</tr>
<tr id="i61" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitions:Ddefault:D2--">mapPartitions$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i62" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitionsInternal:Ddefault:D2--">mapPartitionsInternal$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i63" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithIndex-scala.Function2-boolean-scala.reflect.ClassTag-">mapPartitionsWithIndex</a></span>(scala.Function2&lt;Object,scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                      boolean&nbsp;preservesPartitioning,
                      scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$9)</code>&nbsp;</td>
</tr>
<tr id="i64" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithIndex:Ddefault:D2--">mapPartitionsWithIndex$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i65" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithIndexInternal:Ddefault:D2--">mapPartitionsWithIndexInternal$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i66" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithIndexInternal:Ddefault:D3--">mapPartitionsWithIndexInternal$default$3</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i67" class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithInputSplit-scala.Function2-boolean-scala.reflect.ClassTag-">mapPartitionsWithInputSplit</a></span>(scala.Function2&lt;org.apache.hadoop.mapred.InputSplit,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                           boolean&nbsp;preservesPartitioning,
                           scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</code>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</td>
</tr>
<tr id="i68" class="altColor">
<td class="colFirst"><code>static T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#max-scala.math.Ordering-">max</a></span>(scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i69" class="rowColor">
<td class="colFirst"><code>static T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#min-scala.math.Ordering-">min</a></span>(scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i70" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#name_:Deq-java.lang.String-">name_$eq</a></span>(String&nbsp;x$1)</code>&nbsp;</td>
</tr>
<tr id="i71" class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#name--">name</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i72" class="altColor">
<td class="colFirst"><code>static scala.Option&lt;<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#partitioner--">partitioner</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i73" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#partitions--">partitions</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i74" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a>&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#persist-org.apache.spark.storage.StorageLevel-">persist</a></span>(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;storageLevel)</code>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</td>
</tr>
<tr id="i75" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe-scala.collection.Seq-scala.collection.Map-scala.Function1-scala.Function2-boolean-int-java.lang.String-">pipe</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;command,
    scala.collection.Map&lt;String,String&gt;&nbsp;env,
    scala.Function1&lt;scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;&nbsp;printPipeContext,
    scala.Function2&lt;T,scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;&nbsp;printRDDElement,
    boolean&nbsp;separateWorkingDir,
    int&nbsp;bufferSize,
    String&nbsp;encoding)</code>&nbsp;</td>
</tr>
<tr id="i76" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe-java.lang.String-">pipe</a></span>(String&nbsp;command)</code>&nbsp;</td>
</tr>
<tr id="i77" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe-java.lang.String-scala.collection.Map-">pipe</a></span>(String&nbsp;command,
    scala.collection.Map&lt;String,String&gt;&nbsp;env)</code>&nbsp;</td>
</tr>
<tr id="i78" class="altColor">
<td class="colFirst"><code>static scala.collection.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe:Ddefault:D2--">pipe$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i79" class="rowColor">
<td class="colFirst"><code>static scala.Function1&lt;scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe:Ddefault:D3--">pipe$default$3</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i80" class="altColor">
<td class="colFirst"><code>static scala.Function2&lt;T,scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe:Ddefault:D4--">pipe$default$4</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i81" class="rowColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe:Ddefault:D5--">pipe$default$5</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i82" class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe:Ddefault:D6--">pipe$default$6</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i83" class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#pipe:Ddefault:D7--">pipe$default$7</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i84" class="altColor">
<td class="colFirst"><code>static scala.collection.Seq&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#preferredLocations-org.apache.spark.Partition-">preferredLocations</a></span>(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split)</code>&nbsp;</td>
</tr>
<tr id="i85" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#randomSplit-double:A-long-">randomSplit</a></span>(double[]&nbsp;weights,
           long&nbsp;seed)</code>&nbsp;</td>
</tr>
<tr id="i86" class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#randomSplit:Ddefault:D2--">randomSplit$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i87" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES--">RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES</a></span>()</code>
<div class="block">Update the input bytes read metric each time this number of records has been read</div>
</td>
</tr>
<tr id="i88" class="altColor">
<td class="colFirst"><code>static T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#reduce-scala.Function2-">reduce</a></span>(scala.Function2&lt;T,T,T&gt;&nbsp;f)</code>&nbsp;</td>
</tr>
<tr id="i89" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#repartition-int-scala.math.Ordering-">repartition</a></span>(int&nbsp;numPartitions,
           scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i90" class="altColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#repartition:Ddefault:D2-int-">repartition$default$2</a></span>(int&nbsp;numPartitions)</code>&nbsp;</td>
</tr>
<tr id="i91" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#sample-boolean-double-long-">sample</a></span>(boolean&nbsp;withReplacement,
      double&nbsp;fraction,
      long&nbsp;seed)</code>&nbsp;</td>
</tr>
<tr id="i92" class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#sample:Ddefault:D3--">sample$default$3</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i93" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#saveAsObjectFile-java.lang.String-">saveAsObjectFile</a></span>(String&nbsp;path)</code>&nbsp;</td>
</tr>
<tr id="i94" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#saveAsTextFile-java.lang.String-">saveAsTextFile</a></span>(String&nbsp;path)</code>&nbsp;</td>
</tr>
<tr id="i95" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#saveAsTextFile-java.lang.String-java.lang.Class-">saveAsTextFile</a></span>(String&nbsp;path,
              Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec)</code>&nbsp;</td>
</tr>
<tr id="i96" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#setName-java.lang.String-">setName</a></span>(String&nbsp;_name)</code>&nbsp;</td>
</tr>
<tr id="i97" class="rowColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#sortBy-scala.Function1-boolean-int-scala.math.Ordering-scala.reflect.ClassTag-">sortBy</a></span>(scala.Function1&lt;T,K&gt;&nbsp;f,
      boolean&nbsp;ascending,
      int&nbsp;numPartitions,
      scala.math.Ordering&lt;K&gt;&nbsp;ord,
      scala.reflect.ClassTag&lt;K&gt;&nbsp;ctag)</code>&nbsp;</td>
</tr>
<tr id="i98" class="altColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#sortBy:Ddefault:D2--">sortBy$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i99" class="rowColor">
<td class="colFirst"><code>static &lt;K&gt;&nbsp;int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#sortBy:Ddefault:D3--">sortBy$default$3</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i100" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#sparkContext--">sparkContext</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i101" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#subtract-org.apache.spark.rdd.RDD-">subtract</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</code>&nbsp;</td>
</tr>
<tr id="i102" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#subtract-org.apache.spark.rdd.RDD-int-">subtract</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
        int&nbsp;numPartitions)</code>&nbsp;</td>
</tr>
<tr id="i103" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#subtract-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">subtract</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
        scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i104" class="altColor">
<td class="colFirst"><code>static scala.math.Ordering&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#subtract:Ddefault:D3-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-">subtract$default$3</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                  <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p)</code>&nbsp;</td>
</tr>
<tr id="i105" class="rowColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#take-int-">take</a></span>(int&nbsp;num)</code>&nbsp;</td>
</tr>
<tr id="i106" class="altColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#takeOrdered-int-scala.math.Ordering-">takeOrdered</a></span>(int&nbsp;num,
           scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i107" class="rowColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#takeSample-boolean-int-long-">takeSample</a></span>(boolean&nbsp;withReplacement,
          int&nbsp;num,
          long&nbsp;seed)</code>&nbsp;</td>
</tr>
<tr id="i108" class="altColor">
<td class="colFirst"><code>static long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#takeSample:Ddefault:D3--">takeSample$default$3</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i109" class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#toDebugString--">toDebugString</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i110" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#toJavaRDD--">toJavaRDD</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i111" class="rowColor">
<td class="colFirst"><code>static scala.collection.Iterator&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#toLocalIterator--">toLocalIterator</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i112" class="altColor">
<td class="colFirst"><code>static Object</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#top-int-scala.math.Ordering-">top</a></span>(int&nbsp;num,
   scala.math.Ordering&lt;T&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
<tr id="i113" class="rowColor">
<td class="colFirst"><code>static String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#toString--">toString</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i114" class="altColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;U</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#treeAggregate-U-scala.Function2-scala.Function2-int-scala.reflect.ClassTag-">treeAggregate</a></span>(U&nbsp;zeroValue,
             scala.Function2&lt;U,T,U&gt;&nbsp;seqOp,
             scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
             int&nbsp;depth,
             scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$31)</code>&nbsp;</td>
</tr>
<tr id="i115" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#treeAggregate:Ddefault:D4-U-">treeAggregate$default$4</a></span>(U&nbsp;zeroValue)</code>&nbsp;</td>
</tr>
<tr id="i116" class="altColor">
<td class="colFirst"><code>static T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#treeReduce-scala.Function2-int-">treeReduce</a></span>(scala.Function2&lt;T,T,T&gt;&nbsp;f,
          int&nbsp;depth)</code>&nbsp;</td>
</tr>
<tr id="i117" class="rowColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#treeReduce:Ddefault:D2--">treeReduce$default$2</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i118" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#union-org.apache.spark.rdd.RDD-">union</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</code>&nbsp;</td>
</tr>
<tr id="i119" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#unpersist-boolean-">unpersist</a></span>(boolean&nbsp;blocking)</code>&nbsp;</td>
</tr>
<tr id="i120" class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#unpersist:Ddefault:D1--">unpersist$default$1</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i121" class="rowColor">
<td class="colFirst"><code>static &lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,U&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zip-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">zip</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;other,
   scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$10)</code>&nbsp;</td>
</tr>
<tr id="i122" class="altColor">
<td class="colFirst"><code>static &lt;B,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipPartitions-org.apache.spark.rdd.RDD-boolean-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
             boolean&nbsp;preservesPartitioning,
             scala.Function2&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$11,
             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$12)</code>&nbsp;</td>
</tr>
<tr id="i123" class="rowColor">
<td class="colFirst"><code>static &lt;B,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipPartitions-org.apache.spark.rdd.RDD-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
             scala.Function2&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$13,
             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$14)</code>&nbsp;</td>
</tr>
<tr id="i124" class="altColor">
<td class="colFirst"><code>static &lt;B,C,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
             boolean&nbsp;preservesPartitioning,
             scala.Function3&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$15,
             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$16,
             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$17)</code>&nbsp;</td>
</tr>
<tr id="i125" class="rowColor">
<td class="colFirst"><code>static &lt;B,C,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
             scala.Function3&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$18,
             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$19,
             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$20)</code>&nbsp;</td>
</tr>
<tr id="i126" class="altColor">
<td class="colFirst"><code>static &lt;B,C,D,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;D&gt;&nbsp;rdd4,
             boolean&nbsp;preservesPartitioning,
             scala.Function4&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;D&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$21,
             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$22,
             scala.reflect.ClassTag&lt;D&gt;&nbsp;evidence$23,
             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$24)</code>&nbsp;</td>
</tr>
<tr id="i127" class="rowColor">
<td class="colFirst"><code>static &lt;B,C,D,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;D&gt;&nbsp;rdd4,
             scala.Function4&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;D&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$25,
             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$26,
             scala.reflect.ClassTag&lt;D&gt;&nbsp;evidence$27,
             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$28)</code>&nbsp;</td>
</tr>
<tr id="i128" class="altColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,Object&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipWithIndex--">zipWithIndex</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i129" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,Object&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/rdd/HadoopRDD.html#zipWithUniqueId--">zipWithUniqueId</a></span>()</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.rdd.RDD">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.rdd.<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></h3>
<code><a href="../../../../org/apache/spark/rdd/RDD.html#aggregate-U-scala.Function2-scala.Function2-scala.reflect.ClassTag-">aggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#barrier--">barrier</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cache--">cache</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#cartesian-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">cartesian</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#coalesce-int-boolean-scala.Option-scala.math.Ordering-">coalesce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect--">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#collect-scala.PartialFunction-scala.reflect.ClassTag-">collect</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#context--">context</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#count--">count</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApprox-long-double-">countApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct-double-">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countApproxDistinct-int-int-">countApproxDistinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValue-scala.math.Ordering-">countByValue</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#countByValueApprox-long-double-scala.math.Ordering-">countByValueApprox</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#dependencies--">dependencies</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#distinct--">distinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#distinct-int-scala.math.Ordering-">distinct</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#doubleRDDToDoubleRDDFunctions-org.apache.spark.rdd.RDD-">doubleRDDToDoubleRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#filter-scala.Function1-">filter</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#first--">first</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#flatMap-scala.Function1-scala.reflect.ClassTag-">flatMap</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#fold-T-scala.Function2-">fold</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreach-scala.Function1-">foreach</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#foreachPartition-scala.Function1-">foreachPartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getCheckpointFile--">getCheckpointFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getNumPartitions--">getNumPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#getStorageLevel--">getStorageLevel</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#glom--">glom</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy-scala.Function1-scala.reflect.ClassTag-">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy-scala.Function1-int-scala.reflect.ClassTag-">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#groupBy-scala.Function1-org.apache.spark.Partitioner-scala.reflect.ClassTag-scala.math.Ordering-">groupBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#id--">id</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection-org.apache.spark.rdd.RDD-">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection-org.apache.spark.rdd.RDD-int-">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#intersection-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">intersection</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isCheckpointed--">isCheckpointed</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#isEmpty--">isEmpty</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#iterator-org.apache.spark.Partition-org.apache.spark.TaskContext-">iterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#keyBy-scala.Function1-">keyBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#localCheckpoint--">localCheckpoint</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#map-scala.Function1-scala.reflect.ClassTag-">map</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitions-scala.Function1-boolean-scala.reflect.ClassTag-">mapPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex-scala.Function2-boolean-scala.reflect.ClassTag-">mapPartitionsWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#max-scala.math.Ordering-">max</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#min-scala.math.Ordering-">min</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#name--">name</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#numericRDDToDoubleRDDFunctions-org.apache.spark.rdd.RDD-scala.math.Numeric-">numericRDDToDoubleRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitioner--">partitioner</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#partitions--">partitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#persist--">persist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe-scala.collection.Seq-scala.collection.Map-scala.Function1-scala.Function2-boolean-int-java.lang.String-">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe-java.lang.String-">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#pipe-java.lang.String-scala.collection.Map-">pipe</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#preferredLocations-org.apache.spark.Partition-">preferredLocations</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#randomSplit-double:A-long-">randomSplit</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToAsyncRDDActions-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">rddToAsyncRDDActions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToOrderedRDDFunctions-org.apache.spark.rdd.RDD-scala.math.Ordering-scala.reflect.ClassTag-scala.reflect.ClassTag-">rddToOrderedRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToPairRDDFunctions-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.math.Ordering-">rddToPairRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#rddToSequenceFileRDDFunctions-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-scala.reflect.ClassTag---">rddToSequenceFileRDDFunctions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#reduce-scala.Function2-">reduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#repartition-int-scala.math.Ordering-">repartition</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sample-boolean-double-long-">sample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsObjectFile-java.lang.String-">saveAsObjectFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile-java.lang.String-">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#saveAsTextFile-java.lang.String-java.lang.Class-">saveAsTextFile</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#setName-java.lang.String-">setName</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sortBy-scala.Function1-boolean-int-scala.math.Ordering-scala.reflect.ClassTag-">sortBy</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#sparkContext--">sparkContext</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract-org.apache.spark.rdd.RDD-">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract-org.apache.spark.rdd.RDD-int-">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#subtract-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">subtract</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#take-int-">take</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeOrdered-int-scala.math.Ordering-">takeOrdered</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#takeSample-boolean-int-long-">takeSample</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toDebugString--">toDebugString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toJavaRDD--">toJavaRDD</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toLocalIterator--">toLocalIterator</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#top-int-scala.math.Ordering-">top</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#toString--">toString</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#treeAggregate-U-scala.Function2-scala.Function2-int-scala.reflect.ClassTag-">treeAggregate</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#treeReduce-scala.Function2-int-">treeReduce</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#union-org.apache.spark.rdd.RDD-">union</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#unpersist-boolean-">unpersist</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zip-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">zip</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-boolean-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">zipPartitions</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithIndex--">zipWithIndex</a>, <a href="../../../../org/apache/spark/rdd/RDD.html#zipWithUniqueId--">zipWithUniqueId</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.internal.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.internal.<a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></h3>
<code><a href="../../../../org/apache/spark/internal/Logging.html#initializeLogging-boolean-boolean-">initializeLogging</a>, <a href="../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-">initializeLogIfNecessary</a>, <a href="../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-boolean-">initializeLogIfNecessary</a>, <a href="../../../../org/apache/spark/internal/Logging.html#isTraceEnabled--">isTraceEnabled</a>, <a href="../../../../org/apache/spark/internal/Logging.html#log_--">log_</a>, <a href="../../../../org/apache/spark/internal/Logging.html#log--">log</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-">logDebug</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-java.lang.Throwable-">logDebug</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-">logError</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-java.lang.Throwable-">logError</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-">logInfo</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-java.lang.Throwable-">logInfo</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logName--">logName</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-">logTrace</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-java.lang.Throwable-">logTrace</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-">logWarning</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-java.lang.Throwable-">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="HadoopRDD-org.apache.spark.SparkContext-org.apache.spark.broadcast.Broadcast-scala.Option-java.lang.Class-java.lang.Class-java.lang.Class-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>HadoopRDD</h4>
<pre>public&nbsp;HadoopRDD(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                 <a href="../../../../org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a>&lt;org.apache.spark.util.SerializableConfiguration&gt;&nbsp;broadcastedConf,
                 scala.Option&lt;scala.Function1&lt;org.apache.hadoop.mapred.JobConf,scala.runtime.BoxedUnit&gt;&gt;&nbsp;initLocalJobConfFuncOpt,
                 Class&lt;? extends org.apache.hadoop.mapred.InputFormat&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;&nbsp;inputFormatClass,
                 Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>&gt;&nbsp;keyClass,
                 Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&nbsp;valueClass,
                 int&nbsp;minPartitions)</pre>
</li>
</ul>
<a name="HadoopRDD-org.apache.spark.SparkContext-org.apache.hadoop.mapred.JobConf-java.lang.Class-java.lang.Class-java.lang.Class-int-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HadoopRDD</h4>
<pre>public&nbsp;HadoopRDD(<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sc,
                 org.apache.hadoop.mapred.JobConf&nbsp;conf,
                 Class&lt;? extends org.apache.hadoop.mapred.InputFormat&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;&nbsp;inputFormatClass,
                 Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>&gt;&nbsp;keyClass,
                 Class&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&nbsp;valueClass,
                 int&nbsp;minPartitions)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="CONFIGURATION_INSTANTIATION_LOCK--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>CONFIGURATION_INSTANTIATION_LOCK</h4>
<pre>public static&nbsp;Object&nbsp;CONFIGURATION_INSTANTIATION_LOCK()</pre>
<div class="block">Configuration's constructor is not threadsafe (see SPARK-1097 and HADOOP-10456).
 Therefore, we synchronize on this lock before calling new JobConf() or new Configuration().</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES</h4>
<pre>public static&nbsp;int&nbsp;RECORDS_BETWEEN_BYTES_READ_METRIC_UPDATES()</pre>
<div class="block">Update the input bytes read metric each time this number of records has been read</div>
</li>
</ul>
<a name="getCachedMetadata-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCachedMetadata</h4>
<pre>public static&nbsp;Object&nbsp;getCachedMetadata(String&nbsp;key)</pre>
<div class="block">The three methods below are helpers for accessing the local map, a property of the SparkEnv of
 the local process.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="addLocalConfiguration-java.lang.String-int-int-int-org.apache.hadoop.mapred.JobConf-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addLocalConfiguration</h4>
<pre>public static&nbsp;void&nbsp;addLocalConfiguration(String&nbsp;jobTrackerId,
                                         int&nbsp;jobId,
                                         int&nbsp;splitId,
                                         int&nbsp;attemptId,
                                         org.apache.hadoop.mapred.JobConf&nbsp;conf)</pre>
<div class="block">Add Hadoop configuration specific to a single partition and attempt.</div>
</li>
</ul>
<a name="partitioner--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitioner</h4>
<pre>public static&nbsp;scala.Option&lt;<a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&gt;&nbsp;partitioner()</pre>
</li>
</ul>
<a name="sparkContext--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="id--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>id</h4>
<pre>public static&nbsp;int&nbsp;id()</pre>
</li>
</ul>
<a name="name--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>name</h4>
<pre>public static&nbsp;String&nbsp;name()</pre>
</li>
</ul>
<a name="name_:Deq-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>name_$eq</h4>
<pre>public static&nbsp;void&nbsp;name_$eq(String&nbsp;x$1)</pre>
</li>
</ul>
<a name="setName-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setName</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;setName(String&nbsp;_name)</pre>
</li>
</ul>
<a name="cache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cache</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;cache()</pre>
</li>
</ul>
<a name="unpersist-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unpersist</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;unpersist(boolean&nbsp;blocking)</pre>
</li>
</ul>
<a name="getStorageLevel--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStorageLevel</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;getStorageLevel()</pre>
</li>
</ul>
<a name="dependencies--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dependencies</h4>
<pre>public static final&nbsp;scala.collection.Seq&lt;<a href="../../../../org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</a>&lt;?&gt;&gt;&nbsp;dependencies()</pre>
</li>
</ul>
<a name="partitions--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitions</h4>
<pre>public static final&nbsp;<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]&nbsp;partitions()</pre>
</li>
</ul>
<a name="getNumPartitions--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getNumPartitions</h4>
<pre>public static final&nbsp;int&nbsp;getNumPartitions()</pre>
</li>
</ul>
<a name="preferredLocations-org.apache.spark.Partition-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preferredLocations</h4>
<pre>public static final&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;preferredLocations(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split)</pre>
</li>
</ul>
<a name="iterator-org.apache.spark.Partition-org.apache.spark.TaskContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>iterator</h4>
<pre>public static final&nbsp;scala.collection.Iterator&lt;T&gt;&nbsp;iterator(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split,
                                                          <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</pre>
</li>
</ul>
<a name="map-scala.Function1-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>map</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;map(scala.Function1&lt;T,U&gt;&nbsp;f,
                             scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$3)</pre>
</li>
</ul>
<a name="flatMap-scala.Function1-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flatMap</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;flatMap(scala.Function1&lt;T,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;f,
                                 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$4)</pre>
</li>
</ul>
<a name="filter-scala.Function1-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>filter</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;filter(scala.Function1&lt;T,Object&gt;&nbsp;f)</pre>
</li>
</ul>
<a name="distinct-int-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>distinct</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;distinct(int&nbsp;numPartitions,
                              scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="distinct--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>distinct</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;distinct()</pre>
</li>
</ul>
<a name="repartition-int-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>repartition</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;repartition(int&nbsp;numPartitions,
                                 scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="coalesce-int-boolean-scala.Option-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>coalesce</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;coalesce(int&nbsp;numPartitions,
                              boolean&nbsp;shuffle,
                              scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PartitionCoalescer.html" title="interface in org.apache.spark.rdd">PartitionCoalescer</a>&gt;&nbsp;partitionCoalescer,
                              scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="sample-boolean-double-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sample</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;sample(boolean&nbsp;withReplacement,
                            double&nbsp;fraction,
                            long&nbsp;seed)</pre>
</li>
</ul>
<a name="randomSplit-double:A-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>randomSplit</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;[]&nbsp;randomSplit(double[]&nbsp;weights,
                                   long&nbsp;seed)</pre>
</li>
</ul>
<a name="takeSample-boolean-int-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>takeSample</h4>
<pre>public static&nbsp;Object&nbsp;takeSample(boolean&nbsp;withReplacement,
                                int&nbsp;num,
                                long&nbsp;seed)</pre>
</li>
</ul>
<a name="union-org.apache.spark.rdd.RDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>union</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;union(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</pre>
</li>
</ul>
<a name="Z:Z:Dplus:Dplus-org.apache.spark.rdd.RDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>$plus$plus</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;$plus$plus(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</pre>
</li>
</ul>
<a name="sortBy-scala.Function1-boolean-int-scala.math.Ordering-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sortBy</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;sortBy(scala.Function1&lt;T,K&gt;&nbsp;f,
                                boolean&nbsp;ascending,
                                int&nbsp;numPartitions,
                                scala.math.Ordering&lt;K&gt;&nbsp;ord,
                                scala.reflect.ClassTag&lt;K&gt;&nbsp;ctag)</pre>
</li>
</ul>
<a name="intersection-org.apache.spark.rdd.RDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;intersection(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</pre>
</li>
</ul>
<a name="intersection-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;intersection(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                                  <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                  scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="intersection-org.apache.spark.rdd.RDD-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;intersection(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                                  int&nbsp;numPartitions)</pre>
</li>
</ul>
<a name="glom--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>glom</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;Object&gt;&nbsp;glom()</pre>
</li>
</ul>
<a name="cartesian-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cartesian</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,U&gt;&gt;&nbsp;cartesian(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;other,
                                                   scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$5)</pre>
</li>
</ul>
<a name="groupBy-scala.Function1-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;T&gt;&gt;&gt;&nbsp;groupBy(scala.Function1&lt;T,K&gt;&nbsp;f,
                                                                            scala.reflect.ClassTag&lt;K&gt;&nbsp;kt)</pre>
</li>
</ul>
<a name="groupBy-scala.Function1-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;T&gt;&gt;&gt;&nbsp;groupBy(scala.Function1&lt;T,K&gt;&nbsp;f,
                                                                            int&nbsp;numPartitions,
                                                                            scala.reflect.ClassTag&lt;K&gt;&nbsp;kt)</pre>
</li>
</ul>
<a name="groupBy-scala.Function1-org.apache.spark.Partitioner-scala.reflect.ClassTag-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,scala.collection.Iterable&lt;T&gt;&gt;&gt;&nbsp;groupBy(scala.Function1&lt;T,K&gt;&nbsp;f,
                                                                            <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
                                                                            scala.reflect.ClassTag&lt;K&gt;&nbsp;kt,
                                                                            scala.math.Ordering&lt;K&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="pipe-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;pipe(String&nbsp;command)</pre>
</li>
</ul>
<a name="pipe-java.lang.String-scala.collection.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;pipe(String&nbsp;command,
                               scala.collection.Map&lt;String,String&gt;&nbsp;env)</pre>
</li>
</ul>
<a name="pipe-scala.collection.Seq-scala.collection.Map-scala.Function1-scala.Function2-boolean-int-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;String&gt;&nbsp;pipe(scala.collection.Seq&lt;String&gt;&nbsp;command,
                               scala.collection.Map&lt;String,String&gt;&nbsp;env,
                               scala.Function1&lt;scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;&nbsp;printPipeContext,
                               scala.Function2&lt;T,scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;&nbsp;printRDDElement,
                               boolean&nbsp;separateWorkingDir,
                               int&nbsp;bufferSize,
                               String&nbsp;encoding)</pre>
</li>
</ul>
<a name="mapPartitions-scala.Function1-boolean-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitions</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;mapPartitions(scala.Function1&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                                       boolean&nbsp;preservesPartitioning,
                                       scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$6)</pre>
</li>
</ul>
<a name="mapPartitionsWithIndex-scala.Function2-boolean-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsWithIndex</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;mapPartitionsWithIndex(scala.Function2&lt;Object,scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                                                boolean&nbsp;preservesPartitioning,
                                                scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$9)</pre>
</li>
</ul>
<a name="zip-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zip</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,U&gt;&gt;&nbsp;zip(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;other,
                                             scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$10)</pre>
</li>
</ul>
<a name="zipPartitions-org.apache.spark.rdd.RDD-boolean-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipPartitions</h4>
<pre>public static&nbsp;&lt;B,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;&nbsp;zipPartitions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
                                         boolean&nbsp;preservesPartitioning,
                                         scala.Function2&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
                                         scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$11,
                                         scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$12)</pre>
</li>
</ul>
<a name="zipPartitions-org.apache.spark.rdd.RDD-scala.Function2-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipPartitions</h4>
<pre>public static&nbsp;&lt;B,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;&nbsp;zipPartitions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
                                         scala.Function2&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
                                         scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$13,
                                         scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$14)</pre>
</li>
</ul>
<a name="zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipPartitions</h4>
<pre>public static&nbsp;&lt;B,C,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;&nbsp;zipPartitions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
                                           boolean&nbsp;preservesPartitioning,
                                           scala.Function3&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
                                           scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$15,
                                           scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$16,
                                           scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$17)</pre>
</li>
</ul>
<a name="zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function3-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipPartitions</h4>
<pre>public static&nbsp;&lt;B,C,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;&nbsp;zipPartitions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
                                           <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
                                           scala.Function3&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
                                           scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$18,
                                           scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$19,
                                           scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$20)</pre>
</li>
</ul>
<a name="zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-boolean-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipPartitions</h4>
<pre>public static&nbsp;&lt;B,C,D,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;&nbsp;zipPartitions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
                                             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
                                             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;D&gt;&nbsp;rdd4,
                                             boolean&nbsp;preservesPartitioning,
                                             scala.Function4&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;D&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
                                             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$21,
                                             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$22,
                                             scala.reflect.ClassTag&lt;D&gt;&nbsp;evidence$23,
                                             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$24)</pre>
</li>
</ul>
<a name="zipPartitions-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-org.apache.spark.rdd.RDD-scala.Function4-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipPartitions</h4>
<pre>public static&nbsp;&lt;B,C,D,V&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;V&gt;&nbsp;zipPartitions(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;B&gt;&nbsp;rdd2,
                                             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;C&gt;&nbsp;rdd3,
                                             <a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;D&gt;&nbsp;rdd4,
                                             scala.Function4&lt;scala.collection.Iterator&lt;T&gt;,scala.collection.Iterator&lt;B&gt;,scala.collection.Iterator&lt;C&gt;,scala.collection.Iterator&lt;D&gt;,scala.collection.Iterator&lt;V&gt;&gt;&nbsp;f,
                                             scala.reflect.ClassTag&lt;B&gt;&nbsp;evidence$25,
                                             scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$26,
                                             scala.reflect.ClassTag&lt;D&gt;&nbsp;evidence$27,
                                             scala.reflect.ClassTag&lt;V&gt;&nbsp;evidence$28)</pre>
</li>
</ul>
<a name="foreach-scala.Function1-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreach</h4>
<pre>public static&nbsp;void&nbsp;foreach(scala.Function1&lt;T,scala.runtime.BoxedUnit&gt;&nbsp;f)</pre>
</li>
</ul>
<a name="foreachPartition-scala.Function1-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreachPartition</h4>
<pre>public static&nbsp;void&nbsp;foreachPartition(scala.Function1&lt;scala.collection.Iterator&lt;T&gt;,scala.runtime.BoxedUnit&gt;&nbsp;f)</pre>
</li>
</ul>
<a name="collect--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collect</h4>
<pre>public static&nbsp;Object&nbsp;collect()</pre>
</li>
</ul>
<a name="toLocalIterator--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toLocalIterator</h4>
<pre>public static&nbsp;scala.collection.Iterator&lt;T&gt;&nbsp;toLocalIterator()</pre>
</li>
</ul>
<a name="collect-scala.PartialFunction-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>collect</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;collect(scala.PartialFunction&lt;T,U&gt;&nbsp;f,
                                 scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$29)</pre>
</li>
</ul>
<a name="subtract-org.apache.spark.rdd.RDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;subtract(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other)</pre>
</li>
</ul>
<a name="subtract-org.apache.spark.rdd.RDD-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;subtract(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                              int&nbsp;numPartitions)</pre>
</li>
</ul>
<a name="subtract-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;subtract(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                              <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p,
                              scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="reduce-scala.Function2-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduce</h4>
<pre>public static&nbsp;T&nbsp;reduce(scala.Function2&lt;T,T,T&gt;&nbsp;f)</pre>
</li>
</ul>
<a name="treeReduce-scala.Function2-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>treeReduce</h4>
<pre>public static&nbsp;T&nbsp;treeReduce(scala.Function2&lt;T,T,T&gt;&nbsp;f,
                           int&nbsp;depth)</pre>
</li>
</ul>
<a name="fold-T-scala.Function2-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fold</h4>
<pre>public static&nbsp;T&nbsp;fold(T&nbsp;zeroValue,
                     scala.Function2&lt;T,T,T&gt;&nbsp;op)</pre>
</li>
</ul>
<a name="aggregate-java.lang.Object-scala.Function2-scala.Function2-scala.reflect.ClassTag-">
<!--   -->
</a><a name="aggregate-U-scala.Function2-scala.Function2-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>aggregate</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;U&nbsp;aggregate(U&nbsp;zeroValue,
                              scala.Function2&lt;U,T,U&gt;&nbsp;seqOp,
                              scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
                              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$30)</pre>
</li>
</ul>
<a name="treeAggregate-java.lang.Object-scala.Function2-scala.Function2-int-scala.reflect.ClassTag-">
<!--   -->
</a><a name="treeAggregate-U-scala.Function2-scala.Function2-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>treeAggregate</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;U&nbsp;treeAggregate(U&nbsp;zeroValue,
                                  scala.Function2&lt;U,T,U&gt;&nbsp;seqOp,
                                  scala.Function2&lt;U,U,U&gt;&nbsp;combOp,
                                  int&nbsp;depth,
                                  scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$31)</pre>
</li>
</ul>
<a name="count--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>count</h4>
<pre>public static&nbsp;long&nbsp;count()</pre>
</li>
</ul>
<a name="countApprox-long-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApprox</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a>&lt;<a href="../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a>&gt;&nbsp;countApprox(long&nbsp;timeout,
                                                       double&nbsp;confidence)</pre>
</li>
</ul>
<a name="countByValue-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByValue</h4>
<pre>public static&nbsp;scala.collection.Map&lt;T,Object&gt;&nbsp;countByValue(scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="countByValueApprox-long-double-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByValueApprox</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a>&lt;scala.collection.Map&lt;T,<a href="../../../../org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a>&gt;&gt;&nbsp;countByValueApprox(long&nbsp;timeout,
                                                                                      double&nbsp;confidence,
                                                                                      scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="countApproxDistinct-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinct</h4>
<pre>public static&nbsp;long&nbsp;countApproxDistinct(int&nbsp;p,
                                       int&nbsp;sp)</pre>
</li>
</ul>
<a name="countApproxDistinct-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinct</h4>
<pre>public static&nbsp;long&nbsp;countApproxDistinct(double&nbsp;relativeSD)</pre>
</li>
</ul>
<a name="zipWithIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipWithIndex</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,Object&gt;&gt;&nbsp;zipWithIndex()</pre>
</li>
</ul>
<a name="zipWithUniqueId--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zipWithUniqueId</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;T,Object&gt;&gt;&nbsp;zipWithUniqueId()</pre>
</li>
</ul>
<a name="take-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>take</h4>
<pre>public static&nbsp;Object&nbsp;take(int&nbsp;num)</pre>
</li>
</ul>
<a name="first--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>first</h4>
<pre>public static&nbsp;T&nbsp;first()</pre>
</li>
</ul>
<a name="top-int-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>top</h4>
<pre>public static&nbsp;Object&nbsp;top(int&nbsp;num,
                         scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="takeOrdered-int-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>takeOrdered</h4>
<pre>public static&nbsp;Object&nbsp;takeOrdered(int&nbsp;num,
                                 scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="max-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>max</h4>
<pre>public static&nbsp;T&nbsp;max(scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="min-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>min</h4>
<pre>public static&nbsp;T&nbsp;min(scala.math.Ordering&lt;T&gt;&nbsp;ord)</pre>
</li>
</ul>
<a name="isEmpty--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isEmpty</h4>
<pre>public static&nbsp;boolean&nbsp;isEmpty()</pre>
</li>
</ul>
<a name="saveAsTextFile-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsTextFile</h4>
<pre>public static&nbsp;void&nbsp;saveAsTextFile(String&nbsp;path)</pre>
</li>
</ul>
<a name="saveAsTextFile-java.lang.String-java.lang.Class-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsTextFile</h4>
<pre>public static&nbsp;void&nbsp;saveAsTextFile(String&nbsp;path,
                                  Class&lt;? extends org.apache.hadoop.io.compress.CompressionCodec&gt;&nbsp;codec)</pre>
</li>
</ul>
<a name="saveAsObjectFile-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsObjectFile</h4>
<pre>public static&nbsp;void&nbsp;saveAsObjectFile(String&nbsp;path)</pre>
</li>
</ul>
<a name="keyBy-scala.Function1-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>keyBy</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;K,T&gt;&gt;&nbsp;keyBy(scala.Function1&lt;T,K&gt;&nbsp;f)</pre>
</li>
</ul>
<a name="localCheckpoint--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>localCheckpoint</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;localCheckpoint()</pre>
</li>
</ul>
<a name="isCheckpointed--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isCheckpointed</h4>
<pre>public static&nbsp;boolean&nbsp;isCheckpointed()</pre>
</li>
</ul>
<a name="getCheckpointFile--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getCheckpointFile</h4>
<pre>public static&nbsp;scala.Option&lt;String&gt;&nbsp;getCheckpointFile()</pre>
</li>
</ul>
<a name="barrier--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>barrier</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/rdd/RDDBarrier.html" title="class in org.apache.spark.rdd">RDDBarrier</a>&lt;T&gt;&nbsp;barrier()</pre>
</li>
</ul>
<a name="context--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>context</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;context()</pre>
</li>
</ul>
<a name="toDebugString--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toDebugString</h4>
<pre>public static&nbsp;String&nbsp;toDebugString()</pre>
</li>
</ul>
<a name="toString--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toString</h4>
<pre>public static&nbsp;String&nbsp;toString()</pre>
</li>
</ul>
<a name="toJavaRDD--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toJavaRDD</h4>
<pre>public static&nbsp;<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;T&gt;&nbsp;toJavaRDD()</pre>
</li>
</ul>
<a name="sample:Ddefault:D3--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sample$default$3</h4>
<pre>public static&nbsp;long&nbsp;sample$default$3()</pre>
</li>
</ul>
<a name="mapPartitionsWithIndex:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsWithIndex$default$2</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;boolean&nbsp;mapPartitionsWithIndex$default$2()</pre>
</li>
</ul>
<a name="unpersist:Ddefault:D1--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>unpersist$default$1</h4>
<pre>public static&nbsp;boolean&nbsp;unpersist$default$1()</pre>
</li>
</ul>
<a name="distinct:Ddefault:D2-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>distinct$default$2</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;distinct$default$2(int&nbsp;numPartitions)</pre>
</li>
</ul>
<a name="coalesce:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>coalesce$default$2</h4>
<pre>public static&nbsp;boolean&nbsp;coalesce$default$2()</pre>
</li>
</ul>
<a name="coalesce:Ddefault:D3--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>coalesce$default$3</h4>
<pre>public static&nbsp;scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PartitionCoalescer.html" title="interface in org.apache.spark.rdd">PartitionCoalescer</a>&gt;&nbsp;coalesce$default$3()</pre>
</li>
</ul>
<a name="coalesce:Ddefault:D4-int-boolean-scala.Option-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>coalesce$default$4</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;coalesce$default$4(int&nbsp;numPartitions,
                                                        boolean&nbsp;shuffle,
                                                        scala.Option&lt;<a href="../../../../org/apache/spark/rdd/PartitionCoalescer.html" title="interface in org.apache.spark.rdd">PartitionCoalescer</a>&gt;&nbsp;partitionCoalescer)</pre>
</li>
</ul>
<a name="repartition:Ddefault:D2-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>repartition$default$2</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;repartition$default$2(int&nbsp;numPartitions)</pre>
</li>
</ul>
<a name="subtract:Ddefault:D3-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>subtract$default$3</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;subtract$default$3(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                                                        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p)</pre>
</li>
</ul>
<a name="intersection:Ddefault:D3-org.apache.spark.rdd.RDD-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intersection$default$3</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;intersection$default$3(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;other,
                                                            <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
</li>
</ul>
<a name="randomSplit:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>randomSplit$default$2</h4>
<pre>public static&nbsp;long&nbsp;randomSplit$default$2()</pre>
</li>
</ul>
<a name="sortBy:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sortBy$default$2</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;boolean&nbsp;sortBy$default$2()</pre>
</li>
</ul>
<a name="sortBy:Ddefault:D3--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sortBy$default$3</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;int&nbsp;sortBy$default$3()</pre>
</li>
</ul>
<a name="mapPartitions:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitions$default$2</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;boolean&nbsp;mapPartitions$default$2()</pre>
</li>
</ul>
<a name="groupBy:Ddefault:D4-scala.Function1-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupBy$default$4</h4>
<pre>public static&nbsp;&lt;K&gt;&nbsp;scala.runtime.Null$&nbsp;groupBy$default$4(scala.Function1&lt;T,K&gt;&nbsp;f,
                                                        <a href="../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;p)</pre>
</li>
</ul>
<a name="pipe:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe$default$2</h4>
<pre>public static&nbsp;scala.collection.Map&lt;String,String&gt;&nbsp;pipe$default$2()</pre>
</li>
</ul>
<a name="pipe:Ddefault:D3--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe$default$3</h4>
<pre>public static&nbsp;scala.Function1&lt;scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;&nbsp;pipe$default$3()</pre>
</li>
</ul>
<a name="pipe:Ddefault:D4--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe$default$4</h4>
<pre>public static&nbsp;scala.Function2&lt;T,scala.Function1&lt;String,scala.runtime.BoxedUnit&gt;,scala.runtime.BoxedUnit&gt;&nbsp;pipe$default$4()</pre>
</li>
</ul>
<a name="pipe:Ddefault:D5--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe$default$5</h4>
<pre>public static&nbsp;boolean&nbsp;pipe$default$5()</pre>
</li>
</ul>
<a name="pipe:Ddefault:D6--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe$default$6</h4>
<pre>public static&nbsp;int&nbsp;pipe$default$6()</pre>
</li>
</ul>
<a name="pipe:Ddefault:D7--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pipe$default$7</h4>
<pre>public static&nbsp;String&nbsp;pipe$default$7()</pre>
</li>
</ul>
<a name="treeReduce:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>treeReduce$default$2</h4>
<pre>public static&nbsp;int&nbsp;treeReduce$default$2()</pre>
</li>
</ul>
<a name="treeAggregate:Ddefault:D4-java.lang.Object-">
<!--   -->
</a><a name="treeAggregate:Ddefault:D4-U-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>treeAggregate$default$4</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;int&nbsp;treeAggregate$default$4(U&nbsp;zeroValue)</pre>
</li>
</ul>
<a name="countApprox:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApprox$default$2</h4>
<pre>public static&nbsp;double&nbsp;countApprox$default$2()</pre>
</li>
</ul>
<a name="countByValue:Ddefault:D1--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByValue$default$1</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;countByValue$default$1()</pre>
</li>
</ul>
<a name="countByValueApprox:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByValueApprox$default$2</h4>
<pre>public static&nbsp;double&nbsp;countByValueApprox$default$2()</pre>
</li>
</ul>
<a name="countByValueApprox:Ddefault:D3-long-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countByValueApprox$default$3</h4>
<pre>public static&nbsp;scala.math.Ordering&lt;T&gt;&nbsp;countByValueApprox$default$3(long&nbsp;timeout,
                                                                  double&nbsp;confidence)</pre>
</li>
</ul>
<a name="takeSample:Ddefault:D3--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>takeSample$default$3</h4>
<pre>public static&nbsp;long&nbsp;takeSample$default$3()</pre>
</li>
</ul>
<a name="countApproxDistinct:Ddefault:D1--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countApproxDistinct$default$1</h4>
<pre>public static&nbsp;double&nbsp;countApproxDistinct$default$1()</pre>
</li>
</ul>
<a name="mapPartitionsWithIndexInternal:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsWithIndexInternal$default$2</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;boolean&nbsp;mapPartitionsWithIndexInternal$default$2()</pre>
</li>
</ul>
<a name="mapPartitionsWithIndexInternal:Ddefault:D3--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsWithIndexInternal$default$3</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;boolean&nbsp;mapPartitionsWithIndexInternal$default$3()</pre>
</li>
</ul>
<a name="mapPartitionsInternal:Ddefault:D2--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsInternal$default$2</h4>
<pre>public static&nbsp;&lt;U&gt;&nbsp;boolean&nbsp;mapPartitionsInternal$default$2()</pre>
</li>
</ul>
<a name="getPartitions--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPartitions</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>[]&nbsp;getPartitions()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#getPartitions--">RDD</a></code></span></div>
<div class="block">Implemented by subclasses to return the set of partitions in this RDD. This method will only
 be called once, so it is safe to implement a time-consuming computation in it.
 <p>
 The partitions in this array must satisfy the following property:
   <code>rdd.partitions.zipWithIndex.forall { case (partition, index) =&gt; partition.index == index }</code></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>compute</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;&nbsp;compute(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;theSplit,
                                                        <a href="../../../../org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a>&nbsp;context)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">RDD</a></code></span></div>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#compute-org.apache.spark.Partition-org.apache.spark.TaskContext-">compute</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;</code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>theSplit</code> - (undocumented)</dd>
<dd><code>context</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="mapPartitionsWithInputSplit-scala.Function2-boolean-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapPartitionsWithInputSplit</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;U&gt;&nbsp;mapPartitionsWithInputSplit(scala.Function2&lt;org.apache.hadoop.mapred.InputSplit,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;,scala.collection.Iterator&lt;U&gt;&gt;&nbsp;f,
                                              boolean&nbsp;preservesPartitioning,
                                              scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$1)</pre>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</li>
</ul>
<a name="getPreferredLocations-org.apache.spark.Partition-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPreferredLocations</h4>
<pre>public&nbsp;scala.collection.Seq&lt;String&gt;&nbsp;getPreferredLocations(<a href="../../../../org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a>&nbsp;split)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#getPreferredLocations-org.apache.spark.Partition-">RDD</a></code></span></div>
<div class="block">Optionally overridden by subclasses to specify placement preferences.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>split</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="checkpoint--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>checkpoint</h4>
<pre>public&nbsp;void&nbsp;checkpoint()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#checkpoint--">RDD</a></code></span></div>
<div class="block">Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint
 directory set with <code>SparkContext#setCheckpointDir</code> and all references to its parent
 RDDs will be removed. This function must be called before any job has been
 executed on this RDD. It is strongly recommended that this RDD is persisted in
 memory, otherwise saving it on a file will require recomputation.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#checkpoint--">checkpoint</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;</code></dd>
</dl>
</li>
</ul>
<a name="persist-org.apache.spark.storage.StorageLevel-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>persist</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a>&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&nbsp;persist(<a href="../../../../org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a>&nbsp;storageLevel)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html#persist-org.apache.spark.storage.StorageLevel-">RDD</a></code></span></div>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed. This can only be used to assign a new storage level if the RDD does not
 have a storage level set yet. Local checkpointing is an exception.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code><a href="../../../../org/apache/spark/rdd/RDD.html#persist-org.apache.spark.storage.StorageLevel-">persist</a></code>&nbsp;in class&nbsp;<code><a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="../../../../org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt;&gt;</code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>storageLevel</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="getConf--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;org.apache.hadoop.conf.Configuration&nbsp;getConf()</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/rdd/HadoopRDD.HadoopMapPartitionsWithSplitRDD$.html" title="class in org.apache.spark.rdd"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/rdd/HadoopRDD.html" target="_top">Frames</a></li>
<li><a href="HadoopRDD.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
