<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_222) on Tue Aug 27 22:14:23 UTC 2019 -->
<title>DataFrameStatFunctions (Spark 2.4.4 JavaDoc)</title>
<meta name="date" content="2019-08-27">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="DataFrameStatFunctions (Spark 2.4.4 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/DataFrameStatFunctions.html" target="_top">Frames</a></li>
<li><a href="DataFrameStatFunctions.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class DataFrameStatFunctions" class="title">Class DataFrameStatFunctions</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.DataFrameStatFunctions</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public final class <span class="typeNameLabel">DataFrameStatFunctions</span>
extends Object</pre>
<div class="block">Statistic functions for <code>DataFrame</code>s.
 <p></div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>double[][]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#approxQuantile-java.lang.String:A-double:A-double-">approxQuantile</a></span>(String[]&nbsp;cols,
              double[]&nbsp;probabilities,
              double&nbsp;relativeError)</code>
<div class="block">Calculates the approximate quantiles of numerical columns of a DataFrame.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>double[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#approxQuantile-java.lang.String-double:A-double-">approxQuantile</a></span>(String&nbsp;col,
              double[]&nbsp;probabilities,
              double&nbsp;relativeError)</code>
<div class="block">Calculates the approximate quantiles of a numerical column of a DataFrame.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter-org.apache.spark.sql.Column-long-double-">bloomFilter</a></span>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
           long&nbsp;expectedNumItems,
           double&nbsp;fpp)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter-org.apache.spark.sql.Column-long-long-">bloomFilter</a></span>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
           long&nbsp;expectedNumItems,
           long&nbsp;numBits)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter-java.lang.String-long-double-">bloomFilter</a></span>(String&nbsp;colName,
           long&nbsp;expectedNumItems,
           double&nbsp;fpp)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter-java.lang.String-long-long-">bloomFilter</a></span>(String&nbsp;colName,
           long&nbsp;expectedNumItems,
           long&nbsp;numBits)</code>
<div class="block">Builds a Bloom filter over a specified column.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#corr-java.lang.String-java.lang.String-">corr</a></span>(String&nbsp;col1,
    String&nbsp;col2)</code>
<div class="block">Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#corr-java.lang.String-java.lang.String-java.lang.String-">corr</a></span>(String&nbsp;col1,
    String&nbsp;col2,
    String&nbsp;method)</code>
<div class="block">Calculates the correlation of two columns of a DataFrame.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch-org.apache.spark.sql.Column-double-double-int-">countMinSketch</a></span>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
              double&nbsp;eps,
              double&nbsp;confidence,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch-org.apache.spark.sql.Column-int-int-int-">countMinSketch</a></span>(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
              int&nbsp;depth,
              int&nbsp;width,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch-java.lang.String-double-double-int-">countMinSketch</a></span>(String&nbsp;colName,
              double&nbsp;eps,
              double&nbsp;confidence,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch-java.lang.String-int-int-int-">countMinSketch</a></span>(String&nbsp;colName,
              int&nbsp;depth,
              int&nbsp;width,
              int&nbsp;seed)</code>
<div class="block">Builds a Count-min Sketch over a specified column.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#cov-java.lang.String-java.lang.String-">cov</a></span>(String&nbsp;col1,
   String&nbsp;col2)</code>
<div class="block">Calculate the sample covariance of two numerical columns of a DataFrame.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#crosstab-java.lang.String-java.lang.String-">crosstab</a></span>(String&nbsp;col1,
        String&nbsp;col2)</code>
<div class="block">Computes a pair-wise frequency table of the given columns.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems-scala.collection.Seq-">freqItems</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;cols)</code>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems-scala.collection.Seq-double-">freqItems</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;cols,
         double&nbsp;support)</code>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems-java.lang.String:A-">freqItems</a></span>(String[]&nbsp;cols)</code>
<div class="block">Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems-java.lang.String:A-double-">freqItems</a></span>(String[]&nbsp;cols,
         double&nbsp;support)</code>
<div class="block">Finding frequent items for columns, possibly with false positives.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy-java.lang.String-java.util.Map-long-">sampleBy</a></span>(String&nbsp;col,
        java.util.Map&lt;T,Double&gt;&nbsp;fractions,
        long&nbsp;seed)</code>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy-java.lang.String-scala.collection.immutable.Map-long-">sampleBy</a></span>(String&nbsp;col,
        scala.collection.immutable.Map&lt;T,Object&gt;&nbsp;fractions,
        long&nbsp;seed)</code>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="approxQuantile-java.lang.String-double:A-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>approxQuantile</h4>
<pre>public&nbsp;double[]&nbsp;approxQuantile(String&nbsp;col,
                               double[]&nbsp;probabilities,
                               double&nbsp;relativeError)</pre>
<div class="block">Calculates the approximate quantiles of a numerical column of a DataFrame.
 <p>
 The result of this algorithm has the following deterministic bound:
 If the DataFrame has N elements and if we request the quantile at probability <code>p</code> up to error
 <code>err</code>, then the algorithm will return a sample <code>x</code> from the DataFrame so that the *exact* rank
 of <code>x</code> is close to (p * N).
 More precisely,
 <p>
 <pre><code>
   floor((p - err) * N) &lt;= rank(x) &lt;= ceil((p + err) * N)
 </code></pre>
 <p>
 This method implements a variation of the Greenwald-Khanna algorithm (with some speed
 optimizations).
 The algorithm was first present in <a href="http://dx.doi.org/10.1145/375663.375670">
 Space-efficient Online Computation of Quantile Summaries</a> by Greenwald and Khanna.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - the name of the numerical column</dd>
<dd><code>probabilities</code> - a list of quantile probabilities
   Each number must belong to [0, 1].
   For example 0 is the minimum, 0.5 is the median, 1 is the maximum.</dd>
<dd><code>relativeError</code> - The relative target precision to achieve (greater than or equal to 0).
   If set to zero, the exact quantiles are computed, which could be very expensive.
   Note that values greater than 1 are accepted but give the same result as 1.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the approximate quantiles at the given probabilities
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
<dt><span class="simpleTagLabel">Note:</span></dt>
<dd>null and NaN values will be removed from the numerical column before calculation. If
   the dataframe is empty or the column only contains null or NaN, an empty array is returned.
 <p></dd>
</dl>
</li>
</ul>
<a name="approxQuantile-java.lang.String:A-double:A-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>approxQuantile</h4>
<pre>public&nbsp;double[][]&nbsp;approxQuantile(String[]&nbsp;cols,
                                 double[]&nbsp;probabilities,
                                 double&nbsp;relativeError)</pre>
<div class="block">Calculates the approximate quantiles of numerical columns of a DataFrame.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>cols</code> - the names of the numerical columns</dd>
<dd><code>probabilities</code> - a list of quantile probabilities
   Each number must belong to [0, 1].
   For example 0 is the minimum, 0.5 is the median, 1 is the maximum.</dd>
<dd><code>relativeError</code> - The relative target precision to achieve (greater than or equal to 0).
   If set to zero, the exact quantiles are computed, which could be very expensive.
   Note that values greater than 1 are accepted but give the same result as 1.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the approximate quantiles at the given probabilities of each column
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.2.0</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><code>approxQuantile(col:Str* approxQuantile)</code> for detailed description.
 <p></dd>
<dt><span class="simpleTagLabel">Note:</span></dt>
<dd>null and NaN values will be ignored in numerical columns before calculation. For
   columns only containing null or NaN values, an empty array is returned.
 <p></dd>
</dl>
</li>
</ul>
<a name="bloomFilter-java.lang.String-long-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(String&nbsp;colName,
                               long&nbsp;expectedNumItems,
                               double&nbsp;fpp)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>colName</code> - name of the column over which the filter is built</dd>
<dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd>
<dd><code>fpp</code> - expected false positive probability of the filter.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="bloomFilter-org.apache.spark.sql.Column-long-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                               long&nbsp;expectedNumItems,
                               double&nbsp;fpp)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - the column over which the filter is built</dd>
<dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd>
<dd><code>fpp</code> - expected false positive probability of the filter.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="bloomFilter-java.lang.String-long-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(String&nbsp;colName,
                               long&nbsp;expectedNumItems,
                               long&nbsp;numBits)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>colName</code> - name of the column over which the filter is built</dd>
<dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd>
<dd><code>numBits</code> - expected number of bits of the filter.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="bloomFilter-org.apache.spark.sql.Column-long-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>bloomFilter</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/BloomFilter.html" title="class in org.apache.spark.util.sketch">BloomFilter</a>&nbsp;bloomFilter(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                               long&nbsp;expectedNumItems,
                               long&nbsp;numBits)</pre>
<div class="block">Builds a Bloom filter over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - the column over which the filter is built</dd>
<dd><code>expectedNumItems</code> - expected number of items which will be put into the filter.</dd>
<dd><code>numBits</code> - expected number of bits of the filter.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="corr-java.lang.String-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>corr</h4>
<pre>public&nbsp;double&nbsp;corr(String&nbsp;col1,
                   String&nbsp;col2,
                   String&nbsp;method)</pre>
<div class="block">Calculates the correlation of two columns of a DataFrame. Currently only supports the Pearson
 Correlation Coefficient. For Spearman Correlation, consider using RDD methods found in
 MLlib's Statistics.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col1</code> - the name of the column</dd>
<dd><code>col2</code> - the name of the column to calculate the correlation against</dd>
<dd><code>method</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The Pearson Correlation Coefficient as a Double.
 <p>
 <pre><code>
    val df = sc.parallelize(0 until 10).toDF("id").withColumn("rand1", rand(seed=10))
      .withColumn("rand2", rand(seed=27))
    df.stat.corr("rand1", "rand2")
    res1: Double = 0.613...
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="corr-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>corr</h4>
<pre>public&nbsp;double&nbsp;corr(String&nbsp;col1,
                   String&nbsp;col2)</pre>
<div class="block">Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col1</code> - the name of the column</dd>
<dd><code>col2</code> - the name of the column to calculate the correlation against</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The Pearson Correlation Coefficient as a Double.
 <p>
 <pre><code>
    val df = sc.parallelize(0 until 10).toDF("id").withColumn("rand1", rand(seed=10))
      .withColumn("rand2", rand(seed=27))
    df.stat.corr("rand1", "rand2", "pearson")
    res1: Double = 0.613...
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="countMinSketch-java.lang.String-int-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(String&nbsp;colName,
                                     int&nbsp;depth,
                                     int&nbsp;width,
                                     int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>colName</code> - name of the column over which the sketch is built</dd>
<dd><code>depth</code> - depth of the sketch</dd>
<dd><code>width</code> - width of the sketch</dd>
<dd><code>seed</code> - random seed</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a <code>CountMinSketch</code> over column <code>colName</code></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="countMinSketch-java.lang.String-double-double-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(String&nbsp;colName,
                                     double&nbsp;eps,
                                     double&nbsp;confidence,
                                     int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>colName</code> - name of the column over which the sketch is built</dd>
<dd><code>eps</code> - relative error of the sketch</dd>
<dd><code>confidence</code> - confidence of the sketch</dd>
<dd><code>seed</code> - random seed</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a <code>CountMinSketch</code> over column <code>colName</code></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="countMinSketch-org.apache.spark.sql.Column-int-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                                     int&nbsp;depth,
                                     int&nbsp;width,
                                     int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - the column over which the sketch is built</dd>
<dd><code>depth</code> - depth of the sketch</dd>
<dd><code>width</code> - width of the sketch</dd>
<dd><code>seed</code> - random seed</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a <code>CountMinSketch</code> over column <code>colName</code></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="countMinSketch-org.apache.spark.sql.Column-double-double-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>countMinSketch</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/util/sketch/CountMinSketch.html" title="class in org.apache.spark.util.sketch">CountMinSketch</a>&nbsp;countMinSketch(<a href="../../../../org/apache/spark/sql/Column.html" title="class in org.apache.spark.sql">Column</a>&nbsp;col,
                                     double&nbsp;eps,
                                     double&nbsp;confidence,
                                     int&nbsp;seed)</pre>
<div class="block">Builds a Count-min Sketch over a specified column.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - the column over which the sketch is built</dd>
<dd><code>eps</code> - relative error of the sketch</dd>
<dd><code>confidence</code> - confidence of the sketch</dd>
<dd><code>seed</code> - random seed</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a <code>CountMinSketch</code> over column <code>colName</code></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="cov-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cov</h4>
<pre>public&nbsp;double&nbsp;cov(String&nbsp;col1,
                  String&nbsp;col2)</pre>
<div class="block">Calculate the sample covariance of two numerical columns of a DataFrame.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col1</code> - the name of the first column</dd>
<dd><code>col2</code> - the name of the second column</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the covariance of the two columns.
 <p>
 <pre><code>
    val df = sc.parallelize(0 until 10).toDF("id").withColumn("rand1", rand(seed=10))
      .withColumn("rand2", rand(seed=27))
    df.stat.cov("rand1", "rand2")
    res1: Double = 0.065...
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="crosstab-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>crosstab</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;crosstab(String&nbsp;col1,
                             String&nbsp;col2)</pre>
<div class="block">Computes a pair-wise frequency table of the given columns. Also known as a contingency table.
 The number of distinct values for each column should be less than 1e4. At most 1e6 non-zero
 pair frequencies will be returned.
 The first column of each row will be the distinct values of <code>col1</code> and the column names will
 be the distinct values of <code>col2</code>. The name of the first column will be <code>col1_col2</code>. Counts
 will be returned as <code>Long</code>s. Pairs that have no occurrences will have zero as their counts.
 Null elements will be replaced by "null", and back ticks will be dropped from elements if they
 exist.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col1</code> - The name of the first column. Distinct items will make the first item of
             each row.</dd>
<dd><code>col2</code> - The name of the second column. Distinct items will make the column names
             of the DataFrame.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A DataFrame containing for the contingency table.
 <p>
 <pre><code>
    val df = spark.createDataFrame(Seq((1, 1), (1, 2), (2, 1), (2, 1), (2, 3), (3, 2), (3, 3)))
      .toDF("key", "value")
    val ct = df.stat.crosstab("key", "value")
    ct.show()
    +---------+---+---+---+
    |key_value|  1|  2|  3|
    +---------+---+---+---+
    |        2|  2|  0|  1|
    |        1|  1|  1|  0|
    |        3|  0|  1|  1|
    +---------+---+---+---+
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="freqItems-java.lang.String:A-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(String[]&nbsp;cols,
                              double&nbsp;support)</pre>
<div class="block">Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp,
 Schenker, and Papadimitriou.
 The <code>support</code> should be greater than 1e-4.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>cols</code> - the names of the columns to search frequent items in.</dd>
<dd><code>support</code> - The minimum frequency for an item to be considered <code>frequent</code>. Should be greater
                than 1e-4.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A Local DataFrame with the Array of frequent items for each column.
 <p>
 <pre><code>
    val rows = Seq.tabulate(100) { i =&gt;
      if (i % 2 == 0) (1, -1.0) else (i, i * -1.0)
    }
    val df = spark.createDataFrame(rows).toDF("a", "b")
    // find the items with a frequency greater than 0.4 (observed 40% of the time) for columns
    // "a" and "b"
    val freqSingles = df.stat.freqItems(Array("a", "b"), 0.4)
    freqSingles.show()
    +-----------+-------------+
    |a_freqItems|  b_freqItems|
    +-----------+-------------+
    |    [1, 99]|[-1.0, -99.0]|
    +-----------+-------------+
    // find the pair of items with a frequency greater than 0.1 in columns "a" and "b"
    val pairDf = df.select(struct("a", "b").as("a-b"))
    val freqPairs = pairDf.stat.freqItems(Array("a-b"), 0.1)
    freqPairs.select(explode($"a-b_freqItems").as("freq_ab")).show()
    +----------+
    |   freq_ab|
    +----------+
    |  [1,-1.0]|
    |   ...    |
    +----------+
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="freqItems-java.lang.String:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(String[]&nbsp;cols)</pre>
<div class="block">Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp,
 Schenker, and Papadimitriou.
 Uses a <code>default</code> support of 1%.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>cols</code> - the names of the columns to search frequent items in.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A Local DataFrame with the Array of frequent items for each column.
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="freqItems-scala.collection.Seq-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(scala.collection.Seq&lt;String&gt;&nbsp;cols,
                              double&nbsp;support)</pre>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp, Schenker,
 and Papadimitriou.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>cols</code> - the names of the columns to search frequent items in.</dd>
<dd><code>support</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A Local DataFrame with the Array of frequent items for each column.
 <p>
 <pre><code>
    val rows = Seq.tabulate(100) { i =&gt;
      if (i % 2 == 0) (1, -1.0) else (i, i * -1.0)
    }
    val df = spark.createDataFrame(rows).toDF("a", "b")
    // find the items with a frequency greater than 0.4 (observed 40% of the time) for columns
    // "a" and "b"
    val freqSingles = df.stat.freqItems(Seq("a", "b"), 0.4)
    freqSingles.show()
    +-----------+-------------+
    |a_freqItems|  b_freqItems|
    +-----------+-------------+
    |    [1, 99]|[-1.0, -99.0]|
    +-----------+-------------+
    // find the pair of items with a frequency greater than 0.1 in columns "a" and "b"
    val pairDf = df.select(struct("a", "b").as("a-b"))
    val freqPairs = pairDf.stat.freqItems(Seq("a-b"), 0.1)
    freqPairs.select(explode($"a-b_freqItems").as("freq_ab")).show()
    +----------+
    |   freq_ab|
    +----------+
    |  [1,-1.0]|
    |   ...    |
    +----------+
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="freqItems-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>freqItems</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;freqItems(scala.collection.Seq&lt;String&gt;&nbsp;cols)</pre>
<div class="block">(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
 frequent element count algorithm described in
 <a href="http://dx.doi.org/10.1145/762471.762473">here</a>, proposed by Karp, Schenker,
 and Papadimitriou.
 Uses a <code>default</code> support of 1%.
 <p>
 This function is meant for exploratory data analysis, as we make no guarantee about the
 backward compatibility of the schema of the resulting <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>cols</code> - the names of the columns to search frequent items in.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A Local DataFrame with the Array of frequent items for each column.
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="sampleBy-java.lang.String-scala.collection.immutable.Map-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sampleBy</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sampleBy(String&nbsp;col,
                                 scala.collection.immutable.Map&lt;T,Object&gt;&nbsp;fractions,
                                 long&nbsp;seed)</pre>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - column that defines strata</dd>
<dd><code>fractions</code> - sampling fraction for each stratum. If a stratum is not specified, we treat
                  its fraction as zero.</dd>
<dd><code>seed</code> - random seed</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a new <code>DataFrame</code> that represents the stratified sample
 <p>
 <pre><code>
    val df = spark.createDataFrame(Seq((1, 1), (1, 2), (2, 1), (2, 1), (2, 3), (3, 2),
      (3, 3))).toDF("key", "value")
    val fractions = Map(1 -&gt; 1.0, 3 -&gt; 0.5)
    df.stat.sampleBy("key", fractions, 36L).show()
    +---+-----+
    |key|value|
    +---+-----+
    |  1|    1|
    |  1|    2|
    |  3|    2|
    +---+-----+
 </code></pre>
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.5.0</dd>
</dl>
</li>
</ul>
<a name="sampleBy-java.lang.String-java.util.Map-long-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>sampleBy</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sampleBy(String&nbsp;col,
                                 java.util.Map&lt;T,Double&gt;&nbsp;fractions,
                                 long&nbsp;seed)</pre>
<div class="block">Returns a stratified sample without replacement based on the fraction given on each stratum.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>col</code> - column that defines strata</dd>
<dd><code>fractions</code> - sampling fraction for each stratum. If a stratum is not specified, we treat
                  its fraction as zero.</dd>
<dd><code>seed</code> - random seed</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a new <code>DataFrame</code> that represents the stratified sample
 <p></dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.5.0</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/DataFrameWriter.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/DataFrameStatFunctions.html" target="_top">Frames</a></li>
<li><a href="DataFrameStatFunctions.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
