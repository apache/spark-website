<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_222) on Tue Aug 27 22:14:18 UTC 2019 -->
<title>DataStreamWriter (Spark 2.4.4 JavaDoc)</title>
<meta name="date" content="2019-08-27">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="DataStreamWriter (Spark 2.4.4 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/streaming/DataStreamReader.html" title="class in org.apache.spark.sql.streaming"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/streaming/GroupState.html" title="interface in org.apache.spark.sql.streaming"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/streaming/DataStreamWriter.html" target="_top">Frames</a></li>
<li><a href="DataStreamWriter.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.streaming</div>
<h2 title="Class DataStreamWriter" class="title">Class DataStreamWriter&lt;T&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.streaming.DataStreamWriter&lt;T&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public final class <span class="typeNameLabel">DataStreamWriter&lt;T&gt;</span>
extends Object</pre>
<div class="block">Interface used to write a streaming <code>Dataset</code> to external storage systems (e.g. file systems,
 key-value stores, etc). Use <code>Dataset.writeStream</code> to access this.
 <p></div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreach-org.apache.spark.sql.ForeachWriter-">foreach</a></span>(<a href="../../../../../org/apache/spark/sql/ForeachWriter.html" title="class in org.apache.spark.sql">ForeachWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;writer)</code>
<div class="block">Sets the output of the streaming query to be processed using the provided writer object.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreachBatch-scala.Function2-">foreachBatch</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;,Object,scala.runtime.BoxedUnit&gt;&nbsp;function)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreachBatch-org.apache.spark.api.java.function.VoidFunction2-">foreachBatch</a></span>(<a href="../../../../../org/apache/spark/api/java/function/VoidFunction2.html" title="interface in org.apache.spark.api.java.function">VoidFunction2</a>&lt;<a href="../../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;,Long&gt;&nbsp;function)</code>
<div class="block">:: Experimental ::</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#format-java.lang.String-">format</a></span>(String&nbsp;source)</code>
<div class="block">Specifies the underlying output data source.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option-java.lang.String-boolean-">option</a></span>(String&nbsp;key,
      boolean&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option-java.lang.String-double-">option</a></span>(String&nbsp;key,
      double&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option-java.lang.String-long-">option</a></span>(String&nbsp;key,
      long&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option-java.lang.String-java.lang.String-">option</a></span>(String&nbsp;key,
      String&nbsp;value)</code>
<div class="block">Adds an output option for the underlying data source.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#options-scala.collection.Map-">options</a></span>(scala.collection.Map&lt;String,String&gt;&nbsp;options)</code>
<div class="block">(Scala-specific) Adds output options for the underlying data source.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#options-java.util.Map-">options</a></span>(java.util.Map&lt;String,String&gt;&nbsp;options)</code>
<div class="block">Adds output options for the underlying data source.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#outputMode-org.apache.spark.sql.streaming.OutputMode-">outputMode</a></span>(<a href="../../../../../org/apache/spark/sql/streaming/OutputMode.html" title="class in org.apache.spark.sql.streaming">OutputMode</a>&nbsp;outputMode)</code>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#outputMode-java.lang.String-">outputMode</a></span>(String&nbsp;outputMode)</code>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#partitionBy-scala.collection.Seq-">partitionBy</a></span>(scala.collection.Seq&lt;String&gt;&nbsp;colNames)</code>
<div class="block">Partitions the output by the given columns on the file system.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#partitionBy-java.lang.String...-">partitionBy</a></span>(String...&nbsp;colNames)</code>
<div class="block">Partitions the output by the given columns on the file system.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#queryName-java.lang.String-">queryName</a></span>(String&nbsp;queryName)</code>
<div class="block">Specifies the name of the <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> that can be started with <code>start()</code>.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#start--">start</a></span>()</code>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#start-java.lang.String-">start</a></span>(String&nbsp;path)</code>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#trigger-org.apache.spark.sql.streaming.Trigger-">trigger</a></span>(<a href="../../../../../org/apache/spark/sql/streaming/Trigger.html" title="class in org.apache.spark.sql.streaming">Trigger</a>&nbsp;trigger)</code>
<div class="block">Set the trigger for the stream query.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="foreach-org.apache.spark.sql.ForeachWriter-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreach</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;foreach(<a href="../../../../../org/apache/spark/sql/ForeachWriter.html" title="class in org.apache.spark.sql">ForeachWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;writer)</pre>
<div class="block">Sets the output of the streaming query to be processed using the provided writer object.
 object. See <a href="../../../../../org/apache/spark/sql/ForeachWriter.html" title="class in org.apache.spark.sql"><code>ForeachWriter</code></a> for more details on the lifecycle and
 semantics.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>writer</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="foreachBatch-scala.Function2-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreachBatch</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;foreachBatch(scala.Function2&lt;<a href="../../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;,Object,scala.runtime.BoxedUnit&gt;&nbsp;function)</pre>
<div class="block">:: Experimental ::
 <p>
 (Scala-specific) Sets the output of the streaming query to be processed using the provided
 function. This is supported only the in the micro-batch execution modes (that is, when the
 trigger is not continuous). In every micro-batch, the provided function will be called in
 every micro-batch with (i) the output rows as a Dataset and (ii) the batch identifier.
 The batchId can be used deduplicate and transactionally write the output
 (that is, the provided Dataset) to external systems. The output Dataset is guaranteed
 to exactly same for the same batchId (assuming all operations are deterministic in the query).
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>function</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.4.0</dd>
</dl>
</li>
</ul>
<a name="foreachBatch-org.apache.spark.api.java.function.VoidFunction2-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>foreachBatch</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;foreachBatch(<a href="../../../../../org/apache/spark/api/java/function/VoidFunction2.html" title="interface in org.apache.spark.api.java.function">VoidFunction2</a>&lt;<a href="../../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;,Long&gt;&nbsp;function)</pre>
<div class="block">:: Experimental ::
 <p>
 (Java-specific) Sets the output of the streaming query to be processed using the provided
 function. This is supported only the in the micro-batch execution modes (that is, when the
 trigger is not continuous). In every micro-batch, the provided function will be called in
 every micro-batch with (i) the output rows as a Dataset and (ii) the batch identifier.
 The batchId can be used deduplicate and transactionally write the output
 (that is, the provided Dataset) to external systems. The output Dataset is guaranteed
 to exactly same for the same batchId (assuming all operations are deterministic in the query).
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>function</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.4.0</dd>
</dl>
</li>
</ul>
<a name="format-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>format</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;format(String&nbsp;source)</pre>
<div class="block">Specifies the underlying output data source.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>source</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                                  String&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p>
 You can set the following option(s):
 <ul>
 <li><code>timeZone</code> (default session local timezone): sets the string that indicates a timezone
 to be used to format timestamps in the JSON/CSV datasources or partition values.</li>
 </ul>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                                  boolean&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                                  long&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="option-java.lang.String-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>option</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;option(String&nbsp;key,
                                  double&nbsp;value)</pre>
<div class="block">Adds an output option for the underlying data source.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="options-scala.collection.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>options</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;options(scala.collection.Map&lt;String,String&gt;&nbsp;options)</pre>
<div class="block">(Scala-specific) Adds output options for the underlying data source.
 <p>
 You can set the following option(s):
 <ul>
 <li><code>timeZone</code> (default session local timezone): sets the string that indicates a timezone
 to be used to format timestamps in the JSON/CSV datasources or partition values.</li>
 </ul>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>options</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="options-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>options</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;options(java.util.Map&lt;String,String&gt;&nbsp;options)</pre>
<div class="block">Adds output options for the underlying data source.
 <p>
 You can set the following option(s):
 <ul>
 <li><code>timeZone</code> (default session local timezone): sets the string that indicates a timezone
 to be used to format timestamps in the JSON/CSV datasources or partition values.</li>
 </ul>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>options</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="outputMode-org.apache.spark.sql.streaming.OutputMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>outputMode</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;outputMode(<a href="../../../../../org/apache/spark/sql/streaming/OutputMode.html" title="class in org.apache.spark.sql.streaming">OutputMode</a>&nbsp;outputMode)</pre>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.
 <ul>
 <li> <code>OutputMode.Append()</code>: only the new rows in the streaming DataFrame/Dataset will be
 written to the sink.</li>
 <li> <code>OutputMode.Complete()</code>: all the rows in the streaming DataFrame/Dataset will be written
 to the sink every time there are some updates.</li>
 <li> <code>OutputMode.Update()</code>: only the rows that were updated in the streaming
 DataFrame/Dataset will be written to the sink every time there are some updates.
 If the query doesn't contain aggregations, it will be equivalent to
 <code>OutputMode.Append()</code> mode.</li>
 </ul>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>outputMode</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="outputMode-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>outputMode</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;outputMode(String&nbsp;outputMode)</pre>
<div class="block">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.
 <ul>
 <li> <code>append</code>: only the new rows in the streaming DataFrame/Dataset will be written to
 the sink.</li>
 <li> <code>complete</code>: all the rows in the streaming DataFrame/Dataset will be written to the sink
 every time there are some updates.</li>
 <li> <code>update</code>: only the rows that were updated in the streaming DataFrame/Dataset will
 be written to the sink every time there are some updates. If the query doesn't
 contain aggregations, it will be equivalent to <code>append</code> mode.</li>
 </ul>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>outputMode</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="partitionBy-java.lang.String...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionBy</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;partitionBy(String...&nbsp;colNames)</pre>
<div class="block">Partitions the output by the given columns on the file system. If specified, the output is
 laid out on the file system similar to Hive's partitioning scheme. As an example, when we
 partition a dataset by year and then month, the directory layout would look like:
 <p>
 <ul>
 <li> year=2016/month=01/</li>
 <li> year=2016/month=02/</li>
 </ul>
 <p>
 Partitioning is one of the most widely used techniques to optimize physical data layout.
 It provides a coarse-grained index for skipping unnecessary data reads when queries have
 predicates on the partitioned columns. In order for partitioning to work well, the number
 of distinct values in each column should typically be less than tens of thousands.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="partitionBy-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>partitionBy</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;partitionBy(scala.collection.Seq&lt;String&gt;&nbsp;colNames)</pre>
<div class="block">Partitions the output by the given columns on the file system. If specified, the output is
 laid out on the file system similar to Hive's partitioning scheme. As an example, when we
 partition a dataset by year and then month, the directory layout would look like:
 <p>
 <ul>
 <li> year=2016/month=01/</li>
 <li> year=2016/month=02/</li>
 </ul>
 <p>
 Partitioning is one of the most widely used techniques to optimize physical data layout.
 It provides a coarse-grained index for skipping unnecessary data reads when queries have
 predicates on the partitioned columns. In order for partitioning to work well, the number
 of distinct values in each column should typically be less than tens of thousands.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>colNames</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="queryName-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>queryName</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;queryName(String&nbsp;queryName)</pre>
<div class="block">Specifies the name of the <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> that can be started with <code>start()</code>.
 This name must be unique among all the currently active queries in the associated SQLContext.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>queryName</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="start-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>start</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a>&nbsp;start(String&nbsp;path)</pre>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives. The returned <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> object can be used to interact with
 the stream.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="start--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>start</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming">StreamingQuery</a>&nbsp;start()</pre>
<div class="block">Starts the execution of the streaming query, which will continually output results to the given
 path as new data arrives. The returned <a href="../../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQuery</code></a> object can be used to interact with
 the stream.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="trigger-org.apache.spark.sql.streaming.Trigger-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>trigger</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="class in org.apache.spark.sql.streaming">DataStreamWriter</a>&lt;<a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="type parameter in DataStreamWriter">T</a>&gt;&nbsp;trigger(<a href="../../../../../org/apache/spark/sql/streaming/Trigger.html" title="class in org.apache.spark.sql.streaming">Trigger</a>&nbsp;trigger)</pre>
<div class="block">Set the trigger for the stream query. The default value is <code>ProcessingTime(0)</code> and it will run
 the query as fast as possible.
 <p>
 Scala Example:
 <pre><code>
   df.writeStream.trigger(ProcessingTime("10 seconds"))

   import scala.concurrent.duration._
   df.writeStream.trigger(ProcessingTime(10.seconds))
 </code></pre>
 <p>
 Java Example:
 <pre><code>
   df.writeStream().trigger(ProcessingTime.create("10 seconds"))

   import java.util.concurrent.TimeUnit
   df.writeStream().trigger(ProcessingTime.create(10, TimeUnit.SECONDS))
 </code></pre>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>trigger</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/sql/streaming/DataStreamReader.html" title="class in org.apache.spark.sql.streaming"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../../org/apache/spark/sql/streaming/GroupState.html" title="interface in org.apache.spark.sql.streaming"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/sql/streaming/DataStreamWriter.html" target="_top">Frames</a></li>
<li><a href="DataStreamWriter.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
