<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Multilayer Perceptron Classification Model</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for spark.mlp {SparkR}"><tr><td>spark.mlp {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Multilayer Perceptron Classification Model</h2>

<h3>Description</h3>

<p><code>spark.mlp</code> fits a multi-layer perceptron neural network model against a SparkDataFrame.
Users can call <code>summary</code> to print a summary of the fitted model, <code>predict</code> to make
predictions on new data, and <code>write.ml</code>/<code>read.ml</code> to save/load fitted models.
Only categorical data is supported.
For more details, see
<a href="http://spark.apache.org/docs/latest/ml-classification-regression.html">
Multilayer Perceptron</a>
</p>


<h3>Usage</h3>

<pre>
spark.mlp(data, formula, ...)

## S4 method for signature 'SparkDataFrame,formula'
spark.mlp(data, formula, layers,
  blockSize = 128, solver = "l-bfgs", maxIter = 100, tol = 1e-06,
  stepSize = 0.03, seed = NULL, initialWeights = NULL,
  handleInvalid = c("error", "keep", "skip"))

## S4 method for signature 'MultilayerPerceptronClassificationModel'
summary(object)

## S4 method for signature 'MultilayerPerceptronClassificationModel'
predict(object,
  newData)


  ## S4 method for signature 'MultilayerPerceptronClassificationModel,character'
write.ml(object,
  path, overwrite = FALSE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>data</code></td>
<td>
<p>a <code>SparkDataFrame</code> of observations and labels for model fitting.</p>
</td></tr>
<tr valign="top"><td><code>formula</code></td>
<td>
<p>a symbolic description of the model to be fitted. Currently only a few formula
operators are supported, including '~', '.', ':', '+', and '-'.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>additional arguments passed to the method.</p>
</td></tr>
<tr valign="top"><td><code>layers</code></td>
<td>
<p>integer vector containing the number of nodes for each layer.</p>
</td></tr>
<tr valign="top"><td><code>blockSize</code></td>
<td>
<p>blockSize parameter.</p>
</td></tr>
<tr valign="top"><td><code>solver</code></td>
<td>
<p>solver parameter, supported options: &quot;gd&quot; (minibatch gradient descent) or &quot;l-bfgs&quot;.</p>
</td></tr>
<tr valign="top"><td><code>maxIter</code></td>
<td>
<p>maximum iteration number.</p>
</td></tr>
<tr valign="top"><td><code>tol</code></td>
<td>
<p>convergence tolerance of iterations.</p>
</td></tr>
<tr valign="top"><td><code>stepSize</code></td>
<td>
<p>stepSize parameter.</p>
</td></tr>
<tr valign="top"><td><code>seed</code></td>
<td>
<p>seed parameter for weights initialization.</p>
</td></tr>
<tr valign="top"><td><code>initialWeights</code></td>
<td>
<p>initialWeights parameter for weights initialization, it should be a
numeric vector.</p>
</td></tr>
<tr valign="top"><td><code>handleInvalid</code></td>
<td>
<p>How to handle invalid data (unseen labels or NULL values) in features and
label column of string type.
Supported options: &quot;skip&quot; (filter out rows with invalid data),
&quot;error&quot; (throw an error), &quot;keep&quot; (put invalid data in
a special additional bucket, at index numLabels). Default
is &quot;error&quot;.</p>
</td></tr>
<tr valign="top"><td><code>object</code></td>
<td>
<p>a Multilayer Perceptron Classification Model fitted by <code>spark.mlp</code></p>
</td></tr>
<tr valign="top"><td><code>newData</code></td>
<td>
<p>a SparkDataFrame for testing.</p>
</td></tr>
<tr valign="top"><td><code>path</code></td>
<td>
<p>the directory where the model is saved.</p>
</td></tr>
<tr valign="top"><td><code>overwrite</code></td>
<td>
<p>overwrites or not if the output path already exists. Default is FALSE
which means throw exception if the output path exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>spark.mlp</code> returns a fitted Multilayer Perceptron Classification Model.
</p>
<p><code>summary</code> returns summary information of the fitted model, which is a list.
The list includes <code>numOfInputs</code> (number of inputs), <code>numOfOutputs</code>
(number of outputs), <code>layers</code> (array of layer sizes including input
and output layers), and <code>weights</code> (the weights of layers).
For <code>weights</code>, it is a numeric vector with length equal to the expected
given the architecture (i.e., for 8-10-2 network, 112 connection weights).
</p>
<p><code>predict</code> returns a SparkDataFrame containing predicted labeled in a column named
&quot;prediction&quot;.
</p>


<h3>Note</h3>

<p>spark.mlp since 2.1.0
</p>
<p>summary(MultilayerPerceptronClassificationModel) since 2.1.0
</p>
<p>predict(MultilayerPerceptronClassificationModel) since 2.1.0
</p>
<p>write.ml(MultilayerPerceptronClassificationModel, character) since 2.1.0
</p>


<h3>See Also</h3>

<p><a href="read.ml.html">read.ml</a>
</p>
<p><a href="write.ml.html">write.ml</a>
</p>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D df &lt;- read.df(&quot;data/mllib/sample_multiclass_classification_data.txt&quot;, source = &quot;libsvm&quot;)
##D 
##D # fit a Multilayer Perceptron Classification Model
##D model &lt;- spark.mlp(df, label ~ features, blockSize = 128, layers = c(4, 3), solver = &quot;l-bfgs&quot;,
##D                    maxIter = 100, tol = 0.5, stepSize = 1, seed = 1,
##D                    initialWeights = c(0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9))
##D 
##D # get the summary of the model
##D summary(model)
##D 
##D # make predictions
##D predictions &lt;- predict(model, df)
##D 
##D # save and load the model
##D path &lt;- &quot;path/to/model&quot;
##D write.ml(model, path)
##D savedModel &lt;- read.ml(path)
##D summary(savedModel)
## End(Not run)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 2.4.4 <a href="00Index.html">Index</a>]</div>
</body></html>
