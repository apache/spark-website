<!DOCTYPE html><html><head><title>R: Run a function over a list of elements, distributing the...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body><div class="container">

<table style="width: 100%;"><tr><td>spark.lapply {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Run a function over a list of elements, distributing the computations with Spark</h2>

<h3>Description</h3>

<p>Run a function over a list of elements, distributing the computations with Spark. Applies a
function in a manner that is similar to doParallel or lapply to elements of a list.
The computations are distributed using Spark. It is conceptually the same as the following code:
lapply(list, func)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spark.lapply(list, func)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;"><td><code>list</code></td>
<td>
<p>the list of elements</p>
</td></tr>
<tr style="vertical-align: top;"><td><code>func</code></td>
<td>
<p>a function that takes one argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Known limitations:
</p>

<ul>
<li><p> variable scoping and capture: compared to R's rich support for variable resolutions,
the distributed nature of SparkR limits how variables are resolved at runtime. All the
variables that are available through lexical scoping are embedded in the closure of the
function and available as read-only variables within the function. The environment variables
should be stored into temporary variables outside the function, and not directly accessed
within the function.
</p>
</li>
<li><p> loading external packages: In order to use a package, you need to load it inside the
closure. For example, if you rely on the MASS module, here is how you would use it:
</p>
<pre>
    train &lt;- function(hyperparam) {
      library(MASS)
      lm.ridge("y ~ x+z", data, lambda=hyperparam)
      model
    }
  </pre>
</li></ul>



<h3>Value</h3>

<p>a list of results (the exact type being determined by the function)
</p>


<h3>Note</h3>

<p>spark.lapply since 2.0.0
</p>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D sparkR.session()
##D doubled &lt;- spark.lapply(1:10, function(x) {2 * x})
## End(Not run)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 3.2.2 <a href="00Index.html">Index</a>]</div>
</div>
</body></html>
