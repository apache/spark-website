<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>org.apache.spark.streaming.PairDStreamFunctions</title>
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link type="text/css" media="screen" rel="stylesheet" href="../../../../lib/template.css" />
      <script type="text/javascript" src="../../../../lib/jquery.js"></script>
      <script type="text/javascript" src="../../../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../../../lib/template.js"></script>
      <script type="text/javascript" src="../../../../lib/tools.tooltip.js"></script>
    
        </head>
        <body onload="sh_highlightDocument('../lib/', '.min.js');" class="type">
      <div id="definition">
        <img src="../../../../lib/class_big.png" />
        <p id="owner"><a name="org" class="extype" href="../../../package.html">org</a>.<a name="org.apache" class="extype" href="../../package.html">apache</a>.<a name="org.apache.spark" class="extype" href="../package.html">spark</a>.<a name="org.apache.spark.streaming" class="extype" href="package.html">streaming</a></p>
        <h1>PairDStreamFunctions</h1>
      </div>

      <h4 class="signature" id="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">PairDStreamFunctions</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <span name="scala.Serializable" class="extype">Serializable</span></span>
      </span>
      </h4>
      
      <div class="fullcommenttop" id="comment"><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span name="scala.Serializable" class="extype">Serializable</span>, <span name="java.io.Serializable" class="extype">Serializable</span>, AnyRef, <span name="scala.Any" class="extype">Any</span></div>
        </div></div>
    

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input accesskey="/" type="text" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By inheritance</span></li></ol>
            </div>
        <div id="ancestors">
              <span class="filtertype">Inherited</span>
              <ol><li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li></ol>
              <ol id="linearization"><li name="org.apache.spark.streaming.PairDStreamFunctions" class="in"><span>PairDStreamFunctions</span></li><li name="scala.Serializable" class="in"><span>Serializable</span></li><li name="java.io.Serializable" class="in"><span>Serializable</span></li><li name="scala.AnyRef" class="in"><span>AnyRef</span></li><li name="scala.Any" class="in"><span>Any</span></li></ol>
            </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div class="members" id="constructors">
              <h3>Instance Constructors</h3>
              <ol><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#this" data-isabs="false">
      <a id="this:PairDStreamFunctions[K, V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">PairDStreamFunctions</span><span class="params">(<span name="self">self: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[K]</span>, <span name="arg1">arg1: ClassManifest[V]</span>)</span>
      </span>
      </h4>
      
    </li></ol>
            </div>

        

        

        <div class="values members" id="values">
              <h3>Value Members</h3>
              <ol><li visbl="pub" name="scala.AnyRef#!=" data-isabs="false">
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#!=" data-isabs="false">
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef###" data-isabs="false">
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $hash$hash">##</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#==" data-isabs="false">
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#==" data-isabs="false">
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#asInstanceOf" data-isabs="false">
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#clone" data-isabs="false">
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: AnyRef</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#cogroup" data-isabs="false">
      <a id="cogroup[W](DStream[(K, W)],Partitioner)(ClassManifest[W]):DStream[(K, (Seq[V], Seq[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (Seq[V], Seq[W]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
The supplied org.apache.spark.Partitioner is used to partition the generated RDDs.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#cogroup" data-isabs="false">
      <a id="cogroup[W](DStream[(K, W)],Int)(ClassManifest[W]):DStream[(K, (Seq[V], Seq[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (Seq[V], Seq[W]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#cogroup" data-isabs="false">
      <a id="cogroup[W](DStream[(K, W)])(ClassManifest[W]):DStream[(K, (Seq[V], Seq[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (Seq[V], Seq[W]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with Spark's default number
of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#combineByKey" data-isabs="false">
      <a id="combineByKey[C]((V) ⇒ C,(C, V) ⇒ C,(C, C) ⇒ C,Partitioner)(ClassManifest[C]):DStream[(K, C)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: (V) ⇒ C</span>, <span name="mergeValue">mergeValue: (C, V) ⇒ C</span>, <span name="mergeCombiner">mergeCombiner: (C, C) ⇒ C</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[C]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, C)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Combine elements of each key in DStream's RDDs using custom functions.</p><div class="fullcomment"><div class="comment cmt"><p>Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
combineByKey for RDDs. Please refer to combineByKey in
org.apache.spark.rdd.PairRDDFunctions for more information.
</p></div></div>
    </li><li visbl="pub" name="scala.AnyRef#eq" data-isabs="false">
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#equals" data-isabs="false">
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="prt" name="scala.AnyRef#finalize" data-isabs="false">
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a name="java.lang" class="extype" href="../../../../java/lang/package.html">lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#flatMapValues" data-isabs="false">
      <a id="flatMapValues[U]((V) ⇒ TraversableOnce[U])(ClassManifest[U]):DStream[(K, U)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="flatMapValuesFunc">flatMapValuesFunc: (V) ⇒ TraversableOnce[U]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[U]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, U)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
'this' DStream without changing the key.</p>
    </li><li visbl="pub" name="scala.AnyRef#getClass" data-isabs="false">
      <a id="getClass():java.lang.Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: java.lang.Class[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKey" data-isabs="false">
      <a id="groupByKey(Partitioner):DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> on each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> on each RDD. The supplied org.apache.spark.Partitioner
is used to control the partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKey" data-isabs="false">
      <a id="groupByKey(Int):DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKey" data-isabs="false">
      <a id="groupByKey():DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">()</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration,Duration,Partitioner):DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration,Duration,Int):DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream; if not specified
                      then Spark's default number of partitions will be used
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration,Duration):DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
<code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#groupByKeyAndWindow" data-isabs="false">
      <a id="groupByKeyAndWindow(Duration):DStream[(K, Seq[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, Seq[V])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
<code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#hashCode" data-isabs="false">
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="scala.Any#isInstanceOf" data-isabs="false">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#join" data-isabs="false">
      <a id="join[W](DStream[(K, W)],Partitioner)(ClassManifest[W]):DStream[(K, (V, W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (V, W))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
The supplied org.apache.spark.Partitioner is used to control the partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#join" data-isabs="false">
      <a id="join[W](DStream[(K, W)],Int)(ClassManifest[W]):DStream[(K, (V, W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (V, W))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#join" data-isabs="false">
      <a id="join[W](DStream[(K, W)])(ClassManifest[W]):DStream[(K, (V, W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (V, W))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#leftOuterJoin" data-isabs="false">
      <a id="leftOuterJoin[W](DStream[(K, W)],Partitioner)(ClassManifest[W]):DStream[(K, (V, Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (V, <span name="scala.Option" class="extype">Option</span>[W]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#leftOuterJoin" data-isabs="false">
      <a id="leftOuterJoin[W](DStream[(K, W)],Int)(ClassManifest[W]):DStream[(K, (V, Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (V, <span name="scala.Option" class="extype">Option</span>[W]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#leftOuterJoin" data-isabs="false">
      <a id="leftOuterJoin[W](DStream[(K, W)])(ClassManifest[W]):DStream[(K, (V, Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (V, <span name="scala.Option" class="extype">Option</span>[W]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#mapValues" data-isabs="false">
      <a id="mapValues[U]((V) ⇒ U)(ClassManifest[U]):DStream[(K, U)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="mapValuesFunc">mapValuesFunc: (V) ⇒ U</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[U]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, U)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a map function to the value of each key-value pairs in
'this' DStream without changing the key.</p>
    </li><li visbl="pub" name="scala.AnyRef#ne" data-isabs="false">
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: AnyRef</span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notify" data-isabs="false">
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#notifyAll" data-isabs="false">
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKey" data-isabs="false">
      <a id="reduceByKey((V, V) ⇒ V,Partitioner):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. org.apache.spark.Partitioner is used to control the
partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKey" data-isabs="false">
      <a id="reduceByKey((V, V) ⇒ V,Int):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKey" data-isabs="false">
      <a id="reduceByKey((V, V) ⇒ V):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the associative reduce function. Hash partitioning is used to generate the RDDs
with Spark's default number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,(V, V) ⇒ V,Duration,Duration,Partitioner,((K, V)) ⇒ Boolean):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="invReduceFunc">invReduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>, <span name="filterFunc">filterFunc: ((K, V)) ⇒ <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)
This is more efficient than reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD in the new DStream.</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>Optional function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,(V, V) ⇒ V,Duration,Duration,Int,((K, V)) ⇒ Boolean):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="invReduceFunc">invReduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a> = <span class="symbol"><span class="name"><a href="DStream.html#slideDuration:Duration">self.slideDuration</a></span></span></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span> = <span class="symbol"><span class="name"><a href="StreamingContext.html#sc:SparkContext">ssc.sc.defaultParallelism</a></span></span></span>, <span name="filterFunc">filterFunc: ((K, V)) ⇒ <span name="scala.Boolean" class="extype">Boolean</span> = <span class="symbol">null</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)</li></ol><p> 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)</p><p>This is more efficient than reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>Optional function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration,Duration,Partitioner):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
<code>DStream.reduceByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD
                      in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration,Duration,Int):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration,Duration):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>, <span name="slideDuration">slideDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#reduceByKeyAndWindow" data-isabs="false">
      <a id="reduceByKeyAndWindow((V, V) ⇒ V,Duration):DStream[(K, V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (V, V) ⇒ V</span>, <span name="windowDuration">windowDuration: <a name="org.apache.spark.streaming.Duration" class="extype" href="Duration.html">Duration</a></span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, V)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval
</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#rightOuterJoin" data-isabs="false">
      <a id="rightOuterJoin[W](DStream[(K, W)],Partitioner)(ClassManifest[W]):DStream[(K, (Option[V], W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (<span name="scala.Option" class="extype">Option</span>[V], W))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#rightOuterJoin" data-isabs="false">
      <a id="rightOuterJoin[W](DStream[(K, W)],Int)(ClassManifest[W]):DStream[(K, (Option[V], W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (<span name="scala.Option" class="extype">Option</span>[V], W))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#rightOuterJoin" data-isabs="false">
      <a id="rightOuterJoin[W](DStream[(K, W)])(ClassManifest[W]):DStream[(K, (Option[V], W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, W)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[W]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, (<span name="scala.Option" class="extype">Option</span>[V], W))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#saveAsHadoopFiles" data-isabs="false">
      <a id="saveAsHadoopFiles(String,String,Class[_],Class[_],Class[_ &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]],JobConf):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[_ &lt;: org.apache.hadoop.mapred.OutputFormat[_, _]]</span>, <span name="conf">conf: <span name="org.apache.hadoop.mapred.JobConf" class="extype">JobConf</span> = <span class="symbol"><span class="name"><a href="../../../package.html">new JobConf</a></span></span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
is generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#saveAsHadoopFiles" data-isabs="false">
      <a id="saveAsHadoopFiles[F&lt;:OutputFormat[K, V]](String,String)(ClassManifest[F]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span name="org.apache.hadoop.mapred.OutputFormat" class="extype">OutputFormat</span>[K, V]</span>]</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="fm">fm: ClassManifest[F]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
is generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#saveAsNewAPIHadoopFiles" data-isabs="false">
      <a id="saveAsNewAPIHadoopFiles(String,String,Class[_],Class[_],Class[_ &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]],Configuration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>, <span name="keyClass">keyClass: Class[_]</span>, <span name="valueClass">valueClass: Class[_]</span>, <span name="outputFormatClass">outputFormatClass: Class[_ &lt;: org.apache.hadoop.mapreduce.OutputFormat[_, _]]</span>, <span name="conf">conf: <span name="org.apache.hadoop.conf.Configuration" class="extype">Configuration</span> = <span class="symbol"><span class="name"><a href="../../../package.html">new Configuration</a></span></span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#saveAsNewAPIHadoopFiles" data-isabs="false">
      <a id="saveAsNewAPIHadoopFiles[F&lt;:OutputFormat[K, V]](String,String)(ClassManifest[F]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span name="org.apache.hadoop.mapreduce.OutputFormat" class="extype">OutputFormat</span>[K, V]</span>]</span><span class="params">(<span name="prefix">prefix: String</span>, <span name="suffix">suffix: String</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="fm">fm: ClassManifest[F]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li visbl="pub" name="scala.AnyRef#synchronized" data-isabs="false">
      <a id="synchronized[T0](⇒ T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ T0</span>)</span><span class="result">: T0</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#toString" data-isabs="false">
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span name="java.lang.String" class="extype">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S]((Iterator[(K, Seq[V], Option[S])]) ⇒ Iterator[(K, S)],Partitioner,Boolean)(ClassManifest[S]):DStream[(K, S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (Iterator[(K, Seq[V], <span name="scala.Option" class="extype">Option</span>[S])]) ⇒ Iterator[(K, S)]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>, <span name="rememberPartitioner">rememberPartitioner: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[S]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, S)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated. Note, that
                  this function may generate a different a tuple with a different key
                  than the input key. It is up to the developer to decide whether to
                  remember the partitioner despite the key being changed.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new DStream.</p></dd><dt class="param">rememberPartitioner</dt><dd class="cmt"><p>Whether to remember the paritioner object in the generated RDDs.</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S]((Seq[V], Option[S]) ⇒ Option[S],Partitioner)(ClassManifest[S]):DStream[(K, S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (Seq[V], <span name="scala.Option" class="extype">Option</span>[S]) ⇒ <span name="scala.Option" class="extype">Option</span>[S]</span>, <span name="partitioner">partitioner: <span name="org.apache.spark.Partitioner" class="extype">Partitioner</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[S]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, S)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new DStream.</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S]((Seq[V], Option[S]) ⇒ Option[S],Int)(ClassManifest[S]):DStream[(K, S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (Seq[V], <span name="scala.Option" class="extype">Option</span>[S]) ⇒ <span name="scala.Option" class="extype">Option</span>[S]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[S]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, S)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>Number of partitions of each RDD in the new DStream.</p></dd></dl></div>
    </li><li visbl="pub" name="org.apache.spark.streaming.PairDStreamFunctions#updateStateByKey" data-isabs="false">
      <a id="updateStateByKey[S]((Seq[V], Option[S]) ⇒ Option[S])(ClassManifest[S]):DStream[(K, S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (Seq[V], <span name="scala.Option" class="extype">Option</span>[S]) ⇒ <span name="scala.Option" class="extype">Option</span>[S]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: ClassManifest[S]</span>)</span><span class="result">: <a name="org.apache.spark.streaming.DStream" class="extype" href="DStream.html">DStream</a>[(K, S)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li visbl="pub" name="scala.AnyRef#wait" data-isabs="false">
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">()</span>
              
        </dd></dl></div>
    </li></ol>
            </div>

        
        </div>

        <div id="inheritedMembers">
        <div name="scala.Serializable" class="parent">
              <h3>Inherited from <span name="scala.Serializable" class="extype">Serializable</span></h3>
            </div><div name="java.io.Serializable" class="parent">
              <h3>Inherited from <span name="java.io.Serializable" class="extype">Serializable</span></h3>
            </div><div name="scala.AnyRef" class="parent">
              <h3>Inherited from AnyRef</h3>
            </div><div name="scala.Any" class="parent">
              <h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3>
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>