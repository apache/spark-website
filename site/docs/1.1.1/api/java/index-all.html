<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Mon Nov 24 15:20:42 PST 2014 -->
<title>Index (Spark 1.1.1 JavaDoc)</title>
<meta name="date" content="2014-11-24">
<link rel="stylesheet" type="text/css" href="./stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Index (Spark 1.1.1 JavaDoc)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="./overview-summary.html">Overview</a></li>
<li>Package</li>
<li>Class</li>
<li><a href="./overview-tree.html">Tree</a></li>
<li><a href="./deprecated-list.html">Deprecated</a></li>
<li class="navBarCell1Rev">Index</li>
<li><a href="./help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="./index.html?index-all.html" target="_top">Frames</a></li>
<li><a href="index-all.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="./allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<div class="contentContainer"><a href="#_A_">A</a>&nbsp;<a href="#_B_">B</a>&nbsp;<a href="#_C_">C</a>&nbsp;<a href="#_D_">D</a>&nbsp;<a href="#_E_">E</a>&nbsp;<a href="#_F_">F</a>&nbsp;<a href="#_G_">G</a>&nbsp;<a href="#_H_">H</a>&nbsp;<a href="#_I_">I</a>&nbsp;<a href="#_J_">J</a>&nbsp;<a href="#_K_">K</a>&nbsp;<a href="#_L_">L</a>&nbsp;<a href="#_M_">M</a>&nbsp;<a href="#_N_">N</a>&nbsp;<a href="#_O_">O</a>&nbsp;<a href="#_P_">P</a>&nbsp;<a href="#_Q_">Q</a>&nbsp;<a href="#_R_">R</a>&nbsp;<a href="#_S_">S</a>&nbsp;<a href="#_T_">T</a>&nbsp;<a href="#_U_">U</a>&nbsp;<a href="#_V_">V</a>&nbsp;<a href="#_W_">W</a>&nbsp;<a href="#_Z_">Z</a>&nbsp;<a href="#___">_</a>&nbsp;<a name="_A_">
<!--   -->
</a>
<h2 class="title">A</h2>
<dl>
<dt><a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><span class="strong">Accumulable</span></a>&lt;<a href="./org/apache/spark/Accumulable.html" title="type parameter in Accumulable">R</a>,<a href="./org/apache/spark/Accumulable.html" title="type parameter in Accumulable">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">A data type that can be accumulated, ie has an commutative and associative "add" operation,
 but where the result type, <code>R</code>, may be different from the element type being added, <code>T</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#Accumulable(R, org.apache.spark.AccumulableParam, scala.Option)">Accumulable(R, AccumulableParam&lt;R, T&gt;, Option&lt;String&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#Accumulable(R, org.apache.spark.AccumulableParam)">Accumulable(R, AccumulableParam&lt;R, T&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulable(T, org.apache.spark.AccumulableParam)">accumulable(T, AccumulableParam&lt;T, R&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><code>Accumulable</code></a> shared variable of the given type, to which tasks
 can "add" values with <code>add</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulable(T, java.lang.String, org.apache.spark.AccumulableParam)">accumulable(T, String, AccumulableParam&lt;T, R&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><code>Accumulable</code></a> shared variable of the given type, to which tasks
 can "add" values with <code>add</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#accumulable(T, org.apache.spark.AccumulableParam)">accumulable(T, AccumulableParam&lt;T, R&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><code>Accumulable</code></a> shared variable, to which tasks can add values
 with <code>+=</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#accumulable(T, java.lang.String, org.apache.spark.AccumulableParam)">accumulable(T, String, AccumulableParam&lt;T, R&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><code>Accumulable</code></a> shared variable, with a name for display in the
 Spark UI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#accumulableCollection(R, scala.Function1, scala.reflect.ClassTag)">accumulableCollection(R, Function1&lt;R, Growable&lt;T&gt;&gt;, ClassTag&lt;R&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Create an accumulator from a "mutable collection" type.</div>
</dd>
<dt><a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler"><span class="strong">AccumulableInfo</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Information about an <a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><code>Accumulable</code></a> modified during a task or stage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#AccumulableInfo(long, java.lang.String, scala.Option, java.lang.String)">AccumulableInfo(long, String, Option&lt;String&gt;, String)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark"><span class="strong">AccumulableParam</span></a>&lt;<a href="./org/apache/spark/AccumulableParam.html" title="type parameter in AccumulableParam">R</a>,<a href="./org/apache/spark/AccumulableParam.html" title="type parameter in AccumulableParam">T</a>&gt; - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">Helper object defining how to accumulate values of a particular type.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#accumulables()">accumulables()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>
<div class="block">Terminal values of accumulables updated during this stage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#accumulables()">accumulables()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>
<div class="block">Intermediate updates to accumulables during this task.</div>
</dd>
<dt><a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><span class="strong">Accumulator</span></a>&lt;<a href="./org/apache/spark/Accumulator.html" title="type parameter in Accumulator">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">A simpler value of <a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark"><code>Accumulable</code></a> where the result type being accumulated is the same
 as the types of elements being merged, i.e.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulator.html#Accumulator(T, org.apache.spark.AccumulatorParam, scala.Option)">Accumulator(T, AccumulatorParam&lt;T&gt;, Option&lt;String&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulator.html#Accumulator(T, org.apache.spark.AccumulatorParam)">Accumulator(T, AccumulatorParam&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark">Accumulator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(int)">accumulator(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> integer variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(int, java.lang.String)">accumulator(int, String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> integer variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(double)">accumulator(double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> double variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(double, java.lang.String)">accumulator(double, String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> double variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(T, org.apache.spark.AccumulatorParam)">accumulator(T, AccumulatorParam&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> variable of a given type, which tasks can "add"
 values to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#accumulator(T, java.lang.String, org.apache.spark.AccumulatorParam)">accumulator(T, String, AccumulatorParam&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> variable of a given type, which tasks can "add"
 values to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#accumulator(T, org.apache.spark.AccumulatorParam)">accumulator(T, AccumulatorParam&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> variable of a given type, which tasks can "add"
 values to using the <code>+=</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#accumulator(T, java.lang.String, org.apache.spark.AccumulatorParam)">accumulator(T, String, AccumulatorParam&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> variable of a given type, with a name for display
 in the Spark UI.</div>
</dd>
<dt><a href="./org/apache/spark/AccumulatorParam.html" title="interface in org.apache.spark"><span class="strong">AccumulatorParam</span></a>&lt;<a href="./org/apache/spark/AccumulatorParam.html" title="type parameter in AccumulatorParam">T</a>&gt; - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">A simpler version of <a href="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark"><code>AccumulableParam</code></a> where the only data type you can add
 in is the same type as the accumulated value.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#active()">active()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#activeStages()">activeStages()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#actor()">actor()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver"><span class="strong">ActorHelper</span></a> - Interface in <a href="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A receiver trait to be mixed in with your Actor to gain access to
 the API for pushing received data into Spark Streaming for being processed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy)">actorStream(Props, String, StorageLevel, SupervisorStrategy)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented actor receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel)">actorStream(Props, String, StorageLevel)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented actor receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#actorStream(akka.actor.Props, java.lang.String)">actorStream(Props, String)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented actor receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#actorStream(akka.actor.Props, java.lang.String, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy, scala.reflect.ClassTag)">actorStream(Props, String, StorageLevel, SupervisorStrategy, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented actor receiver.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html" title="class in org.apache.spark.streaming.receiver"><span class="strong">ActorSupervisorStrategy</span></a> - Class in <a href="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A helper with set of defaults for supervisor strategy</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html#ActorSupervisorStrategy()">ActorSupervisorStrategy()</a></span> - Constructor for class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html" title="class in org.apache.spark.streaming.receiver">ActorSupervisorStrategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#actorSystem()">actorSystem()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#add(T)">add(T)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>
<div class="block">Add more data to this accumulator / accumulable</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#add(org.apache.spark.mllib.linalg.Vector)">add(Vector)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</a></dt>
<dd>
<div class="block">Adds a new document.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#add(org.apache.spark.mllib.linalg.Vector)">add(Vector)</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>
<div class="block">Add a new sample to this summarizer, and update the statistical summary.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#add(org.apache.spark.util.Vector)">add(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/AccumulableParam.html#addAccumulator(R, T)">addAccumulator(R, T)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark">AccumulableParam</a></dt>
<dd>
<div class="block">Add additional data to the accumulator value.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/AccumulatorParam.html#addAccumulator(T, T)">addAccumulator(T, T)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/AccumulatorParam.html" title="interface in org.apache.spark">AccumulatorParam</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#addedFiles()">addedFiles()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#addedJars()">addedJars()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#addFile(java.lang.String)">addFile(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Add a file to be downloaded with this Spark job on every node.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#addFile(java.lang.String)">addFile(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Add a file to be downloaded with this Spark job on every node.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/AccumulableParam.html#addInPlace(R, R)">addInPlace(R, R)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark">AccumulableParam</a></dt>
<dd>
<div class="block">Merge two accumulated values together.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#addInPlace(double, double)">addInPlace(double, double)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#addInPlace(float, float)">addInPlace(float, float)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#addInPlace(int, int)">addInPlace(int, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#addInPlace(long, long)">addInPlace(long, long)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#addInPlace(org.apache.spark.util.Vector)">addInPlace(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.VectorAccumParam$.html#addInPlace(org.apache.spark.util.Vector, org.apache.spark.util.Vector)">addInPlace(Vector, Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#addJar(java.lang.String)">addJar(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Adds a JAR dependency for all tasks to be executed on this SparkContext in the future.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#addJar(java.lang.String)">addJar(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Adds a JAR dependency for all tasks to be executed on this SparkContext in the future.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#addLocalConfiguration(java.lang.String, int, int, int, org.apache.hadoop.mapred.JobConf)">addLocalConfiguration(String, int, int, int, JobConf)</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>
<div class="block">Add Hadoop configuration specific to a single partition and attempt.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#addOnCompleteCallback(scala.Function0)">addOnCompleteCallback(Function0&lt;BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>
<div class="block">Add a callback function to be executed on task completion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#addSparkListener(org.apache.spark.scheduler.SparkListener)">addSparkListener(SparkListener)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Register a listener to receive up-calls from events that happen during execution.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#addStreamingListener(org.apache.spark.streaming.scheduler.StreamingListener)">addStreamingListener(StreamingListener)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Add a <a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><code>StreamingListener</code></a> object for
 receiving system events related to streaming.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#addStreamingListener(org.apache.spark.streaming.scheduler.StreamingListener)">addStreamingListener(StreamingListener)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Add a <a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><code>StreamingListener</code></a> object for
 receiving system events related to streaming.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#addTaskCompletionListener(org.apache.spark.util.TaskCompletionListener)">addTaskCompletionListener(TaskCompletionListener)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>
<div class="block">Add a (Java friendly) listener to be executed on task completion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#addTaskCompletionListener(scala.Function1)">addTaskCompletionListener(Function1&lt;TaskContext, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>
<div class="block">Add a listener in the form of a Scala closure to be executed on task completion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#aggregate(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">aggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Aggregate the elements of each partition, and then the results for all the partitions, using
 given combine functions and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#aggregate(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregate(U, Function2&lt;U, T, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Aggregate the elements of each partition, and then the results for all the partitions, using
 given combine functions and a neutral "zero value".</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution"><span class="strong">Aggregate</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Groups input data by <code>groupingExpressions</code> and computes the <code>aggregateExpressions</code> for each
 group.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#Aggregate(boolean, scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan)">Aggregate(boolean, Seq&lt;Expression&gt;, Seq&lt;NamedExpression&gt;, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html#aggregate()">aggregate()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html" title="class in org.apache.spark.sql.execution">Aggregate.ComputedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#aggregate(scala.collection.Seq)">aggregate(Seq&lt;Expression&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Performs an aggregation over all Rows in this RDD.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html" title="class in org.apache.spark.sql.execution"><span class="strong">Aggregate.ComputedAggregate</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">An aggregate that needs to be computed for each row in a group.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html#Aggregate.ComputedAggregate(org.apache.spark.sql.catalyst.expressions.AggregateExpression, org.apache.spark.sql.catalyst.expressions.AggregateExpression, org.apache.spark.sql.catalyst.expressions.AttributeReference)">Aggregate.ComputedAggregate(AggregateExpression, AggregateExpression, AttributeReference)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html" title="class in org.apache.spark.sql.execution">Aggregate.ComputedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate$.html" title="class in org.apache.spark.sql.execution"><span class="strong">Aggregate.ComputedAggregate$</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate$.html#Aggregate.ComputedAggregate$()">Aggregate.ComputedAggregate$()</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate$.html" title="class in org.apache.spark.sql.execution">Aggregate.ComputedAggregate$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#aggregateByKey(U, org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">aggregateByKey(U, Partitioner, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#aggregateByKey(U, int, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">aggregateByKey(U, int, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#aggregateByKey(U, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">aggregateByKey(U, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, org.apache.spark.Partitioner, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregateByKey(U, Partitioner, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, int, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregateByKey(U, int, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#aggregateByKey(U, scala.Function2, scala.Function2, scala.reflect.ClassTag)">aggregateByKey(U, Function2&lt;U, V, U&gt;, Function2&lt;U, U, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Aggregate the values of each key, using given combine functions and a neutral "zero value".</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/AggregateEvaluation.html" title="class in org.apache.spark.sql.execution"><span class="strong">AggregateEvaluation</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/AggregateEvaluation.html#AggregateEvaluation(scala.collection.Seq, scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.catalyst.expressions.Expression)">AggregateEvaluation(Seq&lt;Attribute&gt;, Seq&lt;Expression&gt;, Seq&lt;Expression&gt;, Expression)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/AggregateEvaluation.html" title="class in org.apache.spark.sql.execution">AggregateEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#aggregateExpressions()">aggregateExpressions()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#aggregateExpressions()">aggregateExpressions()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark"><span class="strong">Aggregator</span></a>&lt;<a href="./org/apache/spark/Aggregator.html" title="type parameter in Aggregator">K</a>,<a href="./org/apache/spark/Aggregator.html" title="type parameter in Aggregator">V</a>,<a href="./org/apache/spark/Aggregator.html" title="type parameter in Aggregator">C</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A set of functions used to aggregate data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#Aggregator(scala.Function1, scala.Function2, scala.Function2)">Aggregator(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#aggregator()">aggregator()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration"><span class="strong">Algo</span></a> - Class in <a href="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</a></dt>
<dd>
<div class="block">:: Experimental ::
 Enum to select the algorithm for the decision tree</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Algo.html#Algo()">Algo()</a></span> - Constructor for class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration">Algo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#algo()">algo()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#algo()">algo()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#algorithm()">algorithm()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#ALL_COMPRESSION_CODECS()">ALL_COMPRESSION_CODECS()</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/annotation/AlphaComponent.html" title="annotation in org.apache.spark.annotation"><span class="strong">AlphaComponent</span></a> - Annotation Type in <a href="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</a></dt>
<dd>
<div class="block">A new component of Spark which may have unstable API's.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html#alreadyPlanned()">alreadyPlanned()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution">SparkLogicalPlan</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation"><span class="strong">ALS</span></a> - Class in <a href="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</a></dt>
<dd>
<div class="block">Alternating Least Squares matrix factorization.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#ALS()">ALS()</a></span> - Constructor for class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Constructs an ALS instance with default parameters: {numBlocks: -1, rank: 10, iterations: 10,
 lambda: 0.01, implicitPrefs: false, alpha: 1.0}.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation"><span class="strong">ALS.BlockStats</span></a> - Class in <a href="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Statistics of a block in ALS computation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#ALS.BlockStats(java.lang.String, int, long, long, long, long)">ALS.BlockStats(String, int, long, long, long, long)</a></span> - Constructor for class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats$.html" title="class in org.apache.spark.mllib.recommendation"><span class="strong">ALS.BlockStats$</span></a> - Class in <a href="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats$.html#ALS.BlockStats$()">ALS.BlockStats$()</a></span> - Constructor for class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats$.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#analyze(java.lang.String)">analyze(String)</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>
<div class="block">Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#analyzeBlocks(org.apache.spark.rdd.RDD, int, int)">analyzeBlocks(RDD&lt;Rating&gt;, int, int)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Given an RDD of ratings, number of user blocks, and number of product blocks, computes the
 statistics of each block in ALS computation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.QueryExecution.html#analyzed()">analyzed()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext.QueryExecution</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">AnalyzeTable</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Analyzes the given table in the current database to generate statistics, which will be
 used in query optimizations.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html#AnalyzeTable(java.lang.String)">AnalyzeTable(String)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html" title="class in org.apache.spark.sql.hive.execution">AnalyzeTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#ANY()">ANY()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#appendBias(org.apache.spark.mllib.linalg.Vector)">appendBias(Vector)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Returns a new vector with <code>1.0</code> (bias) appended to the input vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#apply(int)">apply(int)</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrix.html#apply(int, int)">apply(int, int)</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</a></dt>
<dd>
<div class="block">Gets the (i, j)-th element.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#apply(int)">apply(int)</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>
<div class="block">Gets the value of the ith element.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#apply(long, java.lang.String, scala.Option, java.lang.String)">apply(long, String, Option&lt;String&gt;, String)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#apply(long, java.lang.String, java.lang.String)">apply(long, String, String)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#apply(java.lang.String)">apply(String)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>
<div class="block">Converts a BlockId "name" String back into a BlockId.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#apply(java.lang.String, java.lang.String, int, int)">apply(String, String, int, int)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>
<div class="block">Returns a <a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage"><code>BlockManagerId</code></a> for the given configuration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#apply(java.io.ObjectInput)">apply(ObjectInput)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#apply(boolean, boolean, boolean, boolean, int)">apply(boolean, boolean, boolean, boolean, int)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Create a new StorageLevel object without setting useOffHeap.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#apply(boolean, boolean, boolean, int)">apply(boolean, boolean, boolean, int)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Create a new StorageLevel object.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#apply(int, int)">apply(int, int)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Create a new StorageLevel object from its integer representation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#apply(java.io.ObjectInput)">apply(ObjectInput)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Read StorageLevel object from ObjectInput stream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Milliseconds.html#apply(long)">apply(long)</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Milliseconds.html" title="class in org.apache.spark.streaming">Milliseconds</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Minutes.html#apply(long)">apply(long)</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Minutes.html" title="class in org.apache.spark.streaming">Minutes</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Seconds.html#apply(long)">apply(long)</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Seconds.html" title="class in org.apache.spark.streaming">Seconds</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#apply(scala.collection.TraversableOnce)">apply(TraversableOnce&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Build a StatCounter from a list of values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#apply(scala.collection.Seq)">apply(Seq&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Build a StatCounter from a list of values passed as variable-length arguments.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#apply(int)">apply(int)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD, java.lang.Class)">applySchema(JavaRDD&lt;?&gt;, Class&lt;?&gt;)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#applySchema(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.api.java.StructType)">applySchema(JavaRDD&lt;Row&gt;, StructType)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Creates a JavaSchemaRDD from an RDD containing Rows by applying a schema to this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#applySchema(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">applySchema(RDD&lt;Row&gt;, StructType)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Creates a <a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a> from an <code>RDD</code> containing <code>Row</code>s by applying a schema to this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#appName()">appName()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#appName()">appName()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#appName()">appName()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#ApproxHist()">ApproxHist()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#areaUnderPR()">areaUnderPR()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Computes the area under the precision-recall curve.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#areaUnderROC()">areaUnderROC()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Computes the area under the receiver operating characteristic (ROC) curve.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/ArrayType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">ArrayType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing Lists.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#as(scala.Symbol)">as(Symbol)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Applies a qualifier to the attributes of this relation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/DeserializationStream.html#asIterator()">asIterator()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</a></dt>
<dd>
<div class="block">Read the elements of this stream through an iterator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#asRDDId()">asRDDId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd"><span class="strong">AsyncRDDActions</span></a>&lt;<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="type parameter in AsyncRDDActions">T</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">:: Experimental ::
 A set of asynchronous RDD actions available through an implicit conversion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/AsyncRDDActions.html#AsyncRDDActions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">AsyncRDDActions(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#attempt()">attempt()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#attemptId()">attemptId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#attemptId()">attemptId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#attributes()">attributes()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#attributes()">attributes()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination()">awaitTermination()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Wait for the execution to stop.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#awaitTermination(long)">awaitTermination(long)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Wait for the execution to stop.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#awaitTermination()">awaitTermination()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Wait for the execution to stop.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#awaitTermination(long)">awaitTermination(long)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Wait for the execution to stop.</div>
</dd>
</dl>
<a name="_B_">
<!--   -->
</a>
<h2 class="title">B</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#baseLogicalPlan()">baseLogicalPlan()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#baseLogicalPlan()">baseLogicalPlan()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#baseSchemaRDD()">baseSchemaRDD()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#baseSchemaRDD()">baseSchemaRDD()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">BatchInfo</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Class having information on completed batches.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#BatchInfo(org.apache.spark.streaming.Time, scala.collection.immutable.Map, long, scala.Option, scala.Option)">BatchInfo(Time, Map&lt;Object, ReceivedBlockInfo[]&gt;, long, Option&lt;Object&gt;, Option&lt;Object&gt;)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html#batchInfo()">batchInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchCompleted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html#batchInfo()">batchInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchStarted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html#batchInfo()">batchInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchSubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html#batchInfos()">batchInfos()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution"><span class="strong">BatchPythonEvaluation</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Uses PythonRDD to evaluate a <code>PythonUDF</code>, one partition of tuples at a time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html#BatchPythonEvaluation(org.apache.spark.sql.execution.PythonUDF, scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan)">BatchPythonEvaluation(PythonUDF, Seq&lt;Attribute&gt;, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution">BatchPythonEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#batchTime()">batchTime()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random"><span class="strong">BernoulliSampler</span></a>&lt;<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="type parameter in BernoulliSampler">T</a>&gt; - Class in <a href="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A sampler based on Bernoulli trials.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#BernoulliSampler(double, double, boolean)">BernoulliSampler(double, double, boolean)</a></span> - Constructor for class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#BernoulliSampler(double)">BernoulliSampler(double)</a></span> - Constructor for class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation"><span class="strong">BinaryClassificationMetrics</span></a> - Class in <a href="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</a></dt>
<dd>
<div class="block">:: Experimental ::
 Evaluator for binary classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#BinaryClassificationMetrics(org.apache.spark.rdd.RDD)">BinaryClassificationMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</a></span> - Constructor for class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/DataValidators.html#binaryLabelValidator()">binaryLabelValidator()</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util">DataValidators</a></dt>
<dd>
<div class="block">Function to check if labels used for classification are either zero or one.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/BinaryType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">BinaryType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing byte[] values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#BinaryType">BinaryType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the BinaryType object.</div>
</dd>
<dt><a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage"><span class="strong">BlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Identifies a particular Block of data, usually associated with a single file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#BlockId()">BlockId()</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#blockManager()">blockManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#blockManagerId()">blockManagerId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html#blockManagerId()">blockManagerId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerRemoved</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage"><span class="strong">BlockManagerId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 This class represent an unique identifier for a BlockManager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#blockManagerId()">blockManagerId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#blockManagerIdCache()">blockManagerIdCache()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#blockManagerIds()">blockManagerIds()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/BlockNotFoundException.html" title="class in org.apache.spark.storage"><span class="strong">BlockNotFoundException</span></a> - Exception in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockNotFoundException.html#BlockNotFoundException(java.lang.String)">BlockNotFoundException(String)</a></span> - Constructor for exception org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockNotFoundException.html" title="class in org.apache.spark.storage">BlockNotFoundException</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#blocks()">blocks()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the blocks stored in this block manager.</div>
</dd>
<dt><a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage"><span class="strong">BlockStatus</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#BlockStatus(org.apache.spark.storage.StorageLevel, long, long, long)">BlockStatus(StorageLevel, long, long, long)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FetchFailed.html#bmAddress()">bmAddress()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/BooleanType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">BooleanType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing boolean and Boolean values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#BooleanType">BooleanType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the BooleanType object.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#booleanWritableConverter()">booleanWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#boolToBoolWritable(boolean)">boolToBoolWritable(boolean)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#boundCondition()">boundCondition()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#boundCondition()">boundCondition()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial"><span class="strong">BoundedDouble</span></a> - Class in <a href="./org/apache/spark/partial/package-summary.html">org.apache.spark.partial</a></dt>
<dd>
<div class="block">:: Experimental ::
 A Double value with error bars and associated confidence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/BoundedDouble.html#BoundedDouble(double, double, double, double)">BoundedDouble(double, double, double, double)</a></span> - Constructor for class org.apache.spark.partial.<a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#boundGenerator()">boundGenerator()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#broadcast(T)">broadcast(T)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Broadcast a read-only variable to the cluster, returning a
 <a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><code>Broadcast</code></a> object for reading it in distributed functions.</div>
</dd>
<dt><a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><span class="strong">Broadcast</span></a>&lt;<a href="./org/apache/spark/broadcast/Broadcast.html" title="type parameter in Broadcast">T</a>&gt; - Class in <a href="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</a></dt>
<dd>
<div class="block">A broadcast variable.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/Broadcast.html#Broadcast(long, scala.reflect.ClassTag)">Broadcast(long, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#broadcast(T, scala.reflect.ClassTag)">broadcast(T, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Broadcast a read-only variable to the cluster, returning a
 <a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><code>Broadcast</code></a> object for reading it in distributed functions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#broadcast()">broadcast()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#broadcast()">broadcast()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#BROADCAST()">BROADCAST()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage"><span class="strong">BroadcastBlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BroadcastBlockId.html#BroadcastBlockId(long, java.lang.String)">BroadcastBlockId(long, String)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast"><span class="strong">BroadcastFactory</span></a> - Interface in <a href="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 An interface for all the broadcast implementations in Spark (to allow
 multiple broadcast implementations).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#broadcastFuture()">broadcastFuture()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution"><span class="strong">BroadcastHashJoin</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Performs an inner hash join of two child relations.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#BroadcastHashJoin(scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.execution.BuildSide, org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">BroadcastHashJoin(Seq&lt;Expression&gt;, Seq&lt;Expression&gt;, BuildSide, SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BroadcastBlockId.html#broadcastId()">broadcastId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#broadcastManager()">broadcastManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution"><span class="strong">BroadcastNestedLoopJoin</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#BroadcastNestedLoopJoin(org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.BuildSide, org.apache.spark.sql.catalyst.plans.JoinType, scala.Option)">BroadcastNestedLoopJoin(SparkPlan, SparkPlan, BuildSide, JoinType, Option&lt;Expression&gt;)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#build(org.apache.spark.mllib.tree.model.Node[])">build(Node[])</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>
<div class="block">build the left node and right nodes if not leaf</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#buildKeys()">buildKeys()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/BuildLeft.html" title="class in org.apache.spark.sql.execution"><span class="strong">BuildLeft</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BuildLeft.html#BuildLeft()">BuildLeft()</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BuildLeft.html" title="class in org.apache.spark.sql.execution">BuildLeft</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#buildPlan()">buildPlan()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Project.html#buildProjection()">buildProjection()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution">Project</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/BuildRight.html" title="class in org.apache.spark.sql.execution"><span class="strong">BuildRight</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BuildRight.html#BuildRight()">BuildRight()</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BuildRight.html" title="class in org.apache.spark.sql.execution">BuildRight</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#buildSide()">buildSide()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#buildSide()">buildSide()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/BuildSide.html" title="class in org.apache.spark.sql.execution"><span class="strong">BuildSide</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BuildSide.html#BuildSide()">BuildSide()</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BuildSide.html" title="class in org.apache.spark.sql.execution">BuildSide</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#buildSide()">buildSide()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#buildSide()">buildSide()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#buildSide()">buildSide()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#buildSideKeyGenerator()">buildSideKeyGenerator()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#bytesToBytesWritable(byte[])">bytesToBytesWritable(byte[])</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#bytesWritableConverter()">bytesWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/ByteType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">ByteType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing byte and Byte values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#ByteType">ByteType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the ByteType object.</div>
</dd>
</dl>
<a name="_C_">
<!--   -->
</a>
<h2 class="title">C</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#cache()">cache()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cache()">cache()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#cache()">cache()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#cache()">cache()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#cache()">cache()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#cache()">cache()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cache()">cache()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#cache()">cache()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/CacheCommand.html" title="class in org.apache.spark.sql.execution"><span class="strong">CacheCommand</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CacheCommand.html#CacheCommand(java.lang.String, boolean, org.apache.spark.sql.SQLContext)">CacheCommand(String, boolean, SQLContext)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CacheCommand.html" title="class in org.apache.spark.sql.execution">CacheCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#cacheManager()">cacheManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#cacheTable(java.lang.String)">cacheTable(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Caches the specified table in-memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#cacheTables()">cacheTables()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Entropy.html#calculate(double[], double)">calculate(double[], double)</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 information calculation for multiclass classification</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Entropy.html#calculate(double, double, double)">calculate(double, double, double)</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 variance calculation</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Gini.html#calculate(double[], double)">calculate(double[], double)</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 information calculation for multiclass classification</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Gini.html#calculate(double, double, double)">calculate(double, double, double)</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 variance calculation</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Impurity.html#calculate(double[], double)">calculate(double[], double)</a></span> - Method in interface org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Impurity.html" title="interface in org.apache.spark.mllib.tree.impurity">Impurity</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 information calculation for multiclass classification</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Impurity.html#calculate(double, double, double)">calculate(double, double, double)</a></span> - Method in interface org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Impurity.html" title="interface in org.apache.spark.mllib.tree.impurity">Impurity</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 information calculation for regression</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Variance.html#calculate(double[], double)">calculate(double[], double)</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 information calculation for multiclass classification</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Variance.html#calculate(double, double, double)">calculate(double, double, double)</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 variance calculation</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html#call(T)">call(T)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFlatMapFunction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/DoubleFunction.html#call(T)">call(T)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/DoubleFunction.html" title="interface in org.apache.spark.api.java.function">DoubleFunction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/FlatMapFunction.html#call(T)">call(T)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/FlatMapFunction2.html#call(T1, T2)">call(T1, T2)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="interface in org.apache.spark.api.java.function">FlatMapFunction2</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/Function.html#call(T1)">call(T1)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function">Function</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/Function2.html#call(T1, T2)">call(T1, T2)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function">Function2</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/Function3.html#call(T1, T2, T3)">call(T1, T2, T3)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/Function3.html" title="interface in org.apache.spark.api.java.function">Function3</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/PairFlatMapFunction.html#call(T)">call(T)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function">PairFlatMapFunction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/PairFunction.html#call(T)">call(T)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/PairFunction.html" title="interface in org.apache.spark.api.java.function">PairFunction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/function/VoidFunction.html#call(T)">call(T)</a></span> - Method in interface org.apache.spark.api.java.function.<a href="./org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function">VoidFunction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF1.html#call(T1)">call(T1)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF1.html" title="interface in org.apache.spark.sql.api.java">UDF1</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF10.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF10.html" title="interface in org.apache.spark.sql.api.java">UDF10</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF11.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF11.html" title="interface in org.apache.spark.sql.api.java">UDF11</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF12.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF12.html" title="interface in org.apache.spark.sql.api.java">UDF12</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF13.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF13.html" title="interface in org.apache.spark.sql.api.java">UDF13</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF14.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF14.html" title="interface in org.apache.spark.sql.api.java">UDF14</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF15.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF15.html" title="interface in org.apache.spark.sql.api.java">UDF15</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF16.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF16.html" title="interface in org.apache.spark.sql.api.java">UDF16</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF17.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF17.html" title="interface in org.apache.spark.sql.api.java">UDF17</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF18.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF18.html" title="interface in org.apache.spark.sql.api.java">UDF18</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF19.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF19.html" title="interface in org.apache.spark.sql.api.java">UDF19</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF2.html#call(T1, T2)">call(T1, T2)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF2.html" title="interface in org.apache.spark.sql.api.java">UDF2</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF20.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF20.html" title="interface in org.apache.spark.sql.api.java">UDF20</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF21.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF21.html" title="interface in org.apache.spark.sql.api.java">UDF21</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF22.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21, T22)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18, T19, T20, T21, T22)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF22.html" title="interface in org.apache.spark.sql.api.java">UDF22</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF3.html#call(T1, T2, T3)">call(T1, T2, T3)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF3.html" title="interface in org.apache.spark.sql.api.java">UDF3</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF4.html#call(T1, T2, T3, T4)">call(T1, T2, T3, T4)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF4.html" title="interface in org.apache.spark.sql.api.java">UDF4</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF5.html#call(T1, T2, T3, T4, T5)">call(T1, T2, T3, T4, T5)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF5.html" title="interface in org.apache.spark.sql.api.java">UDF5</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF6.html#call(T1, T2, T3, T4, T5, T6)">call(T1, T2, T3, T4, T5, T6)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF6.html" title="interface in org.apache.spark.sql.api.java">UDF6</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF7.html#call(T1, T2, T3, T4, T5, T6, T7)">call(T1, T2, T3, T4, T5, T6, T7)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF7.html" title="interface in org.apache.spark.sql.api.java">UDF7</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF8.html#call(T1, T2, T3, T4, T5, T6, T7, T8)">call(T1, T2, T3, T4, T5, T6, T7, T8)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF8.html" title="interface in org.apache.spark.sql.api.java">UDF8</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/UDF9.html#call(T1, T2, T3, T4, T5, T6, T7, T8, T9)">call(T1, T2, T3, T4, T5, T6, T7, T8, T9)</a></span> - Method in interface org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/UDF9.html" title="interface in org.apache.spark.sql.api.java">UDF9</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#cancel()">cancel()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#cancel()">cancel()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">Cancels the execution of this action.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SimpleFutureAction.html#cancel()">cancel()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#cancelAllJobs()">cancelAllJobs()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Cancel all jobs that have been scheduled or are running.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#cancelAllJobs()">cancelAllJobs()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Cancel all jobs that have been scheduled or are running.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#cancelJobGroup(java.lang.String)">cancelJobGroup(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Cancel active jobs for the specified group.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#cancelJobGroup(java.lang.String)">cancelJobGroup(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Cancel active jobs for the specified group.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#cancelled()">cancelled()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>
<div class="block">Returns whether the promise has been cancelled.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#canEqual(java.lang.Object)">canEqual(Object)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#canEqual(java.lang.Object)">canEqual(Object)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#cartesian(org.apache.spark.api.java.JavaRDDLike)">cartesian(JavaRDDLike&lt;U, ?&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#cartesian(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">cartesian(RDD&lt;U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of
 elements (a, b) where a is in <code>this</code> and b is in <code>other</code>.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/CartesianProduct.html" title="class in org.apache.spark.sql.execution"><span class="strong">CartesianProduct</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CartesianProduct.html#CartesianProduct(org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">CartesianProduct(SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CartesianProduct.html" title="class in org.apache.spark.sql.execution">CartesianProduct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html#Categorical()">Categorical()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration">FeatureType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#categoricalFeaturesInfo()">categoricalFeaturesInfo()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Split.html#categories()">categories()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#category()">category()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#checkpoint()">checkpoint()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Mark this RDD for checkpointing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#checkpoint()">checkpoint()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#checkpoint()">checkpoint()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Mark this RDD for checkpointing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#checkpoint(org.apache.spark.streaming.Duration)">checkpoint(Duration)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Enable periodic checkpointing of RDDs of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#checkpoint(java.lang.String)">checkpoint(String)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Sets the context to periodically checkpoint the DStream operations for master
 fault-tolerance.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#checkpoint(org.apache.spark.streaming.Duration)">checkpoint(Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Enable periodic checkpointing of RDDs of this DStream</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#checkpoint(java.lang.String)">checkpoint(String)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Set the context to periodically checkpoint the DStream operations for driver
 fault-tolerance.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#checkpointData()">checkpointData()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#checkpointData()">checkpointData()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#checkpointDir()">checkpointDir()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#checkpointDir()">checkpointDir()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#checkpointDuration()">checkpointDuration()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#checkpointDuration()">checkpointDuration()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution">BatchPythonEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/DescribeCommand.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/DescribeCommand.html" title="class in org.apache.spark.sql.execution">DescribeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Distinct.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution">Distinct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/EvaluatePython.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/EvaluatePython.html" title="class in org.apache.spark.sql.execution">EvaluatePython</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Exchange.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution">Exchange</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Filter.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution">Filter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Limit.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution">Limit</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/OutputFaker.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/OutputFaker.html" title="class in org.apache.spark.sql.execution">OutputFaker</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Project.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution">Project</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#child()">child()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#child()">child()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#child()">child()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html#child()">child()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet">InsertIntoParquetTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html#children()">children()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution">BatchPythonEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/OutputFaker.html#children()">children()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/OutputFaker.html" title="class in org.apache.spark.sql.execution">OutputFaker</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html#children()">children()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution">SparkLogicalPlan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Union.html#children()">children()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Union.html" title="class in org.apache.spark.sql.execution">Union</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)">chiSqTest(Vector, Vector)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Conduct Pearson's chi-squared goodness of fit test of the observed data against the
 expected distribution.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.mllib.linalg.Vector)">chiSqTest(Vector)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Conduct Pearson's chi-squared goodness of fit test of the observed data against the uniform
 distribution, with each category having an expected frequency of <code>1 / observed.size</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.mllib.linalg.Matrix)">chiSqTest(Matrix)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Conduct Pearson's independence test on the input contingency matrix, which cannot contain
 negative entries or columns or rows that sum up to 0.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#chiSqTest(org.apache.spark.rdd.RDD)">chiSqTest(RDD&lt;LabeledPoint&gt;)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Conduct Pearson's independence test for every feature against the label across the input RDD.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test"><span class="strong">ChiSqTestResult</span></a> - Class in <a href="./org/apache/spark/mllib/stat/test/package-summary.html">org.apache.spark.mllib.stat.test</a></dt>
<dd>
<div class="block">:: Experimental ::
 Object containing the test results for the chi-squared hypothesis test.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Algo.html#Classification()">Classification()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration">Algo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification"><span class="strong">ClassificationModel</span></a> - Interface in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents a classification model that predicts to which of a set of categories an example
 belongs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExceptionFailure.html#className()">className()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/env/EnvironmentListener.html#classpathEntries()">classpathEntries()</a></span> - Method in class org.apache.spark.ui.env.<a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#classTag()">classTag()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#classTag()">classTag()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#classTag()">classTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#cleaner()">cleaner()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#clearCallSite()">clearCallSite()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Pass-through to SparkContext.setCallSite.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#clearCallSite()">clearCallSite()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Clear the thread-local property for overriding the call sites
 of actions and RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#clearDependencies()">clearDependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#clearDependencies()">clearDependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#clearDependencies()">clearDependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#clearFiles()">clearFiles()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Clear the job's list of files added by <code>addFile</code> so that they do not get downloaded to
 any new nodes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#clearFiles()">clearFiles()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Clear the job's list of files added by <code>addFile</code> so that they do not get downloaded to
 any new nodes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#clearJars()">clearJars()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Clear the job's list of JARs added by <code>addJar</code> so that they do not get downloaded to
 any new nodes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#clearJars()">clearJars()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Clear the job's list of JARs added by <code>addJar</code> so that they do not get downloaded to
 any new nodes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#clearJobGroup()">clearJobGroup()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Clear the current thread's job group ID and its description.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#clearJobGroup()">clearJobGroup()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Clear the current thread's job group ID and its description.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#clearThreshold()">clearThreshold()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</a></dt>
<dd>
<div class="block">:: Experimental ::
 Clears the threshold so that <code>predict</code> will output raw prediction scores.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMModel.html#clearThreshold()">clearThreshold()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</a></dt>
<dd>
<div class="block">:: Experimental ::
 Clears the threshold so that <code>predict</code> will output raw prediction scores.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#clone()">clone()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Copy this object</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#clone()">clone()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#clone()">clone()</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/PoissonSampler.html#clone()">clone()</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/RandomSampler.html#clone()">clone()</a></span> - Method in interface org.apache.spark.util.random.<a href="./org/apache/spark/util/random/RandomSampler.html" title="interface in org.apache.spark.util.random">RandomSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#cloneComplement()">cloneComplement()</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>
<div class="block">Return a sampler that is the complement of the range specified of the current sampler.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/DeserializationStream.html#close()">close()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializationStream.html#close()">close()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#closureSerializer()">closureSerializer()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#clusterCenters()">clusterCenters()</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#coalesce(int)">coalesce(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#coalesce(int, boolean)">coalesce(int, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#coalesce(int)">coalesce(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#coalesce(int, boolean)">coalesce(int, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#coalesce(int)">coalesce(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#coalesce(int, boolean)">coalesce(int, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#coalesce(int, boolean, scala.math.Ordering)">coalesce(int, boolean, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#coalesce(int, boolean)">coalesce(int, boolean)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return a new RDD that is reduced into <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#coalesce(int, boolean, scala.math.Ordering)">coalesce(int, boolean, Ordering&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#codegenEnabled()">codegenEnabled()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">cogroup(JavaPairRDD&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD)">cogroup(JavaPairRDD&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)">cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)">cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, int)">cogroup(JavaPairRDD&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, int)">cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#cogroup(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, int)">cogroup(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD)">cogroup(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, int)">cogroup(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other</code>, return a resulting RDD that contains a tuple with the
 list of values for that key in <code>this</code> as well as <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)">cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code>, return a resulting RDD that contains a
 tuple with the list of values for that key in <code>this</code>, <code>other1</code> and <code>other2</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#cogroup(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, int)">cogroup(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">For each key k in <code>this</code> or <code>other1</code> or <code>other2</code> or <code>other3</code>,
 return a resulting RDD that contains a tuple with the list of values
 for that key in <code>this</code>, <code>other1</code>, <code>other2</code> and <code>other3</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cogroup(org.apache.spark.streaming.api.java.JavaPairDStream)">cogroup(JavaPairDStream&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cogroup(org.apache.spark.streaming.api.java.JavaPairDStream, int)">cogroup(JavaPairDStream&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#cogroup(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)">cogroup(JavaPairDStream&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">cogroup(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">cogroup(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">cogroup(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd"><span class="strong">CoGroupedRDD</span></a>&lt;<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="type parameter in CoGroupedRDD">K</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A RDD that cogroups its parents.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#CoGroupedRDD(scala.collection.Seq, org.apache.spark.Partitioner)">CoGroupedRDD(Seq&lt;RDD&lt;? extends Product2&lt;K, ?&gt;&gt;&gt;, Partitioner)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#collect()">collect()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an array that contains all of the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#collect()">collect()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an array that contains all of the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#collect(scala.PartialFunction, scala.reflect.ClassTag)">collect(PartialFunction&lt;T, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD that contains all matching values by applying <code>f</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#collect()">collect()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#collect()">collect()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#collectAsMap()">collectAsMap()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return the key-value pairs in this RDD to the master as a Map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#collectAsMap()">collectAsMap()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return the key-value pairs in this RDD to the master as a Map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/AsyncRDDActions.html#collectAsync()">collectAsync()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</a></dt>
<dd>
<div class="block">Returns a future for retrieving all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#collectPartitions(int[])">collectPartitions(int[])</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an array that contains all of the elements in a specific partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#colStats(org.apache.spark.rdd.RDD)">colStats(RDD&lt;Vector&gt;)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Computes column-wise summary statistics for the input RDD[Vector].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#columnPruningPred()">columnPruningPred()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)">combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Generic function to combine the elements for each key using a custom set of aggregation
 functions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, int)">combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Simplified version of combineByKey that hash-partitions the output RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2)">combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Simplified version of combineByKey that hash-partitions the resulting RDD using the existing
 partitioner/parallelism level.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, org.apache.spark.serializer.Serializer)">combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean, Serializer)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Generic function to combine the elements for each key using a custom set of aggregation
 functions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, int)">combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Simplified version of combineByKey that hash-partitions the output RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2)">combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Simplified version of combineByKey that hash-partitions the resulting RDD using the
 existing partitioner/parallelism level.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)">combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Combine elements of each key in DStream's RDDs using custom function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#combineByKey(org.apache.spark.api.java.function.Function, org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner, boolean)">combineByKey(Function&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Combine elements of each key in DStream's RDDs using custom function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#combineByKey(scala.Function1, scala.Function2, scala.Function2, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)">combineByKey(Function1&lt;V, C&gt;, Function2&lt;C, V, C&gt;, Function2&lt;C, C, C&gt;, Partitioner, boolean, ClassTag&lt;C&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Combine elements of each key in DStream's RDDs using custom functions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#combineCombinersByKey(scala.collection.Iterator)">combineCombinersByKey(Iterator&lt;Product2&lt;K, C&gt;&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#combineCombinersByKey(scala.collection.Iterator, org.apache.spark.TaskContext)">combineCombinersByKey(Iterator&lt;Product2&lt;K, C&gt;&gt;, TaskContext)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#combineValuesByKey(scala.collection.Iterator)">combineValuesByKey(Iterator&lt;Product2&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#combineValuesByKey(scala.collection.Iterator, org.apache.spark.TaskContext)">combineValuesByKey(Iterator&lt;Product2&lt;K, V&gt;&gt;, TaskContext)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Command.html" title="interface in org.apache.spark.sql.execution"><span class="strong">Command</span></a> - Interface in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html#commands()">commands()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext.TestTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#compare(org.apache.spark.storage.RDDInfo)">compare(RDDInfo)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#completedStages()">completedStages()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#completionTime()">completionTime()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>
<div class="block">Time when all tasks in the stage completed or when the stage was cancelled.</div>
</dd>
<dt><a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark"><span class="strong">ComplexFutureAction</span></a>&lt;<a href="./org/apache/spark/ComplexFutureAction.html" title="type parameter in ComplexFutureAction">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: Experimental ::
 A <a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark"><code>FutureAction</code></a> for actions that could trigger multiple Spark jobs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#ComplexFutureAction()">ComplexFutureAction()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#compressedInputStream(java.io.InputStream)">compressedInputStream(InputStream)</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/LZ4CompressionCodec.html#compressedInputStream(java.io.InputStream)">compressedInputStream(InputStream)</a></span> - Method in class org.apache.spark.io.<a href="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io">LZ4CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/LZFCompressionCodec.html#compressedInputStream(java.io.InputStream)">compressedInputStream(InputStream)</a></span> - Method in class org.apache.spark.io.<a href="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io">LZFCompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/SnappyCompressionCodec.html#compressedInputStream(java.io.InputStream)">compressedInputStream(InputStream)</a></span> - Method in class org.apache.spark.io.<a href="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io">SnappyCompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#compressedOutputStream(java.io.OutputStream)">compressedOutputStream(OutputStream)</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/LZ4CompressionCodec.html#compressedOutputStream(java.io.OutputStream)">compressedOutputStream(OutputStream)</a></span> - Method in class org.apache.spark.io.<a href="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io">LZ4CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/LZFCompressionCodec.html#compressedOutputStream(java.io.OutputStream)">compressedOutputStream(OutputStream)</a></span> - Method in class org.apache.spark.io.<a href="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io">LZFCompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/SnappyCompressionCodec.html#compressedOutputStream(java.io.OutputStream)">compressedOutputStream(OutputStream)</a></span> - Method in class org.apache.spark.io.<a href="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io">SnappyCompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><span class="strong">CompressionCodec</span></a> - Interface in <a href="./org/apache/spark/io/package-summary.html">org.apache.spark.io</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 CompressionCodec allows the customization of choosing different compression implementations
 to be used in block storage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/Gradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization">Gradient</a></dt>
<dd>
<div class="block">Compute the gradient and loss given the features of a single data point.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/Gradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization">Gradient</a></dt>
<dd>
<div class="block">Compute the gradient and loss given the features of a single data point,
 add the gradient to a provided vector to avoid creating new objects, and return loss.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/HingeGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization">HingeGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/HingeGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization">HingeGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/L1Updater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)">compute(Vector, Vector, double, int, double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/L1Updater.html" title="class in org.apache.spark.mllib.optimization">L1Updater</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization">LeastSquaresGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization">LeastSquaresGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LogisticGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LogisticGradient.html#compute(org.apache.spark.mllib.linalg.Vector, double, org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector)">compute(Vector, double, Vector, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/SimpleUpdater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)">compute(Vector, Vector, double, int, double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/SimpleUpdater.html" title="class in org.apache.spark.mllib.optimization">SimpleUpdater</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/SquaredL2Updater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)">compute(Vector, Vector, double, int, double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/SquaredL2Updater.html" title="class in org.apache.spark.mllib.optimization">SquaredL2Updater</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/Updater.html#compute(org.apache.spark.mllib.linalg.Vector, org.apache.spark.mllib.linalg.Vector, double, int, double)">compute(Vector, Vector, double, int, double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/Updater.html" title="class in org.apache.spark.mllib.optimization">Updater</a></dt>
<dd>
<div class="block">Compute an updated value for weights given the gradient, stepSize, iteration number and
 regularization parameter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/JdbcRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/NewHadoopRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PartitionPruningRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd">PartitionPruningRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Implemented by subclasses to compute a given partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#compute(org.apache.spark.Partition, org.apache.spark.TaskContext)">compute(Partition, TaskContext)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#compute(org.apache.spark.streaming.Time)">compute(Time)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Generate an RDD for the given duration</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#compute(org.apache.spark.streaming.Time)">compute(Time)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Method that generates a RDD for the given Duration</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#compute(org.apache.spark.streaming.Time)">compute(Time)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#compute(org.apache.spark.streaming.Time)">compute(Time)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Method that generates a RDD for the given time</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#compute(org.apache.spark.streaming.Time)">compute(Time)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</a></dt>
<dd>
<div class="block">Ask ReceiverInputTracker for received data blocks and generates RDDs with them.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeColumnSummaryStatistics()">computeColumnSummaryStatistics()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Computes column-wise summary statistics.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#computeCost(org.apache.spark.rdd.RDD)">computeCost(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>
<div class="block">Return the K-means cost (sum of squared distances of points to their nearest center) for this
 model on the given data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeCovariance()">computeCovariance()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Computes the covariance matrix, treating each row as an observation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#computeGramianMatrix()">computeGramianMatrix()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>
<div class="block">Computes the Gramian matrix <code>A^T A</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeGramianMatrix()">computeGramianMatrix()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Computes the Gramian matrix <code>A^T A</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#computePreferredLocations(scala.collection.Seq)">computePreferredLocations(Seq&lt;InputFormatInfo&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>
<div class="block">Computes the preferred locations based on input(s) and returned a location to block map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computePrincipalComponents(int)">computePrincipalComponents(int)</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Computes the top k principal components.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#computeSVD(int, boolean, double)">computeSVD(int, boolean, double)</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>
<div class="block">Computes the singular value decomposition of this matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#computeSVD(int, boolean, double)">computeSVD(int, boolean, double)</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Computes singular value decomposition of this matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#condition()">condition()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Filter.html#condition()">condition()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution">Filter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#condition()">condition()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#condition()">condition()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Filter.html#conditionEvaluator()">conditionEvaluator()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution">Filter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#conf()">conf()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#conf()">conf()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#conf()">conf()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/BoundedDouble.html#confidence()">confidence()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#configuration()">configuration()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#CONFIGURATION_INSTANTIATION_LOCK()">CONFIGURATION_INSTANTIATION_LOCK()</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>
<div class="block">Configuration's constructor is not threadsafe (see SPARK-1097 and HADOOP-10456).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#confusionMatrix()">confusionMatrix()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns confusion matrix:
 predicted classes are in columns,
 they are ordered by class label ascending,
 as in "labels"</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#connectionManager()">connectionManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="strong">ConstantInputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="type parameter in ConstantInputDStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</a></dt>
<dd>
<div class="block">An input stream that always returns the same RDD on each timestep.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#ConstantInputDStream(org.apache.spark.streaming.StreamingContext, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">ConstantInputDStream(StreamingContext, RDD&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#contains(java.lang.String)">contains(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Does the configuration contain a given parameter?</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#containsBlock(org.apache.spark.storage.BlockId)">containsBlock(BlockId)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return whether the given block is stored in this block manager in O(1) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#containsCachedMetadata(java.lang.String)">containsCachedMetadata(String)</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#context()">context()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">The <a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><code>SparkContext</code></a> that this RDD was created on.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/InterruptibleIterator.html#context()">context()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#context()">context()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">The <a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><code>SparkContext</code></a> that this RDD was created on.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#context()">context()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#context()">context()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return the <a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><code>StreamingContext</code></a> associated with this DStream</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#context()">context()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return the StreamingContext associated with this DStream</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html#Continuous()">Continuous()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration">FeatureType</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><span class="strong">CoordinateMatrix</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents a matrix in coordinate format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#CoordinateMatrix(org.apache.spark.rdd.RDD, long, long)">CoordinateMatrix(RDD&lt;MatrixEntry&gt;, long, long)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#CoordinateMatrix(org.apache.spark.rdd.RDD)">CoordinateMatrix(RDD&lt;MatrixEntry&gt;)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>
<div class="block">Alternative constructor leaving matrix dimensions to be determined automatically.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#copy()">copy()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#copy()">copy()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#copy()">copy()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>
<div class="block">Makes a deep copy of this vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/PoissonGenerator.html#copy()">copy()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomDataGenerator.html#copy()">copy()</a></span> - Method in interface org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="interface in org.apache.spark.mllib.random">RandomDataGenerator</a></dt>
<dd>
<div class="block">Returns a copy of the RandomDataGenerator with a new instance of the rng object used in the
 class when applicable for non-locking concurrent usage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html#copy()">copy()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/UniformGenerator.html#copy()">copy()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#copy()">copy()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Clone this StatCounter</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD)">corr(RDD&lt;Vector&gt;)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Compute the Pearson correlation matrix for the input RDD of Vectors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD, java.lang.String)">corr(RDD&lt;Vector&gt;, String)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Compute the correlation matrix for the input RDD of Vectors using the specified method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">corr(RDD&lt;Object&gt;, RDD&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Compute the Pearson correlation for the input RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#corr(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, java.lang.String)">corr(RDD&lt;Object&gt;, RDD&lt;Object&gt;, String)</a></span> - Static method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>
<div class="block">:: Experimental ::
 Compute the correlation for the input RDDs using the specified method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#count()">count()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return the number of elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#count()">count()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#count()">count()</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#count()">count()</a></span> - Method in interface org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</a></dt>
<dd>
<div class="block">Sample size.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#count()">count()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the number of elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#count()">count()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Return the number of elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#count()">count()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by counting each RDD
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#count()">count()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by counting each RDD
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#count()">count()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#countApprox(long, double)">countApprox(long, double)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#countApprox(long)">countApprox(long)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#countApprox(long, double)">countApprox(long, double)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of count() that returns a potentially incomplete result
 within a timeout, even if not all tasks have finished.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#countApproxDistinct(double)">countApproxDistinct(double)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return approximate number of distinct elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#countApproxDistinct(int, int)">countApproxDistinct(int, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Return approximate number of distinct elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#countApproxDistinct(double)">countApproxDistinct(double)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return approximate number of distinct elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#countApproxDistinctByKey(double, org.apache.spark.Partitioner)">countApproxDistinctByKey(double, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#countApproxDistinctByKey(double, int)">countApproxDistinctByKey(double, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#countApproxDistinctByKey(double)">countApproxDistinctByKey(double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(int, int, org.apache.spark.Partitioner)">countApproxDistinctByKey(int, int, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">:: Experimental ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double, org.apache.spark.Partitioner)">countApproxDistinctByKey(double, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double, int)">countApproxDistinctByKey(double, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#countApproxDistinctByKey(double)">countApproxDistinctByKey(double)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return approximate number of distinct values for each key in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/AsyncRDDActions.html#countAsync()">countAsync()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</a></dt>
<dd>
<div class="block">Returns a future for counting the number of elements in the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#countByKey()">countByKey()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Count the number of elements for each key, and return the result to the master as a Map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#countByKey()">countByKey()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Count the number of elements for each key, and return the result to the master as a Map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#countByKeyApprox(long)">countByKeyApprox(long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#countByKeyApprox(long, double)">countByKeyApprox(long, double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#countByKeyApprox(long, double)">countByKeyApprox(long, double)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of countByKey that can return a partial result if it does
 not finish within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#countByValue()">countByValue()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return the count of each unique value in this RDD as a map of (value, count) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#countByValue(scala.math.Ordering)">countByValue(Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the count of each unique value in this RDD as a map of (value, count) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValue()">countByValue()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains the counts of each distinct value in
 each RDD of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValue(int)">countByValue(int)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains the counts of each distinct value in
 each RDD of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#countByValue(int, scala.math.Ordering)">countByValue(int, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains the counts of each distinct value in
 each RDD of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValueAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">countByValueAndWindow(Duration, Duration)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains the count of distinct elements in
 RDDs in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByValueAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">countByValueAndWindow(Duration, Duration, int)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains the count of distinct elements in
 RDDs in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#countByValueAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, scala.math.Ordering)">countByValueAndWindow(Duration, Duration, int, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains the count of distinct elements in
 RDDs in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#countByValueApprox(long, double)">countByValueApprox(long, double)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">(Experimental) Approximate version of countByValue().</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#countByValueApprox(long)">countByValueApprox(long)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">(Experimental) Approximate version of countByValue().</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#countByValueApprox(long, double, scala.math.Ordering)">countByValueApprox(long, double, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate version of countByValue().</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#countByWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">countByWindow(Duration, Duration)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by counting the number
 of elements in a window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#countByWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">countByWindow(Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by counting the number
 of elements in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#create(boolean, boolean, boolean, int)">create(boolean, boolean, boolean, int)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span></div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#create(boolean, boolean, boolean, boolean, int)">create(boolean, boolean, boolean, boolean, int)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>
<div class="block">Create a new StorageLevel object.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PartitionPruningRDD.html#create(org.apache.spark.rdd.RDD, scala.Function1)">create(RDD&lt;T&gt;, Function1&lt;Object, Object&gt;)</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd">PartitionPruningRDD</a></dt>
<dd>
<div class="block">Create a PartitionPruningRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#create(java.lang.Object...)">create(Object...)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Creates a Row with the given values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#create(scala.collection.Seq)">create(Seq&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Creates a Row with the given values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html#create()">create()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java">JavaStreamingContextFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createArrayType(org.apache.spark.sql.api.java.DataType)">createArrayType(DataType)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates an ArrayType by specifying the data type of elements (<code>elementType</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createArrayType(org.apache.spark.sql.api.java.DataType, boolean)">createArrayType(DataType, boolean)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates an ArrayType by specifying the data type of elements (<code>elementType</code>) and
 whether the array contains null values (<code>containsNull</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#createCodec(org.apache.spark.SparkConf)">createCodec(SparkConf)</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#createCodec(org.apache.spark.SparkConf, java.lang.String)">createCodec(SparkConf, String)</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#createCombiner()">createCombiner()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createMapType(org.apache.spark.sql.api.java.DataType, org.apache.spark.sql.api.java.DataType)">createMapType(DataType, DataType)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates a MapType by specifying the data type of keys (<code>keyType</code>) and values
 (<code>keyType</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createMapType(org.apache.spark.sql.api.java.DataType, org.apache.spark.sql.api.java.DataType, boolean)">createMapType(DataType, DataType, boolean)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates a MapType by specifying the data type of keys (<code>keyType</code>), the data type of
 values (<code>keyType</code>), and whether values contain any null value
 (<code>valueContainsNull</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#createParquetFile(java.lang.Class, java.lang.String, boolean, org.apache.hadoop.conf.Configuration)">createParquetFile(Class&lt;?&gt;, String, boolean, Configuration)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Creates an empty parquet file with the schema of class <code>beanClass</code>, which can be registered as
 a table.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#createParquetFile(java.lang.String, boolean, org.apache.hadoop.conf.Configuration, scala.reflect.api.TypeTags.TypeTag)">createParquetFile(String, boolean, Configuration, TypeTags.TypeTag&lt;A&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Creates an empty parquet file with the schema of class <code>A</code>, which can be registered as a table.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.StreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)">createPollingStream(StreamingContext, String, int, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.StreamingContext, scala.collection.Seq, org.apache.spark.storage.StorageLevel)">createPollingStream(StreamingContext, Seq&lt;InetSocketAddress&gt;, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.StreamingContext, scala.collection.Seq, org.apache.spark.storage.StorageLevel, int, int)">createPollingStream(StreamingContext, Seq&lt;InetSocketAddress&gt;, StorageLevel, int, int)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int)">createPollingStream(JavaStreamingContext, String, int)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)">createPollingStream(JavaStreamingContext, String, int, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.net.InetSocketAddress[], org.apache.spark.storage.StorageLevel)">createPollingStream(JavaStreamingContext, InetSocketAddress[], StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createPollingStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.net.InetSocketAddress[], org.apache.spark.storage.StorageLevel, int, int)">createPollingStream(JavaStreamingContext, InetSocketAddress[], StorageLevel, int, int)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates an input stream that is to be used with the Spark Sink deployed on a Flume agent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#createSchemaRDD(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">createSchemaRDD(RDD&lt;A&gt;, TypeTags.TypeTag&lt;A&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Creates a SchemaRDD from an RDD of case classes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)">createStream(StreamingContext, String, int, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Create a input stream from a Flume source.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel, boolean)">createStream(StreamingContext, String, int, StorageLevel, boolean)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Create a input stream from a Flume source.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int)">createStream(JavaStreamingContext, String, int)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates a input stream from a Flume source.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, String, int, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates a input stream from a Flume source.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, int, org.apache.spark.storage.StorageLevel, boolean)">createStream(JavaStreamingContext, String, int, StorageLevel, boolean)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>
<div class="block">Creates a input stream from a Flume source.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, scala.collection.immutable.Map, org.apache.spark.storage.StorageLevel)">createStream(StreamingContext, String, String, Map&lt;String, Object&gt;, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.kafka.<a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</a></dt>
<dd>
<div class="block">Create an input stream that pulls messages from a Kafka Broker.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.StreamingContext, scala.collection.immutable.Map, scala.collection.immutable.Map, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">createStream(StreamingContext, Map&lt;String, String&gt;, Map&lt;String, Object&gt;, StorageLevel, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;U&gt;, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.streaming.kafka.<a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</a></dt>
<dd>
<div class="block">Create an input stream that pulls messages from a Kafka Broker.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, java.util.Map)">createStream(JavaStreamingContext, String, String, Map&lt;String, Integer&gt;)</a></span> - Static method in class org.apache.spark.streaming.kafka.<a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</a></dt>
<dd>
<div class="block">Create an input stream that pulls messages form a Kafka Broker.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, java.util.Map, org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, String, String, Map&lt;String, Integer&gt;, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.kafka.<a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</a></dt>
<dd>
<div class="block">Create an input stream that pulls messages form a Kafka Broker.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class, java.util.Map, java.util.Map, org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, Class&lt;K&gt;, Class&lt;V&gt;, Class&lt;U&gt;, Class&lt;T&gt;, Map&lt;String, String&gt;, Map&lt;String, Integer&gt;, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.kafka.<a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</a></dt>
<dd>
<div class="block">Create an input stream that pulls messages form a Kafka Broker.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.storage.StorageLevel)">createStream(StreamingContext, String, String, Duration, InitialPositionInStream, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.kinesis.<a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</a></dt>
<dd>
<div class="block">Create an InputDStream that pulls messages from a Kinesis stream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, com.amazonaws.services.kinesis.clientlibrary.lib.worker.InitialPositionInStream, org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, String, String, Duration, InitialPositionInStream, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.kinesis.<a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</a></dt>
<dd>
<div class="block">Create a Java-friendly InputDStream that pulls messages from a Kinesis stream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, java.lang.String, org.apache.spark.storage.StorageLevel)">createStream(StreamingContext, String, String, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.mqtt.<a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a MQTT publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String)">createStream(JavaStreamingContext, String, String)</a></span> - Static method in class org.apache.spark.streaming.mqtt.<a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a MQTT publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, java.lang.String, org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, String, String, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.mqtt.<a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a MQTT publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.StreamingContext, scala.Option, scala.collection.Seq, org.apache.spark.storage.StorageLevel)">createStream(StreamingContext, Option&lt;Authorization&gt;, Seq&lt;String&gt;, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext)">createStream(JavaStreamingContext)</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter using Twitter4J's default
 OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
 twitter4j.oauth.consumerSecret, twitter4j.oauth.accessToken and
 twitter4j.oauth.accessTokenSecret.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String[])">createStream(JavaStreamingContext, String[])</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter using Twitter4J's default
 OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
 twitter4j.oauth.consumerSecret, twitter4j.oauth.accessToken and
 twitter4j.oauth.accessTokenSecret.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String[], org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, String[], StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter using Twitter4J's default
 OAuth authentication; this requires the system properties twitter4j.oauth.consumerKey,
 twitter4j.oauth.consumerSecret, twitter4j.oauth.accessToken and
 twitter4j.oauth.accessTokenSecret.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, twitter4j.auth.Authorization)">createStream(JavaStreamingContext, Authorization)</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, twitter4j.auth.Authorization, java.lang.String[])">createStream(JavaStreamingContext, Authorization, String[])</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, twitter4j.auth.Authorization, java.lang.String[], org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, Authorization, String[], StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>
<div class="block">Create a input stream that returns tweets received from Twitter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.StreamingContext, java.lang.String, akka.zeromq.Subscribe, scala.Function1, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy, scala.reflect.ClassTag)">createStream(StreamingContext, String, Subscribe, Function1&lt;Seq&lt;ByteString&gt;, Iterator&lt;T&gt;&gt;, StorageLevel, SupervisorStrategy, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.streaming.zeromq.<a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a zeromq publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, akka.zeromq.Subscribe, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel, akka.actor.SupervisorStrategy)">createStream(JavaStreamingContext, String, Subscribe, Function&lt;byte[][], Iterable&lt;T&gt;&gt;, StorageLevel, SupervisorStrategy)</a></span> - Static method in class org.apache.spark.streaming.zeromq.<a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a zeromq publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, akka.zeromq.Subscribe, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel)">createStream(JavaStreamingContext, String, Subscribe, Function&lt;byte[][], Iterable&lt;T&gt;&gt;, StorageLevel)</a></span> - Static method in class org.apache.spark.streaming.zeromq.<a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a zeromq publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#createStream(org.apache.spark.streaming.api.java.JavaStreamingContext, java.lang.String, akka.zeromq.Subscribe, org.apache.spark.api.java.function.Function)">createStream(JavaStreamingContext, String, Subscribe, Function&lt;byte[][], Iterable&lt;T&gt;&gt;)</a></span> - Static method in class org.apache.spark.streaming.zeromq.<a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</a></dt>
<dd>
<div class="block">Create an input stream that receives messages pushed by a zeromq publisher.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createStructField(java.lang.String, org.apache.spark.sql.api.java.DataType, boolean)">createStructField(String, DataType, boolean)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates a StructField by specifying the name (<code>name</code>), data type (<code>dataType</code>) and
 whether values of this field can be null values (<code>nullable</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createStructType(java.util.List)">createStructType(List&lt;StructField&gt;)</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates a StructType with the given list of StructFields (<code>fields</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#createStructType(org.apache.spark.sql.api.java.StructField[])">createStructType(StructField[])</a></span> - Static method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Creates a StructType with the given StructField array (<code>fields</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#createTable(java.lang.String, boolean, scala.reflect.api.TypeTags.TypeTag)">createTable(String, boolean, TypeTags.TypeTag&lt;A&gt;)</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>
<div class="block">Creates a table using the schema of the given class.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#creationSite()">creationSite()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">User code that created this RDD (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#creationSite()">creationSite()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_D_">
<!--   -->
</a>
<h2 class="title">D</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#dagScheduler()">dagScheduler()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">DataType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The base type of all Spark SQL data types.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#DataType()">DataType()</a></span> - Constructor for class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util"><span class="strong">DataValidators</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A collection of methods used to validate data before applying ML algorithms.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/DataValidators.html#DataValidators()">DataValidators()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/DataValidators.html" title="class in org.apache.spark.mllib.util">DataValidators</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#DecimalType">DecimalType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the DecimalType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/DecimalType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">DecimalType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing java.math.BigDecimal values.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree"><span class="strong">DecisionTree</span></a> - Class in <a href="./org/apache/spark/mllib/tree/package-summary.html">org.apache.spark.mllib.tree</a></dt>
<dd>
<div class="block">:: Experimental ::
 A class which implements a decision tree learning algorithm for classification and regression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/DecisionTree.html#DecisionTree(org.apache.spark.mllib.tree.configuration.Strategy)">DecisionTree(Strategy)</a></span> - Constructor for class org.apache.spark.mllib.tree.<a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model"><span class="strong">DecisionTreeModel</span></a> - Class in <a href="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</a></dt>
<dd>
<div class="block">:: Experimental ::
 Decision tree model for classification or regression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#DecisionTreeModel(org.apache.spark.mllib.tree.model.Node, scala.Enumeration.Value)">DecisionTreeModel(Node, Enumeration.Value)</a></span> - Constructor for class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#DEFAULT_CLEANER_TTL()">DEFAULT_CLEANER_TTL()</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#DEFAULT_COMPRESSION_CODEC()">DEFAULT_COMPRESSION_CODEC()</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#DEFAULT_POOL_NAME()">DEFAULT_POOL_NAME()</a></span> - Static method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#DEFAULT_RETAINED_STAGES()">DEFAULT_RETAINED_STAGES()</a></span> - Static method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#defaultMinPartitions()">defaultMinPartitions()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Default min number of partitions for Hadoop RDDs when not given by user</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#defaultMinPartitions()">defaultMinPartitions()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Default min number of partitions for Hadoop RDDs when not given by user</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#defaultMinSplits()">defaultMinSplits()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>As of Spark 1.0.0, defaultMinSplits is deprecated, use
            <a href="./org/apache/spark/api/java/JavaSparkContext.html#defaultMinPartitions()"><code>JavaSparkContext.defaultMinPartitions()</code></a> instead</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#defaultMinSplits()">defaultMinSplits()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Default min number of partitions for Hadoop RDDs when not given by user</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#defaultParallelism()">defaultParallelism()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Default level of parallelism to use when not given by user (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#defaultParallelism()">defaultParallelism()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Default level of parallelism to use when not given by user (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Partitioner.html#defaultPartitioner(org.apache.spark.rdd.RDD, scala.collection.Seq)">defaultPartitioner(RDD&lt;?&gt;, Seq&lt;RDD&lt;?&gt;&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a></dt>
<dd>
<div class="block">Choose a partitioner to use for a cogroup-like operation between a number of RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html#defaultStrategy()">defaultStrategy()</a></span> - Static method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/ActorSupervisorStrategy.html" title="class in org.apache.spark.streaming.receiver">ActorSupervisorStrategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#degreesOfFreedom()">degreesOfFreedom()</a></span> - Method in class org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/TestResult.html#degreesOfFreedom()">degreesOfFreedom()</a></span> - Method in interface org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</a></dt>
<dd>
<div class="block">Returns the degree(s) of freedom of the hypothesis test.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/InterruptibleIterator.html#delegate()">delegate()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrices.html#dense(int, int, double[])">dense(int, int, double[])</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</a></dt>
<dd>
<div class="block">Creates a column-majored dense matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#dense(double, double...)">dense(double, double...)</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a dense vector from its values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#dense(double, scala.collection.Seq)">dense(double, Seq&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a dense vector from its values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#dense(double[])">dense(double[])</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a dense vector from a double array.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg"><span class="strong">DenseMatrix</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">Column-majored dense matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseMatrix.html#DenseMatrix(int, int, double[])">DenseMatrix(int, int, double[])</a></span> - Constructor for class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg"><span class="strong">DenseVector</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">A dense vector represented by a value array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#DenseVector(double[])">DenseVector(double[])</a></span> - Constructor for class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#dependencies()">dependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Get the list of dependencies of this RDD, taking into account whether the
 RDD is checkpointed or not.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#dependencies()">dependencies()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">List of parent DStreams on which this DStream depends on</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/InputDStream.html#dependencies()">dependencies()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/Dependency.html" title="class in org.apache.spark"><span class="strong">Dependency</span></a>&lt;<a href="./org/apache/spark/Dependency.html" title="type parameter in Dependency">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Base class for dependencies.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Dependency.html#Dependency()">Dependency()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#depth()">depth()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>
<div class="block">Get depth of tree.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/DescribeCommand.html" title="class in org.apache.spark.sql.execution"><span class="strong">DescribeCommand</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/DescribeCommand.html#DescribeCommand(org.apache.spark.sql.execution.SparkPlan, scala.collection.Seq, org.apache.spark.sql.SQLContext)">DescribeCommand(SparkPlan, Seq&lt;Attribute&gt;, SQLContext)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/DescribeCommand.html" title="class in org.apache.spark.sql.execution">DescribeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#describedTable()">describedTable()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">DescribeHiveTableCommand</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">Implementation for "describe [extended] table".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#DescribeHiveTableCommand(org.apache.spark.sql.hive.MetastoreRelation, scala.collection.Seq, boolean, org.apache.spark.sql.hive.HiveContext)">DescribeHiveTableCommand(org.apache.spark.sql.hive.MetastoreRelation, Seq&lt;Attribute&gt;, boolean, HiveContext)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExceptionFailure.html#description()">description()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#description()">description()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer"><span class="strong">DeserializationStream</span></a> - Class in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A stream for reading serialized objects.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/DeserializationStream.html#DeserializationStream()">DeserializationStream()</a></span> - Constructor for class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializerInstance.html#deserialize(java.nio.ByteBuffer, scala.reflect.ClassTag)">deserialize(ByteBuffer, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializerInstance.html#deserialize(java.nio.ByteBuffer, java.lang.ClassLoader, scala.reflect.ClassTag)">deserialize(ByteBuffer, ClassLoader, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#deserialize(org.apache.hadoop.io.Writable)">deserialize(Writable)</a></span> - Method in class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#deserialized()">deserialized()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializerInstance.html#deserializeStream(java.io.InputStream)">deserializeStream(InputStream)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#details()">details()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#determineBounds(scala.collection.mutable.ArrayBuffer, int, scala.math.Ordering, scala.reflect.ClassTag)">determineBounds(ArrayBuffer&lt;Tuple2&lt;K, Object&gt;&gt;, int, Ordering&lt;K&gt;, ClassTag&lt;K&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>
<div class="block">Determines the bounds for range partitioning from candidates with weights indicating how many
 items each represents.</div>
</dd>
<dt><a href="./org/apache/spark/annotation/DeveloperApi.html" title="annotation in org.apache.spark.annotation"><span class="strong">DeveloperApi</span></a> - Annotation Type in <a href="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</a></dt>
<dd>
<div class="block">A lower-level, unstable API intended for developers.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#DISK_ONLY">DISK_ONLY</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#DISK_ONLY()">DISK_ONLY()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#DISK_ONLY_2">DISK_ONLY_2</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#DISK_ONLY_2()">DISK_ONLY_2()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#diskSize()">diskSize()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#diskSize()">diskSize()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#diskUsed()">diskUsed()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the disk space used by this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#diskUsedByRdd(int)">diskUsedByRdd(int)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the disk space used by the given RDD in this block manager in O(1) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#dist(org.apache.spark.util.Vector)">dist(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#distinct()">distinct()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#distinct(int)">distinct(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#distinct()">distinct()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#distinct(int)">distinct(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#distinct()">distinct()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#distinct(int)">distinct(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#distinct(int, scala.math.Ordering)">distinct(int, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#distinct()">distinct()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#distinct()">distinct()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#distinct(int)">distinct(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing the distinct elements in this RDD.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution"><span class="strong">Distinct</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Computes the set of distinct input rows using a HashSet.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Distinct.html#Distinct(boolean, org.apache.spark.sql.execution.SparkPlan)">Distinct(boolean, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution">Distinct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#distinct()">distinct()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#distinct(int, scala.math.Ordering)">distinct(int, Ordering&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed"><span class="strong">DistributedMatrix</span></a> - Interface in <a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a></dt>
<dd>
<div class="block">Represents a distributively stored matrix backed by one or more RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#divide(double)">divide(double)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CacheCommand.html#doCache()">doCache()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CacheCommand.html" title="class in org.apache.spark.sql.execution">CacheCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#dot(org.apache.spark.util.Vector)">dot(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#doubleAccumulator(double)">doubleAccumulator(double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> double variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#doubleAccumulator(double, java.lang.String)">doubleAccumulator(double, String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> double variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="interface in org.apache.spark.api.java.function"><span class="strong">DoubleFlatMapFunction</span></a>&lt;<a href="./org/apache/spark/api/java/function/DoubleFlatMapFunction.html" title="type parameter in DoubleFlatMapFunction">T</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function that returns zero or more records of type Double from each input record.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/DoubleFunction.html" title="interface in org.apache.spark.api.java.function"><span class="strong">DoubleFunction</span></a>&lt;<a href="./org/apache/spark/api/java/function/DoubleFunction.html" title="type parameter in DoubleFunction">T</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function that returns Doubles, and can be used to construct DoubleRDDs.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="strong">DoubleRDDFunctions</span></a> - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">Extra functions available on RDDs of Doubles through an implicit conversion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#DoubleRDDFunctions(org.apache.spark.rdd.RDD)">DoubleRDDFunctions(RDD&lt;Object&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#doubleRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD)">doubleRDDToDoubleRDDFunctions(RDD&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#doubleToDoubleWritable(double)">doubleToDoubleWritable(double)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#doubleToMultiplier(double)">doubleToMultiplier(double)</a></span> - Static method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#DoubleType">DoubleType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the DoubleType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/DoubleType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">DoubleType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing double and Double values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#doubleWritableConverter()">doubleWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#driverActorSystemName()">driverActorSystemName()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">DropTable</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Drops a table from the metastore and removes it if it is cached.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DropTable.html#DropTable(java.lang.String, boolean)">DropTable(String, boolean)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution">DropTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#dstream()">dstream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#dstream()">dstream()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#dstream()">dstream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream"><span class="strong">DStream</span></a>&lt;<a href="./org/apache/spark/streaming/dstream/DStream.html" title="type parameter in DStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</a></dt>
<dd>
<div class="block">A Discretized Stream (DStream), the basic abstraction in Spark Streaming, is a continuous
 sequence of RDDs (of the same type) representing a continuous stream of data (see
 org.apache.spark.rdd.RDD in the Spark core documentation for more details on RDDs).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#DStream(org.apache.spark.streaming.StreamingContext, scala.reflect.ClassTag)">DStream(StreamingContext, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#duration()">duration()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><span class="strong">Duration</span></a> - Class in <a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#Duration(long)">Duration(long)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_E_">
<!--   -->
</a>
<h2 class="title">E</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#elements()">elements()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#empty()">empty()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#emptyRDD()">emptyRDD()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD that has no partitions or elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#emptyRDD(scala.reflect.ClassTag)">emptyRDD(ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD that has no partitions or elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#entries()">entries()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity"><span class="strong">Entropy</span></a> - Class in <a href="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</a></dt>
<dd>
<div class="block">:: Experimental ::
 Class for calculating <code>entropy</code> during
 binary classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Entropy.html#Entropy()">Entropy()</a></span> - Constructor for class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#env()">env()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#env()">env()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#env()">env()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html#environmentDetails()">environmentDetails()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerEnvironmentUpdate</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env"><span class="strong">EnvironmentListener</span></a> - Class in <a href="./org/apache/spark/ui/env/package-summary.html">org.apache.spark.ui.env</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A SparkListener that prepares information to be displayed on the EnvironmentTab</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/env/EnvironmentListener.html#EnvironmentListener()">EnvironmentListener()</a></span> - Constructor for class org.apache.spark.ui.env.<a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#EPSILON()">EPSILON()</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/HashPartitioner.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/ArrayType.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/ArrayType.html" title="class in org.apache.spark.sql.api.java">ArrayType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/MapType.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/MapType.html" title="class in org.apache.spark.sql.api.java">MapType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructField.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructField.html" title="class in org.apache.spark.sql.api.java">StructField</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructType.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructType.html" title="class in org.apache.spark.sql.api.java">StructType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#equals(java.lang.Object)">equals(Object)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/EvaluatePython.html" title="class in org.apache.spark.sql.execution"><span class="strong">EvaluatePython</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Evaluates a <code>PythonUDF</code>, appending the result to the end of the input tuple.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/EvaluatePython.html#EvaluatePython(org.apache.spark.sql.execution.PythonUDF, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">EvaluatePython(PythonUDF, LogicalPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/EvaluatePython.html" title="class in org.apache.spark.sql.execution">EvaluatePython</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#event()">event()</a></span> - Method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#eventLogger()">eventLogger()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Except.html" title="class in org.apache.spark.sql.execution"><span class="strong">Except</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Returns a table with the elements from left that are not in right using
 the built-in spark subtract function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Except.html#Except(org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">Except(SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Except.html" title="class in org.apache.spark.sql.execution">Except</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#except(org.apache.spark.sql.SchemaRDD)">except(SchemaRDD)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Performs a relational except on two SchemaRDDs</div>
</dd>
<dt><a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark"><span class="strong">ExceptionFailure</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Task failed due to a runtime exception.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExceptionFailure.html#ExceptionFailure(java.lang.String, java.lang.String, java.lang.StackTraceElement[], scala.Option)">ExceptionFailure(String, String, StackTraceElement[], Option&lt;TaskMetrics&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution"><span class="strong">Exchange</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Exchange.html#Exchange(org.apache.spark.sql.catalyst.plans.physical.Partitioning, org.apache.spark.sql.execution.SparkPlan)">Exchange(Partitioning, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution">Exchange</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html#execId()">execId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorMetricsUpdate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>
<div class="block">Substituted version of aggregateExpressions expressions which are used to compute final
 output rows given a group and the result of all aggregate computations.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution">BatchPythonEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CacheCommand.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CacheCommand.html" title="class in org.apache.spark.sql.execution">CacheCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CartesianProduct.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CartesianProduct.html" title="class in org.apache.spark.sql.execution">CartesianProduct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/DescribeCommand.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/DescribeCommand.html" title="class in org.apache.spark.sql.execution">DescribeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Distinct.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution">Distinct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Except.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Except.html" title="class in org.apache.spark.sql.execution">Except</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Exchange.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution">Exchange</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExistingRdd.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution">ExistingRdd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExplainCommand.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution">ExplainCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Filter.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution">Filter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Intersect.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Intersect.html" title="class in org.apache.spark.sql.execution">Intersect</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Limit.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution">Limit</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/OutputFaker.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/OutputFaker.html" title="class in org.apache.spark.sql.execution">OutputFaker</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Project.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution">Project</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SetCommand.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution">SetCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>
<div class="block">Runs this query returning the result as an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Union.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Union.html" title="class in org.apache.spark.sql.execution">Union</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html" title="class in org.apache.spark.sql.hive.execution">AnalyzeTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DropTable.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution">DropTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/NativeCommand.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/NativeCommand.html" title="class in org.apache.spark.sql.hive.execution">NativeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet">InsertIntoParquetTable</a></dt>
<dd>
<div class="block">Inserts all rows into the Parquet file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#execute()">execute()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Limit.html#executeCollect()">executeCollect()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution">Limit</a></dt>
<dd>
<div class="block">A custom implementation modeled after the take function on RDDs but which never runs any job
 locally.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#executeCollect()">executeCollect()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>
<div class="block">Runs this query returning the result as an array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#executeCollect()">executeCollect()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#executePlan(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">executePlan(LogicalPlan)</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#executor_()">executor_()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Handler object that runs the receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#executorActorSystemName()">executorActorSystemName()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#executorEnvs()">executorEnvs()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#executorId()">executorId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#executorId()">executorId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#executorId()">executorId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#executorIdToBlockManagerId()">executorIdToBlockManagerId()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#executorIdToStorageStatus()">executorIdToStorageStatus()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark"><span class="strong">ExecutorLostFailure</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 The task failed because the executor that it was running on was lost.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExecutorLostFailure.html#ExecutorLostFailure()">ExecutorLostFailure()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark">ExecutorLostFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#executorMemory()">executorMemory()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec"><span class="strong">ExecutorsListener</span></a> - Class in <a href="./org/apache/spark/ui/exec/package-summary.html">org.apache.spark.ui.exec</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A SparkListener that prepares information to be displayed on the ExecutorsTab</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#ExecutorsListener(org.apache.spark.storage.StorageStatusListener)">ExecutorsListener(StorageStatusListener)</a></span> - Constructor for class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToDuration()">executorToDuration()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToInputBytes()">executorToInputBytes()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToShuffleRead()">executorToShuffleRead()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToShuffleWrite()">executorToShuffleWrite()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToTasksActive()">executorToTasksActive()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToTasksComplete()">executorToTasksComplete()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#executorToTasksFailed()">executorToTasksFailed()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution"><span class="strong">ExistingRdd</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExistingRdd.html#ExistingRdd(scala.collection.Seq, org.apache.spark.rdd.RDD)">ExistingRdd(Seq&lt;Attribute&gt;, RDD&lt;Row&gt;)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution">ExistingRdd</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/annotation/Experimental.html" title="annotation in org.apache.spark.annotation"><span class="strong">Experimental</span></a> - Annotation Type in <a href="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</a></dt>
<dd>
<div class="block">An experimental user-facing API.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution"><span class="strong">ExplainCommand</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">An explain command for users to see how a command will be executed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExplainCommand.html#ExplainCommand(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan, scala.collection.Seq, boolean, org.apache.spark.sql.SQLContext)">ExplainCommand(LogicalPlan, Seq&lt;Attribute&gt;, boolean, SQLContext)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution">ExplainCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExplainCommand.html#extended()">extended()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution">ExplainCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html#extractDistribution(scala.Function1)">extractDistribution(Function1&lt;BatchInfo, Option&lt;Object&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#extractDoubleDistribution(scala.collection.Seq, scala.Function2)">extractDoubleDistribution(Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#extractLongDistribution(scala.collection.Seq, scala.Function2)">extractLongDistribution(Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_F_">
<!--   -->
</a>
<h2 class="title">F</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#failed()">failed()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#failedStages()">failedStages()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#failureReason()">failureReason()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>
<div class="block">If the stage failed, the reason why.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SchedulingMode.html#FAIR()">FAIR()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet"><span class="strong">FakeParquetSerDe</span></a> - Class in <a href="./org/apache/spark/sql/hive/parquet/package-summary.html">org.apache.spark.sql.hive.parquet</a></dt>
<dd>
<div class="block">A placeholder that allows SparkSQL users to create metastore tables that are stored as
 parquet files.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#FakeParquetSerDe()">FakeParquetSerDe()</a></span> - Constructor for class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#falsePositiveRate(double)">falsePositiveRate(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns false positive rate for a given label (category)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Split.html#feature()">feature()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LabeledPoint.html#features()">features()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration"><span class="strong">FeatureType</span></a> - Class in <a href="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</a></dt>
<dd>
<div class="block">:: Experimental ::
 Enum to describe whether a feature is "continuous" or "categorical"</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html#FeatureType()">FeatureType()</a></span> - Constructor for class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/FeatureType.html" title="class in org.apache.spark.mllib.tree.configuration">FeatureType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Split.html#featureType()">featureType()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark"><span class="strong">FetchFailed</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Task failed to fetch shuffle data from a remote node.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/FetchFailed.html#FetchFailed(org.apache.spark.storage.BlockManagerId, int, int, int)">FetchFailed(BlockManagerId, int, int, int)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BroadcastBlockId.html#field()">field()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SchedulingMode.html#FIFO()">FIFO()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#files()">files()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#fileStream(java.lang.String)">fileStream(String)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#fileStream(java.lang.String, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">fileStream(String, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#fileStream(java.lang.String, scala.Function1, boolean, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">fileStream(String, Function1&lt;Path, Object&gt;, boolean, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them using the given key-value types and input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#filter(org.apache.spark.api.java.function.Function)">filter(Function&lt;Double, Boolean&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#filter(org.apache.spark.api.java.function.Function)">filter(Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#filter(org.apache.spark.api.java.function.Function)">filter(Function&lt;T, Boolean&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#filter(scala.Function1)">filter(Function1&lt;T, Object&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#filter(org.apache.spark.api.java.function.Function)">filter(Function&lt;Row, Boolean&gt;)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return a new RDD containing only the elements that satisfy a predicate.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution"><span class="strong">Filter</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Filter.html#Filter(org.apache.spark.sql.catalyst.expressions.Expression, org.apache.spark.sql.execution.SparkPlan)">Filter(Expression, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution">Filter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#filter(scala.Function1)">filter(Function1&lt;Row, Object&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#filter(org.apache.spark.api.java.function.Function)">filter(Function&lt;T, Boolean&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Return a new DStream containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#filter(org.apache.spark.api.java.function.Function)">filter(Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#filter(scala.Function1)">filter(Function1&lt;T, Object&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream containing only the elements that satisfy a predicate.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#filterWith(scala.Function1, scala.Function2)">filterWith(Function1&lt;Object, A&gt;, Function2&lt;T, A, Object&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Filters this RDD with p, where p takes an additional parameter of type A.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2VecModel.html#findSynonyms(java.lang.String, int)">findSynonyms(String, int)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</a></dt>
<dd>
<div class="block">Find synonyms of a word</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2VecModel.html#findSynonyms(org.apache.spark.mllib.linalg.Vector, int)">findSynonyms(Vector, int)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</a></dt>
<dd>
<div class="block">Find synonyms of the vector representation of a word</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#finished()">finished()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#finishTime()">finishTime()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>
<div class="block">The time when the task has completed successfully (including the time to remotely fetch
 results, if necessary).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#first()">first()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#first()">first()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#first()">first()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return the first element in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#first()">first()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the first element in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.html#fit(org.apache.spark.rdd.RDD)">fit(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</a></dt>
<dd>
<div class="block">Computes the inverse document frequency.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.html#fit(org.apache.spark.api.java.JavaRDD)">fit(JavaRDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</a></dt>
<dd>
<div class="block">Computes the inverse document frequency.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScaler.html#fit(org.apache.spark.rdd.RDD)">fit(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature">StandardScaler</a></dt>
<dd>
<div class="block">Computes the mean and variance and stores as a model to be used for later scaling.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#fit(org.apache.spark.rdd.RDD)">fit(RDD&lt;S&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Computes the vector representation of each word in vocabulary.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#fit(org.apache.spark.api.java.JavaRDD)">fit(JavaRDD&lt;S&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Computes the vector representation of each word in vocabulary (Java version).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#flatMap(org.apache.spark.api.java.function.FlatMapFunction)">flatMap(FlatMapFunction&lt;T, U&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#flatMap(scala.Function1, scala.reflect.ClassTag)">flatMap(Function1&lt;T, TraversableOnce&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#flatMap(org.apache.spark.api.java.function.FlatMapFunction)">flatMap(FlatMapFunction&lt;T, U&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream by applying a function to all elements of this DStream,
 and then flattening the results</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#flatMap(scala.Function1, scala.reflect.ClassTag)">flatMap(Function1&lt;T, Traversable&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying a function to all elements of this DStream,
 and then flattening the results</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/FlatMapFunction.html" title="interface in org.apache.spark.api.java.function"><span class="strong">FlatMapFunction</span></a>&lt;<a href="./org/apache/spark/api/java/function/FlatMapFunction.html" title="type parameter in FlatMapFunction">T</a>,<a href="./org/apache/spark/api/java/function/FlatMapFunction.html" title="type parameter in FlatMapFunction">R</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function that returns zero or more output records from each input record.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="interface in org.apache.spark.api.java.function"><span class="strong">FlatMapFunction2</span></a>&lt;<a href="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="type parameter in FlatMapFunction2">T1</a>,<a href="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="type parameter in FlatMapFunction2">T2</a>,<a href="./org/apache/spark/api/java/function/FlatMapFunction2.html" title="type parameter in FlatMapFunction2">R</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function that takes two inputs and returns zero or more output records.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#flatMapToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)">flatMapToDouble(DoubleFlatMapFunction&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)">flatMapToPair(PairFlatMapFunction&lt;T, K2, V2&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by first applying a function to all elements of this
  RDD, and then flattening the results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#flatMapToPair(org.apache.spark.api.java.function.PairFlatMapFunction)">flatMapToPair(PairFlatMapFunction&lt;T, K2, V2&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream by applying a function to all elements of this DStream,
 and then flattening the results</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#flatMapValues(org.apache.spark.api.java.function.Function)">flatMapValues(Function&lt;V, Iterable&lt;U&gt;&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Pass each value in the key-value pair RDD through a flatMap function without changing the
 keys; this also retains the original RDD's partitioning.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#flatMapValues(scala.Function1)">flatMapValues(Function1&lt;V, TraversableOnce&lt;U&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Pass each value in the key-value pair RDD through a flatMap function without changing the
 keys; this also retains the original RDD's partitioning.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#flatMapValues(org.apache.spark.api.java.function.Function)">flatMapValues(Function&lt;V, Iterable&lt;U&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#flatMapValues(scala.Function1, scala.reflect.ClassTag)">flatMapValues(Function1&lt;V, TraversableOnce&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#flatMapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">flatMapWith(Function1&lt;Object, A&gt;, boolean, Function2&lt;T, A, Seq&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">FlatMaps f over this RDD, where f takes an additional parameter of type A.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#floatToFloatWritable(float)">floatToFloatWritable(float)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#FloatType">FloatType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the FloatType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/FloatType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">FloatType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing float and Float values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#floatWritableConverter()">floatWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#floor(org.apache.spark.streaming.Duration)">floor(Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume"><span class="strong">FlumeUtils</span></a> - Class in <a href="./org/apache/spark/streaming/flume/package-summary.html">org.apache.spark.streaming.flume</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/FlumeUtils.html#FlumeUtils()">FlumeUtils()</a></span> - Constructor for class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/FlumeUtils.html" title="class in org.apache.spark.streaming.flume">FlumeUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializationStream.html#flush()">flush()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#fMeasure(double, double)">fMeasure(double, double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns f-measure for a given label (category)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#fMeasure(double)">fMeasure(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns f1-measure for a given label (category)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#fMeasure()">fMeasure()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns f-measure
 (equals to precision and recall because precision equals recall)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#fMeasureByThreshold(double)">fMeasureByThreshold(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns the (threshold, F-Measure) curve.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#fMeasureByThreshold()">fMeasureByThreshold()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns the (threshold, F-Measure) curve with beta = 1.0.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#fold(T, org.apache.spark.api.java.function.Function2)">fold(T, Function2&lt;T, T, T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Aggregate the elements of each partition, and then the results for all the partitions, using a
 given associative function and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#fold(T, scala.Function2)">fold(T, Function2&lt;T, T, T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Aggregate the elements of each partition, and then the results for all the partitions, using a
 given associative function and a neutral "zero value".</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#foldByKey(V, org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function2)">foldByKey(V, Partitioner, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g ., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#foldByKey(V, int, org.apache.spark.api.java.function.Function2)">foldByKey(V, int, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g ., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#foldByKey(V, org.apache.spark.api.java.function.Function2)">foldByKey(V, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value"
 which may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, org.apache.spark.Partitioner, scala.Function2)">foldByKey(V, Partitioner, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, int, scala.Function2)">foldByKey(V, int, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#foldByKey(V, scala.Function2)">foldByKey(V, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative function and a neutral "zero value" which
 may be added to the result an arbitrary number of times, and must not change the result
 (e.g., Nil for list concatenation, 0 for addition, or 1 for multiplication.).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#foreach(org.apache.spark.api.java.function.VoidFunction)">foreach(VoidFunction&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Applies a function f to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#foreach(scala.Function1)">foreach(Function1&lt;T, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Applies a function f to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreach(org.apache.spark.api.java.function.Function)">foreach(Function&lt;R, Void&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>As of release 0.9.0, replaced by foreachRDD</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreach(org.apache.spark.api.java.function.Function2)">foreach(Function2&lt;R, Time, Void&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>As of release 0.9.0, replaced by foreachRDD</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#foreach(scala.Function1)">foreach(Function1&lt;RDD&lt;T&gt;, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Apply a function to each RDD in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#foreach(scala.Function2)">foreach(Function2&lt;RDD&lt;T&gt;, Time, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Apply a function to each RDD in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/AsyncRDDActions.html#foreachAsync(scala.Function1)">foreachAsync(Function1&lt;T, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</a></dt>
<dd>
<div class="block">Applies a function f to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#foreachPartition(org.apache.spark.api.java.function.VoidFunction)">foreachPartition(VoidFunction&lt;Iterator&lt;T&gt;&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Applies a function f to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#foreachPartition(scala.Function1)">foreachPartition(Function1&lt;Iterator&lt;T&gt;, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Applies a function f to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/AsyncRDDActions.html#foreachPartitionAsync(scala.Function1)">foreachPartitionAsync(Function1&lt;Iterator&lt;T&gt;, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</a></dt>
<dd>
<div class="block">Applies a function f to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreachRDD(org.apache.spark.api.java.function.Function)">foreachRDD(Function&lt;R, Void&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Apply a function to each RDD in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#foreachRDD(org.apache.spark.api.java.function.Function2)">foreachRDD(Function2&lt;R, Time, Void&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Apply a function to each RDD in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#foreachRDD(scala.Function1)">foreachRDD(Function1&lt;RDD&lt;T&gt;, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Apply a function to each RDD in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#foreachRDD(scala.Function2)">foreachRDD(Function2&lt;RDD&lt;T&gt;, Time, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Apply a function to each RDD in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#foreachWith(scala.Function1, scala.Function2)">foreachWith(Function1&lt;Object, A&gt;, Function2&lt;T, A, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Applies f to each element of this RDD, where f takes an additional parameter of type A.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#formatExecutorId(java.lang.String)">formatExecutorId(String)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>
<div class="block">In the local mode, there is a discrepancy between the executor ID according to the
 task ("localhost") and that according to SparkEnv ("<driver>").</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#fraction()">fraction()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#fromAvroFlumeEvent(org.apache.flume.source.avro.AvroFlumeEvent)">fromAvroFlumeEvent(AvroFlumeEvent)</a></span> - Static method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#fromDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">fromDStream(DStream&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Convert a scala <a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream"><code>DStream</code></a> to a Java-friendly
 <a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java"><code>JavaDStream</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html#fromInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag)">fromInputDStream(InputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</a></dt>
<dd>
<div class="block">Convert a scala <a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>InputDStream</code></a> to a Java-friendly
 <a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java"><code>JavaInputDStream</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#fromInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)">fromInputDStream(InputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</a></dt>
<dd>
<div class="block">Convert a scala <a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>InputDStream</code></a> of pairs to a
 Java-friendly <a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java"><code>JavaPairInputDStream</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fromJavaDStream(org.apache.spark.streaming.api.java.JavaDStream)">fromJavaDStream(JavaDStream&lt;Tuple2&lt;K, V&gt;&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#fromJavaRDD(org.apache.spark.api.java.JavaRDD)">fromJavaRDD(JavaRDD&lt;Tuple2&lt;K, V&gt;&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Convert a JavaRDD of key-value pairs to JavaPairRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#fromPairDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag)">fromPairDStream(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExistingRdd.html#fromProductRdd(org.apache.spark.rdd.RDD, scala.reflect.api.TypeTags.TypeTag)">fromProductRdd(RDD&lt;A&gt;, TypeTags.TypeTag&lt;A&gt;)</a></span> - Static method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution">ExistingRdd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#fromRDD(org.apache.spark.rdd.RDD)">fromRDD(RDD&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#fromRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)">fromRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#fromRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">fromRDD(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#fromRdd(org.apache.spark.rdd.RDD)">fromRdd(RDD&lt;?&gt;)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#fromReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)">fromReceiverInputDStream(ReceiverInputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</a></dt>
<dd>
<div class="block">Convert a scala <a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>ReceiverInputDStream</code></a> to a Java-friendly
 <a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><code>JavaReceiverInputDStream</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#fromReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag)">fromReceiverInputDStream(ReceiverInputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</a></dt>
<dd>
<div class="block">Convert a scala <a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>ReceiverInputDStream</code></a> to a Java-friendly
 <a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><code>JavaReceiverInputDStream</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#fromSparkContext(org.apache.spark.SparkContext)">fromSparkContext(SparkContext)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#fromStage(org.apache.spark.scheduler.Stage, scala.Option)">fromStage(Stage, Option&lt;Object&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>
<div class="block">Construct a StageInfo from a Stage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#fromString(java.lang.String)">fromString(String)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Return the StorageLevel object with the specified name.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/Function.html" title="interface in org.apache.spark.api.java.function"><span class="strong">Function</span></a>&lt;<a href="./org/apache/spark/api/java/function/Function.html" title="type parameter in Function">T1</a>,<a href="./org/apache/spark/api/java/function/Function.html" title="type parameter in Function">R</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">Base interface for functions whose return types do not create special RDDs.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/Function2.html" title="interface in org.apache.spark.api.java.function"><span class="strong">Function2</span></a>&lt;<a href="./org/apache/spark/api/java/function/Function2.html" title="type parameter in Function2">T1</a>,<a href="./org/apache/spark/api/java/function/Function2.html" title="type parameter in Function2">T2</a>,<a href="./org/apache/spark/api/java/function/Function2.html" title="type parameter in Function2">R</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A two-argument function that takes arguments of type T1 and T2 and returns an R.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/Function3.html" title="interface in org.apache.spark.api.java.function"><span class="strong">Function3</span></a>&lt;<a href="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">T1</a>,<a href="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">T2</a>,<a href="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">T3</a>,<a href="./org/apache/spark/api/java/function/Function3.html" title="type parameter in Function3">R</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A three-argument function that takes arguments of type T1, T2 and T3 and returns an R.</div>
</dd>
<dt><a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark"><span class="strong">FutureAction</span></a>&lt;<a href="./org/apache/spark/FutureAction.html" title="type parameter in FutureAction">T</a>&gt; - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: Experimental ::
 A future for the result of an action to support cancellation.</div>
</dd>
</dl>
<a name="_G_">
<!--   -->
</a>
<h2 class="title">G</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#gain()">gain()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression"><span class="strong">GeneralizedLinearAlgorithm</span></a>&lt;<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="type parameter in GeneralizedLinearAlgorithm">M</a> extends <a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a>&gt; - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 GeneralizedLinearAlgorithm implements methods to train a Generalized Linear Model (GLM).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#GeneralizedLinearAlgorithm()">GeneralizedLinearAlgorithm()</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression"><span class="strong">GeneralizedLinearModel</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 GeneralizedLinearModel (GLM) represents a model trained using
 GeneralizedLinearAlgorithm.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#GeneralizedLinearModel(org.apache.spark.mllib.linalg.Vector, double)">GeneralizedLinearModel(Vector, double)</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution"><span class="strong">Generate</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Applies a <code>Generator</code> to a stream of input rows, combining the
 output of each into a new stream of rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#Generate(org.apache.spark.sql.catalyst.expressions.Generator, boolean, boolean, org.apache.spark.sql.execution.SparkPlan)">Generate(Generator, boolean, boolean, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#generate(org.apache.spark.sql.catalyst.expressions.Generator, boolean, boolean, scala.Option)">generate(Generator, boolean, boolean, Option&lt;String&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Applies the given Generator, or table generating function, to this relation.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution"><span class="strong">GeneratedAggregate</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Alternate version of aggregation that leverages projection and thus code generation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#GeneratedAggregate(boolean, scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan)">GeneratedAggregate(boolean, Seq&lt;Expression&gt;, Seq&lt;NamedExpression&gt;, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#generatedRDDs()">generatedRDDs()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html#generateKMeansRDD(org.apache.spark.SparkContext, int, int, int, double, int)">generateKMeansRDD(SparkContext, int, int, int, double, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util">KMeansDataGenerator</a></dt>
<dd>
<div class="block">Generate an RDD containing test data for KMeans.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearInput(double, double[], int, int, double)">generateLinearInput(double, double[], int, int, double)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearInputAsList(double, double[], int, int, double)">generateLinearInputAsList(double, double[], int, int, double)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</a></dt>
<dd>
<div class="block">Return a Java List of synthetic data randomly generated according to a multi
 collinear model.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LinearDataGenerator.html#generateLinearRDD(org.apache.spark.SparkContext, int, int, double, int, double)">generateLinearRDD(SparkContext, int, int, double, int, double)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</a></dt>
<dd>
<div class="block">Generate an RDD containing sample data for Linear Regression models - including Ridge, Lasso,
 and uregularized variants.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html#generateLogisticRDD(org.apache.spark.SparkContext, int, int, double, int, double)">generateLogisticRDD(SparkContext, int, int, double, int, double)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util">LogisticRegressionDataGenerator</a></dt>
<dd>
<div class="block">Generate an RDD containing test data for LogisticRegression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#generator()">generator()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#get()">get()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">Blocks and returns the result of this job.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#get(java.lang.String)">get(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter; throws a NoSuchElementException if it's not set</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#get(java.lang.String, java.lang.String)">get(String, String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter, falling back to a default if not set</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#get()">get()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>
<div class="block">Returns the ThreadLocal SparkEnv, if non-null.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkFiles.html#get(java.lang.String)">get(String)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark">SparkFiles</a></dt>
<dd>
<div class="block">Get the absolute path of a file added through <code>SparkContext.addFile()</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#get(int)">get(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column `i`.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getAkkaConf()">getAkkaConf()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get all akka conf variables set on this SparkConf</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getAll()">getAll()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get all parameters as a list of pairs</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getAllPools()">getAllPools()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Return pools for fair scheduler</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#getBlock(org.apache.spark.storage.BlockId)">getBlock(BlockId)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the given block stored in this block manager in O(1) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getBoolean(java.lang.String, boolean)">getBoolean(String, boolean)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter as a boolean, falling back to a default if not set</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getBoolean(int)">getBoolean(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a bool.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getByte(int)">getByte(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a byte.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#getCachedBlockManagerId(org.apache.spark.storage.BlockManagerId)">getCachedBlockManagerId(BlockManagerId)</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#getCachedMetadata(java.lang.String)">getCachedMetadata(String)</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>
<div class="block">The three methods below are helpers for accessing the local map, a property of the SparkEnv of
 the local process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#getCheckpointDir()">getCheckpointDir()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getCheckpointDir()">getCheckpointDir()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#getCheckpointFile()">getCheckpointFile()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Gets the name of the file to which this RDD was checkpointed</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#getCheckpointFile()">getCheckpointFile()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Gets the name of the file to which this RDD was checkpointed</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#getConf()">getConf()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Return a copy of this JavaSparkContext's configuration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#getConf()">getConf()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/NewHadoopRDD.html#getConf()">getConf()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getConf()">getConf()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Return a copy of this SparkContext's configuration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#getCreationSite()">getCreationSite()</a></span> - Static method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Get the creation site of a DStream from the stack trace of when the DStream is created.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructField.html#getDataType()">getDataType()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructField.html" title="class in org.apache.spark.sql.api.java">StructField</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#getDependencies()">getDependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#getDependencies()">getDependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#getDependencies()">getDependencies()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getDouble(java.lang.String, double)">getDouble(String, double)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter as a double, falling back to a default if not set</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getDouble(int)">getDouble(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a double.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/ArrayType.html#getElementType()">getElementType()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/ArrayType.html" title="class in org.apache.spark.sql.api.java">ArrayType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getExecutorEnv()">getExecutorEnv()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get all executor environment variables set on this SparkConf</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getExecutorMemoryStatus()">getExecutorMemoryStatus()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Return a map from the slave to the max memory available for caching and the remaining
 memory available for caching.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getExecutorStorageStatus()">getExecutorStorageStatus()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Return information about blocks stored in all of the slaves</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructType.html#getFields()">getFields()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructType.html" title="class in org.apache.spark.sql.api.java">StructType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#getFinalValue()">getFinalValue()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>
<div class="block">Blocking method to wait for and return the final value.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getFloat(int)">getFloat(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a float.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#getHiveFile(java.lang.String)">getHiveFile(String)</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getInt(java.lang.String, int)">getInt(String, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter as an integer, falling back to a default if not set</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getInt(int)">getInt(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as an int.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/MapType.html#getKeyType()">getKeyType()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/MapType.html" title="class in org.apache.spark.sql.api.java">MapType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#getLocalProperty(java.lang.String)">getLocalProperty(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get a local property set in this thread, or null if it is missing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getLocalProperty(java.lang.String)">getLocalProperty(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get a local property set in this thread, or null if it is missing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getLong(java.lang.String, long)">getLong(String, long)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter as a long, falling back to a default if not set</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getLong(int)">getLong(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a long.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructField.html#getName()">getName()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructField.html" title="class in org.apache.spark.sql.api.java">StructField</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#getObjectInspector()">getObjectInspector()</a></span> - Method in class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#getOption(java.lang.String)">getOption(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Get a parameter as an Option</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)">getOrCreate(String, JavaStreamingContextFactory)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory)">getOrCreate(String, Configuration, JavaStreamingContextFactory)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#getOrCreate(java.lang.String, org.apache.hadoop.conf.Configuration, org.apache.spark.streaming.api.java.JavaStreamingContextFactory, boolean)">getOrCreate(String, Configuration, JavaStreamingContextFactory, boolean)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#getOrCreate(java.lang.String, scala.Function0, org.apache.hadoop.conf.Configuration, boolean)">getOrCreate(String, Function0&lt;StreamingContext&gt;, Configuration, boolean)</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Either recreate a StreamingContext from checkpoint data or create a new StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/NarrowDependency.html#getParents(int)">getParents(int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark">NarrowDependency</a></dt>
<dd>
<div class="block">Get the parent partitions for a child partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/OneToOneDependency.html#getParents(int)">getParents(int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/OneToOneDependency.html" title="class in org.apache.spark">OneToOneDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangeDependency.html#getParents(int)">getParents(int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/RangeDependency.html" title="class in org.apache.spark">RangeDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/HashPartitioner.html#getPartition(java.lang.Object)">getPartition(Object)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Partitioner.html#getPartition(java.lang.Object)">getPartition(Object)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#getPartition(java.lang.Object)">getPartition(Object)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/JdbcRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/NewHadoopRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#getPartitions()">getPartitions()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getPersistentRDDs()">getPersistentRDDs()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Returns an immutable map of RDDs that have marked themselves as persistent via cache() call.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getPoolForName(java.lang.String)">getPoolForName(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Return the pool associated with the given name, if one exists</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#getPreferredLocations(org.apache.spark.Partition)">getPreferredLocations(Partition)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/NewHadoopRDD.html#getPreferredLocations(org.apache.spark.Partition)">getPreferredLocations(Partition)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#getPreferredLocations(org.apache.spark.Partition)">getPreferredLocations(Partition)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getRDDStorageInfo()">getRDDStorageInfo()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Return information about what RDDs are cached, if they are in mem or on disk, how much space
 they take, etc.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#getReceiver()">getReceiver()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</a></dt>
<dd>
<div class="block">Gets the receiver object that will be sent to the worker nodes
 to receive data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkFiles.html#getRootDirectory()">getRootDirectory()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark">SparkFiles</a></dt>
<dd>
<div class="block">Get the root directory that contains files added through <code>SparkContext.addFile()</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#getSchedulingMode()">getSchedulingMode()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Return current scheduling mode</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#getSerDeStats()">getSerDeStats()</a></span> - Method in class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#getSerializedClass()">getSerializedClass()</a></span> - Method in class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/Serializer.html#getSerializer(org.apache.spark.serializer.Serializer)">getSerializer(Serializer)</a></span> - Static method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/Serializer.html#getSerializer(scala.Option)">getSerializer(Option&lt;Serializer&gt;)</a></span> - Static method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getShort(int)">getShort(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a short.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#getSparkHome()">getSparkHome()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get Spark's home location from either a value set through the constructor,
 or the spark.home Java property, or the SPARK_HOME environment variable
 (in that order of preference).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#getStorageLevel()">getStorageLevel()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Get the RDD's current storage level, or StorageLevel.NONE if none is set.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#getStorageLevel()">getStorageLevel()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Get the RDD's current storage level, or StorageLevel.NONE if none is set.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#getString(int)">getString(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the value of column <code>i</code> as a String.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#getThreadLocal()">getThreadLocal()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>
<div class="block">Returns the ThreadLocal SparkEnv.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#gettingResult()">gettingResult()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#gettingResultTime()">gettingResultTime()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>
<div class="block">The time when the task started remotely getting the result.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/MapType.html#getValueType()">getValueType()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/MapType.html" title="class in org.apache.spark.sql.api.java">MapType</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity"><span class="strong">Gini</span></a> - Class in <a href="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</a></dt>
<dd>
<div class="block">:: Experimental ::
 Class for calculating the
 <code>Gini impurity</code>
 during binary classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Gini.html#Gini()">Gini()</a></span> - Constructor for class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#global()">global()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#glom()">glom()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an RDD created by coalescing all elements within each partition into an array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#glom()">glom()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD created by coalescing all elements within each partition into an array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#glom()">glom()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying glom() to each RDD of
 this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#glom()">glom()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying glom() to each RDD of
 this DStream.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">Gradient</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Class used to compute the gradient for a loss function, given a single data point.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/Gradient.html#Gradient()">Gradient()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/Gradient.html" title="class in org.apache.spark.mllib.optimization">Gradient</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">GradientDescent</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">Class used to solve an optimization problem using Gradient Descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#graph()">graph()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#graph()">graph()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#groupBy(org.apache.spark.api.java.function.Function)">groupBy(Function&lt;T, K&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an RDD of grouped elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#groupBy(org.apache.spark.api.java.function.Function, int)">groupBy(Function&lt;T, K&gt;, int)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an RDD of grouped elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, scala.reflect.ClassTag)">groupBy(Function1&lt;T, K&gt;, ClassTag&lt;K&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD of grouped items.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, int, scala.reflect.ClassTag)">groupBy(Function1&lt;T, K&gt;, int, ClassTag&lt;K&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD of grouped elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#groupBy(scala.Function1, org.apache.spark.Partitioner, scala.reflect.ClassTag, scala.math.Ordering)">groupBy(Function1&lt;T, K&gt;, Partitioner, ClassTag&lt;K&gt;, Ordering&lt;K&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD of grouped items.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#groupBy(scala.collection.Seq, scala.collection.Seq)">groupBy(Seq&lt;Expression&gt;, Seq&lt;Expression&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Performs a grouping followed by an aggregation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#groupByKey(org.apache.spark.Partitioner)">groupByKey(Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#groupByKey(int)">groupByKey(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#groupByKey()">groupByKey()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#groupByKey(org.apache.spark.Partitioner)">groupByKey(Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#groupByKey(int)">groupByKey(int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#groupByKey()">groupByKey()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Group the values for each key in the RDD into a single sequence.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKey()">groupByKey()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKey(int)">groupByKey(int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKey(org.apache.spark.Partitioner)">groupByKey(Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> on each RDD of <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey()">groupByKey()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(int)">groupByKey(int)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(org.apache.spark.Partitioner)">groupByKey(Partitioner)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> on each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration)">groupByKeyAndWindow(Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">groupByKeyAndWindow(Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">groupByKeyAndWindow(Duration, Duration, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)">groupByKeyAndWindow(Duration, Duration, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration)">groupByKeyAndWindow(Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">groupByKeyAndWindow(Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">groupByKeyAndWindow(Duration, Duration, int)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)">groupByKeyAndWindow(Duration, Duration, Partitioner)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#groupingExpressions()">groupingExpressions()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#groupingExpressions()">groupingExpressions()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#groupWith(org.apache.spark.api.java.JavaPairRDD)">groupWith(JavaPairRDD&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Alias for cogroup.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#groupWith(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)">groupWith(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Alias for cogroup.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#groupWith(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD, org.apache.spark.api.java.JavaPairRDD)">groupWith(JavaPairRDD&lt;K, W1&gt;, JavaPairRDD&lt;K, W2&gt;, JavaPairRDD&lt;K, W3&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Alias for cogroup.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD)">groupWith(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Alias for cogroup.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">groupWith(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Alias for cogroup.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#groupWith(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD)">groupWith(RDD&lt;Tuple2&lt;K, W1&gt;&gt;, RDD&lt;Tuple2&lt;K, W2&gt;&gt;, RDD&lt;Tuple2&lt;K, W3&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Alias for cogroup.</div>
</dd>
</dl>
<a name="_H_">
<!--   -->
</a>
<h2 class="title">H</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#hadoopConfiguration()">hadoopConfiguration()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Returns the Hadoop configuration used for the Hadoop code (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#hadoopConfiguration()">hadoopConfiguration()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">A default Hadoop Configuration for the Hadoop code (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#hadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, int)">hadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop file with an arbitrary InputFormat.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#hadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)">hadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop file with an arbitrary InputFormat</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#hadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, int)">hadoopFile(String, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop file with an arbitrary InputFormat</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#hadoopFile(java.lang.String, int, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">hadoopFile(String, int, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Smarter version of hadoopFile() that uses class tags to figure out the classes of keys,
 values and the InputFormat so that users don't need to pass them directly.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#hadoopFile(java.lang.String, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">hadoopFile(String, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Smarter version of hadoopFile() that uses class tags to figure out the classes of keys,
 values and the InputFormat so that users don't need to pass them directly.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#hadoopJobMetadata()">hadoopJobMetadata()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#hadoopRDD(org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class, int)">hadoopRDD(JobConf, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop-readable dataset from a Hadooop JobConf giving its InputFormat and any
 other necessary info (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#hadoopRDD(org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class)">hadoopRDD(JobConf, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop-readable dataset from a Hadooop JobConf giving its InputFormat and any
 other necessary info (e.g.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd"><span class="strong">HadoopRDD</span></a>&lt;<a href="./org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">K</a>,<a href="./org/apache/spark/rdd/HadoopRDD.html" title="type parameter in HadoopRDD">V</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 An RDD that provides core functionality for reading data stored in Hadoop (e.g., files in HDFS,
 sources in HBase, or S3), using the older MapReduce API (<code>org.apache.hadoop.mapred</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#HadoopRDD(org.apache.spark.SparkContext, org.apache.spark.broadcast.Broadcast, scala.Option, java.lang.Class, java.lang.Class, java.lang.Class, int)">HadoopRDD(SparkContext, Broadcast&lt;SerializableWritable&lt;Configuration&gt;&gt;, Option&lt;Function1&lt;JobConf, BoxedUnit&gt;&gt;, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#HadoopRDD(org.apache.spark.SparkContext, org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class, int)">HadoopRDD(SparkContext, JobConf, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#hadoopRDD(org.apache.hadoop.mapred.JobConf, java.lang.Class, java.lang.Class, java.lang.Class, int)">hadoopRDD(JobConf, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop-readable dataset from a Hadoop JobConf given its InputFormat and other
 necessary info (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/HashPartitioner.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#hashCode()">hashCode()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Partition.html#hashCode()">hashCode()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/ArrayType.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/ArrayType.html" title="class in org.apache.spark.sql.api.java">ArrayType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/MapType.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/MapType.html" title="class in org.apache.spark.sql.api.java">MapType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructField.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructField.html" title="class in org.apache.spark.sql.api.java">StructField</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructType.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructType.html" title="class in org.apache.spark.sql.api.java">StructType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#hashCode()">hashCode()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature"><span class="strong">HashingTF</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Maps a sequence of terms to their term frequencies using the hashing trick.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#HashingTF(int)">HashingTF(int)</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#HashingTF()">HashingTF()</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution"><span class="strong">HashJoin</span></a> - Interface in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution"><span class="strong">HashOuterJoin</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Performs a hash based outer join for two child relations by shuffling the data using
 the join keys.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#HashOuterJoin(scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.catalyst.plans.JoinType, scala.Option, org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">HashOuterJoin(Seq&lt;Expression&gt;, Seq&lt;Expression&gt;, JoinType, Option&lt;Expression&gt;, SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark"><span class="strong">HashPartitioner</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">A <a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark"><code>Partitioner</code></a> that implements hash-based partitioning using
 Java's <code>Object.hashCode</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/HashPartitioner.html#HashPartitioner(int)">HashPartitioner(int)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/InterruptibleIterator.html#hasNext()">hasNext()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/BoundedDouble.html#high()">high()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">HingeGradient</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Compute gradient and loss for a Hinge loss function, as used in SVM binary classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/HingeGradient.html#HingeGradient()">HingeGradient()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/HingeGradient.html" title="class in org.apache.spark.mllib.optimization">HingeGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#histogram(int)">histogram(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute a histogram of the data using bucketCount number of buckets evenly
  spaced between the minimum and maximum of the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#histogram(double[])">histogram(double[])</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute a histogram using the provided buckets.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#histogram(java.lang.Double[], boolean)">histogram(Double[], boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#histogram(int)">histogram(int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute a histogram of the data using bucketCount number of buckets evenly
  spaced between the minimum and maximum of the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#histogram(double[], boolean)">histogram(double[], boolean)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute a histogram using the provided buckets.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html#hiveContext()">hiveContext()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html" title="class in org.apache.spark.sql.hive.execution">AnalyzeTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DropTable.html#hiveContext()">hiveContext()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution">DropTable</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive"><span class="strong">HiveContext</span></a> - Class in <a href="./org/apache/spark/sql/hive/package-summary.html">org.apache.spark.sql.hive</a></dt>
<dd>
<div class="block">An instance of the Spark SQL execution engine that integrates with data stored in Hive.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#HiveContext(org.apache.spark.SparkContext)">HiveContext(SparkContext)</a></span> - Constructor for class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#hiveDevHome()">hiveDevHome()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>
<div class="block">The location of the hive source code.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#hiveFilesTemp()">hiveFilesTemp()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#hiveHome()">hiveHome()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>
<div class="block">The location of the compiled hive distribution</div>
</dd>
<dt><a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html" title="class in org.apache.spark.sql.hive"><span class="strong">HiveMetastoreTypes</span></a> - Class in <a href="./org/apache/spark/sql/hive/package-summary.html">org.apache.spark.sql.hive</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Provides conversions between Spark SQL data types and Hive Metastore types.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html#HiveMetastoreTypes()">HiveMetastoreTypes()</a></span> - Constructor for class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html" title="class in org.apache.spark.sql.hive">HiveMetastoreTypes</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#hivePlanner()">hivePlanner()</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#hiveql(java.lang.String)">hiveql(String)</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#hiveQTestUtilTables()">hiveQTestUtilTables()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#hiveString()">hiveString()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">HiveTableScan</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 The Hive table scan operator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#HiveTableScan(scala.collection.Seq, org.apache.spark.sql.hive.MetastoreRelation, scala.Option, org.apache.spark.sql.hive.HiveContext)">HiveTableScan(Seq&lt;Attribute&gt;, org.apache.spark.sql.hive.MetastoreRelation, Option&lt;Expression&gt;, HiveContext)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#host()">host()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#host()">host()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#hostLocation()">hostLocation()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#hostPort()">hostPort()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#hours()">hours()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html#hql(java.lang.String)">hql(String)</a></span> - Method in class org.apache.spark.sql.hive.api.java.<a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html" title="class in org.apache.spark.sql.hive.api.java">JavaHiveContext</a></dt>
<dd>
<div class="block">DEPRECATED: Use sql(...) Instead</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#hql(java.lang.String)">hql(String)</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast"><span class="strong">HttpBroadcastFactory</span></a> - Class in <a href="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</a></dt>
<dd>
<div class="block">A <a href="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast"><code>BroadcastFactory</code></a> implementation that uses a
 HTTP server as the broadcast mechanism.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html#HttpBroadcastFactory()">HttpBroadcastFactory()</a></span> - Constructor for class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#httpFileServer()">httpFileServer()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_I_">
<!--   -->
</a>
<h2 class="title">I</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#i()">i()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#id()">id()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#id()">id()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">A unique ID for this RDD (within its SparkContext).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/Broadcast.html#id()">id()</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#id()">id()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#id()">id()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">A unique ID for this RDD (within its SparkContext).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#id()">id()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#id()">id()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#id()">id()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#id()">id()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</a></dt>
<dd>
<div class="block">This is an unique identifier for the network input stream.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature"><span class="strong">IDF</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Inverse document frequency (IDF).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.html#IDF()">IDF()</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.html" title="class in org.apache.spark.mllib.feature">IDF</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#idf()">idf()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</a></dt>
<dd>
<div class="block">Returns the current IDF vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDFModel.html#idf()">idf()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature"><span class="strong">IDF.DocumentFrequencyAggregator</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">Document frequency aggregator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#IDF.DocumentFrequencyAggregator()">IDF.DocumentFrequencyAggregator()</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature"><span class="strong">IDFModel</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents an IDF model that can transform term frequency vectors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DropTable.html#ifExists()">ifExists()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution">DropTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#impurity()">impurity()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/impurity/Impurity.html" title="interface in org.apache.spark.mllib.tree.impurity"><span class="strong">Impurity</span></a> - Interface in <a href="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</a></dt>
<dd>
<div class="block">:: Experimental ::
 Trait for calculating information gain.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#impurity()">impurity()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html#index()">index()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRow</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#index()">index()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Partition.html#index()">index()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Partition.html" title="interface in org.apache.spark">Partition</a></dt>
<dd>
<div class="block">Get the split's index within its parent RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#index()">index()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed"><span class="strong">IndexedRow</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents a row of <a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><code>IndexedRowMatrix</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html#IndexedRow(long, org.apache.spark.mllib.linalg.Vector)">IndexedRow(long, Vector)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRow</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><span class="strong">IndexedRowMatrix</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents a row-oriented <a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed"><code>DistributedMatrix</code></a> with
 indexed rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#IndexedRowMatrix(org.apache.spark.rdd.RDD, long, int)">IndexedRowMatrix(RDD&lt;IndexedRow&gt;, long, int)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#IndexedRowMatrix(org.apache.spark.rdd.RDD)">IndexedRowMatrix(RDD&lt;IndexedRow&gt;)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>
<div class="block">Alternative constructor leaving matrix dimensions to be determined automatically.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#indexOf(java.lang.Object)">indexOf(Object)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>
<div class="block">Returns the index of the input term.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#indices()">indices()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model"><span class="strong">InformationGainStats</span></a> - Class in <a href="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Information gain statistics for each split</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#InformationGainStats(double, double, double, double, double, double)">InformationGainStats(double, double, double, double, double, double)</a></span> - Constructor for class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/BroadcastFactory.html#initialize(boolean, org.apache.spark.SparkConf, org.apache.spark.SecurityManager)">initialize(boolean, SparkConf, org.apache.spark.SecurityManager)</a></span> - Method in interface org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html#initialize(boolean, org.apache.spark.SparkConf, org.apache.spark.SecurityManager)">initialize(boolean, SparkConf, org.apache.spark.SecurityManager)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#initialize(boolean, org.apache.spark.SparkConf, org.apache.spark.SecurityManager)">initialize(boolean, SparkConf, org.apache.spark.SecurityManager)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#initialize(org.apache.hadoop.conf.Configuration, java.util.Properties)">initialize(Configuration, Properties)</a></span> - Method in class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#initialized()">initialized()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#initializeIfNecessary()">initializeIfNecessary()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#initializeLogging()">initializeLogging()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#initialValue()">initialValue()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/AggregateEvaluation.html#initialValues()">initialValues()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/AggregateEvaluation.html" title="class in org.apache.spark.sql.execution">AggregateEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#initLocalProperties()">initLocalProperties()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#initLock()">initLock()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#input()">input()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html#inputDStream()">inputDStream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#inputDStream()">inputDStream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="strong">InputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="type parameter in InputDStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</a></dt>
<dd>
<div class="block">This is the abstract base class for all input streams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/InputDStream.html#InputDStream(org.apache.spark.streaming.StreamingContext, scala.reflect.ClassTag)">InputDStream(StreamingContext, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#inputFormatClazz()">inputFormatClazz()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#inputFormatClazz()">inputFormatClazz()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler"><span class="strong">InputFormatInfo</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Parses and holds information about inputFormat (and files) specified as a parameter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#InputFormatInfo(org.apache.hadoop.conf.Configuration, java.lang.Class, java.lang.String)">InputFormatInfo(Configuration, Class&lt;?&gt;, String)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#inRepoTests()">inRepoTests()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">InsertIntoHiveTable</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#InsertIntoHiveTable(org.apache.spark.sql.hive.MetastoreRelation, scala.collection.immutable.Map, org.apache.spark.sql.execution.SparkPlan, boolean, org.apache.spark.sql.hive.HiveContext)">InsertIntoHiveTable(org.apache.spark.sql.hive.MetastoreRelation, Map&lt;String, Option&lt;String&gt;&gt;, SparkPlan, boolean, HiveContext)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet"><span class="strong">InsertIntoParquetTable</span></a> - Class in <a href="./org/apache/spark/sql/parquet/package-summary.html">org.apache.spark.sql.parquet</a></dt>
<dd>
<div class="block">Operator that acts as a sink for queries on RDDs and can be used to
 store the output inside a directory of Parquet files.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html#InsertIntoParquetTable(org.apache.spark.sql.parquet.ParquetRelation, org.apache.spark.sql.execution.SparkPlan, boolean)">InsertIntoParquetTable(ParquetRelation, SparkPlan, boolean)</a></span> - Constructor for class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet">InsertIntoParquetTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Entropy.html#instance()">instance()</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Entropy.html" title="class in org.apache.spark.mllib.tree.impurity">Entropy</a></dt>
<dd>
<div class="block">Get this impurity instance.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Gini.html#instance()">instance()</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Gini.html" title="class in org.apache.spark.mllib.tree.impurity">Gini</a></dt>
<dd>
<div class="block">Get this impurity instance.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Variance.html#instance()">instance()</a></span> - Static method in class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</a></dt>
<dd>
<div class="block">Get this impurity instance.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#intAccumulator(int)">intAccumulator(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> integer variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#intAccumulator(int, java.lang.String)">intAccumulator(int, String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create an <a href="./org/apache/spark/Accumulator.html" title="class in org.apache.spark"><code>Accumulator</code></a> integer variable, which tasks can "add" values
 to using the <code>add</code> method.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#IntegerType">IntegerType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the IntegerType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/IntegerType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">IntegerType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing int and Integer values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#intercept()">intercept()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMModel.html#intercept()">intercept()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#intercept()">intercept()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoModel.html#intercept()">intercept()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html#intercept()">intercept()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#intercept()">intercept()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark"><span class="strong">InterruptibleIterator</span></a>&lt;<a href="./org/apache/spark/InterruptibleIterator.html" title="type parameter in InterruptibleIterator">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 An iterator that wraps around an existing iterator to provide task killing functionality.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/InterruptibleIterator.html#InterruptibleIterator(org.apache.spark.TaskContext, scala.collection.Iterator)">InterruptibleIterator(TaskContext, Iterator&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Intersect.html" title="class in org.apache.spark.sql.execution"><span class="strong">Intersect</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Returns the rows in left that also appear in right using the built in spark
 intersection function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Intersect.html#Intersect(org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">Intersect(SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Intersect.html" title="class in org.apache.spark.sql.execution">Intersect</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#intersect(org.apache.spark.sql.SchemaRDD)">intersect(SchemaRDD)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Performs a relational intersect on two SchemaRDDs</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#intersection(org.apache.spark.api.java.JavaDoubleRDD)">intersection(JavaDoubleRDD)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#intersection(org.apache.spark.api.java.JavaPairRDD)">intersection(JavaPairRDD&lt;K, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#intersection(org.apache.spark.api.java.JavaRDD)">intersection(JavaRDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD)">intersection(RDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">intersection(RDD&lt;T&gt;, Partitioner, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#intersection(org.apache.spark.rdd.RDD, int)">intersection(RDD&lt;T&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#intersection(org.apache.spark.sql.api.java.JavaSchemaRDD)">intersection(JavaSchemaRDD)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#intersection(org.apache.spark.sql.api.java.JavaSchemaRDD, org.apache.spark.Partitioner)">intersection(JavaSchemaRDD, Partitioner)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#intersection(org.apache.spark.sql.api.java.JavaSchemaRDD, int)">intersection(JavaSchemaRDD, int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return the intersection of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD)">intersection(RDD&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">intersection(RDD&lt;Row&gt;, Partitioner, Ordering&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#intersection(org.apache.spark.rdd.RDD, int)">intersection(RDD&lt;Row&gt;, int)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#intToIntWritable(int)">intToIntWritable(int)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#intWritableConverter()">intWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#isAkkaConf(java.lang.String)">isAkkaConf(String)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Return whether the given config is an akka config (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#isAllowed(scala.Enumeration.Value, scala.Enumeration.Value)">isAllowed(Enumeration.Value, Enumeration.Value)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#isBroadcast()">isBroadcast()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#isCached(java.lang.String)">isCached(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Returns true if the table is currently cached in-memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#isCached()">isCached()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#isCached()">isCached()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#isCheckpointed()">isCheckpointed()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return whether this RDD has been checkpointed or not</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#isCheckpointed()">isCheckpointed()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return whether this RDD has been checkpointed or not</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#isCheckpointPresent()">isCheckpointPresent()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#isCompleted()">isCompleted()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#isCompleted()">isCompleted()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">Returns whether the action has already been completed with a value or an exception.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SimpleFutureAction.html#isCompleted()">isCompleted()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#isCompleted()">isCompleted()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>
<div class="block">Checks whether the task has completed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/ArrayType.html#isContainsNull()">isContainsNull()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/ArrayType.html" title="class in org.apache.spark.sql.api.java">ArrayType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#isDriver()">isDriver()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#isExecutorStartupConf(java.lang.String)">isExecutorStartupConf(String)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Return whether the given config should be passed to an executor on start-up.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#isExtended()">isExtended()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#isInitialValueFinal()">isInitialValueFinal()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#isInterrupted()">isInterrupted()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>
<div class="block">Checks whether the task has been killed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#isLeaf()">isLeaf()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#isLocal()">isLocal()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#isLocal()">isLocal()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#isMulticlassClassification()">isMulticlassClassification()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#isMulticlassWithCategoricalFeatures()">isMulticlassWithCategoricalFeatures()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#isMultipleOf(org.apache.spark.streaming.Duration)">isMultipleOf(Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#isMultipleOf(org.apache.spark.streaming.Duration)">isMultipleOf(Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/StructField.html#isNullable()">isNullable()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/StructField.html" title="class in org.apache.spark.sql.api.java">StructField</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#isNullAt(int)">isNullAt(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns true if value at column `i` is NULL.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#isRDD()">isRDD()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#isShuffle()">isShuffle()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#isSparkPortConf(java.lang.String)">isSparkPortConf(String)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Return whether the given config is a Spark port config.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#isStarted()">isStarted()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Check if the receiver has started or not.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#isStopped()">isStopped()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Check if receiver has been marked for stopping.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#isTraceEnabled()">isTraceEnabled()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#isValid()">isValid()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/MapType.html#isValueContainsNull()">isValueContainsNull()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/MapType.html" title="class in org.apache.spark.sql.api.java">MapType</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#isZero()">isZero()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)">iterator(Partition, TaskContext)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Internal method to this RDD; will read from cache if applicable, or otherwise compute it.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#iterator(org.apache.spark.Partition, org.apache.spark.TaskContext)">iterator(Partition, TaskContext)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Internal method to this RDD; will read from cache if applicable, or otherwise compute it.</div>
</dd>
</dl>
<a name="_J_">
<!--   -->
</a>
<h2 class="title">J</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#j()">j()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#jarOfClass(java.lang.Class)">jarOfClass(Class&lt;?&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#jarOfClass(java.lang.Class)">jarOfClass(Class&lt;?&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#jarOfClass(java.lang.Class)">jarOfClass(Class&lt;?&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#jarOfClass(java.lang.Class)">jarOfClass(Class&lt;?&gt;)</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Find the JAR from which a given class was loaded, to make it easy for users to pass
 their JARs to StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#jarOfObject(java.lang.Object)">jarOfObject(Object)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Find the JAR that contains the class of a particular object, to make it easy for users
 to pass their JARs to SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#jarOfObject(java.lang.Object)">jarOfObject(Object)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Find the JAR that contains the class of a particular object, to make it easy for users
 to pass their JARs to SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#jars()">jars()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#jars()">jars()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java"><span class="strong">JavaDoubleRDD</span></a> - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#JavaDoubleRDD(org.apache.spark.rdd.RDD)">JavaDoubleRDD(RDD&lt;Object&gt;)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaDStream</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="type parameter in JavaDStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly interface to <a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream"><code>DStream</code></a>, the basic
 abstraction in Spark Streaming that represents a continuous stream of data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#JavaDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">JavaDStream(DStream&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java"><span class="strong">JavaDStreamLike</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">T</a>,<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">This</a> extends <a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">T</a>,<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">This</a>,<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">R</a>&gt;,<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">R</a> extends <a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">T</a>,<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="type parameter in JavaDStreamLike">R</a>&gt;&gt; - Interface in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java"><span class="strong">JavaHadoopRDD</span></a>&lt;<a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="type parameter in JavaHadoopRDD">K</a>,<a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="type parameter in JavaHadoopRDD">V</a>&gt; - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaHadoopRDD.html#JavaHadoopRDD(org.apache.spark.rdd.HadoopRDD, scala.reflect.ClassTag, scala.reflect.ClassTag)">JavaHadoopRDD(HadoopRDD&lt;K, V&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html" title="class in org.apache.spark.sql.hive.api.java"><span class="strong">JavaHiveContext</span></a> - Class in <a href="./org/apache/spark/sql/hive/api/java/package-summary.html">org.apache.spark.sql.hive.api.java</a></dt>
<dd>
<div class="block">The entry point for executing Spark SQL queries from a Java program.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html#JavaHiveContext(org.apache.spark.api.java.JavaSparkContext)">JavaHiveContext(JavaSparkContext)</a></span> - Constructor for class org.apache.spark.sql.hive.api.java.<a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html" title="class in org.apache.spark.sql.hive.api.java">JavaHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaInputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="type parameter in JavaInputDStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly interface to <a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>InputDStream</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html#JavaInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag)">JavaInputDStream(InputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming"><span class="strong">JavaKinesisWordCountASL</span></a> - Class in <a href="./org/apache/spark/examples/streaming/package-summary.html">org.apache.spark.examples.streaming</a></dt>
<dd>
<div class="block">Java-friendly Kinesis Spark Streaming WordCount example

 See http://spark.apache.org/docs/latest/streaming-kinesis.html for more details
 on the Kinesis Spark Streaming integration.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java"><span class="strong">JavaNewHadoopRDD</span></a>&lt;<a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="type parameter in JavaNewHadoopRDD">K</a>,<a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="type parameter in JavaNewHadoopRDD">V</a>&gt; - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html#JavaNewHadoopRDD(org.apache.spark.rdd.NewHadoopRDD, scala.reflect.ClassTag, scala.reflect.ClassTag)">JavaNewHadoopRDD(NewHadoopRDD&lt;K, V&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaPairDStream</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="type parameter in JavaPairDStream">K</a>,<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="type parameter in JavaPairDStream">V</a>&gt; - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly interface to a DStream of key-value pairs, which provides extra methods
 like <code>reduceByKey</code> and <code>join</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#JavaPairDStream(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag)">JavaPairDStream(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaPairInputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="type parameter in JavaPairInputDStream">K</a>,<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="type parameter in JavaPairInputDStream">V</a>&gt; - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly interface to <a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>InputDStream</code></a> of
 key-value pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#JavaPairInputDStream(org.apache.spark.streaming.dstream.InputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)">JavaPairInputDStream(InputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java"><span class="strong">JavaPairRDD</span></a>&lt;<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="type parameter in JavaPairRDD">K</a>,<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="type parameter in JavaPairRDD">V</a>&gt; - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#JavaPairRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag)">JavaPairRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaPairReceiverInputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="type parameter in JavaPairReceiverInputDStream">K</a>,<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="type parameter in JavaPairReceiverInputDStream">V</a>&gt; - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly interface to <a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>ReceiverInputDStream</code></a>, the
 abstract class for defining any input stream that receives data over the network.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#JavaPairReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag, scala.reflect.ClassTag)">JavaPairReceiverInputDStream(ReceiverInputDStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java"><span class="strong">JavaRDD</span></a>&lt;<a href="./org/apache/spark/api/java/JavaRDD.html" title="type parameter in JavaRDD">T</a>&gt; - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#JavaRDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">JavaRDD(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java"><span class="strong">JavaRDDLike</span></a>&lt;<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</a>,<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">This</a> extends <a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a>&lt;<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">T</a>,<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="type parameter in JavaRDDLike">This</a>&gt;&gt; - Interface in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaReceiverInputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="type parameter in JavaReceiverInputDStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly interface to <a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>ReceiverInputDStream</code></a>, the
 abstract class for defining any input stream that receives data over the network.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#JavaReceiverInputDStream(org.apache.spark.streaming.dstream.ReceiverInputDStream, scala.reflect.ClassTag)">JavaReceiverInputDStream(ReceiverInputDStream&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java"><span class="strong">JavaSchemaRDD</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">An RDD of <a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java"><code>Row</code></a> objects that is returned as the result of a Spark SQL query.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#JavaSchemaRDD(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">JavaSchemaRDD(SQLContext, LogicalPlan)</a></span> - Constructor for class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer"><span class="strong">JavaSerializer</span></a> - Class in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A Spark serializer that uses Java's built-in serialization.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/JavaSerializer.html#JavaSerializer(org.apache.spark.SparkConf)">JavaSerializer(SparkConf)</a></span> - Constructor for class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java"><span class="strong">JavaSparkContext</span></a> - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>
<div class="block">A Java-friendly version of <a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><code>SparkContext</code></a> that returns
 <a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java"><code>JavaRDD</code></a>s and works with Java collections instead of Scala ones.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(org.apache.spark.SparkContext)">JavaSparkContext(SparkContext)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext()">JavaSparkContext()</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Create a JavaSparkContext that loads settings from system properties (for instance, when
 launching with ./bin/spark-submit).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(org.apache.spark.SparkConf)">JavaSparkContext(SparkConf)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String)">JavaSparkContext(String, String)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, org.apache.spark.SparkConf)">JavaSparkContext(String, String, SparkConf)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String)">JavaSparkContext(String, String, String, String)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String[])">JavaSparkContext(String, String, String, String[])</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#JavaSparkContext(java.lang.String, java.lang.String, java.lang.String, java.lang.String[], java.util.Map)">JavaSparkContext(String, String, String, String[], Map&lt;String, String&gt;)</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java"><span class="strong">JavaSQLContext</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The entry point for executing Spark SQL queries from a Java program.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#JavaSQLContext(org.apache.spark.sql.SQLContext)">JavaSQLContext(SQLContext)</a></span> - Constructor for class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#JavaSQLContext(org.apache.spark.api.java.JavaSparkContext)">JavaSQLContext(JavaSparkContext)</a></span> - Constructor for class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java"><span class="strong">JavaStreamingContext</span></a> - Class in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">A Java-friendly version of <a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><code>StreamingContext</code></a> which is the main
 entry point for Spark Streaming functionality.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.streaming.StreamingContext)">JavaStreamingContext(StreamingContext)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration)">JavaStreamingContext(String, String, Duration)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String)">JavaStreamingContext(String, String, Duration, String, String)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[])">JavaStreamingContext(String, String, Duration, String, String[])</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, java.lang.String[], java.util.Map)">JavaStreamingContext(String, String, Duration, String, String[], Map&lt;String, String&gt;)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.api.java.JavaSparkContext, org.apache.spark.streaming.Duration)">JavaStreamingContext(JavaSparkContext, Duration)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a JavaStreamingContext using an existing JavaSparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(org.apache.spark.SparkConf, org.apache.spark.streaming.Duration)">JavaStreamingContext(SparkConf, Duration)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a JavaStreamingContext using a SparkConf configuration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String)">JavaStreamingContext(String)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Recreate a JavaStreamingContext from a checkpoint file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#JavaStreamingContext(java.lang.String, org.apache.hadoop.conf.Configuration)">JavaStreamingContext(String, Configuration)</a></span> - Constructor for class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Re-creates a JavaStreamingContext from a checkpoint file.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/api/java/JavaStreamingContextFactory.html" title="interface in org.apache.spark.streaming.api.java"><span class="strong">JavaStreamingContextFactory</span></a> - Interface in <a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a></dt>
<dd>
<div class="block">Factory interface for creating a new JavaStreamingContext</div>
</dd>
<dt><a href="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd"><span class="strong">JdbcRDD</span></a>&lt;<a href="./org/apache/spark/rdd/JdbcRDD.html" title="type parameter in JdbcRDD">T</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">An RDD that executes an SQL query on a JDBC connection and reads results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/JdbcRDD.html#JdbcRDD(org.apache.spark.SparkContext, scala.Function0, java.lang.String, long, long, int, scala.Function1, scala.reflect.ClassTag)">JdbcRDD(SparkContext, Function0&lt;Connection&gt;, String, long, long, int, Function1&lt;ResultSet, T&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html#jobId()">jobId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobStart.html#jobId()">jobId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler"><span class="strong">JobLogger</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A logger class to record runtime information for jobs in Spark.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#JobLogger(java.lang.String, java.lang.String)">JobLogger(String, String)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#JobLogger()">JobLogger()</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs"><span class="strong">JobProgressListener</span></a> - Class in <a href="./org/apache/spark/ui/jobs/package-summary.html">org.apache.spark.ui.jobs</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Tracks task-level information to be displayed in the UI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#JobProgressListener(org.apache.spark.SparkConf)">JobProgressListener(SparkConf)</a></span> - Constructor for class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/JobResult.html" title="interface in org.apache.spark.scheduler"><span class="strong">JobResult</span></a> - Interface in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A result of a job in the DAGScheduler.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html#jobResult()">jobResult()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/JobSucceeded.html" title="class in org.apache.spark.scheduler"><span class="strong">JobSucceeded</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobSucceeded.html#JobSucceeded()">JobSucceeded()</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobSucceeded.html" title="class in org.apache.spark.scheduler">JobSucceeded</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#join(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">join(JavaPairRDD&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#join(org.apache.spark.api.java.JavaPairRDD)">join(JavaPairRDD&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#join(org.apache.spark.api.java.JavaPairRDD, int)">join(JavaPairRDD&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">join(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD)">join(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#join(org.apache.spark.rdd.RDD, int)">join(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD containing all pairs of elements with matching keys in <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#join()">join()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#join(org.apache.spark.sql.SchemaRDD, org.apache.spark.sql.catalyst.plans.JoinType, scala.Option)">join(SchemaRDD, JoinType, Option&lt;Expression&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Performs a relational join on two SchemaRDDs</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#join(org.apache.spark.streaming.api.java.JavaPairDStream)">join(JavaPairDStream&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#join(org.apache.spark.streaming.api.java.JavaPairDStream, int)">join(JavaPairDStream&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#join(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)">join(JavaPairDStream&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">join(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">join(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">join(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#joinIterators(scala.collection.Iterator, scala.collection.Iterator)">joinIterators(Iterator&lt;Row&gt;, Iterator&lt;Row&gt;)</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#joinType()">joinType()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#joinType()">joinType()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#jsonFile(java.lang.String)">jsonFile(String)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">Loads a JSON file (one object per line), returning the result as a JavaSchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.api.java.StructType)">jsonFile(String, StructType)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a JavaSchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String)">jsonFile(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Loads a JSON file (one object per line), returning the result as a <a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, org.apache.spark.sql.catalyst.types.StructType)">jsonFile(String, StructType)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Loads a JSON file (one object per line) and applies the given schema,
 returning the result as a <a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#jsonFile(java.lang.String, double)">jsonFile(String, double)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD)">jsonRDD(JavaRDD&lt;String&gt;)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 JavaSchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#jsonRDD(org.apache.spark.api.java.JavaRDD, org.apache.spark.sql.api.java.StructType)">jsonRDD(JavaRDD&lt;String&gt;, StructType)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a JavaSchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD)">jsonRDD(RDD&lt;String&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Loads an RDD[String] storing JSON objects (one object per record), returning the result as a
 <a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, org.apache.spark.sql.catalyst.types.StructType)">jsonRDD(RDD&lt;String&gt;, StructType)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Loads an RDD[String] storing JSON objects (one object per record) and applies the given schema,
 returning the result as a <a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#jsonRDD(org.apache.spark.rdd.RDD, double)">jsonRDD(RDD&lt;String&gt;, double)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: Experimental ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/env/EnvironmentListener.html#jvmInformation()">jvmInformation()</a></span> - Method in class org.apache.spark.ui.env.<a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_K_">
<!--   -->
</a>
<h2 class="title">K</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#k()">k()</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>
<div class="block">Total number of clusters.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#K_MEANS_PARALLEL()">K_MEANS_PARALLEL()</a></span> - Static method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka"><span class="strong">KafkaUtils</span></a> - Class in <a href="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kafka/KafkaUtils.html#KafkaUtils()">KafkaUtils()</a></span> - Constructor for class org.apache.spark.streaming.kafka.<a href="./org/apache/spark/streaming/kafka/KafkaUtils.html" title="class in org.apache.spark.streaming.kafka">KafkaUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaHadoopRDD.html#kClassTag()">kClassTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html#kClassTag()">kClassTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#kClassTag()">kClassTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#kClassTag()">kClassTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#kClassTag()">kClassTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SetCommand.html#key()">key()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution">SetCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#keyBy(org.apache.spark.api.java.function.Function)">keyBy(Function&lt;T, K&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Creates tuples of the elements in this RDD by applying <code>f</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#keyBy(scala.Function1)">keyBy(Function1&lt;T, K&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Creates tuples of the elements in this RDD by applying <code>f</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#keyOrdering()">keyOrdering()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#keys()">keys()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the keys of each tuple.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#keys()">keys()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD with the keys of each tuple.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#kFold(org.apache.spark.rdd.RDD, int, int, scala.reflect.ClassTag)">kFold(RDD&lt;T&gt;, int, int, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">:: Experimental ::
 Return a k element array of pairs of RDDs with the first element of each pair
 containing the training data, a complement of the validation data and the second
 element, the validation data, containing a unique 1/kth of the data.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis"><span class="strong">KinesisUtils</span></a> - Class in <a href="./org/apache/spark/streaming/kinesis/package-summary.html">org.apache.spark.streaming.kinesis</a></dt>
<dd>
<div class="block">Helper class to create Amazon Kinesis Input Stream
 :: Experimental ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html#KinesisUtils()">KinesisUtils()</a></span> - Constructor for class org.apache.spark.streaming.kinesis.<a href="./org/apache/spark/streaming/kinesis/KinesisUtils.html" title="class in org.apache.spark.streaming.kinesis">KinesisUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#kManifest()">kManifest()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering"><span class="strong">KMeans</span></a> - Class in <a href="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</a></dt>
<dd>
<div class="block">K-means clustering with support for multiple parallel runs and a k-means++ like initialization
 mode (the k-means|| algorithm by Bahmani et al).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#KMeans()">KMeans()</a></span> - Constructor for class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Constructs a KMeans instance with default parameters: {k: 2, maxIterations: 20, runs: 1,
 initializationMode: "k-means||", initializationSteps: 5, epsilon: 1e-4}.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util"><span class="strong">KMeansDataGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generate test data for KMeans.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html#KMeansDataGenerator()">KMeansDataGenerator()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util">KMeansDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering"><span class="strong">KMeansModel</span></a> - Class in <a href="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</a></dt>
<dd>
<div class="block">A clustering model for K-means.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#KMeansModel(org.apache.spark.mllib.linalg.Vector[])">KMeansModel(Vector[])</a></span> - Constructor for class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/serializer/KryoRegistrator.html" title="interface in org.apache.spark.serializer"><span class="strong">KryoRegistrator</span></a> - Interface in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">Interface implemented by clients to register their classes with Kryo when using Kryo
 serialization.</div>
</dd>
<dt><a href="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer"><span class="strong">KryoSerializer</span></a> - Class in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">A Spark serializer that uses the <code>Kryo serialization library</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/KryoSerializer.html#KryoSerializer(org.apache.spark.SparkConf)">KryoSerializer(SparkConf)</a></span> - Constructor for class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_L_">
<!--   -->
</a>
<h2 class="title">L</h2>
<dl>
<dt><a href="./org/apache/spark/mllib/optimization/L1Updater.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">L1Updater</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Updater for L1 regularized problems.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/L1Updater.html#L1Updater()">L1Updater()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/L1Updater.html" title="class in org.apache.spark.mllib.optimization">L1Updater</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LabeledPoint.html#label()">label()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression"><span class="strong">LabeledPoint</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Class that represents the features and labels of a data point.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LabeledPoint.html#LabeledPoint(double, org.apache.spark.mllib.linalg.Vector)">LabeledPoint(double, Vector)</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html#labels()">labels()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#labels()">labels()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns the sequence of labels in ascending order</div>
</dd>
<dt><a href="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression"><span class="strong">LassoModel</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Regression model trained using Lasso.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoModel.html#LassoModel(org.apache.spark.mllib.linalg.Vector, double)">LassoModel(Vector, double)</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression"><span class="strong">LassoWithSGD</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Train a regression model with L1-regularization using Stochastic Gradient Descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html#LassoWithSGD()">LassoWithSGD()</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</a></dt>
<dd>
<div class="block">Construct a Lasso object with default parameters: {stepSize: 1.0, numIterations: 100,
 regParam: 1.0, miniBatchFraction: 1.0}.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#lastError()">lastError()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#lastErrorMessage()">lastErrorMessage()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/InputDStream.html#lastValidTime()">lastValidTime()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#latestModel()">latestModel()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</a></dt>
<dd>
<div class="block">Return the latest model.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#launchTime()">launchTime()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">LBFGS</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Class used to solve an optimization problem using Limited-memory BFGS.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#LBFGS(org.apache.spark.mllib.optimization.Gradient, org.apache.spark.mllib.optimization.Updater)">LBFGS(Gradient, Updater)</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">LeastSquaresGradient</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Compute gradient and loss for a Least-squared loss function, as used in linear regression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html#LeastSquaresGradient()">LeastSquaresGradient()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LeastSquaresGradient.html" title="class in org.apache.spark.mllib.optimization">LeastSquaresGradient</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CartesianProduct.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CartesianProduct.html" title="class in org.apache.spark.sql.execution">CartesianProduct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Except.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Except.html" title="class in org.apache.spark.sql.execution">Except</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#left()">left()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Intersect.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Intersect.html" title="class in org.apache.spark.sql.execution">Intersect</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>
<div class="block">The Streamed Relation</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#left()">left()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#leftImpurity()">leftImpurity()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#leftKeys()">leftKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#leftKeys()">leftKeys()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#leftKeys()">leftKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#leftKeys()">leftKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#leftKeys()">leftKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#leftNode()">leftNode()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#leftOuterJoin(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">leftOuterJoin(JavaPairRDD&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#leftOuterJoin(org.apache.spark.api.java.JavaPairRDD)">leftOuterJoin(JavaPairRDD&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#leftOuterJoin(org.apache.spark.api.java.JavaPairRDD, int)">leftOuterJoin(JavaPairRDD&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">leftOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD)">leftOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#leftOuterJoin(org.apache.spark.rdd.RDD, int)">leftOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Perform a left outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#leftOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream)">leftOuterJoin(JavaPairDStream&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#leftOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, int)">leftOuterJoin(JavaPairDStream&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#leftOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)">leftOuterJoin(JavaPairDStream&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">leftOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">leftOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">leftOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution"><span class="strong">LeftSemiJoinBNL</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Using BroadcastNestedLoopJoin to calculate left semi join result when there's no join keys
 for hash join.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#LeftSemiJoinBNL(org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan, scala.Option)">LeftSemiJoinBNL(SparkPlan, SparkPlan, Option&lt;Expression&gt;)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution"><span class="strong">LeftSemiJoinHash</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Build the right table's join keys into a HashSet, and iteratively go through the left
 table, to find the if join keys are in the Hash set.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#LeftSemiJoinHash(scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">LeftSemiJoinHash(Seq&lt;Expression&gt;, Seq&lt;Expression&gt;, SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#length()">length()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#length()">length()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>
<div class="block">Returns the number of columns present in this Row.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#length()">length()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution"><span class="strong">Limit</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Take the first limit elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Limit.html#Limit(int, org.apache.spark.sql.execution.SparkPlan)">Limit(int, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution">Limit</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Limit.html#limit()">limit()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution">Limit</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#limit()">limit()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#limit(org.apache.spark.sql.catalyst.expressions.Expression)">limit(Expression)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#limit(int)">limit(int)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Limits the results by the given integer.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util"><span class="strong">LinearDataGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generate sample data used for Linear Data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LinearDataGenerator.html#LinearDataGenerator()">LinearDataGenerator()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression"><span class="strong">LinearRegressionModel</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Regression model trained using LinearRegression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html#LinearRegressionModel(org.apache.spark.mllib.linalg.Vector, double)">LinearRegressionModel(Vector, double)</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression"><span class="strong">LinearRegressionWithSGD</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Train a linear regression model with no regularization using Stochastic Gradient Descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#LinearRegressionWithSGD()">LinearRegressionWithSGD()</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Construct a LinearRegression object with default parameters: {stepSize: 1.0,
 numIterations: 100, miniBatchFraction: 1.0}.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#listenerBus()">listenerBus()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledData(org.apache.spark.SparkContext, java.lang.String)">loadLabeledData(SparkContext, String)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>Should use <a href="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><code>RDD.saveAsTextFile(java.lang.String)</code></a> for saving and
            <a href="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><code>MLUtils.loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)</code></a> for loading.</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)">loadLabeledPoints(SparkContext, String, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads labeled points saved using <code>RDD[LabeledPoint].saveAsTextFile</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String)">loadLabeledPoints(SparkContext, String)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads labeled points saved using <code>RDD[LabeledPoint].saveAsTextFile</code> with the default number of
 partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, int, int)">loadLibSVMFile(SparkContext, String, int, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads labeled data in the LIBSVM format into an RDD[LabeledPoint].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, boolean, int, int)">loadLibSVMFile(SparkContext, String, boolean, int, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, int)">loadLibSVMFile(SparkContext, String, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads labeled data in the LIBSVM format into an RDD[LabeledPoint], with the default number of
 partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, boolean, int)">loadLibSVMFile(SparkContext, String, boolean, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String, boolean)">loadLibSVMFile(SparkContext, String, boolean)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadLibSVMFile(org.apache.spark.SparkContext, java.lang.String)">loadLibSVMFile(SparkContext, String)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads binary labeled data in the LIBSVM format into an RDD[LabeledPoint], with number of
 features determined automatically and the default number of partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#loadTestTable(java.lang.String)">loadTestTable(String)</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadVectors(org.apache.spark.SparkContext, java.lang.String, int)">loadVectors(SparkContext, String, int)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads vectors saved using <code>RDD[Vector].saveAsTextFile</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#loadVectors(org.apache.spark.SparkContext, java.lang.String)">loadVectors(SparkContext, String)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Loads vectors saved using <code>RDD[Vector].saveAsTextFile</code> with the default number of partitions.</div>
</dd>
<dt><a href="./org/apache/spark/sql/hive/LocalHiveContext.html" title="class in org.apache.spark.sql.hive"><span class="strong">LocalHiveContext</span></a> - Class in <a href="./org/apache/spark/sql/hive/package-summary.html">org.apache.spark.sql.hive</a></dt>
<dd>
<div class="block">DEPRECATED: Use HiveContext instead.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/LocalHiveContext.html#LocalHiveContext(org.apache.spark.SparkContext)">LocalHiveContext(SparkContext)</a></span> - Constructor for class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/LocalHiveContext.html" title="class in org.apache.spark.sql.hive">LocalHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#localValue()">localValue()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>
<div class="block">Get the current value of this accumulator from within a task.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#location()">location()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#log()">log()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#log_()">log_()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logDebug(scala.Function0)">logDebug(Function0&lt;String&gt;)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logDebug(scala.Function0, java.lang.Throwable)">logDebug(Function0&lt;String&gt;, Throwable)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#logDirName()">logDirName()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logError(scala.Function0)">logError(Function0&lt;String&gt;)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logError(scala.Function0, java.lang.Throwable)">logError(Function0&lt;String&gt;, Throwable)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark"><span class="strong">Logging</span></a> - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Utility trait for classes that want to log data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExplainCommand.html#logicalPlan()">logicalPlan()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution">ExplainCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#logicalPlanToSparkQuery(org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">logicalPlanToSparkQuery(LogicalPlan)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Allows catalyst LogicalPlans to be executed as a SchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logInfo(scala.Function0)">logInfo(Function0&lt;String&gt;)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logInfo(scala.Function0, java.lang.Throwable)">logInfo(Function0&lt;String&gt;, Throwable)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">LogisticGradient</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Compute gradient and loss for a logistic loss function, as used in binary classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LogisticGradient.html#LogisticGradient()">LogisticGradient()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LogisticGradient.html" title="class in org.apache.spark.mllib.optimization">LogisticGradient</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util"><span class="strong">LogisticRegressionDataGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generate test data for LogisticRegression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html#LogisticRegressionDataGenerator()">LogisticRegressionDataGenerator()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util">LogisticRegressionDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification"><span class="strong">LogisticRegressionModel</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Classification model trained using Logistic Regression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#LogisticRegressionModel(org.apache.spark.mllib.linalg.Vector, double)">LogisticRegressionModel(Vector, double)</a></span> - Constructor for class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification"><span class="strong">LogisticRegressionWithLBFGS</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Train a classification model for Logistic Regression using Limited-memory BFGS.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html#LogisticRegressionWithLBFGS()">LogisticRegressionWithLBFGS()</a></span> - Constructor for class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithLBFGS</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification"><span class="strong">LogisticRegressionWithSGD</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Train a classification model for Logistic Regression using Stochastic Gradient Descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#LogisticRegressionWithSGD()">LogisticRegressionWithSGD()</a></span> - Constructor for class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</a></dt>
<dd>
<div class="block">Construct a LogisticRegression object with default parameters</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logName()">logName()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logTrace(scala.Function0)">logTrace(Function0&lt;String&gt;)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logTrace(scala.Function0, java.lang.Throwable)">logTrace(Function0&lt;String&gt;, Throwable)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logWarning(scala.Function0)">logWarning(Function0&lt;String&gt;)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Logging.html#logWarning(scala.Function0, java.lang.Throwable)">logWarning(Function0&lt;String&gt;, Throwable)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/Logging.html" title="interface in org.apache.spark">Logging</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#longToLongWritable(long)">longToLongWritable(long)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#LongType">LongType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the LongType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/LongType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">LongType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing long and Long values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#longWritableConverter()">longWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#lookup(K)">lookup(K)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return the list of values in the RDD for key <code>key</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#lookup(K)">lookup(K)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return the list of values in the RDD for key <code>key</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/BoundedDouble.html#low()">low()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io"><span class="strong">LZ4CompressionCodec</span></a> - Class in <a href="./org/apache/spark/io/package-summary.html">org.apache.spark.io</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 LZ4 implementation of <a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><code>CompressionCodec</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/LZ4CompressionCodec.html#LZ4CompressionCodec(org.apache.spark.SparkConf)">LZ4CompressionCodec(SparkConf)</a></span> - Constructor for class org.apache.spark.io.<a href="./org/apache/spark/io/LZ4CompressionCodec.html" title="class in org.apache.spark.io">LZ4CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io"><span class="strong">LZFCompressionCodec</span></a> - Class in <a href="./org/apache/spark/io/package-summary.html">org.apache.spark.io</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 LZF implementation of <a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><code>CompressionCodec</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/LZFCompressionCodec.html#LZFCompressionCodec(org.apache.spark.SparkConf)">LZFCompressionCodec(SparkConf)</a></span> - Constructor for class org.apache.spark.io.<a href="./org/apache/spark/io/LZFCompressionCodec.html" title="class in org.apache.spark.io">LZFCompressionCodec</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_M_">
<!--   -->
</a>
<h2 class="title">M</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html#main(java.lang.String[])">main(String[])</a></span> - Static method in class org.apache.spark.examples.streaming.<a href="./org/apache/spark/examples/streaming/JavaKinesisWordCountASL.html" title="class in org.apache.spark.examples.streaming">JavaKinesisWordCountASL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html#main(java.lang.String[])">main(String[])</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/KMeansDataGenerator.html" title="class in org.apache.spark.mllib.util">KMeansDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LinearDataGenerator.html#main(java.lang.String[])">main(String[])</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LinearDataGenerator.html" title="class in org.apache.spark.mllib.util">LinearDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html#main(java.lang.String[])">main(String[])</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/LogisticRegressionDataGenerator.html" title="class in org.apache.spark.mllib.util">LogisticRegressionDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MFDataGenerator.html#main(java.lang.String[])">main(String[])</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MFDataGenerator.html" title="class in org.apache.spark.mllib.util">MFDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/SVMDataGenerator.html#main(java.lang.String[])">main(String[])</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/SVMDataGenerator.html" title="class in org.apache.spark.mllib.util">SVMDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#makeCopy(java.lang.Object[])">makeCopy(Object[])</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>
<div class="block">Overridden make copy also propogates sqlContext to copied plan.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#makeRDD(scala.collection.Seq, int, scala.reflect.ClassTag)">makeRDD(Seq&lt;T&gt;, int, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#makeRDD(scala.collection.Seq, scala.reflect.ClassTag)">makeRDD(Seq&lt;Tuple2&lt;T, Seq&lt;String&gt;&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD, with one or more
 location preferences (hostnames of Spark nodes) for each object.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#map(org.apache.spark.api.java.function.Function)">map(Function&lt;T, R&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#map(scala.Function1)">map(Function1&lt;R, T&gt;)</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>
<div class="block">Transform this PartialResult into a PartialResult of type T.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#map(scala.Function1, scala.reflect.ClassTag)">map(Function1&lt;T, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#map(org.apache.spark.api.java.function.Function)">map(Function&lt;T, R&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream by applying a function to all elements of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#map(scala.Function1, scala.reflect.ClassTag)">map(Function1&lt;T, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying a function to all elements of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/FetchFailed.html#mapId()">mapId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleBlockId.html#mapId()">mapId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleIndexBlockId.html#mapId()">mapId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#mapOutputTracker()">mapOutputTracker()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction)">mapPartitions(FlatMapFunction&lt;Iterator&lt;T&gt;, U&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction, boolean)">mapPartitions(FlatMapFunction&lt;Iterator&lt;T&gt;, U&gt;, boolean)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)">mapPartitions(Function1&lt;Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#mapPartitions(org.apache.spark.api.java.function.FlatMapFunction)">mapPartitions(FlatMapFunction&lt;Iterator&lt;T&gt;, U&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#mapPartitions(scala.Function1, boolean, scala.reflect.ClassTag)">mapPartitions(Function1&lt;Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction)">mapPartitionsToDouble(DoubleFlatMapFunction&lt;Iterator&lt;T&gt;&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToDouble(org.apache.spark.api.java.function.DoubleFlatMapFunction, boolean)">mapPartitionsToDouble(DoubleFlatMapFunction&lt;Iterator&lt;T&gt;&gt;, boolean)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction)">mapPartitionsToPair(PairFlatMapFunction&lt;Iterator&lt;T&gt;, K2, V2&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction, boolean)">mapPartitionsToPair(PairFlatMapFunction&lt;Iterator&lt;T&gt;, K2, V2&gt;, boolean)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#mapPartitionsToPair(org.apache.spark.api.java.function.PairFlatMapFunction)">mapPartitionsToPair(PairFlatMapFunction&lt;Iterator&lt;T&gt;, K2, V2&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying mapPartitions() to each RDDs
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#mapPartitionsWithContext(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithContext(Function2&lt;TaskContext, Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Return a new RDD by applying a function to each partition of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapPartitionsWithIndex(org.apache.spark.api.java.function.Function2, boolean)">mapPartitionsWithIndex(Function2&lt;Integer, Iterator&lt;T&gt;, Iterator&lt;R&gt;&gt;, boolean)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#mapPartitionsWithIndex(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithIndex(Function2&lt;Object, Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaHadoopRDD.html#mapPartitionsWithInputSplit(org.apache.spark.api.java.function.Function2, boolean)">mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;R&gt;&gt;, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</a></dt>
<dd>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html#mapPartitionsWithInputSplit(org.apache.spark.api.java.function.Function2, boolean)">mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;R&gt;&gt;, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</a></dt>
<dd>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#mapPartitionsWithInputSplit(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/NewHadoopRDD.html#mapPartitionsWithInputSplit(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithInputSplit(Function2&lt;InputSplit, Iterator&lt;Tuple2&lt;K, V&gt;&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a></dt>
<dd>
<div class="block">Maps over a partition, providing the InputSplit that was used as the base of the partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#mapPartitionsWithSplit(scala.Function2, boolean, scala.reflect.ClassTag)">mapPartitionsWithSplit(Function2&lt;Object, Iterator&lt;T&gt;, Iterator&lt;U&gt;&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to each partition of this RDD, while tracking the index
 of the original partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#mapredInputFormat()">mapredInputFormat()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#mapreduceInputFormat()">mapreduceInputFormat()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#mapSideCombine()">mapSideCombine()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapToDouble(org.apache.spark.api.java.function.DoubleFunction)">mapToDouble(DoubleFunction&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#mapToPair(org.apache.spark.api.java.function.PairFunction)">mapToPair(PairFunction&lt;T, K2, V2&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return a new RDD by applying a function to all elements of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#mapToPair(org.apache.spark.api.java.function.PairFunction)">mapToPair(PairFunction&lt;T, K2, V2&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream by applying a function to all elements of this DStream.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/MapType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">MapType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing Maps.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#mapValues(org.apache.spark.api.java.function.Function)">mapValues(Function&lt;V, U&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Pass each value in the key-value pair RDD through a map function without changing the keys;
 this also retains the original RDD's partitioning.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#mapValues(scala.Function1)">mapValues(Function1&lt;V, U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Pass each value in the key-value pair RDD through a map function without changing the keys;
 this also retains the original RDD's partitioning.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#mapValues(org.apache.spark.api.java.function.Function)">mapValues(Function&lt;V, U&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapValues(scala.Function1, scala.reflect.ClassTag)">mapValues(Function1&lt;V, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#mapWith(scala.Function1, boolean, scala.Function2, scala.reflect.ClassTag)">mapWith(Function1&lt;Object, A&gt;, boolean, Function2&lt;T, A, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Maps f over this RDD, where f takes an additional parameter of type A.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#master()">master()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#master()">master()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg"><span class="strong">Matrices</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">Factory methods for <a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg"><code>Matrix</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrices.html#Matrices()">Matrices()</a></span> - Constructor for class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrices.html" title="class in org.apache.spark.mllib.linalg">Matrices</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg"><span class="strong">Matrix</span></a> - Interface in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">Trait for a local matrix.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed"><span class="strong">MatrixEntry</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents an entry in an distributed matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#MatrixEntry(long, long, double)">MatrixEntry(long, long, double)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation"><span class="strong">MatrixFactorizationModel</span></a> - Class in <a href="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</a></dt>
<dd>
<div class="block">Model representing the result of matrix factorization.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#max(java.util.Comparator)">max(Comparator&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Returns the maximum element from this RDD as defined by the specified
 Comparator[T].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#max()">max()</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#max()">max()</a></span> - Method in interface org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</a></dt>
<dd>
<div class="block">Maximum value of each column.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#max(scala.math.Ordering)">max(Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Returns the max of this RDD as defined by the implicit Ordering[T].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#max(org.apache.spark.streaming.Duration)">max(Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#max(org.apache.spark.streaming.Time)">max(Time)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#max()">max()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#maxBins()">maxBins()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#maxDepth()">maxDepth()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#maxMem()">maxMem()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#maxMem()">maxMem()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#maxMemoryInMB()">maxMemoryInMB()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#mean()">mean()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute the mean of this RDD's elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScalerModel.html#mean()">mean()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/PoissonGenerator.html#mean()">mean()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#mean()">mean()</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#mean()">mean()</a></span> - Method in interface org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</a></dt>
<dd>
<div class="block">Sample mean vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/BoundedDouble.html#mean()">mean()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#mean()">mean()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute the mean of this RDD's elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#mean()">mean()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#meanApprox(long, java.lang.Double)">meanApprox(long, Double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return the approximate mean of the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#meanApprox(long)">meanApprox(long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate operation to return the mean within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#meanApprox(long, double)">meanApprox(long, double)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate operation to return the mean within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK">MEMORY_AND_DISK</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK()">MEMORY_AND_DISK()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK_2">MEMORY_AND_DISK_2</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK_2()">MEMORY_AND_DISK_2()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK_SER">MEMORY_AND_DISK_SER</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK_SER()">MEMORY_AND_DISK_SER()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_AND_DISK_SER_2">MEMORY_AND_DISK_SER_2</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_AND_DISK_SER_2()">MEMORY_AND_DISK_SER_2()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY">MEMORY_ONLY</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY()">MEMORY_ONLY()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY_2">MEMORY_ONLY_2</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY_2()">MEMORY_ONLY_2()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY_SER">MEMORY_ONLY_SER</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY_SER()">MEMORY_ONLY_SER()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#MEMORY_ONLY_SER_2">MEMORY_ONLY_SER_2</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#MEMORY_ONLY_SER_2()">MEMORY_ONLY_SER_2()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#memRemaining()">memRemaining()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the memory remaining in this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#memSize()">memSize()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#memSize()">memSize()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#memUsed()">memUsed()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the memory used by this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#memUsedByRdd(int)">memUsedByRdd(int)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the memory used by the given RDD in this block manager in O(1) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#merge(R)">merge(R)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>
<div class="block">Merge two accumulable objects together</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html#merge(org.apache.spark.mllib.feature.IDF.DocumentFrequencyAggregator)">merge(IDF.DocumentFrequencyAggregator)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDF.DocumentFrequencyAggregator.html" title="class in org.apache.spark.mllib.feature">IDF.DocumentFrequencyAggregator</a></dt>
<dd>
<div class="block">Merges another.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#merge(org.apache.spark.mllib.stat.MultivariateOnlineSummarizer)">merge(MultivariateOnlineSummarizer)</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>
<div class="block">Merge another MultivariateOnlineSummarizer, and update the statistical summary.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#merge(double)">merge(double)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Add a value into this StatCounter, updating the internal statistics.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#merge(scala.collection.TraversableOnce)">merge(TraversableOnce&lt;Object&gt;)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Add multiple values into this StatCounter, updating the internal statistics.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#merge(org.apache.spark.util.StatCounter)">merge(StatCounter)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Merge another StatCounter into this one, adding up the internal statistics.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#mergeCombiners()">mergeCombiners()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Aggregator.html#mergeValue()">mergeValue()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Aggregator.html" title="class in org.apache.spark">Aggregator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#metadataCleaner()">metadataCleaner()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/LocalHiveContext.html#metastorePath()">metastorePath()</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/LocalHiveContext.html" title="class in org.apache.spark.sql.hive">LocalHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#metastorePath()">metastorePath()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#method()">method()</a></span> - Method in class org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExceptionFailure.html#metrics()">metrics()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#metricsSystem()">metricsSystem()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/util/MFDataGenerator.html" title="class in org.apache.spark.mllib.util"><span class="strong">MFDataGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generate RDD(s) containing data for Matrix Factorization.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MFDataGenerator.html#MFDataGenerator()">MFDataGenerator()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MFDataGenerator.html" title="class in org.apache.spark.mllib.util">MFDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#milliseconds()">milliseconds()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/Milliseconds.html" title="class in org.apache.spark.streaming"><span class="strong">Milliseconds</span></a> - Class in <a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a></dt>
<dd>
<div class="block">Helper object that creates instance of <a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><code>Duration</code></a> representing
 a given number of milliseconds.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Milliseconds.html#Milliseconds()">Milliseconds()</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Milliseconds.html" title="class in org.apache.spark.streaming">Milliseconds</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#milliseconds()">milliseconds()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#millisToString(long)">millisToString(long)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>
<div class="block">Reformat a time interval in milliseconds to a prettier format for output</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#min(java.util.Comparator)">min(Comparator&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Returns the minimum element from this RDD as defined by the specified
 Comparator[T].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#min()">min()</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#min()">min()</a></span> - Method in interface org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</a></dt>
<dd>
<div class="block">Minimum value of each column.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#min(scala.math.Ordering)">min(Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Returns the min of this RDD as defined by the implicit Ordering[T].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#min(org.apache.spark.streaming.Duration)">min(Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#min(org.apache.spark.streaming.Time)">min(Time)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#min()">min()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#MinMax()">MinMax()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#minutes()">minutes()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/Minutes.html" title="class in org.apache.spark.streaming"><span class="strong">Minutes</span></a> - Class in <a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a></dt>
<dd>
<div class="block">Helper object that creates instance of <a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><code>Duration</code></a> representing
 a given number of minutes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Minutes.html#Minutes()">Minutes()</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Minutes.html" title="class in org.apache.spark.streaming">Minutes</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util"><span class="strong">MLUtils</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">Helper methods to load, save and pre-process data used in ML Lib.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#MLUtils()">MLUtils()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#model()">model()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt"><span class="strong">MQTTUtils</span></a> - Class in <a href="./org/apache/spark/streaming/mqtt/package-summary.html">org.apache.spark.streaming.mqtt</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html#MQTTUtils()">MQTTUtils()</a></span> - Constructor for class org.apache.spark.streaming.mqtt.<a href="./org/apache/spark/streaming/mqtt/MQTTUtils.html" title="class in org.apache.spark.streaming.mqtt">MQTTUtils</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation"><span class="strong">MulticlassMetrics</span></a> - Class in <a href="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</a></dt>
<dd>
<div class="block">::Experimental::
 Evaluator for multiclass classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#MulticlassMetrics(org.apache.spark.rdd.RDD)">MulticlassMetrics(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</a></span> - Constructor for class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#multiply(org.apache.spark.mllib.linalg.Matrix)">multiply(Matrix)</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>
<div class="block">Multiply this matrix by a local matrix on the right.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#multiply(org.apache.spark.mllib.linalg.Matrix)">multiply(Matrix)</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Multiply this matrix by a local matrix on the right.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#multiply(double)">multiply(double)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat"><span class="strong">MultivariateOnlineSummarizer</span></a> - Class in <a href="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 MultivariateOnlineSummarizer implements <a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat"><code>MultivariateStatisticalSummary</code></a> to compute the mean,
 variance, minimum, maximum, counts, and nonzero counts for samples in sparse or dense vector
 format in a online fashion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#MultivariateOnlineSummarizer()">MultivariateOnlineSummarizer()</a></span> - Constructor for class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat"><span class="strong">MultivariateStatisticalSummary</span></a> - Interface in <a href="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</a></dt>
<dd>
<div class="block">Trait for multivariate statistical summary of a data matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#mustCheckpoint()">mustCheckpoint()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util"><span class="strong">MutablePair</span></a>&lt;<a href="./org/apache/spark/util/MutablePair.html" title="type parameter in MutablePair">T1</a>,<a href="./org/apache/spark/util/MutablePair.html" title="type parameter in MutablePair">T2</a>&gt; - Class in <a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A tuple of 2 elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#MutablePair(T1, T2)">MutablePair(T1, T2)</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#MutablePair()">MutablePair()</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>
<div class="block">No-arg constructor for serialization</div>
</dd>
</dl>
<a name="_N_">
<!--   -->
</a>
<h2 class="title">N</h2>
<dl>
<dt><a href="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification"><span class="strong">NaiveBayes</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Trains a Naive Bayes model given an RDD of <code>(label, features)</code> pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayes.html#NaiveBayes()">NaiveBayes()</a></span> - Constructor for class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification"><span class="strong">NaiveBayesModel</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Model for Naive Bayes Classifiers.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#name()">name()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#name()">name()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#name()">name()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">A friendly name for this RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#name()">name()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#name()">name()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html#name()">name()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext.TestTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>
<div class="block">A globally unique identifier for this Block.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BroadcastBlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BroadcastBlockId.html" title="class in org.apache.spark.storage">BroadcastBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDBlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleBlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleIndexBlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StreamBlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/TaskResultBlockId.html#name()">name()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage">TaskResultBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#name()">name()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark"><span class="strong">NarrowDependency</span></a>&lt;<a href="./org/apache/spark/NarrowDependency.html" title="type parameter in NarrowDependency">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Base class for dependencies where each partition of the child RDD depends on a small number
 of partitions of the parent RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/NarrowDependency.html#NarrowDependency(org.apache.spark.rdd.RDD)">NarrowDependency(RDD&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark">NarrowDependency</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/NativeCommand.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">NativeCommand</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/NativeCommand.html#NativeCommand(java.lang.String, scala.collection.Seq, org.apache.spark.sql.hive.HiveContext)">NativeCommand(String, Seq&lt;Attribute&gt;, HiveContext)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/NativeCommand.html" title="class in org.apache.spark.sql.hive.execution">NativeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#nettyPort()">nettyPort()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#networkStream(org.apache.spark.streaming.receiver.Receiver, scala.reflect.ClassTag)">networkStream(Receiver&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#newAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">newAPIHadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, Configuration)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#newAPIHadoopFile(java.lang.String, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">newAPIHadoopFile(String, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop file with an arbitrary new API InputFormat.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#newAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">newAPIHadoopFile(String, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;, Configuration)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#newAPIHadoopRDD(org.apache.hadoop.conf.Configuration, java.lang.Class, java.lang.Class, java.lang.Class)">newAPIHadoopRDD(Configuration, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#newAPIHadoopRDD(org.apache.hadoop.conf.Configuration, java.lang.Class, java.lang.Class, java.lang.Class)">newAPIHadoopRDD(Configuration, Class&lt;F&gt;, Class&lt;K&gt;, Class&lt;V&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a given Hadoop file with an arbitrary new API InputFormat
 and extra configuration options to pass to the input format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/BroadcastFactory.html#newBroadcast(T, boolean, long, scala.reflect.ClassTag)">newBroadcast(T, boolean, long, ClassTag&lt;T&gt;)</a></span> - Method in interface org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</a></dt>
<dd>
<div class="block">Creates a new broadcast variable.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html#newBroadcast(T, boolean, long, scala.reflect.ClassTag)">newBroadcast(T, boolean, long, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#newBroadcast(T, boolean, long, scala.reflect.ClassTag)">newBroadcast(T, boolean, long, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd"><span class="strong">NewHadoopRDD</span></a>&lt;<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">K</a>,<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="type parameter in NewHadoopRDD">V</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 An RDD that provides core functionality for reading data stored in Hadoop (e.g., files in HDFS,
 sources in HBase, or S3), using the new MapReduce API (<code>org.apache.hadoop.mapreduce</code>).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/NewHadoopRDD.html#NewHadoopRDD(org.apache.spark.SparkContext, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">NewHadoopRDD(SparkContext, Class&lt;? extends InputFormat&lt;K, V&gt;&gt;, Class&lt;K&gt;, Class&lt;V&gt;, Configuration)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/NewHadoopRDD.html" title="class in org.apache.spark.rdd">NewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/JavaSerializer.html#newInstance()">newInstance()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/KryoSerializer.html#newInstance()">newInstance()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/Serializer.html#newInstance()">newInstance()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</a></dt>
<dd>
<div class="block">Creates a new <a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer"><code>SerializerInstance</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html#newInstance()">newInstance()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution">SparkLogicalPlan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/KryoSerializer.html#newKryo()">newKryo()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/KryoSerializer.html#newKryoOutput()">newKryoOutput()</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/KryoSerializer.html" title="class in org.apache.spark.serializer">KryoSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Exchange.html#newPartitioning()">newPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution">Exchange</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/InterruptibleIterator.html#next()">next()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/InterruptibleIterator.html" title="class in org.apache.spark">InterruptibleIterator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/PoissonGenerator.html#nextValue()">nextValue()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomDataGenerator.html#nextValue()">nextValue()</a></span> - Method in interface org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="interface in org.apache.spark.mllib.random">RandomDataGenerator</a></dt>
<dd>
<div class="block">Returns an i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html#nextValue()">nextValue()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/UniformGenerator.html#nextValue()">nextValue()</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#NO_PREF()">NO_PREF()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model"><span class="strong">Node</span></a> - Class in <a href="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Node in a decision tree</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#Node(int, double, boolean, scala.Option, scala.Option, scala.Option, scala.Option)">Node(int, double, boolean, Option&lt;Split&gt;, Option&lt;Node&gt;, Option&lt;Node&gt;, Option&lt;InformationGainStats&gt;)</a></span> - Constructor for class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#NODE_LOCAL()">NODE_LOCAL()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#NONE">NONE</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SchedulingMode.html#NONE()">NONE()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#NONE()">NONE()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature"><span class="strong">Normalizer</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Normalizes samples individually to unit L^p^ norm</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Normalizer.html#Normalizer(double)">Normalizer(double)</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature">Normalizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Normalizer.html#Normalizer()">Normalizer()</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature">Normalizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)">normalJavaRDD(JavaSparkContext, long, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Java-friendly version of <a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalRDD(org.apache.spark.SparkContext, long, int, long)"><code>RandomRDDs.normalRDD(org.apache.spark.SparkContext, long, int, long)</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int)">normalJavaRDD(JavaSparkContext, long, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><code>RandomRDDs.normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</code></a> with the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long)">normalJavaRDD(JavaSparkContext, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><code>RandomRDDs.normalJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</code></a> with the default number of partitions and the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)">normalJavaVectorRDD(JavaSparkContext, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Java-friendly version of <a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalVectorRDD(org.apache.spark.SparkContext, long, int, int, long)"><code>RandomRDDs.normalVectorRDD(org.apache.spark.SparkContext, long, int, int, long)</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int)">normalJavaVectorRDD(JavaSparkContext, long, int, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><code>RandomRDDs.normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</code></a> with the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int)">normalJavaVectorRDD(JavaSparkContext, long, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><code>RandomRDDs.normalJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</code></a> with the default number of partitions and the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#normalOutput()">normalOutput()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalRDD(org.apache.spark.SparkContext, long, int, long)">normalRDD(SparkContext, long, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Generates an RDD comprised of i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#normalVectorRDD(org.apache.spark.SparkContext, long, int, int, long)">normalVectorRDD(SparkContext, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Generates an RDD[Vector] with vectors containing i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#nullHypothesis()">nullHypothesis()</a></span> - Method in class org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/TestResult.html#nullHypothesis()">nullHypothesis()</a></span> - Method in interface org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</a></dt>
<dd>
<div class="block">Null hypothesis of the test.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Statistics.html#numberOfHiccups()">numberOfHiccups()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Statistics.html#numberOfMsgs()">numberOfMsgs()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Statistics.html#numberOfWorkers()">numberOfWorkers()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#numBlocks()">numBlocks()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the number of blocks stored in this block manager in O(RDDs) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#numCachedPartitions()">numCachedPartitions()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#numClassesForClassification()">numClassesForClassification()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseMatrix.html#numCols()">numCols()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#numCols()">numCols()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>
<div class="block">Gets or computes the number of columns.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html#numCols()">numCols()</a></span> - Method in interface org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed">DistributedMatrix</a></dt>
<dd>
<div class="block">Gets or computes the number of columns.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#numCols()">numCols()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#numCols()">numCols()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Gets or computes the number of columns.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrix.html#numCols()">numCols()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</a></dt>
<dd>
<div class="block">Number of columns.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#numericRDDToDoubleRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Numeric)">numericRDDToDoubleRDDFunctions(RDD&lt;T&gt;, Numeric&lt;T&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#numFeatures()">numFeatures()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#numInLinks()">numInLinks()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#numNodes()">numNodes()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>
<div class="block">Get number of nodes in tree, including leaf nodes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#numNonzeros()">numNonzeros()</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#numNonzeros()">numNonzeros()</a></span> - Method in interface org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</a></dt>
<dd>
<div class="block">Number of nonzero elements (including explicitly presented zero values) in each column.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#numOutLinks()">numOutLinks()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/HashPartitioner.html#numPartitions()">numPartitions()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/HashPartitioner.html" title="class in org.apache.spark">HashPartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Partitioner.html#numPartitions()">numPartitions()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#numPartitions()">numPartitions()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#numPartitions()">numPartitions()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html#numRatings()">numRatings()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.BlockStats.html" title="class in org.apache.spark.mllib.recommendation">ALS.BlockStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#numRddBlocks()">numRddBlocks()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the number of RDD blocks stored in this block manager in O(RDDs) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#numRddBlocksById(int)">numRddBlocksById(int)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the number of blocks that belong to the given RDD in O(1) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseMatrix.html#numRows()">numRows()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#numRows()">numRows()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>
<div class="block">Gets or computes the number of rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html#numRows()">numRows()</a></span> - Method in interface org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed">DistributedMatrix</a></dt>
<dd>
<div class="block">Gets or computes the number of rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#numRows()">numRows()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#numRows()">numRows()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Gets or computes the number of rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrix.html#numRows()">numRows()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</a></dt>
<dd>
<div class="block">Number of rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#numTasks()">numTasks()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_O_">
<!--   -->
</a>
<h2 class="title">O</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#objectFile(java.lang.String, int)">objectFile(String, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Load an RDD saved as a SequenceFile containing serialized objects, with NullWritable keys and
 BytesWritable values that contain a serialized partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#objectFile(java.lang.String)">objectFile(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Load an RDD saved as a SequenceFile containing serialized objects, with NullWritable keys and
 BytesWritable values that contain a serialized partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#objectFile(java.lang.String, int, scala.reflect.ClassTag)">objectFile(String, int, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Load an RDD saved as a SequenceFile containing serialized objects, with NullWritable keys and
 BytesWritable values that contain a serialized partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#OFF_HEAP">OFF_HEAP</a></span> - Static variable in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#OFF_HEAP()">OFF_HEAP()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#offHeapUsed()">offHeapUsed()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the off-heap space used by this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#offHeapUsedByRdd(int)">offHeapUsedByRdd(int)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the off-heap space used by the given RDD in this block manager in O(1) time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onApplicationEnd(org.apache.spark.scheduler.SparkListenerApplicationEnd)">onApplicationEnd(SparkListenerApplicationEnd)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when the application ends</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onApplicationStart(org.apache.spark.scheduler.SparkListenerApplicationStart)">onApplicationStart(SparkListenerApplicationStart)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when the application starts</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html#onBatchCompleted(org.apache.spark.streaming.scheduler.StreamingListenerBatchCompleted)">onBatchCompleted(StreamingListenerBatchCompleted)</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html#onBatchCompleted(org.apache.spark.streaming.scheduler.StreamingListenerBatchCompleted)">onBatchCompleted(StreamingListenerBatchCompleted)</a></span> - Method in interface org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</a></dt>
<dd>
<div class="block">Called when processing of a batch of jobs has completed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html#onBatchStarted(org.apache.spark.streaming.scheduler.StreamingListenerBatchStarted)">onBatchStarted(StreamingListenerBatchStarted)</a></span> - Method in interface org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</a></dt>
<dd>
<div class="block">Called when processing of a batch of jobs has started.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html#onBatchSubmitted(org.apache.spark.streaming.scheduler.StreamingListenerBatchSubmitted)">onBatchSubmitted(StreamingListenerBatchSubmitted)</a></span> - Method in interface org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</a></dt>
<dd>
<div class="block">Called when a batch of jobs has been submitted for processing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)">onBlockManagerAdded(SparkListenerBlockManagerAdded)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a new block manager has joined</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)">onBlockManagerAdded(SparkListenerBlockManagerAdded)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onBlockManagerAdded(org.apache.spark.scheduler.SparkListenerBlockManagerAdded)">onBlockManagerAdded(SparkListenerBlockManagerAdded)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)">onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when an existing block manager has been removed</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)">onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onBlockManagerRemoved(org.apache.spark.scheduler.SparkListenerBlockManagerRemoved)">onBlockManagerRemoved(SparkListenerBlockManagerRemoved)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#onComplete(scala.Function1, scala.concurrent.ExecutionContext)">onComplete(Function1&lt;Try&lt;T&gt;, U&gt;, ExecutionContext)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#onComplete(scala.Function1, scala.concurrent.ExecutionContext)">onComplete(Function1&lt;Try&lt;T&gt;, U&gt;, ExecutionContext)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">When this action is completed, either through an exception, or a value, applies the provided
 function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#onComplete(scala.Function1)">onComplete(Function1&lt;R, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>
<div class="block">Set a handler to be called when this PartialResult completes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SimpleFutureAction.html#onComplete(scala.Function1, scala.concurrent.ExecutionContext)">onComplete(Function1&lt;Try&lt;T&gt;, U&gt;, ExecutionContext)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)">onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when environment properties have been updated</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/env/EnvironmentListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)">onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</a></span> - Method in class org.apache.spark.ui.env.<a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onEnvironmentUpdate(org.apache.spark.scheduler.SparkListenerEnvironmentUpdate)">onEnvironmentUpdate(SparkListenerEnvironmentUpdate)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#ones(int)">ones(int)</a></span> - Static method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/OneToOneDependency.html" title="class in org.apache.spark"><span class="strong">OneToOneDependency</span></a>&lt;<a href="./org/apache/spark/OneToOneDependency.html" title="type parameter in OneToOneDependency">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Represents a one-to-one dependency between partitions of the parent and child RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/OneToOneDependency.html#OneToOneDependency(org.apache.spark.rdd.RDD)">OneToOneDependency(RDD&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/OneToOneDependency.html" title="class in org.apache.spark">OneToOneDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onExecutorMetricsUpdate(org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate)">onExecutorMetricsUpdate(SparkListenerExecutorMetricsUpdate)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when the driver receives task metrics from an executor in a heartbeat.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onExecutorMetricsUpdate(org.apache.spark.scheduler.SparkListenerExecutorMetricsUpdate)">onExecutorMetricsUpdate(SparkListenerExecutorMetricsUpdate)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#onFail(scala.Function1)">onFail(Function1&lt;Exception, BoxedUnit&gt;)</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>
<div class="block">Set a handler to be called if this PartialResult's job fails.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)">onJobEnd(SparkListenerJobEnd)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>
<div class="block">When job ends, recording job completion status and close log file</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onJobEnd(org.apache.spark.scheduler.SparkListenerJobEnd)">onJobEnd(SparkListenerJobEnd)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a job ends</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)">onJobStart(SparkListenerJobStart)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>
<div class="block">When job starts, record job property and stage graph</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onJobStart(org.apache.spark.scheduler.SparkListenerJobStart)">onJobStart(SparkListenerJobStart)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a job starts</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html#onReceiverError(org.apache.spark.streaming.scheduler.StreamingListenerReceiverError)">onReceiverError(StreamingListenerReceiverError)</a></span> - Method in interface org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</a></dt>
<dd>
<div class="block">Called when a receiver has reported an error</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html#onReceiverStarted(org.apache.spark.streaming.scheduler.StreamingListenerReceiverStarted)">onReceiverStarted(StreamingListenerReceiverStarted)</a></span> - Method in interface org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</a></dt>
<dd>
<div class="block">Called when a receiver has been started</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html#onReceiverStopped(org.apache.spark.streaming.scheduler.StreamingListenerReceiverStopped)">onReceiverStopped(StreamingListenerReceiverStopped)</a></span> - Method in interface org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler">StreamingListener</a></dt>
<dd>
<div class="block">Called when a receiver has been stopped</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)">onStageCompleted(SparkListenerStageCompleted)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>
<div class="block">When stage is completed, record stage completion status</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)">onStageCompleted(SparkListenerStageCompleted)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a stage completes successfully or fails, with information on the completed stage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)">onStageCompleted(SparkListenerStageCompleted)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)">onStageCompleted(SparkListenerStageCompleted)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#onStageCompleted(org.apache.spark.scheduler.SparkListenerStageCompleted)">onStageCompleted(SparkListenerStageCompleted)</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)">onStageSubmitted(SparkListenerStageSubmitted)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>
<div class="block">When stage is submitted, record stage submit info</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)">onStageSubmitted(SparkListenerStageSubmitted)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a stage is submitted</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)">onStageSubmitted(SparkListenerStageSubmitted)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>
<div class="block">For FIFO, all stages are contained by "default" pool but "default" pool here is meaningless</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#onStageSubmitted(org.apache.spark.scheduler.SparkListenerStageSubmitted)">onStageSubmitted(SparkListenerStageSubmitted)</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#onStart()">onStart()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">This method is called by the system when the receiver is started.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#onStop()">onStop()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">This method is called by the system when the receiver is stopped.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/TaskCompletionListener.html#onTaskCompletion(org.apache.spark.TaskContext)">onTaskCompletion(TaskContext)</a></span> - Method in interface org.apache.spark.util.<a href="./org/apache/spark/util/TaskCompletionListener.html" title="interface in org.apache.spark.util">TaskCompletionListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>
<div class="block">When task ends, record task completion status and metrics</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a task ends</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#onTaskEnd(org.apache.spark.scheduler.SparkListenerTaskEnd)">onTaskEnd(SparkListenerTaskEnd)</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>
<div class="block">Assumes the storage status list is fully up-to-date.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onTaskGettingResult(org.apache.spark.scheduler.SparkListenerTaskGettingResult)">onTaskGettingResult(SparkListenerTaskGettingResult)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a task begins remotely fetching its result (will not be called for tasks that do
 not need to fetch the result remotely).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onTaskGettingResult(org.apache.spark.scheduler.SparkListenerTaskGettingResult)">onTaskGettingResult(SparkListenerTaskGettingResult)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)">onTaskStart(SparkListenerTaskStart)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when a task starts</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)">onTaskStart(SparkListenerTaskStart)</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#onTaskStart(org.apache.spark.scheduler.SparkListenerTaskStart)">onTaskStart(SparkListenerTaskStart)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)">onUnpersistRDD(SparkListenerUnpersistRDD)</a></span> - Method in interface org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler">SparkListener</a></dt>
<dd>
<div class="block">Called when an RDD is manually unpersisted by the application</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)">onUnpersistRDD(SparkListenerUnpersistRDD)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#onUnpersistRDD(org.apache.spark.scheduler.SparkListenerUnpersistRDD)">onUnpersistRDD(SparkListenerUnpersistRDD)</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#optimize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)">optimize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Runs gradient descent on the given training data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#optimize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)">optimize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Vector)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/Optimizer.html#optimize(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)">optimize(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Vector)</a></span> - Method in interface org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/Optimizer.html" title="interface in org.apache.spark.mllib.optimization">Optimizer</a></dt>
<dd>
<div class="block">Solve the provided convex optimization problem.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithLBFGS.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithLBFGS</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/Optimizer.html" title="interface in org.apache.spark.mllib.optimization"><span class="strong">Optimizer</span></a> - Interface in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Trait for optimization problem solvers.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a></dt>
<dd>
<div class="block">The optimizer to solve the problem.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#optimizer()">optimizer()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#orderBy(scala.collection.Seq)">orderBy(Seq&lt;SortOrder&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Sorts the results by the given expressions.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="strong">OrderedRDDFunctions</span></a>&lt;<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">K</a>,<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">V</a>,<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">P</a> extends scala.Product2&lt;<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">K</a>,<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="type parameter in OrderedRDDFunctions">V</a>&gt;&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">Extra functions available on RDDs of (key, value) pairs where the key is sortable through
 an implicit conversion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/OrderedRDDFunctions.html#OrderedRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Ordering, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">OrderedRDDFunctions(RDD&lt;P&gt;, Ordering&lt;K&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, ClassTag&lt;P&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd">OrderedRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#ordering()">ordering()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#ordering()">ordering()</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/package-summary.html">org.apache.spark</a> - package org.apache.spark</dt>
<dd>
<div class="block">Core Spark classes in Scala.</div>
</dd>
<dt><a href="./org/apache/spark/annotation/package-summary.html">org.apache.spark.annotation</a> - package org.apache.spark.annotation</dt>
<dd>
<div class="block">Spark annotations to mark an API experimental or intended only for advanced usages by developers.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a> - package org.apache.spark.api.java</dt>
<dd>
<div class="block">Spark Java programming APIs.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a> - package org.apache.spark.api.java.function</dt>
<dd>
<div class="block">Set of interfaces to represent functions in Spark's Java API.</div>
</dd>
<dt><a href="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</a> - package org.apache.spark.broadcast</dt>
<dd>
<div class="block">Spark's broadcast variables, used to broadcast immutable datasets to all nodes.</div>
</dd>
<dt><a href="./org/apache/spark/examples/streaming/package-summary.html">org.apache.spark.examples.streaming</a> - package org.apache.spark.examples.streaming</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/io/package-summary.html">org.apache.spark.io</a> - package org.apache.spark.io</dt>
<dd>
<div class="block">IO codecs used for compression.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a> - package org.apache.spark.mllib.classification</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/clustering/package-summary.html">org.apache.spark.mllib.clustering</a> - package org.apache.spark.mllib.clustering</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/evaluation/package-summary.html">org.apache.spark.mllib.evaluation</a> - package org.apache.spark.mllib.evaluation</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a> - package org.apache.spark.mllib.feature</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a> - package org.apache.spark.mllib.linalg</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a> - package org.apache.spark.mllib.linalg.distributed</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a> - package org.apache.spark.mllib.optimization</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</a> - package org.apache.spark.mllib.random</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</a> - package org.apache.spark.mllib.recommendation</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a> - package org.apache.spark.mllib.regression</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</a> - package org.apache.spark.mllib.stat</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/stat/test/package-summary.html">org.apache.spark.mllib.stat.test</a> - package org.apache.spark.mllib.stat.test</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/package-summary.html">org.apache.spark.mllib.tree</a> - package org.apache.spark.mllib.tree</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</a> - package org.apache.spark.mllib.tree.configuration</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</a> - package org.apache.spark.mllib.tree.impurity</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</a> - package org.apache.spark.mllib.tree.model</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a> - package org.apache.spark.mllib.util</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/partial/package-summary.html">org.apache.spark.partial</a> - package org.apache.spark.partial</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a> - package org.apache.spark.rdd</dt>
<dd>
<div class="block">Provides implementation's of various RDDs.</div>
</dd>
<dt><a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a> - package org.apache.spark.scheduler</dt>
<dd>
<div class="block">Spark's DAG scheduler.</div>
</dd>
<dt><a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a> - package org.apache.spark.serializer</dt>
<dd>
<div class="block">Pluggable serializers for RDD and shuffle data.</div>
</dd>
<dt><a href="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</a> - package org.apache.spark.sql</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a> - package org.apache.spark.sql.api.java</dt>
<dd>
<div class="block">Allows the execution of relational queries, including those expressed in SQL using Spark.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a> - package org.apache.spark.sql.execution</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/package-summary.html">org.apache.spark.sql.hive</a> - package org.apache.spark.sql.hive</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/api/java/package-summary.html">org.apache.spark.sql.hive.api.java</a> - package org.apache.spark.sql.hive.api.java</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a> - package org.apache.spark.sql.hive.execution</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/parquet/package-summary.html">org.apache.spark.sql.hive.parquet</a> - package org.apache.spark.sql.hive.parquet</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/test/package-summary.html">org.apache.spark.sql.hive.test</a> - package org.apache.spark.sql.hive.test</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/parquet/package-summary.html">org.apache.spark.sql.parquet</a> - package org.apache.spark.sql.parquet</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/test/package-summary.html">org.apache.spark.sql.test</a> - package org.apache.spark.sql.test</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a> - package org.apache.spark.storage</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a> - package org.apache.spark.streaming</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/api/java/package-summary.html">org.apache.spark.streaming.api.java</a> - package org.apache.spark.streaming.api.java</dt>
<dd>
<div class="block">Java APIs for spark streaming.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</a> - package org.apache.spark.streaming.dstream</dt>
<dd>
<div class="block">Various implementations of DStreams.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/flume/package-summary.html">org.apache.spark.streaming.flume</a> - package org.apache.spark.streaming.flume</dt>
<dd>
<div class="block">Spark streaming receiver for Flume.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/kafka/package-summary.html">org.apache.spark.streaming.kafka</a> - package org.apache.spark.streaming.kafka</dt>
<dd>
<div class="block">Kafka receiver for spark streaming.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/kinesis/package-summary.html">org.apache.spark.streaming.kinesis</a> - package org.apache.spark.streaming.kinesis</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/mqtt/package-summary.html">org.apache.spark.streaming.mqtt</a> - package org.apache.spark.streaming.mqtt</dt>
<dd>
<div class="block">MQTT receiver for Spark Streaming.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</a> - package org.apache.spark.streaming.receiver</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a> - package org.apache.spark.streaming.scheduler</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/twitter/package-summary.html">org.apache.spark.streaming.twitter</a> - package org.apache.spark.streaming.twitter</dt>
<dd>
<div class="block">Twitter feed receiver for spark streaming.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/zeromq/package-summary.html">org.apache.spark.streaming.zeromq</a> - package org.apache.spark.streaming.zeromq</dt>
<dd>
<div class="block">Zeromq receiver for spark streaming.</div>
</dd>
<dt><a href="./org/apache/spark/ui/env/package-summary.html">org.apache.spark.ui.env</a> - package org.apache.spark.ui.env</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/exec/package-summary.html">org.apache.spark.ui.exec</a> - package org.apache.spark.ui.exec</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/jobs/package-summary.html">org.apache.spark.ui.jobs</a> - package org.apache.spark.ui.jobs</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/storage/package-summary.html">org.apache.spark.ui.storage</a> - package org.apache.spark.ui.storage</dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a> - package org.apache.spark.util</dt>
<dd>
<div class="block">Spark utilities.</div>
</dd>
<dt><a href="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</a> - package org.apache.spark.util.random</dt>
<dd>
<div class="block">Utilities for random number generation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExplainCommand.html#otherCopyArgs()">otherCopyArgs()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution">ExplainCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SetCommand.html#otherCopyArgs()">otherCopyArgs()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution">SetCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#otherCopyArgs()">otherCopyArgs()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#otherCopyArgs()">otherCopyArgs()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/NativeCommand.html#otherCopyArgs()">otherCopyArgs()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/NativeCommand.html" title="class in org.apache.spark.sql.hive.execution">NativeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#otherCopyArgs()">otherCopyArgs()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Statistics.html#otherInfo()">otherInfo()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#outer()">outer()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution">BatchPythonEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CacheCommand.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CacheCommand.html" title="class in org.apache.spark.sql.execution">CacheCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CartesianProduct.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CartesianProduct.html" title="class in org.apache.spark.sql.execution">CartesianProduct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/DescribeCommand.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/DescribeCommand.html" title="class in org.apache.spark.sql.execution">DescribeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Distinct.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution">Distinct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/EvaluatePython.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/EvaluatePython.html" title="class in org.apache.spark.sql.execution">EvaluatePython</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Except.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Except.html" title="class in org.apache.spark.sql.execution">Except</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Exchange.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution">Exchange</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExistingRdd.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution">ExistingRdd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExplainCommand.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExplainCommand.html" title="class in org.apache.spark.sql.execution">ExplainCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Filter.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Filter.html" title="class in org.apache.spark.sql.execution">Filter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Generate.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Generate.html" title="class in org.apache.spark.sql.execution">Generate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#output()">output()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Intersect.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Intersect.html" title="class in org.apache.spark.sql.execution">Intersect</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Limit.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Limit.html" title="class in org.apache.spark.sql.execution">Limit</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/OutputFaker.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/OutputFaker.html" title="class in org.apache.spark.sql.execution">OutputFaker</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Project.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution">Project</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SetCommand.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution">SetCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution">SparkLogicalPlan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Union.html#output()">output()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Union.html" title="class in org.apache.spark.sql.execution">Union</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html" title="class in org.apache.spark.sql.hive.execution">AnalyzeTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DropTable.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution">DropTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/NativeCommand.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/NativeCommand.html" title="class in org.apache.spark.sql.hive.execution">NativeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#output()">output()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html#output()">output()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet">InsertIntoParquetTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#output()">output()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#outputClass()">outputClass()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/OutputFaker.html" title="class in org.apache.spark.sql.execution"><span class="strong">OutputFaker</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A plan node that does nothing but lie about the output of its child.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/OutputFaker.html#OutputFaker(scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan)">OutputFaker(Seq&lt;Attribute&gt;, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/OutputFaker.html" title="class in org.apache.spark.sql.execution">OutputFaker</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Exchange.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Exchange.html" title="class in org.apache.spark.sql.execution">Exchange</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#outputPartitioning()">outputPartitioning()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>
<div class="block">Specifies how data is partitioned across different nodes in the cluster.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#overwrite()">overwrite()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html#overwrite()">overwrite()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet">InsertIntoParquetTable</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_P_">
<!--   -->
</a>
<h2 class="title">P</h2>
<dl>
<dt><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream"><span class="strong">PairDStreamFunctions</span></a>&lt;<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt; - Class in <a href="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</a></dt>
<dd>
<div class="block">Extra functions available on DStream of (key, value) pairs through an implicit conversion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#PairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">PairDStreamFunctions(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</a></span> - Constructor for class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="interface in org.apache.spark.api.java.function"><span class="strong">PairFlatMapFunction</span></a>&lt;<a href="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="type parameter in PairFlatMapFunction">T</a>,<a href="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="type parameter in PairFlatMapFunction">K</a>,<a href="./org/apache/spark/api/java/function/PairFlatMapFunction.html" title="type parameter in PairFlatMapFunction">V</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function that returns zero or more key-value pair records from each input record.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/function/PairFunction.html" title="interface in org.apache.spark.api.java.function"><span class="strong">PairFunction</span></a>&lt;<a href="./org/apache/spark/api/java/function/PairFunction.html" title="type parameter in PairFunction">T</a>,<a href="./org/apache/spark/api/java/function/PairFunction.html" title="type parameter in PairFunction">K</a>,<a href="./org/apache/spark/api/java/function/PairFunction.html" title="type parameter in PairFunction">V</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function that returns key-value pairs (Tuple2<K, V>), and can be used to construct PairRDDs.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="strong">PairRDDFunctions</span></a>&lt;<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">K</a>,<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="type parameter in PairRDDFunctions">V</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">Extra functions available on RDDs of (key, value) pairs through an implicit conversion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#PairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">PairRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#parallelize(java.util.List, int)">parallelize(List&lt;T&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#parallelize(java.util.List)">parallelize(List&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#parallelize(scala.collection.Seq, int, scala.reflect.ClassTag)">parallelize(Seq&lt;T&gt;, int, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#parallelizeDoubles(java.util.List, int)">parallelizeDoubles(List&lt;Double&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#parallelizeDoubles(java.util.List)">parallelizeDoubles(List&lt;Double&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#parallelizePairs(java.util.List, int)">parallelizePairs(List&lt;Tuple2&lt;K, V&gt;&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#parallelizePairs(java.util.List)">parallelizePairs(List&lt;Tuple2&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Distribute a local Scala collection to form an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#parquetFile(java.lang.String)">parquetFile(String)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">Loads a parquet file, returning the result as a <a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java"><code>JavaSchemaRDD</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#parquetFile(java.lang.String)">parquetFile(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Loads a Parquet file, returning the result as a <a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><code>SchemaRDD</code></a>.</div>
</dd>
<dt><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet"><span class="strong">ParquetTableScan</span></a> - Class in <a href="./org/apache/spark/sql/parquet/package-summary.html">org.apache.spark.sql.parquet</a></dt>
<dd>
<div class="block">Parquet table scan operator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#ParquetTableScan(scala.collection.Seq, org.apache.spark.sql.parquet.ParquetRelation, scala.collection.Seq)">ParquetTableScan(Seq&lt;Attribute&gt;, ParquetRelation, Seq&lt;Expression&gt;)</a></span> - Constructor for class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#parse(java.lang.String)">parse(String)</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Parses a string resulted from <code>Vector#toString</code> into
 an <a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg"><code>Vector</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LabeledPoint.html#parse(java.lang.String)">parse(String)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</a></dt>
<dd>
<div class="block">Parses a string resulted from <code>LabeledPoint#toString</code> into
 an <a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression"><code>LabeledPoint</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#partial()">partial()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Distinct.html#partial()">partial()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution">Distinct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#partial()">partial()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial"><span class="strong">PartialResult</span></a>&lt;<a href="./org/apache/spark/partial/PartialResult.html" title="type parameter in PartialResult">R</a>&gt; - Class in <a href="./org/apache/spark/partial/package-summary.html">org.apache.spark.partial</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#PartialResult(R, boolean)">PartialResult(R, boolean)</a></span> - Constructor for class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/Partition.html" title="interface in org.apache.spark"><span class="strong">Partition</span></a> - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">A partition of an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#partition()">partition()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#partitionBy(org.apache.spark.Partitioner)">partitionBy(Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a copy of the RDD partitioned using the specified partitioner.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#partitionBy(org.apache.spark.Partitioner)">partitionBy(Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return a copy of the RDD partitioned using the specified partitioner.</div>
</dd>
<dt><a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark"><span class="strong">Partitioner</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">An object that defines how the elements in a key-value pair RDD are partitioned by key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Partitioner.html#Partitioner()">Partitioner()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#partitioner()">partitioner()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#partitioner()">partitioner()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Optionally overridden by subclasses to specify how they are partitioned.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#partitioner()">partitioner()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#partitioner()">partitioner()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#partitionId()">partitionId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#partitionPruningPred()">partitionPruningPred()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd"><span class="strong">PartitionPruningRDD</span></a>&lt;<a href="./org/apache/spark/rdd/PartitionPruningRDD.html" title="type parameter in PartitionPruningRDD">T</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A RDD used to prune RDD partitions/partitions so we can avoid launching tasks on
 all partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PartitionPruningRDD.html#PartitionPruningRDD(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag)">PartitionPruningRDD(RDD&lt;T&gt;, Function1&lt;Object, Object&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PartitionPruningRDD.html" title="class in org.apache.spark.rdd">PartitionPruningRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#partitions()">partitions()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Set of partitions in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#partitions()">partitions()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Get the array of partitions of this RDD, taking into account whether the
 RDD is checkpointed or not.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#partOutput()">partOutput()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#path()">path()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#path()">path()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#percentiles()">percentiles()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#percentilesHeader()">percentilesHeader()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#persist()">persist()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#persist()">persist()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Persist this RDD with the default storage level (`MEMORY_ONLY`).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Set this RDD's storage level to persist its values across operations after the first time
 it is computed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#persist()">persist()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Persist the RDDs of this DStream with the given storage level</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#persist()">persist()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Persist the RDDs of this DStream with the given storage level</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#persist(org.apache.spark.storage.StorageLevel)">persist(StorageLevel)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Persist the RDDs of this DStream with the given storage level</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#persist()">persist()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Persist RDDs of this DStream with the default storage level (MEMORY_ONLY_SER)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#persistentRdds()">persistentRdds()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html#pi()">pi()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#pipe(java.lang.String)">pipe(String)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an RDD created by piping elements to a forked external process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#pipe(java.util.List)">pipe(List&lt;String&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an RDD created by piping elements to a forked external process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#pipe(java.util.List, java.util.Map)">pipe(List&lt;String&gt;, Map&lt;String, String&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an RDD created by piping elements to a forked external process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#pipe(java.lang.String)">pipe(String)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD created by piping elements to a forked external process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#pipe(java.lang.String, scala.collection.Map)">pipe(String, Map&lt;String, String&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD created by piping elements to a forked external process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#pipe(scala.collection.Seq, scala.collection.Map, scala.Function1, scala.Function2, boolean)">pipe(Seq&lt;String&gt;, Map&lt;String, String&gt;, Function1&lt;Function1&lt;String, BoxedUnit&gt;, BoxedUnit&gt;, Function2&lt;T, Function1&lt;String, BoxedUnit&gt;, BoxedUnit&gt;, boolean)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD created by piping elements to a forked external process.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#plusDot(org.apache.spark.util.Vector, org.apache.spark.util.Vector)">plusDot(Vector, Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>
<div class="block">return (this + plus) dot other, but without creating any intermediate storage</div>
</dd>
<dt><a href="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random"><span class="strong">PoissonGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generates i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/PoissonGenerator.html#PoissonGenerator(double)">PoissonGenerator(double)</a></span> - Constructor for class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)">poissonJavaRDD(JavaSparkContext, double, long, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Java-friendly version of <a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonRDD(org.apache.spark.SparkContext, double, long, int, long)"><code>RandomRDDs.poissonRDD(org.apache.spark.SparkContext, double, long, int, long)</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int)">poissonJavaRDD(JavaSparkContext, double, long, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><code>RandomRDDs.poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)</code></a> with the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long)">poissonJavaRDD(JavaSparkContext, double, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)"><code>RandomRDDs.poissonJavaRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, long)</code></a> with the default number of partitions and the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)">poissonJavaVectorRDD(JavaSparkContext, double, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Java-friendly version of <a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)"><code>RandomRDDs.poissonVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int)">poissonJavaVectorRDD(JavaSparkContext, double, long, int, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><code>RandomRDDs.poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)</code></a> with the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int)">poissonJavaVectorRDD(JavaSparkContext, double, long, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)"><code>RandomRDDs.poissonJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, double, long, int, int, long)</code></a> with the default number of partitions and the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonRDD(org.apache.spark.SparkContext, double, long, int, long)">poissonRDD(SparkContext, double, long, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Generates an RDD comprised of i.i.d.</div>
</dd>
<dt><a href="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random"><span class="strong">PoissonSampler</span></a>&lt;<a href="./org/apache/spark/util/random/PoissonSampler.html" title="type parameter in PoissonSampler">T</a>&gt; - Class in <a href="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A sampler based on values drawn from Poisson distribution.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/PoissonSampler.html#PoissonSampler(double)">PoissonSampler(double)</a></span> - Constructor for class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#poissonVectorRDD(org.apache.spark.SparkContext, double, long, int, int, long)">poissonVectorRDD(SparkContext, double, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Generates an RDD[Vector] with vectors containing i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#poolToActiveStages()">poolToActiveStages()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#port()">port()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#pr()">pr()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns the precision-recall curve, which is an RDD of (recall, precision),
 NOT (precision, recall), with (0.0, 1.0) prepended to it.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#precision(double)">precision(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns precision for a given label (category)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#precision()">precision()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns precision</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#precisionByThreshold()">precisionByThreshold()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns the (threshold, precision) curve.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/ClassificationModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Vector&gt;)</a></span> - Method in interface org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification">ClassificationModel</a></dt>
<dd>
<div class="block">Predict values for the given data set using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/ClassificationModel.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in interface org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification">ClassificationModel</a></dt>
<dd>
<div class="block">Predict values for a single data point using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/ClassificationModel.html#predict(org.apache.spark.api.java.JavaRDD)">predict(JavaRDD&lt;Vector&gt;)</a></span> - Method in interface org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/ClassificationModel.html" title="interface in org.apache.spark.mllib.classification">ClassificationModel</a></dt>
<dd>
<div class="block">Predict values for examples stored in a JavaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>
<div class="block">Returns the cluster index that a given point belongs to.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>
<div class="block">Maps given points to their cluster indices.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeansModel.html#predict(org.apache.spark.api.java.JavaRDD)">predict(JavaRDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeansModel.html" title="class in org.apache.spark.mllib.clustering">KMeansModel</a></dt>
<dd>
<div class="block">Maps given points to their cluster indices.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#predict(int, int)">predict(int, int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>
<div class="block">Predict the rating of one user for one product.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Tuple2&lt;Object, Object&gt;&gt;)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>
<div class="block">Predict the rating of many users for many products.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#predict(org.apache.spark.api.java.JavaRDD)">predict(JavaRDD&lt;byte[]&gt;)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Predict the rating of many users for many products.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a></dt>
<dd>
<div class="block">Predict values for the given data set using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a></dt>
<dd>
<div class="block">Predict values for a single data point using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RegressionModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Vector&gt;)</a></span> - Method in interface org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression">RegressionModel</a></dt>
<dd>
<div class="block">Predict values for the given data set using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RegressionModel.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in interface org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression">RegressionModel</a></dt>
<dd>
<div class="block">Predict values for a single data point using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RegressionModel.html#predict(org.apache.spark.api.java.JavaRDD)">predict(JavaRDD&lt;Vector&gt;)</a></span> - Method in interface org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression">RegressionModel</a></dt>
<dd>
<div class="block">Predict values for examples stored in a JavaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>
<div class="block">Predict values for a single data point using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#predict(org.apache.spark.rdd.RDD)">predict(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>
<div class="block">Predict values for the given data set using the model trained.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#predict()">predict()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#predict()">predict()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#predict(org.apache.spark.mllib.linalg.Vector)">predict(Vector)</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>
<div class="block">predict value if node is not leaf</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#predictOn(org.apache.spark.streaming.dstream.DStream)">predictOn(DStream&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</a></dt>
<dd>
<div class="block">Use the model to make predictions on batches of data from a DStream</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#predictOnValues(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">predictOnValues(DStream&lt;Tuple2&lt;K, Vector&gt;&gt;, ClassTag&lt;K&gt;)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</a></dt>
<dd>
<div class="block">Use the model to make predictions on the values of a DStream and carry over its keys.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#preferredLocation()">preferredLocation()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Override this to specify a preferred location (hostname).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#preferredLocations(org.apache.spark.Partition)">preferredLocations(Partition)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Get the preferred locations of a partition (as hostnames), taking into account whether the
 RDD is checkpointed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#preferredNodeLocationData()">preferredNodeLocationData()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#prettyPrint()">prettyPrint()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#prev()">prev()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#print()">print()</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Print the first ten elements of each RDD generated in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#print()">print()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Print the first ten elements of each RDD generated in this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html#printStats()">printStats()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#prob()">prob()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#probabilities()">probabilities()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#PROCESS_LOCAL()">PROCESS_LOCAL()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#processingDelay()">processingDelay()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>
<div class="block">Time taken for the all jobs of this batch to finish processing from the time they started
 processing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#processingEndTime()">processingEndTime()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#processingStartTime()">processingStartTime()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/Rating.html#product()">product()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#productFeatures()">productFeatures()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExistingRdd.html#productToRowRdd(org.apache.spark.rdd.RDD)">productToRowRdd(RDD&lt;A&gt;)</a></span> - Static method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution">ExistingRdd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#progressListener()">progressListener()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution"><span class="strong">Project</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Project.html#Project(scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan)">Project(Seq&lt;NamedExpression&gt;, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution">Project</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Project.html#projectList()">projectList()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Project.html" title="class in org.apache.spark.sql.execution">Project</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobStart.html#properties()">properties()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html#properties()">properties()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler">SparkListenerStageSubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#pruneColumns(scala.collection.Seq)">pruneColumns(Seq&lt;Attribute&gt;)</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/random/Pseudorandom.html" title="interface in org.apache.spark.util.random"><span class="strong">Pseudorandom</span></a> - Interface in <a href="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A class with pseudorandom behavior.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/HadoopRDD.html#putCachedMetadata(java.lang.String, java.lang.Object)">putCachedMetadata(String, Object)</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/HadoopRDD.html" title="class in org.apache.spark.rdd">HadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#pValue()">pValue()</a></span> - Method in class org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/TestResult.html#pValue()">pValue()</a></span> - Method in interface org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</a></dt>
<dd>
<div class="block">The probability of obtaining a test statistic result at least as extreme as the one that was
 actually observed, assuming that the null hypothesis is true.</div>
</dd>
</dl>
<a name="_Q_">
<!--   -->
</a>
<h2 class="title">Q</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#quantileCalculationStrategy()">quantileCalculationStrategy()</a></span> - Method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration"><span class="strong">QuantileStrategy</span></a> - Class in <a href="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</a></dt>
<dd>
<div class="block">:: Experimental ::
 Enum for selecting the quantile calculation strategy</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#QuantileStrategy()">QuantileStrategy()</a></span> - Constructor for class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/QueryExecutionException.html" title="class in org.apache.spark.sql.execution"><span class="strong">QueryExecutionException</span></a> - Exception in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/QueryExecutionException.html#QueryExecutionException(java.lang.String)">QueryExecutionException(String)</a></span> - Constructor for exception org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/QueryExecutionException.html" title="class in org.apache.spark.sql.execution">QueryExecutionException</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue)">queueStream(Queue&lt;JavaRDD&lt;T&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from an queue of RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue, boolean)">queueStream(Queue&lt;JavaRDD&lt;T&gt;&gt;, boolean)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from an queue of RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#queueStream(java.util.Queue, boolean, org.apache.spark.api.java.JavaRDD)">queueStream(Queue&lt;JavaRDD&lt;T&gt;&gt;, boolean, JavaRDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from an queue of RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#queueStream(scala.collection.mutable.Queue, boolean, scala.reflect.ClassTag)">queueStream(Queue&lt;RDD&lt;T&gt;&gt;, boolean, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from a queue of RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#queueStream(scala.collection.mutable.Queue, boolean, org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">queueStream(Queue&lt;RDD&lt;T&gt;&gt;, boolean, RDD&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from a queue of RDDs.</div>
</dd>
</dl>
<a name="_R_">
<!--   -->
</a>
<h2 class="title">R</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#RACK_LOCAL()">RACK_LOCAL()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#RANDOM()">RANDOM()</a></span> - Static method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#random(int, scala.util.Random)">random(int, Random)</a></span> - Static method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>
<div class="block">Creates this <a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util"><code>Vector</code></a> of given length containing random numbers
 between 0.0 and 1.0.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="interface in org.apache.spark.mllib.random"><span class="strong">RandomDataGenerator</span></a>&lt;<a href="./org/apache/spark/mllib/random/RandomDataGenerator.html" title="type parameter in RandomDataGenerator">T</a>&gt; - Interface in <a href="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Trait for random data generators that generate i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#randomRDD(org.apache.spark.SparkContext, org.apache.spark.mllib.random.RandomDataGenerator, long, int, long, scala.reflect.ClassTag)">randomRDD(SparkContext, RandomDataGenerator&lt;T&gt;, long, int, long, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generates an RDD comprised of i.i.d.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random"><span class="strong">RandomRDDs</span></a> - Class in <a href="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</a></dt>
<dd>
<div class="block">:: Experimental ::
 Generator methods for creating RDDs comprised of i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#RandomRDDs()">RandomRDDs()</a></span> - Constructor for class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/random/RandomSampler.html" title="interface in org.apache.spark.util.random"><span class="strong">RandomSampler</span></a>&lt;<a href="./org/apache/spark/util/random/RandomSampler.html" title="type parameter in RandomSampler">T</a>,<a href="./org/apache/spark/util/random/RandomSampler.html" title="type parameter in RandomSampler">U</a>&gt; - Interface in <a href="./org/apache/spark/util/random/package-summary.html">org.apache.spark.util.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A pseudorandom sampler.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#randomSplit(double[])">randomSplit(double[])</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Randomly splits this RDD with the provided weights.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#randomSplit(double[], long)">randomSplit(double[], long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Randomly splits this RDD with the provided weights.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#randomSplit(double[], long)">randomSplit(double[], long)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Randomly splits this RDD with the provided weights.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#randomVectorRDD(org.apache.spark.SparkContext, org.apache.spark.mllib.random.RandomDataGenerator, long, int, int, long)">randomVectorRDD(SparkContext, RandomDataGenerator&lt;Object&gt;, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generates an RDD[Vector] with vectors containing i.i.d.</div>
</dd>
<dt><a href="./org/apache/spark/RangeDependency.html" title="class in org.apache.spark"><span class="strong">RangeDependency</span></a>&lt;<a href="./org/apache/spark/RangeDependency.html" title="type parameter in RangeDependency">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Represents a one-to-one dependency between ranges of partitions in the parent and child RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangeDependency.html#RangeDependency(org.apache.spark.rdd.RDD, int, int, int)">RangeDependency(RDD&lt;T&gt;, int, int, int)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/RangeDependency.html" title="class in org.apache.spark">RangeDependency</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark"><span class="strong">RangePartitioner</span></a>&lt;<a href="./org/apache/spark/RangePartitioner.html" title="type parameter in RangePartitioner">K</a>,<a href="./org/apache/spark/RangePartitioner.html" title="type parameter in RangePartitioner">V</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">A <a href="./org/apache/spark/Partitioner.html" title="class in org.apache.spark"><code>Partitioner</code></a> that partitions sortable records by range into roughly
 equal ranges.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#RangePartitioner(int, org.apache.spark.rdd.RDD, boolean, scala.math.Ordering, scala.reflect.ClassTag)">RangePartitioner(int, RDD&lt;? extends Product2&lt;K, V&gt;&gt;, boolean, Ordering&lt;K&gt;, ClassTag&lt;K&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#rank()">rank()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation"><span class="strong">Rating</span></a> - Class in <a href="./org/apache/spark/mllib/recommendation/package-summary.html">org.apache.spark.mllib.recommendation</a></dt>
<dd>
<div class="block">:: Experimental ::
 A more compact class to represent a rating than Tuple3[Int, Int, Double].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/Rating.html#Rating(int, int, double)">Rating(int, int, double)</a></span> - Constructor for class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/Rating.html#rating()">rating()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#rawSocketStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)">rawSocketStream(String, int, StorageLevel)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#rawSocketStream(java.lang.String, int)">rawSocketStream(String, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#rawSocketStream(java.lang.String, int, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)">rawSocketStream(String, int, StorageLevel, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a input stream from network source hostname:port, where data is received
 as serialized blocks (serialized using the Spark's serializer) that can be directly
 pushed into the block manager without deserializing them.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#rdd()">rdd()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Dependency.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Dependency.html" title="class in org.apache.spark">Dependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/NarrowDependency.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/NarrowDependency.html" title="class in org.apache.spark">NarrowDependency</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd"><span class="strong">RDD</span></a>&lt;<a href="./org/apache/spark/rdd/RDD.html" title="type parameter in RDD">T</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#RDD(org.apache.spark.SparkContext, scala.collection.Seq, scala.reflect.ClassTag)">RDD(SparkContext, Seq&lt;Dependency&lt;?&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#RDD(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">RDD(RDD&lt;?&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Construct an RDD with just a one-to-one dependency on one parent</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ExistingRdd.html#rdd()">rdd()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ExistingRdd.html" title="class in org.apache.spark.sql.execution">ExistingRdd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#RDD()">RDD()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage"><span class="strong">RDDBlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDBlockId.html#RDDBlockId(int, int)">RDDBlockId(int, int)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#rddBlocks()">rddBlocks()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the RDD blocks stored in this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#rddBlocksById(int)">rddBlocksById(int)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the blocks that belong to the given RDD stored in this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html#rddId()">rddId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html" title="class in org.apache.spark.scheduler">SparkListenerUnpersistRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDBlockId.html#rddId()">rddId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage"><span class="strong">RDDInfo</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#RDDInfo(int, java.lang.String, int, org.apache.spark.storage.StorageLevel)">RDDInfo(int, String, int, StorageLevel)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#rddInfoList()">rddInfoList()</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>
<div class="block">Filter RDD info to include only those with cached partitions</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#rddInfos()">rddInfos()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#rdds()">rdds()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#rdds()">rdds()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#rddStorageLevel(int)">rddStorageLevel(int)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Return the storage level, if any, used by the given RDD in this block manager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#rddToAsyncRDDActions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">rddToAsyncRDDActions(RDD&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#rddToOrderedRDDFunctions(org.apache.spark.rdd.RDD, scala.math.Ordering, scala.reflect.ClassTag, scala.reflect.ClassTag)">rddToOrderedRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Ordering&lt;K&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#rddToPairRDDFunctions(org.apache.spark.rdd.RDD, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">rddToPairRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#rddToSequenceFileRDDFunctions(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag, scala.Function1, scala.reflect.ClassTag)">rddToSequenceFileRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Function1&lt;K, Writable&gt;, ClassTag&lt;K&gt;, Function1&lt;V, Writable&gt;, ClassTag&lt;V&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/JavaSerializer.html#readExternal(java.io.ObjectInput)">readExternal(ObjectInput)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#readExternal(java.io.ObjectInput)">readExternal(ObjectInput)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#readExternal(java.io.ObjectInput)">readExternal(ObjectInput)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#readExternal(java.io.ObjectInput)">readExternal(ObjectInput)</a></span> - Method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/DeserializationStream.html#readObject(scala.reflect.ClassTag)">readObject(ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/DeserializationStream.html" title="class in org.apache.spark.serializer">DeserializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#ready(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)">ready(Duration, CanAwait)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#ready(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)">ready(Duration, CanAwait)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">Blocks until this action completes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SimpleFutureAction.html#ready(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)">ready(Duration, CanAwait)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#reason()">reason()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#recall(double)">recall(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns recall for a given label (category)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#recall()">recall()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns recall
 (equals to precision for multiclass classifier
 because sum of all false positives is equal to sum
 of all false negatives)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#recallByThreshold()">recallByThreshold()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns the (threshold, recall) curve.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#receivedBlockInfo()">receivedBlockInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver"><span class="strong">Receiver</span></a>&lt;<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="type parameter in Receiver">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Abstract class of a receiver that can be run on worker nodes to receive external data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#Receiver(org.apache.spark.storage.StorageLevel)">Receiver(StorageLevel)</a></span> - Constructor for class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">ReceiverInfo</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Class having information about a receiver</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#ReceiverInfo(int, java.lang.String, akka.actor.ActorRef, boolean, java.lang.String, java.lang.String, java.lang.String)">ReceiverInfo(int, String, ActorRef, boolean, String, String, String)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html#receiverInfo()">receiverInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverError</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html#receiverInfo()">receiverInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStarted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html#receiverInfo()">receiverInfo()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStopped</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#receiverInputDStream()">receiverInputDStream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html#receiverInputDStream()">receiverInputDStream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="strong">ReceiverInputDStream</span></a>&lt;<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="type parameter in ReceiverInputDStream">T</a>&gt; - Class in <a href="./org/apache/spark/streaming/dstream/package-summary.html">org.apache.spark.streaming.dstream</a></dt>
<dd>
<div class="block">Abstract class for defining any <a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream"><code>InputDStream</code></a>
 that has to start a receiver on worker nodes to receive external data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#ReceiverInputDStream(org.apache.spark.streaming.StreamingContext, scala.reflect.ClassTag)">ReceiverInputDStream(StreamingContext, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#receiverStream(org.apache.spark.streaming.receiver.Receiver)">receiverStream(Receiver&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#receiverStream(org.apache.spark.streaming.receiver.Receiver, scala.reflect.ClassTag)">receiverStream(Receiver&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create an input stream with any arbitrary user implemented receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#recommendProducts(int, int)">recommendProducts(int, int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>
<div class="block">Recommends products to a user.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#recommendUsers(int, int)">recommendUsers(int, int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>
<div class="block">Recommends users to a product.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#reduce(org.apache.spark.api.java.function.Function2)">reduce(Function2&lt;T, T, T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Reduces the elements of this RDD using the specified commutative and associative binary
 operator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#reduce(scala.Function2)">reduce(Function2&lt;T, T, T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Reduces the elements of this RDD using the specified commutative and
 associative binary operator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduce(org.apache.spark.api.java.function.Function2)">reduce(Function2&lt;T, T, T&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by reducing each RDD
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#reduce(scala.Function2)">reduce(Function2&lt;T, T, T&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by reducing each RDD
 of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKey(org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function2)">reduceByKey(Partitioner, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKey(org.apache.spark.api.java.function.Function2, int)">reduceByKey(Function2&lt;V, V, V&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKey(org.apache.spark.api.java.function.Function2)">reduceByKey(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(org.apache.spark.Partitioner, scala.Function2)">reduceByKey(Partitioner, Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(scala.Function2, int)">reduceByKey(Function2&lt;V, V, V&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKey(scala.Function2)">reduceByKey(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKey(org.apache.spark.api.java.function.Function2)">reduceByKey(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKey(org.apache.spark.api.java.function.Function2, int)">reduceByKey(Function2&lt;V, V, V&gt;, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKey(org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)">reduceByKey(Function2&lt;V, V, V&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2)">reduceByKey(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2, int)">reduceByKey(Function2&lt;V, V, V&gt;, int)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(scala.Function2, org.apache.spark.Partitioner)">reduceByKey(Function2&lt;V, V, V&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Create a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by reducing over a using incremental computation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, org.apache.spark.api.java.function.Function)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, int, Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#reduceByKeyAndWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner, org.apache.spark.api.java.function.Function)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner, Function&lt;Tuple2&lt;K, V&gt;, Boolean&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, int)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, int, scala.Function1)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, int, Function1&lt;Tuple2&lt;K, V&gt;, Object&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration, org.apache.spark.Partitioner, scala.Function1)">reduceByKeyAndWindow(Function2&lt;V, V, V&gt;, Function2&lt;V, V, V&gt;, Duration, Duration, Partitioner, Function1&lt;Tuple2&lt;K, V&gt;, Object&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#reduceByKeyLocally(org.apache.spark.api.java.function.Function2)">reduceByKeyLocally(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function, but return the results
 immediately to the master as a Map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKeyLocally(scala.Function2)">reduceByKeyLocally(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Merge the values for each key using an associative reduce function, but return the results
 immediately to the master as a Map.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#reduceByKeyToDriver(scala.Function2)">reduceByKeyToDriver(Function2&lt;V, V, V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Alias for reduceByKeyLocally</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduceByWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByWindow(Function2&lt;T, T, T&gt;, Duration, Duration)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#reduceByWindow(org.apache.spark.api.java.function.Function2, org.apache.spark.api.java.function.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByWindow(Function2&lt;T, T, T&gt;, Function2&lt;T, T, T&gt;, Duration, Duration)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#reduceByWindow(scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByWindow(Function2&lt;T, T, T&gt;, Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#reduceByWindow(scala.Function2, scala.Function2, org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">reduceByWindow(Function2&lt;T, T, T&gt;, Function2&lt;T, T, T&gt;, Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD has a single element generated by reducing all
 elements in a sliding window over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/FetchFailed.html#reduceId()">reduceId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleBlockId.html#reduceId()">reduceId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleIndexBlockId.html#reduceId()">reduceId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/KryoRegistrator.html#registerClasses(com.esotericsoftware.kryo.Kryo)">registerClasses(Kryo)</a></span> - Method in interface org.apache.spark.serializer.<a href="./org/apache/spark/serializer/KryoRegistrator.html" title="interface in org.apache.spark.serializer">KryoRegistrator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#registerRDDAsTable(org.apache.spark.sql.api.java.JavaSchemaRDD, java.lang.String)">registerRDDAsTable(JavaSchemaRDD, String)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">Registers the given RDD as a temporary table in the catalog.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#registerRDDAsTable(org.apache.spark.sql.SchemaRDD, java.lang.String)">registerRDDAsTable(SchemaRDD, String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Registers the given RDD as a temporary table in the catalog.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#registerTestTable(org.apache.spark.sql.hive.test.TestHiveContext.TestTable)">registerTestTable(TestHiveContext.TestTable)</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Algo.html#Regression()">Regression()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Algo.html" title="class in org.apache.spark.mllib.tree.configuration">Algo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/RegressionModel.html" title="interface in org.apache.spark.mllib.regression"><span class="strong">RegressionModel</span></a> - Interface in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html#relation()">relation()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/HiveTableScan.html" title="class in org.apache.spark.sql.hive.execution">HiveTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html#relation()">relation()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/InsertIntoParquetTable.html" title="class in org.apache.spark.sql.parquet">InsertIntoParquetTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/parquet/ParquetTableScan.html#relation()">relation()</a></span> - Method in class org.apache.spark.sql.parquet.<a href="./org/apache/spark/sql/parquet/ParquetTableScan.html" title="class in org.apache.spark.sql.parquet">ParquetTableScan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#remember(org.apache.spark.streaming.Duration)">remember(Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Sets each DStreams in this context to remember RDDs it generated in the last given duration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#remember(org.apache.spark.streaming.Duration)">remember(Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Set each DStreams in this context to remember RDDs it generated in the last given duration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#rememberDuration()">rememberDuration()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#remove(java.lang.String)">remove(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Remove a parameter from the configuration</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a new RDD that has exactly numPartitions partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a new RDD that has exactly numPartitions partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a new RDD that has exactly numPartitions partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#repartition(int, scala.math.Ordering)">repartition(int, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a new RDD that has exactly numPartitions partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return a new RDD that has exactly <code>numPartitions</code> partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#repartition(int, scala.math.Ordering)">repartition(int, Ordering&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Return a new DStream with an increased or decreased level of parallelism.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream with an increased or decreased level of parallelism.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#repartition(int)">repartition(int)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream with an increased or decreased level of parallelism.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#replication()">replication()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#reportError(java.lang.String, java.lang.Throwable)">reportError(String, Throwable)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Report exceptions in receiving data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.html" title="class in org.apache.spark.sql.execution">Aggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Distinct.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Distinct.html" title="class in org.apache.spark.sql.execution">Distinct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/GeneratedAggregate.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/GeneratedAggregate.html" title="class in org.apache.spark.sql.execution">GeneratedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#requiredChildDistribution()">requiredChildDistribution()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>
<div class="block">Specifies any partition requirements on the input data for this operator.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#reset()">reset()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>
<div class="block">Resets the test instance by deleting any tables that have been created.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#restart(java.lang.String)">restart(String)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Restart the receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#restart(java.lang.String, java.lang.Throwable)">restart(String, Throwable)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Restart the receiver.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#restart(java.lang.String, java.lang.Throwable, int)">restart(String, Throwable, int)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Restart the receiver.</div>
</dd>
<dt><a href="./org/apache/spark/Resubmitted.html" title="class in org.apache.spark"><span class="strong">Resubmitted</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A <code>ShuffleMapTask</code> that completed successfully earlier, but we
 lost the executor before the stage completed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Resubmitted.html#Resubmitted()">Resubmitted()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Resubmitted.html" title="class in org.apache.spark">Resubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#result(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)">result(Duration, CanAwait)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#result(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)">result(Duration, CanAwait)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">Awaits and returns the result (of type T) of this action.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SimpleFutureAction.html#result(scala.concurrent.duration.Duration, scala.concurrent.CanAwait)">result(Duration, CanAwait)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/AggregateEvaluation.html#result()">result()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/AggregateEvaluation.html" title="class in org.apache.spark.sql.execution">AggregateEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html#resultAttribute()">resultAttribute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html" title="class in org.apache.spark.sql.execution">Aggregate.ComputedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/EvaluatePython.html#resultAttribute()">resultAttribute()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/EvaluatePython.html" title="class in org.apache.spark.sql.execution">EvaluatePython</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/JdbcRDD.html#resultSetToObjectArray(java.sql.ResultSet)">resultSetToObjectArray(ResultSet)</a></span> - Static method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/JdbcRDD.html" title="class in org.apache.spark.rdd">JdbcRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#retainedStages()">retainedStages()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression"><span class="strong">RidgeRegressionModel</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Regression model trained using RidgeRegression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#RidgeRegressionModel(org.apache.spark.mllib.linalg.Vector, double)">RidgeRegressionModel(Vector, double)</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression"><span class="strong">RidgeRegressionWithSGD</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Train a regression model with L2-regularization using Stochastic Gradient Descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#RidgeRegressionWithSGD()">RidgeRegressionWithSGD()</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</a></dt>
<dd>
<div class="block">Construct a RidgeRegression object with default parameters: {stepSize: 1.0, numIterations: 100,
 regParam: 1.0, miniBatchFraction: 1.0}.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CartesianProduct.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CartesianProduct.html" title="class in org.apache.spark.sql.execution">CartesianProduct</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Except.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Except.html" title="class in org.apache.spark.sql.execution">Except</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#right()">right()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Intersect.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Intersect.html" title="class in org.apache.spark.sql.execution">Intersect</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>
<div class="block">The Broadcast relation</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#right()">right()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#rightImpurity()">rightImpurity()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html#rightKeys()">rightKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastHashJoin.html" title="class in org.apache.spark.sql.execution">BroadcastHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#rightKeys()">rightKeys()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashOuterJoin.html#rightKeys()">rightKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashOuterJoin.html" title="class in org.apache.spark.sql.execution">HashOuterJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html#rightKeys()">rightKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinHash.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinHash</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#rightKeys()">rightKeys()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#rightNode()">rightNode()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#rightOuterJoin(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">rightOuterJoin(JavaPairRDD&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#rightOuterJoin(org.apache.spark.api.java.JavaPairRDD)">rightOuterJoin(JavaPairRDD&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#rightOuterJoin(org.apache.spark.api.java.JavaPairRDD, int)">rightOuterJoin(JavaPairRDD&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">rightOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD)">rightOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#rightOuterJoin(org.apache.spark.rdd.RDD, int)">rightOuterJoin(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Perform a right outer join of <code>this</code> and <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#rightOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream)">rightOuterJoin(JavaPairDStream&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#rightOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, int)">rightOuterJoin(JavaPairDStream&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#rightOuterJoin(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.Partitioner)">rightOuterJoin(JavaPairDStream&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag)">rightOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, int, scala.reflect.ClassTag)">rightOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin(org.apache.spark.streaming.dstream.DStream, org.apache.spark.Partitioner, scala.reflect.ClassTag)">rightOuterJoin(DStream&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#rng()">rng()</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/PoissonSampler.html#rng()">rng()</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#roc()">roc()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns the receiver operating characteristic (ROC) curve,
 which is an RDD of (false positive rate, true positive rate)
 with (0.0, 0.0) prepended and (1.0, 1.0) appended to it.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java"><span class="strong">Row</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A result row from a SparkSQL query.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#Row(org.apache.spark.sql.catalyst.expressions.Row)">Row(Row)</a></span> - Constructor for class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/Row.html#row()">row()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/Row.html" title="class in org.apache.spark.sql.api.java">Row</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><span class="strong">RowMatrix</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/distributed/package-summary.html">org.apache.spark.mllib.linalg.distributed</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents a row-oriented distributed Matrix with no meaningful row indices.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#RowMatrix(org.apache.spark.rdd.RDD, long, int)">RowMatrix(RDD&lt;Vector&gt;, long, int)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#RowMatrix(org.apache.spark.rdd.RDD)">RowMatrix(RDD&lt;Vector&gt;)</a></span> - Constructor for class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>
<div class="block">Alternative constructor leaving matrix dimensions to be determined automatically.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#rows()">rows()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html#rows()">rows()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">RowMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#run(scala.Function0, scala.concurrent.ExecutionContext)">run(Function0&lt;T&gt;, ExecutionContext)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>
<div class="block">Executes some action enclosed in the closure.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayes.html#run(org.apache.spark.rdd.RDD)">run(RDD&lt;LabeledPoint&gt;)</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</a></dt>
<dd>
<div class="block">Run the algorithm with the configured parameters on an input RDD of LabeledPoint entries.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#run(org.apache.spark.rdd.RDD)">run(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Train a K-means model on the given set of points; <code>data</code> should be cached for high
 performance, because this is an iterative algorithm.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#run(org.apache.spark.rdd.RDD)">run(RDD&lt;Rating&gt;)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Run ALS with the configured parameters on an input RDD of (user, product, rating) triples.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#run(org.apache.spark.rdd.RDD)">run(RDD&lt;LabeledPoint&gt;)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a></dt>
<dd>
<div class="block">Run the algorithm with the configured parameters on an input
 RDD of LabeledPoint entries.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#run(org.apache.spark.rdd.RDD, org.apache.spark.mllib.linalg.Vector)">run(RDD&lt;LabeledPoint&gt;, Vector)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a></dt>
<dd>
<div class="block">Run the algorithm with the configured parameters on an input RDD
 of LabeledPoint entries starting from the initial weights provided.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runApproximateJob(org.apache.spark.rdd.RDD, scala.Function2, , long)">runApproximateJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, &lt;any&gt;, long)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Run a job that can return approximate results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.collection.Seq, scala.Function2, scala.Function0)">runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, Function2&lt;Object, U, BoxedUnit&gt;, Function0&lt;R&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>
<div class="block">Runs a Spark job.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.collection.Seq, boolean, scala.Function2, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, boolean, Function2&lt;Object, U, BoxedUnit&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a function on a given set of partitions in an RDD and pass the results to the given
 handler function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.collection.Seq, boolean, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a function on a given set of partitions in an RDD and return the results as an array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.collection.Seq, boolean, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, boolean, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a job on a given set of partitions of an RDD, but take a function of type
 <code>Iterator[T] => U</code> instead of <code>(TaskContext, Iterator[T]) => U</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a job on all partitions in an RDD and return the results in an array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a job on all partitions in an RDD and return the results in an array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function2, scala.Function2, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function2&lt;TaskContext, Iterator&lt;T&gt;, U&gt;, Function2&lt;Object, U, BoxedUnit&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a job on all partitions in an RDD and pass the results to a handler function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#runJob(org.apache.spark.rdd.RDD, scala.Function1, scala.Function2, scala.reflect.ClassTag)">runJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Function2&lt;Object, U, BoxedUnit&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Run a job on all partitions in an RDD and pass the results to a handler function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#runLBFGS(org.apache.spark.rdd.RDD, org.apache.spark.mllib.optimization.Gradient, org.apache.spark.mllib.optimization.Updater, int, double, int, double, org.apache.spark.mllib.linalg.Vector)">runLBFGS(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Gradient, Updater, int, double, int, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Run Limited-memory BFGS (L-BFGS) in parallel.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#runMiniBatchSGD(org.apache.spark.rdd.RDD, org.apache.spark.mllib.optimization.Gradient, org.apache.spark.mllib.optimization.Updater, double, int, double, double, org.apache.spark.mllib.linalg.Vector)">runMiniBatchSGD(RDD&lt;Tuple2&lt;Object, Vector&gt;&gt;, Gradient, Updater, double, int, double, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">Run stochastic gradient descent (SGD) in parallel using mini batches.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#running()">running()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#runningLocally()">runningLocally()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#runSqlHive(java.lang.String)">runSqlHive(String)</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_S_">
<!--   -->
</a>
<h2 class="title">S</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#s()">s()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sample(boolean, java.lang.Double)">sample(boolean, Double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sample(boolean, java.lang.Double, long)">sample(boolean, Double, long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sample(boolean, double)">sample(boolean, double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sample(boolean, double, long)">sample(boolean, double, long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#sample(boolean, double)">sample(boolean, double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#sample(boolean, double, long)">sample(boolean, double, long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#sample(boolean, double, long)">sample(boolean, double, long)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a sampled subset of this RDD.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution"><span class="strong">Sample</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#Sample(double, boolean, long, org.apache.spark.sql.execution.SparkPlan)">Sample(double, boolean, long, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#sample(boolean, double, long)">sample(boolean, double, long)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Returns a sampled version of the underlying dataset.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#sample(scala.collection.Iterator)">sample(Iterator&lt;T&gt;)</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/PoissonSampler.html#sample(scala.collection.Iterator)">sample(Iterator&lt;T&gt;)</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/RandomSampler.html#sample(scala.collection.Iterator)">sample(Iterator&lt;T&gt;)</a></span> - Method in interface org.apache.spark.util.random.<a href="./org/apache/spark/util/random/RandomSampler.html" title="interface in org.apache.spark.util.random">RandomSampler</a></dt>
<dd>
<div class="block">take a random sample</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKey(boolean, java.util.Map, long)">sampleByKey(boolean, Map&lt;K, Object&gt;, long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a subset of this RDD sampled by key (via stratified sampling).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKey(boolean, java.util.Map)">sampleByKey(boolean, Map&lt;K, Object&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return a subset of this RDD sampled by key (via stratified sampling).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#sampleByKey(boolean, scala.collection.Map, long)">sampleByKey(boolean, Map&lt;K, Object&gt;, long)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return a subset of this RDD sampled by key (via stratified sampling).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKeyExact(boolean, java.util.Map, long)">sampleByKeyExact(boolean, Map&lt;K, Object&gt;, long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">::Experimental::
 Return a subset of this RDD sampled by key (via stratified sampling) containing exactly
 math.ceil(numItems * samplingRate) for each stratum (group of pairs with the same key).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sampleByKeyExact(boolean, java.util.Map)">sampleByKeyExact(boolean, Map&lt;K, Object&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">::Experimental::
 Return a subset of this RDD sampled by key (via stratified sampling) containing exactly
 math.ceil(numItems * samplingRate) for each stratum (group of pairs with the same key).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#sampleByKeyExact(boolean, scala.collection.Map, long)">sampleByKeyExact(boolean, Map&lt;K, Object&gt;, long)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">::Experimental::
 Return a subset of this RDD sampled by key (via stratified sampling) containing exactly
 math.ceil(numItems * samplingRate) for each stratum (group of pairs with the same key).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sampleStdev()">sampleStdev()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute the sample standard deviation of this RDD's elements (which corrects for bias in
 estimating the standard deviation by dividing by N-1 instead of N).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#sampleStdev()">sampleStdev()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute the sample standard deviation of this RDD's elements (which corrects for bias in
 estimating the standard deviation by dividing by N-1 instead of N).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#sampleStdev()">sampleStdev()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Return the sample standard deviation of the values, which corrects for bias in estimating the
 variance by dividing by N-1 instead of N.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sampleVariance()">sampleVariance()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute the sample variance of this RDD's elements (which corrects for bias in
 estimating the standard variance by dividing by N-1 instead of N).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#sampleVariance()">sampleVariance()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute the sample variance of this RDD's elements (which corrects for bias in
 estimating the variance by dividing by N-1 instead of N).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#sampleVariance()">sampleVariance()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Return the sample variance, which corrects for bias in estimating the variance by dividing
 by N-1 instead of N.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)">saveAsHadoopDataset(JobConf)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
 that storage system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopDataset(org.apache.hadoop.mapred.JobConf)">saveAsHadoopDataset(JobConf)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported storage system, using a Hadoop JobConf object for
 that storage system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)">saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, JobConf)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, Class&lt;? extends CompressionCodec&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, compressing with the supplied codec.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, scala.reflect.ClassTag)">saveAsHadoopFile(String, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, scala.reflect.ClassTag)">saveAsHadoopFile(String, Class&lt;? extends CompressionCodec&gt;, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Class&lt;? extends CompressionCodec&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf, scala.Option)">saveAsHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, JobConf, Option&lt;Class&lt;? extends CompressionCodec&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, using a Hadoop <code>OutputFormat</code> class
 supporting the key and value types K and V in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsHadoopFiles(java.lang.String, java.lang.String)">saveAsHadoopFiles(String, String)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)">saveAsHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, JobConf)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)">saveAsHadoopFiles(String, String, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.mapred.JobConf)">saveAsHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, JobConf)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#saveAsHiveFile(org.apache.spark.rdd.RDD, java.lang.Class, org.apache.hadoop.hive.ql.plan.FileSinkDesc, org.apache.hadoop.mapred.JobConf, boolean)">saveAsHiveFile(RDD&lt;Writable&gt;, Class&lt;?&gt;, FileSinkDesc, JobConf, boolean)</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#saveAsLibSVMFile(org.apache.spark.rdd.RDD, java.lang.String)">saveAsLibSVMFile(RDD&lt;LabeledPoint&gt;, String)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block">Save labeled data in LIBSVM format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopDataset(Configuration)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported storage system, using
 a Configuration object for that storage system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopDataset(org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopDataset(Configuration)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported storage system with new Hadoop API, using a Hadoop
 Configuration object for that storage system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;, Configuration)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsNewAPIHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;F&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopFile(java.lang.String, scala.reflect.ClassTag)">saveAsNewAPIHadoopFile(String, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#saveAsNewAPIHadoopFile(java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopFile(String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Configuration)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD to any Hadoop-supported file system, using a new Hadoop API <code>OutputFormat</code>
 (mapreduce.OutputFormat) object supporting the key and value types K and V in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String)">saveAsNewAPIHadoopFiles(String, String)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class)">saveAsNewAPIHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Configuration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, scala.reflect.ClassTag)">saveAsNewAPIHadoopFiles(String, String, ClassTag&lt;F&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(java.lang.String, java.lang.String, java.lang.Class, java.lang.Class, java.lang.Class, org.apache.hadoop.conf.Configuration)">saveAsNewAPIHadoopFiles(String, String, Class&lt;?&gt;, Class&lt;?&gt;, Class&lt;? extends OutputFormat&lt;?, ?&gt;&gt;, Configuration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile(String)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Save this RDD as a SequenceFile of serialized objects.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#saveAsObjectFile(java.lang.String)">saveAsObjectFile(String)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Save this RDD as a SequenceFile of serialized objects.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#saveAsObjectFiles(java.lang.String, java.lang.String)">saveAsObjectFiles(String, String)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Save each RDD in this DStream as a Sequence file of serialized objects.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html#saveAsSequenceFile(java.lang.String, scala.Option)">saveAsSequenceFile(String, Option&lt;Class&lt;? extends CompressionCodec&gt;&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd">SequenceFileRDDFunctions</a></dt>
<dd>
<div class="block">Output the RDD as a Hadoop SequenceFile using the Writable types we infer from the RDD's key
 and value types.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#saveAsTextFile(java.lang.String)">saveAsTextFile(String)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Save this RDD as a text file, using string representations of elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#saveAsTextFile(java.lang.String, java.lang.Class)">saveAsTextFile(String, Class&lt;? extends CompressionCodec&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Save this RDD as a compressed text file, using string representations of elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)">saveAsTextFile(String)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Save this RDD as a text file, using string representations of elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String, java.lang.Class)">saveAsTextFile(String, Class&lt;? extends CompressionCodec&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Save this RDD as a compressed text file, using string representations of elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#saveAsTextFiles(java.lang.String, java.lang.String)">saveAsTextFiles(String, String)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Save each RDD in this DStream as at text file, using string representation
 of elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/MLUtils.html#saveLabeledData(org.apache.spark.rdd.RDD, java.lang.String)">saveLabeledData(RDD&lt;LabeledPoint&gt;, String)</a></span> - Static method in class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/MLUtils.html" title="class in org.apache.spark.mllib.util">MLUtils</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>Should use <a href="./org/apache/spark/rdd/RDD.html#saveAsTextFile(java.lang.String)"><code>RDD.saveAsTextFile(java.lang.String)</code></a> for saving and
            <a href="./org/apache/spark/mllib/util/MLUtils.html#loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)"><code>MLUtils.loadLabeledPoints(org.apache.spark.SparkContext, java.lang.String, int)</code></a> for loading.</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#sc()">sc()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#sc()">sc()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#sc()">sc()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#scalaIntToJavaLong(org.apache.spark.streaming.dstream.DStream)">scalaIntToJavaLong(DStream&lt;Object&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#scalaToJavaLong(org.apache.spark.streaming.api.java.JavaPairDStream, scala.reflect.ClassTag)">scalaToJavaLong(JavaPairDStream&lt;K, Object&gt;, ClassTag&lt;K&gt;)</a></span> - Static method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#scheduler()">scheduler()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#schedulingDelay()">schedulingDelay()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>
<div class="block">Time taken for the first job of this batch to start processing from the time this batch
 was submitted to the streaming scheduler.</div>
</dd>
<dt><a href="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler"><span class="strong">SchedulingMode</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">"FAIR" and "FIFO" determines which policy is used
    to order tasks amongst a Schedulable's sub-queues
  "NONE" is used when the a Schedulable has no sub-queues.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SchedulingMode.html#SchedulingMode()">SchedulingMode()</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SchedulingMode.html" title="class in org.apache.spark.scheduler">SchedulingMode</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#schedulingMode()">schedulingMode()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#schema()">schema()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Returns the schema of this JavaSchemaRDD (represented by a StructType).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/AggregateEvaluation.html#schema()">schema()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/AggregateEvaluation.html" title="class in org.apache.spark.sql.execution">AggregateEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#schema()">schema()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Returns the schema of this SchemaRDD (represented by a <code>StructType</code>).</div>
</dd>
<dt><a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql"><span class="strong">SchemaRDD</span></a> - Class in <a href="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</a></dt>
<dd>
<div class="block">:: AlphaComponent ::
 An RDD of <code>Row</code> objects that has an associated schema.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#SchemaRDD(org.apache.spark.sql.SQLContext, org.apache.spark.sql.catalyst.plans.logical.LogicalPlan)">SchemaRDD(SQLContext, LogicalPlan)</a></span> - Constructor for class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#script()">script()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution"><span class="strong">ScriptTransformation</span></a> - Class in <a href="./org/apache/spark/sql/hive/execution/package-summary.html">org.apache.spark.sql.hive.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Transforms the input by forking and running the specified script.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html#ScriptTransformation(scala.collection.Seq, java.lang.String, scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.hive.HiveContext)">ScriptTransformation(Seq&lt;Expression&gt;, String, Seq&lt;Attribute&gt;, SparkPlan, HiveContext)</a></span> - Constructor for class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/ScriptTransformation.html" title="class in org.apache.spark.sql.hive.execution">ScriptTransformation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#seconds()">seconds()</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/Seconds.html" title="class in org.apache.spark.streaming"><span class="strong">Seconds</span></a> - Class in <a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a></dt>
<dd>
<div class="block">Helper object that creates instance of <a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming"><code>Duration</code></a> representing
 a given number of seconds.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Seconds.html#Seconds()">Seconds()</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Seconds.html" title="class in org.apache.spark.streaming">Seconds</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#securityManager()">securityManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#seed()">seed()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#select(scala.collection.Seq)">select(Seq&lt;Expression&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Changes the output of this relation to the given expressions, similar to the <code>SELECT</code> clause
 in SQL.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class, int)">sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop SequenceFile with given key and value types.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class)">sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop SequenceFile.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class, int)">sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop SequenceFile with given key and value types.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#sequenceFile(java.lang.String, java.lang.Class, java.lang.Class)">sequenceFile(String, Class&lt;K&gt;, Class&lt;V&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Get an RDD for a Hadoop SequenceFile with given key and value types.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#sequenceFile(java.lang.String, int, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.Function0, scala.Function0)">sequenceFile(String, int, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Function0&lt;WritableConverter&lt;K&gt;&gt;, Function0&lt;WritableConverter&lt;V&gt;&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Version of sequenceFile() for types implicitly convertible to Writables through a
 WritableConverter.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd"><span class="strong">SequenceFileRDDFunctions</span></a>&lt;<a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="type parameter in SequenceFileRDDFunctions">K</a>,<a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="type parameter in SequenceFileRDDFunctions">V</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">Extra functions available on RDDs of (key, value) pairs to create a Hadoop SequenceFile,
 through an implicit conversion.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html#SequenceFileRDDFunctions(org.apache.spark.rdd.RDD, scala.Function1, scala.reflect.ClassTag, scala.Function1, scala.reflect.ClassTag)">SequenceFileRDDFunctions(RDD&lt;Tuple2&lt;K, V&gt;&gt;, Function1&lt;K, Writable&gt;, ClassTag&lt;K&gt;, Function1&lt;V, Writable&gt;, ClassTag&lt;V&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/SequenceFileRDDFunctions.html" title="class in org.apache.spark.rdd">SequenceFileRDDFunctions</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark"><span class="strong">SerializableWritable</span></a>&lt;<a href="./org/apache/spark/SerializableWritable.html" title="type parameter in SerializableWritable">T</a> extends org.apache.hadoop.io.Writable&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SerializableWritable.html#SerializableWritable(T)">SerializableWritable(T)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer"><span class="strong">SerializationStream</span></a> - Class in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A stream for writing serialized objects.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializationStream.html#SerializationStream()">SerializationStream()</a></span> - Constructor for class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializerInstance.html#serialize(T, scala.reflect.ClassTag)">serialize(T, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html#serialize(java.lang.Object, org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector)">serialize(Object, ObjectInspector)</a></span> - Method in class org.apache.spark.sql.hive.parquet.<a href="./org/apache/spark/sql/hive/parquet/FakeParquetSerDe.html" title="class in org.apache.spark.sql.hive.parquet">FakeParquetSerDe</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer"><span class="strong">Serializer</span></a> - Class in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A serializer.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/Serializer.html#Serializer()">Serializer()</a></span> - Constructor for class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#serializer()">serializer()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#serializer()">serializer()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer"><span class="strong">SerializerInstance</span></a> - Class in <a href="./org/apache/spark/serializer/package-summary.html">org.apache.spark.serializer</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 An instance of a serializer, for use by one thread at a time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializerInstance.html#SerializerInstance()">SerializerInstance()</a></span> - Constructor for class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializerInstance.html#serializeStream(java.io.OutputStream)">serializeStream(OutputStream)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializerInstance.html" title="class in org.apache.spark.serializer">SerializerInstance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#set(java.lang.String, java.lang.String)">set(String, String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set a configuration variable.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#set(org.apache.spark.SparkEnv)">set(SparkEnv)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#setAggregator(org.apache.spark.Aggregator)">setAggregator(Aggregator&lt;K, V, C&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>
<div class="block">Set aggregator for RDD's shuffle.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setAll(scala.collection.Traversable)">setAll(Traversable&lt;Tuple2&lt;String, String&gt;&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set multiple parameters together</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setAlpha(double)">setAlpha(double)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">:: Experimental ::
 Sets the constant used in computing confidence in implicit ALS.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setAppName(java.lang.String)">setAppName(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set a name for your application.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setBlocks(int)">setBlocks(int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set the number of blocks for both user blocks and product blocks to parallelize the computation
 into; pass -1 for an auto-configured number of blocks.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#setCallSite(java.lang.String)">setCallSite(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Pass-through to SparkContext.setCallSite.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#setCallSite(java.lang.String)">setCallSite(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Set the thread-local property for overriding the call sites
 of actions and RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#setCheckpointDir(java.lang.String)">setCheckpointDir(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Set the directory under which RDDs are going to be checkpointed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#setCheckpointDir(java.lang.String)">setCheckpointDir(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Set the directory under which RDDs are going to be checkpointed.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution"><span class="strong">SetCommand</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SetCommand.html#SetCommand(scala.Option, scala.Option, scala.collection.Seq, org.apache.spark.sql.SQLContext)">SetCommand(Option&lt;String&gt;, Option&lt;String&gt;, Seq&lt;Attribute&gt;, SQLContext)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution">SetCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#setConf(java.lang.String, java.lang.String)">setConf(String, String)</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setConvergenceTol(double)">setConvergenceTol(double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Set the convergence tolerance of iterations for L-BFGS.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/Serializer.html#setDefaultClassLoader(java.lang.ClassLoader)">setDefaultClassLoader(ClassLoader)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/Serializer.html" title="class in org.apache.spark.serializer">Serializer</a></dt>
<dd>
<div class="block">Sets a class loader for the serializer to use in deserialization.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#setEpsilon(double)">setEpsilon(double)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Set the distance threshold within which we've consider centers to have converged.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setExecutorEnv(java.lang.String, java.lang.String)">setExecutorEnv(String, String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set an environment variable to be used when launching executors for this application.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setExecutorEnv(scala.collection.Seq)">setExecutorEnv(Seq&lt;Tuple2&lt;String, String&gt;&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set multiple environment variables to be used when launching executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setExecutorEnv(scala.Tuple2[])">setExecutorEnv(Tuple2&lt;String, String&gt;[])</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set multiple environment variables to be used when launching executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#setGradient(org.apache.spark.mllib.optimization.Gradient)">setGradient(Gradient)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">Set the gradient function (of the loss function of one single data example)
 to be used for SGD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setGradient(org.apache.spark.mllib.optimization.Gradient)">setGradient(Gradient)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Set the gradient function (of the loss function of one single data example)
 to be used for L-BFGS.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setIfMissing(java.lang.String, java.lang.String)">setIfMissing(String, String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set a parameter if it isn't already configured</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setImplicitPrefs(boolean)">setImplicitPrefs(boolean)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Sets whether to use implicit preference.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#setInitializationMode(java.lang.String)">setInitializationMode(String)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Set the initialization algorithm.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#setInitializationSteps(int)">setInitializationSteps(int)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Set the number of steps for the k-means|| initialization mode.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setInitialWeights(org.apache.spark.mllib.linalg.Vector)">setInitialWeights(Vector)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Set the initial weights.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#setIntercept(boolean)">setIntercept(boolean)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a></dt>
<dd>
<div class="block">Set if the algorithm should add an intercept.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setIntermediateRDDStorageLevel(org.apache.spark.storage.StorageLevel)">setIntermediateRDDStorageLevel(StorageLevel)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Sets storage level for intermediate RDDs (user/product in/out links).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setIterations(int)">setIterations(int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set the number of iterations to run.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setJars(scala.collection.Seq)">setJars(Seq&lt;String&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set JAR files to distribute to the cluster.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setJars(java.lang.String[])">setJars(String[])</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set JAR files to distribute to the cluster.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#setJobDescription(java.lang.String)">setJobDescription(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Set a human readable description of the current job.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#setJobGroup(java.lang.String, java.lang.String, boolean)">setJobGroup(String, String, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Assigns a group ID to all the jobs started by this thread until the group ID is set to a
 different value or cleared.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#setJobGroup(java.lang.String, java.lang.String)">setJobGroup(String, String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Assigns a group ID to all the jobs started by this thread until the group ID is set to a
 different value or cleared.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#setJobGroup(java.lang.String, java.lang.String, boolean)">setJobGroup(String, String, boolean)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Assigns a group ID to all the jobs started by this thread until the group ID is set to a
 different value or cleared.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#setK(int)">setK(int)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Set the number of clusters to create (k).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#setKeyOrdering(scala.math.Ordering)">setKeyOrdering(Ordering&lt;K&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>
<div class="block">Set key ordering for RDD's shuffle.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayes.html#setLambda(double)">setLambda(double)</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</a></dt>
<dd>
<div class="block">Set the smoothing parameter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setLambda(double)">setLambda(double)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set the regularization parameter, lambda.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#setLearningRate(double)">setLearningRate(double)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Sets initial learning rate (default: 0.025).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#setLocalProperty(java.lang.String, java.lang.String)">setLocalProperty(String, String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Set a local property that affects jobs submitted from this thread, such as the
 Spark fair scheduler pool.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#setLocalProperty(java.lang.String, java.lang.String)">setLocalProperty(String, String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Set a local property that affects jobs submitted from this thread, such as the
 Spark fair scheduler pool.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#setMapSideCombine(boolean)">setMapSideCombine(boolean)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>
<div class="block">Set mapSideCombine flag for RDD's shuffle.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setMaster(java.lang.String)">setMaster(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">The master URL to connect to, such as "local" to run locally with one thread, "local[4]" to
 run locally with 4 cores, or "spark://master:7077" to run on a Spark standalone cluster.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#setMaxIterations(int)">setMaxIterations(int)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Set maximum number of iterations to run.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setMaxNumIterations(int)">setMaxNumIterations(int)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>use <a href="./org/apache/spark/mllib/optimization/LBFGS.html#setNumIterations(int)"><code>LBFGS.setNumIterations(int)</code></a> instead</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#setMiniBatchFraction(double)">setMiniBatchFraction(double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">:: Experimental ::
 Set fraction of data to be used for each SGD iteration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setMiniBatchFraction(double)">setMiniBatchFraction(double)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Set the fraction of each batch to use for updates.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#setName(java.lang.String)">setName(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Assign a name to this RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#setName(java.lang.String)">setName(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Assign a name to this RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#setName(java.lang.String)">setName(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Assign a name to this RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#setName(java.lang.String)">setName(String)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Assign a name to this RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#setName(java.lang.String)">setName(String)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Assign a name to this RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setNonnegative(boolean)">setNonnegative(boolean)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set whether the least-squares problems solved at each iteration should have
 nonnegativity constraints.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setNumCorrections(int)">setNumCorrections(int)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Set the number of corrections used in the LBFGS update.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#setNumIterations(int)">setNumIterations(int)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Sets number of iterations (default: 1), which should be smaller than or equal to number of
 partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#setNumIterations(int)">setNumIterations(int)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">Set the number of iterations for SGD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setNumIterations(int)">setNumIterations(int)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Set the maximal number of iterations for L-BFGS.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setNumIterations(int)">setNumIterations(int)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Set the number of iterations of gradient descent to run per update.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#setNumPartitions(int)">setNumPartitions(int)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Sets number of partitions (default: 1).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setProductBlocks(int)">setProductBlocks(int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set the number of product blocks to parallelize the computation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setRank(int)">setRank(int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set the rank of the feature matrices computed (number of features).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#setRegParam(double)">setRegParam(double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">Set the regularization parameter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setRegParam(double)">setRegParam(double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Set the regularization parameter.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#setRuns(int)">setRuns(int)</a></span> - Method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">:: Experimental ::
 Set the number of runs of the algorithm to execute in parallel.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Sets random seed (default: a random long integer).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/PoissonGenerator.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/PoissonGenerator.html" title="class in org.apache.spark.mllib.random">PoissonGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/UniformGenerator.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Sets a random seed to have deterministic results.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/BernoulliSampler.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/BernoulliSampler.html" title="class in org.apache.spark.util.random">BernoulliSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/PoissonSampler.html#setSeed(long)">setSeed(long)</a></span> - Method in class org.apache.spark.util.random.<a href="./org/apache/spark/util/random/PoissonSampler.html" title="class in org.apache.spark.util.random">PoissonSampler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/random/Pseudorandom.html#setSeed(long)">setSeed(long)</a></span> - Method in interface org.apache.spark.util.random.<a href="./org/apache/spark/util/random/Pseudorandom.html" title="interface in org.apache.spark.util.random">Pseudorandom</a></dt>
<dd>
<div class="block">Set random seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/CoGroupedRDD.html#setSerializer(org.apache.spark.serializer.Serializer)">setSerializer(Serializer)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/CoGroupedRDD.html" title="class in org.apache.spark.rdd">CoGroupedRDD</a></dt>
<dd>
<div class="block">Set a serializer for this RDD's shuffle, or null to use the default (spark.serializer)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#setSerializer(org.apache.spark.serializer.Serializer)">setSerializer(Serializer)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>
<div class="block">Set a serializer for this RDD's shuffle, or null to use the default (spark.serializer)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#setSparkHome(java.lang.String)">setSparkHome(String)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Set the location where Spark is installed on worker nodes.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#setStepSize(double)">setStepSize(double)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">Set the initial step size of SGD for the first step.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#setStepSize(double)">setStepSize(double)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Set the step size for gradient descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#setThreshold(double)">setThreshold(double)</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</a></dt>
<dd>
<div class="block">:: Experimental ::
 Sets the threshold that separates positive predictions from negative predictions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMModel.html#setThreshold(double)">setThreshold(double)</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</a></dt>
<dd>
<div class="block">:: Experimental ::
 Sets the threshold that separates positive predictions from negative predictions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#settings()">settings()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/GradientDescent.html#setUpdater(org.apache.spark.mllib.optimization.Updater)">setUpdater(Updater)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/GradientDescent.html" title="class in org.apache.spark.mllib.optimization">GradientDescent</a></dt>
<dd>
<div class="block">Set the updater function to actually perform a gradient step in a given direction.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/LBFGS.html#setUpdater(org.apache.spark.mllib.optimization.Updater)">setUpdater(Updater)</a></span> - Method in class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/LBFGS.html" title="class in org.apache.spark.mllib.optimization">LBFGS</a></dt>
<dd>
<div class="block">Set the updater function to actually perform a gradient step in a given direction.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#setUserBlocks(int)">setUserBlocks(int)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Set the number of user blocks to parallelize the computation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html#setValidateData(boolean)">setValidateData(boolean)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a></dt>
<dd>
<div class="block">Set if the algorithm should validate data before training.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#setValue(R)">setValue(R)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>
<div class="block">Set the accumulator's value; only allowed on master</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#setVectorSize(int)">setVectorSize(int)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>
<div class="block">Sets vector size (default: 100).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/CompressionCodec.html#shortCompressionCodecNames()">shortCompressionCodecNames()</a></span> - Method in interface org.apache.spark.io.<a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io">CompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#ShortType">ShortType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the ShortType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/ShortType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">ShortType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing short and Short values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showBytesDistribution(java.lang.String, scala.Function2, scala.collection.Seq)">showBytesDistribution(String, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;, Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showBytesDistribution(java.lang.String, scala.Option)">showBytesDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showBytesDistribution(java.lang.String, org.apache.spark.util.Distribution)">showBytesDistribution(String, org.apache.spark.util.Distribution)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, org.apache.spark.util.Distribution, scala.Function1)">showDistribution(String, org.apache.spark.util.Distribution, Function1&lt;Object, String&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, scala.Option, scala.Function1)">showDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;, Function1&lt;Object, String&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, scala.Option, java.lang.String)">showDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;, String)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showDistribution(java.lang.String, java.lang.String, scala.Function2, scala.collection.Seq)">showDistribution(String, String, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;, Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showMillisDistribution(java.lang.String, scala.Option)">showMillisDistribution(String, Option&lt;org.apache.spark.util.Distribution&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#showMillisDistribution(java.lang.String, scala.Function2, scala.collection.Seq)">showMillisDistribution(String, Function2&lt;TaskInfo, TaskMetrics, Option&lt;Object&gt;&gt;, Seq&lt;Tuple2&lt;TaskInfo, TaskMetrics&gt;&gt;)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html#showMillisDistribution(java.lang.String, scala.Function1)">showMillisDistribution(String, Function1&lt;BatchInfo, Option&lt;Object&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#SHUFFLE()">SHUFFLE()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#SHUFFLE_INDEX()">SHUFFLE_INDEX()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage"><span class="strong">ShuffleBlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleBlockId.html#ShuffleBlockId(int, int, int)">ShuffleBlockId(int, int, int)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark"><span class="strong">ShuffleDependency</span></a>&lt;<a href="./org/apache/spark/ShuffleDependency.html" title="type parameter in ShuffleDependency">K</a>,<a href="./org/apache/spark/ShuffleDependency.html" title="type parameter in ShuffleDependency">V</a>,<a href="./org/apache/spark/ShuffleDependency.html" title="type parameter in ShuffleDependency">C</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Represents a dependency on the output of a shuffle stage.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#ShuffleDependency(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.Option, scala.Option, scala.Option, boolean)">ShuffleDependency(RDD&lt;? extends Product2&lt;K, V&gt;&gt;, Partitioner, Option&lt;Serializer&gt;, Option&lt;Ordering&lt;K&gt;&gt;, Option&lt;Aggregator&lt;K, V, C&gt;&gt;, boolean)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution"><span class="strong">ShuffledHashJoin</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Performs an inner hash join of two child relations by first shuffling the data using the join
 keys.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html#ShuffledHashJoin(scala.collection.Seq, scala.collection.Seq, org.apache.spark.sql.execution.BuildSide, org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.execution.SparkPlan)">ShuffledHashJoin(Seq&lt;Expression&gt;, Seq&lt;Expression&gt;, BuildSide, SparkPlan, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/ShuffledHashJoin.html" title="class in org.apache.spark.sql.execution">ShuffledHashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd"><span class="strong">ShuffledRDD</span></a>&lt;<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="type parameter in ShuffledRDD">K</a>,<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="type parameter in ShuffledRDD">V</a>,<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="type parameter in ShuffledRDD">C</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 The resulting RDD from a shuffle (e.g.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/ShuffledRDD.html#ShuffledRDD(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner)">ShuffledRDD(RDD&lt;? extends Product2&lt;K, V&gt;&gt;, Partitioner)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/ShuffledRDD.html" title="class in org.apache.spark.rdd">ShuffledRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#shuffleHandle()">shuffleHandle()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FetchFailed.html#shuffleId()">shuffleId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ShuffleDependency.html#shuffleId()">shuffleId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ShuffleDependency.html" title="class in org.apache.spark">ShuffleDependency</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleBlockId.html#shuffleId()">shuffleId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleBlockId.html" title="class in org.apache.spark.storage">ShuffleBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleIndexBlockId.html#shuffleId()">shuffleId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage"><span class="strong">ShuffleIndexBlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/ShuffleIndexBlockId.html#ShuffleIndexBlockId(int, int, int)">ShuffleIndexBlockId(int, int, int)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/ShuffleIndexBlockId.html" title="class in org.apache.spark.storage">ShuffleIndexBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#shuffleManager()">shuffleManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#shuffleMemoryManager()">shuffleMemoryManager()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Command.html#sideEffectResult()">sideEffectResult()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Command.html" title="interface in org.apache.spark.sql.execution">Command</a></dt>
<dd>
<div class="block">A concrete command should override this lazy field to wrap up any side effects caused by the
 command or any other computation that should be evaluated exactly once.</div>
</dd>
<dt><a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark"><span class="strong">SimpleFutureAction</span></a>&lt;<a href="./org/apache/spark/SimpleFutureAction.html" title="type parameter in SimpleFutureAction">T</a>&gt; - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: Experimental ::
 A <a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark"><code>FutureAction</code></a> holding the result of an action that triggers a single job.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/optimization/SimpleUpdater.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">SimpleUpdater</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A simple updater for gradient descent *without* any regularization.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/SimpleUpdater.html#SimpleUpdater()">SimpleUpdater()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/SimpleUpdater.html" title="class in org.apache.spark.mllib.optimization">SimpleUpdater</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg"><span class="strong">SingularValueDecomposition</span></a>&lt;<a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="type parameter in SingularValueDecomposition">UType</a>,<a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="type parameter in SingularValueDecomposition">VType</a>&gt; - Class in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents singular value decomposition (SVD) factors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#SingularValueDecomposition(UType, org.apache.spark.mllib.linalg.Vector, VType)">SingularValueDecomposition(UType, Vector, VType)</a></span> - Constructor for class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#size()">size()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#size()">size()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#size()">size()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>
<div class="block">Size of the vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/RangePartitioner.html#sketch(org.apache.spark.rdd.RDD, int, scala.reflect.ClassTag)">sketch(RDD&lt;K&gt;, int, ClassTag&lt;K&gt;)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/RangePartitioner.html" title="class in org.apache.spark">RangePartitioner</a></dt>
<dd>
<div class="block">Sketches the input RDD via reservoir sampling on each partition.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#slice(org.apache.spark.streaming.Time, org.apache.spark.streaming.Time)">slice(Time, Time)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return all the RDDs between 'fromDuration' to 'toDuration' (both included)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#slice(org.apache.spark.streaming.Interval)">slice(org.apache.spark.streaming.Interval)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return all the RDDs defined by the Interval object (both end times included)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#slice(org.apache.spark.streaming.Time, org.apache.spark.streaming.Time)">slice(Time, Time)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return all the RDDs between 'fromTime' to 'toTime' (both included)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#slideDuration()">slideDuration()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Time interval after which the DStream generates a RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/InputDStream.html#slideDuration()">slideDuration()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io"><span class="strong">SnappyCompressionCodec</span></a> - Class in <a href="./org/apache/spark/io/package-summary.html">org.apache.spark.io</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Snappy implementation of <a href="./org/apache/spark/io/CompressionCodec.html" title="interface in org.apache.spark.io"><code>CompressionCodec</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/io/SnappyCompressionCodec.html#SnappyCompressionCodec(org.apache.spark.SparkConf)">SnappyCompressionCodec(SparkConf)</a></span> - Constructor for class org.apache.spark.io.<a href="./org/apache/spark/io/SnappyCompressionCodec.html" title="class in org.apache.spark.io">SnappyCompressionCodec</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketStream(java.lang.String, int, org.apache.spark.api.java.function.Function, org.apache.spark.storage.StorageLevel)">socketStream(String, int, Function&lt;InputStream, Iterable&lt;T&gt;&gt;, StorageLevel)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from network source hostname:port.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#socketStream(java.lang.String, int, scala.Function1, org.apache.spark.storage.StorageLevel, scala.reflect.ClassTag)">socketStream(String, int, Function1&lt;InputStream, Iterator&lt;T&gt;&gt;, StorageLevel, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a input stream from TCP source hostname:port.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketTextStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)">socketTextStream(String, int, StorageLevel)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from network source hostname:port.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#socketTextStream(java.lang.String, int)">socketTextStream(String, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream from network source hostname:port.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#socketTextStream(java.lang.String, int, org.apache.spark.storage.StorageLevel)">socketTextStream(String, int, StorageLevel)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a input stream from TCP source hostname:port.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#solveLeastSquares(org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, org.apache.spark.mllib.optimization.NNLS.Workspace)">solveLeastSquares(DoubleMatrix, DoubleMatrix, org.apache.spark.mllib.optimization.NNLS.Workspace)</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Given A^T A and A^T b, find the x minimising ||Ax - b||_2, possibly subject
 to nonnegativity constraints if <code>nonnegative</code> is true.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html#Sort()">Sort()</a></span> - Static method in class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/QuantileStrategy.html" title="class in org.apache.spark.mllib.tree.configuration">QuantileStrategy</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution"><span class="strong">Sort</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#Sort(scala.collection.Seq, boolean, org.apache.spark.sql.execution.SparkPlan)">Sort(Seq&lt;SortOrder&gt;, boolean, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#sortBy(org.apache.spark.api.java.function.Function, boolean, int)">sortBy(Function&lt;T, S&gt;, boolean, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return this RDD sorted by the given key function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#sortBy(scala.Function1, boolean, int, scala.math.Ordering, scala.reflect.ClassTag)">sortBy(Function1&lt;T, K&gt;, boolean, int, Ordering&lt;K&gt;, ClassTag&lt;K&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return this RDD sorted by the given key function.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey()">sortByKey()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements in
 ascending order.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(boolean)">sortByKey(boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(boolean, int)">sortByKey(boolean, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(java.util.Comparator)">sortByKey(Comparator&lt;K&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(java.util.Comparator, boolean)">sortByKey(Comparator&lt;K&gt;, boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#sortByKey(java.util.Comparator, boolean, int)">sortByKey(Comparator&lt;K&gt;, boolean, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/OrderedRDDFunctions.html#sortByKey(boolean, int)">sortByKey(boolean, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/OrderedRDDFunctions.html" title="class in org.apache.spark.rdd">OrderedRDDFunctions</a></dt>
<dd>
<div class="block">Sort the RDD by key, so that each partition contains a sorted range of the elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sort.html#sortOrder()">sortOrder()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sort.html" title="class in org.apache.spark.sql.execution">Sort</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#sortOrder()">sortOrder()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SPARK_JOB_DESCRIPTION()">SPARK_JOB_DESCRIPTION()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SPARK_JOB_GROUP_ID()">SPARK_JOB_GROUP_ID()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SPARK_JOB_INTERRUPT_ON_CANCEL()">SPARK_JOB_INTERRUPT_ON_CANCEL()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SPARK_UNKNOWN_USER()">SPARK_UNKNOWN_USER()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SPARK_VERSION()">SPARK_VERSION()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark"><span class="strong">SparkConf</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">Configuration for a Spark application.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#SparkConf(boolean)">SparkConf(boolean)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#SparkConf()">SparkConf()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Create a SparkConf that loads defaults from system properties and the classpath</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#sparkContext()">sparkContext()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">The SparkContext that created this RDD.</div>
</dd>
<dt><a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark"><span class="strong">SparkContext</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">Main entry point for Spark functionality.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SparkContext(org.apache.spark.SparkConf)">SparkContext(SparkConf)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SparkContext()">SparkContext()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Create a SparkContext that loads settings from system properties (for instance, when
 launching with ./bin/spark-submit).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SparkContext(org.apache.spark.SparkConf, scala.collection.Map)">SparkContext(SparkConf, Map&lt;String, Set&lt;SplitInfo&gt;&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Alternative constructor for setting preferred locations where Spark will create executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SparkContext(java.lang.String, java.lang.String, org.apache.spark.SparkConf)">SparkContext(String, String, SparkConf)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Alternative constructor that allows setting common Spark properties directly</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#SparkContext(java.lang.String, java.lang.String, java.lang.String, scala.collection.Seq, scala.collection.Map, scala.collection.Map)">SparkContext(String, String, String, Seq&lt;String&gt;, Map&lt;String, String&gt;, Map&lt;String, Set&lt;SplitInfo&gt;&gt;)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Alternative constructor that allows setting common Spark properties directly</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#sparkContext()">sparkContext()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#sparkContext()">sparkContext()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">The underlying SparkContext</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#sparkContext()">sparkContext()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Return the associated Spark context</div>
</dd>
<dt><a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark"><span class="strong">SparkContext.DoubleAccumulatorParam$</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#SparkContext.DoubleAccumulatorParam$()">SparkContext.DoubleAccumulatorParam$()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark"><span class="strong">SparkContext.FloatAccumulatorParam$</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#SparkContext.FloatAccumulatorParam$()">SparkContext.FloatAccumulatorParam$()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark"><span class="strong">SparkContext.IntAccumulatorParam$</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#SparkContext.IntAccumulatorParam$()">SparkContext.IntAccumulatorParam$()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark"><span class="strong">SparkContext.LongAccumulatorParam$</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#SparkContext.LongAccumulatorParam$()">SparkContext.LongAccumulatorParam$()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark"><span class="strong">SparkEnv</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Holds all the runtime environment objects for a running Spark instance (either master or worker),
 including the serializer, Akka actor system, block manager, map output tracker, etc.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#SparkEnv(java.lang.String, akka.actor.ActorSystem, org.apache.spark.serializer.Serializer, org.apache.spark.serializer.Serializer, org.apache.spark.CacheManager, org.apache.spark.MapOutputTracker, org.apache.spark.shuffle.ShuffleManager, org.apache.spark.broadcast.BroadcastManager, org.apache.spark.storage.BlockManager, org.apache.spark.network.ConnectionManager, org.apache.spark.SecurityManager, org.apache.spark.HttpFileServer, java.lang.String, org.apache.spark.metrics.MetricsSystem, org.apache.spark.shuffle.ShuffleMemoryManager, org.apache.spark.SparkConf)">SparkEnv(String, ActorSystem, Serializer, Serializer, CacheManager, MapOutputTracker, ShuffleManager, org.apache.spark.broadcast.BroadcastManager, org.apache.spark.storage.BlockManager, ConnectionManager, SecurityManager, HttpFileServer, String, org.apache.spark.metrics.MetricsSystem, ShuffleMemoryManager, SparkConf)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkException.html" title="class in org.apache.spark"><span class="strong">SparkException</span></a> - Exception in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkException.html#SparkException(java.lang.String, java.lang.Throwable)">SparkException(String, Throwable)</a></span> - Constructor for exception org.apache.spark.<a href="./org/apache/spark/SparkException.html" title="class in org.apache.spark">SparkException</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkException.html#SparkException(java.lang.String)">SparkException(String)</a></span> - Constructor for exception org.apache.spark.<a href="./org/apache/spark/SparkException.html" title="class in org.apache.spark">SparkException</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark"><span class="strong">SparkFiles</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">Resolves paths to files added through <code>SparkContext.addFile()</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkFiles.html#SparkFiles()">SparkFiles()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/SparkFiles.html" title="class in org.apache.spark">SparkFiles</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkEnv.html#sparkFilesDir()">sparkFilesDir()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkEnv.html" title="class in org.apache.spark">SparkEnv</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume"><span class="strong">SparkFlumeEvent</span></a> - Class in <a href="./org/apache/spark/streaming/flume/package-summary.html">org.apache.spark.streaming.flume</a></dt>
<dd>
<div class="block">A wrapper class for AvroFlumeEvent's with a custom serialization format.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#SparkFlumeEvent()">SparkFlumeEvent()</a></span> - Constructor for class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListener.html" title="interface in org.apache.spark.scheduler"><span class="strong">SparkListener</span></a> - Interface in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Interface for listening to events from the Spark scheduler.</div>
</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerApplicationEnd</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html#SparkListenerApplicationEnd(long)">SparkListenerApplicationEnd(long)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationEnd</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerApplicationStart</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#SparkListenerApplicationStart(java.lang.String, long, java.lang.String)">SparkListenerApplicationStart(String, long, String)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerBlockManagerAdded</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html#SparkListenerBlockManagerAdded(org.apache.spark.storage.BlockManagerId, long)">SparkListenerBlockManagerAdded(BlockManagerId, long)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerBlockManagerAdded.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerAdded</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerBlockManagerRemoved</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html#SparkListenerBlockManagerRemoved(org.apache.spark.storage.BlockManagerId)">SparkListenerBlockManagerRemoved(BlockManagerId)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerBlockManagerRemoved.html" title="class in org.apache.spark.scheduler">SparkListenerBlockManagerRemoved</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerEnvironmentUpdate</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html#SparkListenerEnvironmentUpdate(scala.collection.Map)">SparkListenerEnvironmentUpdate(Map&lt;String, Seq&lt;Tuple2&lt;String, String&gt;&gt;&gt;)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerEnvironmentUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerEnvironmentUpdate</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerEvent.html" title="interface in org.apache.spark.scheduler"><span class="strong">SparkListenerEvent</span></a> - Interface in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerExecutorMetricsUpdate</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">Periodic updates from executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html#SparkListenerExecutorMetricsUpdate(java.lang.String, scala.collection.Seq)">SparkListenerExecutorMetricsUpdate(String, Seq&lt;Tuple4&lt;Object, Object, Object, TaskMetrics&gt;&gt;)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorMetricsUpdate</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerJobEnd</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html#SparkListenerJobEnd(int, org.apache.spark.scheduler.JobResult)">SparkListenerJobEnd(int, JobResult)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobEnd.html" title="class in org.apache.spark.scheduler">SparkListenerJobEnd</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerJobStart</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobStart.html#SparkListenerJobStart(int, scala.collection.Seq, java.util.Properties)">SparkListenerJobStart(int, Seq&lt;Object&gt;, Properties)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerStageCompleted.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerStageCompleted</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerStageCompleted.html#SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo)">SparkListenerStageCompleted(StageInfo)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerStageCompleted.html" title="class in org.apache.spark.scheduler">SparkListenerStageCompleted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerStageSubmitted</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html#SparkListenerStageSubmitted(org.apache.spark.scheduler.StageInfo, java.util.Properties)">SparkListenerStageSubmitted(StageInfo, Properties)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler">SparkListenerStageSubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerTaskEnd</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#SparkListenerTaskEnd(int, int, java.lang.String, org.apache.spark.TaskEndReason, org.apache.spark.scheduler.TaskInfo, org.apache.spark.executor.TaskMetrics)">SparkListenerTaskEnd(int, int, String, TaskEndReason, TaskInfo, TaskMetrics)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerTaskGettingResult</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html#SparkListenerTaskGettingResult(org.apache.spark.scheduler.TaskInfo)">SparkListenerTaskGettingResult(TaskInfo)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html" title="class in org.apache.spark.scheduler">SparkListenerTaskGettingResult</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerTaskStart</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html#SparkListenerTaskStart(int, int, org.apache.spark.scheduler.TaskInfo)">SparkListenerTaskStart(int, int, TaskInfo)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html" title="class in org.apache.spark.scheduler"><span class="strong">SparkListenerUnpersistRDD</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html#SparkListenerUnpersistRDD(int)">SparkListenerUnpersistRDD(int)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerUnpersistRDD.html" title="class in org.apache.spark.scheduler">SparkListenerUnpersistRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution"><span class="strong">SparkLogicalPlan</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Allows already planned SparkQueries to be linked into logical query plans.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html#SparkLogicalPlan(org.apache.spark.sql.execution.SparkPlan, org.apache.spark.sql.SQLContext)">SparkLogicalPlan(SparkPlan, SQLContext)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution">SparkLogicalPlan</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution"><span class="strong">SparkPlan</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkPlan.html#SparkPlan()">SparkPlan()</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkPlan.html" title="class in org.apache.spark.sql.execution">SparkPlan</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/env/EnvironmentListener.html#sparkProperties()">sparkProperties()</a></span> - Method in class org.apache.spark.ui.env.<a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#sparkUser()">sparkUser()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#sparkUser()">sparkUser()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#sparkUser()">sparkUser()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#sparse(int, int[], double[])">sparse(int, int[], double[])</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a sparse vector providing its index array and value array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#sparse(int, scala.collection.Seq)">sparse(int, Seq&lt;Tuple2&lt;Object, Object&gt;&gt;)</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a sparse vector using unordered (index, value) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#sparse(int, java.lang.Iterable)">sparse(int, Iterable&lt;Tuple2&lt;Integer, Double&gt;&gt;)</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a sparse vector using unordered (index, value) pairs in a Java friendly way.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg"><span class="strong">SparseVector</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">A sparse vector represented by an index array and an value array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#SparseVector(int, int[], double[])">SparseVector(int, int[], double[])</a></span> - Constructor for class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#speculative()">speculative()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#split()">split()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model"><span class="strong">Split</span></a> - Class in <a href="./org/apache/spark/mllib/tree/model/package-summary.html">org.apache.spark.mllib.tree.model</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Split applied to a feature</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Split.html#Split(int, double, scala.Enumeration.Value, scala.collection.immutable.List)">Split(int, double, Enumeration.Value, List&lt;Object&gt;)</a></span> - Constructor for class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#splitId()">splitId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDBlockId.html#splitIndex()">splitIndex()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDBlockId.html" title="class in org.apache.spark.storage">RDDBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler"><span class="strong">SplitInfo</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#SplitInfo(java.lang.Class, java.lang.String, java.lang.String, long, java.lang.Object)">SplitInfo(Class&lt;?&gt;, String, String, long, Object)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#splits()">splits()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#sql(java.lang.String)">sql(String)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html#sql(java.lang.String)">sql(String)</a></span> - Method in class org.apache.spark.sql.hive.api.java.<a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html" title="class in org.apache.spark.sql.hive.api.java">JavaHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/NativeCommand.html#sql()">sql()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/NativeCommand.html" title="class in org.apache.spark.sql.hive.execution">NativeCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveContext.html#sql(java.lang.String)">sql(String)</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveContext.html" title="class in org.apache.spark.sql.hive">HiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#sql(java.lang.String)">sql(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Executes a SQL query using Spark, returning the result as a SchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#sqlContext()">sqlContext()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSQLContext.html#sqlContext()">sqlContext()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSQLContext.html" title="class in org.apache.spark.sql.api.java">JavaSQLContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html#sqlContext()">sqlContext()</a></span> - Method in class org.apache.spark.sql.hive.api.java.<a href="./org/apache/spark/sql/hive/api/java/JavaHiveContext.html" title="class in org.apache.spark.sql.hive.api.java">JavaHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#sqlContext()">sqlContext()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><span class="strong">SQLContext</span></a> - Class in <a href="./org/apache/spark/sql/package-summary.html">org.apache.spark.sql</a></dt>
<dd>
<div class="block">:: AlphaComponent ::
 The entry point for running relational queries using Spark.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#SQLContext(org.apache.spark.SparkContext)">SQLContext(SparkContext)</a></span> - Constructor for class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#squaredDist(org.apache.spark.util.Vector)">squaredDist(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/optimization/SquaredL2Updater.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">SquaredL2Updater</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Updater for L2 regularized problems.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/SquaredL2Updater.html#SquaredL2Updater()">SquaredL2Updater()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/SquaredL2Updater.html" title="class in org.apache.spark.mllib.optimization">SquaredL2Updater</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#srdd()">srdd()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#ssc()">ssc()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#ssc()">ssc()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExceptionFailure.html#stackTrace()">stackTrace()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#stageAttemptId()">stageAttemptId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html#stageAttemptId()">stageAttemptId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#stageFailed(java.lang.String)">stageFailed(String)</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#stageId()">stageId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html#stageId()">stageId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#stageId()">stageId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#stageId()">stageId()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerJobStart.html#stageIds()">stageIds()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerJobStart.html" title="class in org.apache.spark.scheduler">SparkListenerJobStart</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#stageIdToData()">stageIdToData()</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerStageCompleted.html#stageInfo()">stageInfo()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerStageCompleted.html" title="class in org.apache.spark.scheduler">SparkListenerStageCompleted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html#stageInfo()">stageInfo()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerStageSubmitted.html" title="class in org.apache.spark.scheduler">SparkListenerStageSubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler"><span class="strong">StageInfo</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Stores information about a stage to pass from the scheduler to SparkListeners.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#StageInfo(int, int, java.lang.String, int, scala.collection.Seq, java.lang.String)">StageInfo(int, int, String, int, Seq&lt;RDDInfo&gt;, String)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random"><span class="strong">StandardNormalGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generates i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html#StandardNormalGenerator()">StandardNormalGenerator()</a></span> - Constructor for class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/StandardNormalGenerator.html" title="class in org.apache.spark.mllib.random">StandardNormalGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature"><span class="strong">StandardScaler</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Standardizes features by removing the mean and scaling to unit variance using column summary
 statistics on the samples in the training set.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScaler.html#StandardScaler(boolean, boolean)">StandardScaler(boolean, boolean)</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature">StandardScaler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScaler.html#StandardScaler()">StandardScaler()</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScaler.html" title="class in org.apache.spark.mllib.feature">StandardScaler</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature"><span class="strong">StandardScalerModel</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Represents a StandardScaler model that can transform vectors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#start()">start()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Start the execution of the streams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#start()">start()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/InputDStream.html#start()">start()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</a></dt>
<dd>
<div class="block">Method called to start receiving data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#start()">start()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#start()">start()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Start the execution of the streams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#startTime()">startTime()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#startTime()">startTime()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util"><span class="strong">StatCounter</span></a> - Class in <a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a></dt>
<dd>
<div class="block">A class for tracking the statistics of a set of numbers (count, mean and variance) in a
 numerically robust way.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#StatCounter(scala.collection.TraversableOnce)">StatCounter(TraversableOnce&lt;Object&gt;)</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#StatCounter()">StatCounter()</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Initialize the StatCounter with no values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#state()">state()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#statistic()">statistic()</a></span> - Method in class org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/TestResult.html#statistic()">statistic()</a></span> - Method in interface org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</a></dt>
<dd>
<div class="block">Test statistic.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat"><span class="strong">Statistics</span></a> - Class in <a href="./org/apache/spark/mllib/stat/package-summary.html">org.apache.spark.mllib.stat</a></dt>
<dd>
<div class="block">API for statistical functions in MLlib.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/Statistics.html#Statistics()">Statistics()</a></span> - Constructor for class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/Statistics.html" title="class in org.apache.spark.mllib.stat">Statistics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html#statistics()">statistics()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SparkLogicalPlan.html" title="class in org.apache.spark.sql.execution">SparkLogicalPlan</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver"><span class="strong">Statistics</span></a> - Class in <a href="./org/apache/spark/streaming/receiver/package-summary.html">org.apache.spark.streaming.receiver</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Statistics for querying the supervisor about state of workers.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Statistics.html#Statistics(int, int, int, java.lang.String)">Statistics(int, int, int, String)</a></span> - Constructor for class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Statistics.html" title="class in org.apache.spark.streaming.receiver">Statistics</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#stats()">stats()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return a <a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util"><code>StatCounter</code></a> object that captures the mean, variance and
 count of the RDD's elements in one operation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#stats()">stats()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#stats()">stats()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Return a <a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util"><code>StatCounter</code></a> object that captures the mean, variance and
 count of the RDD's elements in one operation.</div>
</dd>
<dt><a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler"><span class="strong">StatsReportListener</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Simple SparkListener that logs a few summary statistics when each stage completes</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StatsReportListener.html#StatsReportListener()">StatsReportListener()</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StatsReportListener.html" title="class in org.apache.spark.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StatsReportListener</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A simple StreamingListener that logs summary statistics across Spark Streaming batches</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html#StatsReportListener(int)">StatsReportListener(int)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StatsReportListener.html" title="class in org.apache.spark.streaming.scheduler">StatsReportListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#status()">status()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#stdev()">stdev()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute the standard deviation of this RDD's elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#stdev()">stdev()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute the standard deviation of this RDD's elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#stdev()">stdev()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Return the standard deviation of the values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#stop()">stop()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Shut down the SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/BroadcastFactory.html#stop()">stop()</a></span> - Method in interface org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html#stop()">stop()</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#stop()">stop()</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#stop()">stop()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Shut down the SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop()">stop()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Stop the execution of the streams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop(boolean)">stop(boolean)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Stop the execution of the streams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#stop(boolean, boolean)">stop(boolean, boolean)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Stop the execution of the streams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html#stop()">stop()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ConstantInputDStream.html" title="class in org.apache.spark.streaming.dstream">ConstantInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/InputDStream.html#stop()">stop()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/InputDStream.html" title="class in org.apache.spark.streaming.dstream">InputDStream</a></dt>
<dd>
<div class="block">Method called to stop receiving data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html#stop()">stop()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream">ReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#stop(java.lang.String)">stop(String)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Stop the receiver completely.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#stop(java.lang.String, java.lang.Throwable)">stop(String, Throwable)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Stop the receiver completely due to an exception</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#stop(boolean)">stop(boolean)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Stop the execution of the streams immediately (does not wait for all received data
 to be processed).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#stop(boolean, boolean)">stop(boolean, boolean)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Stop the execution of the streams, with option of ensuring all received data
 has been processed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#storageLevel()">storageLevel()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#storageLevel()">storageLevel()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage"><span class="strong">StorageLevel</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Flags for controlling the storage of an RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#StorageLevel()">StorageLevel()</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#storageLevel()">storageLevel()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#storageLevel()">storageLevel()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#storageLevelCache()">storageLevelCache()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Read StorageLevel object from ObjectInput stream.</div>
</dd>
<dt><a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java"><span class="strong">StorageLevels</span></a> - Class in <a href="./org/apache/spark/api/java/package-summary.html">org.apache.spark.api.java</a></dt>
<dd>
<div class="block">Expose some commonly useful storage level constants.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/StorageLevels.html#StorageLevels()">StorageLevels()</a></span> - Constructor for class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/StorageLevels.html" title="class in org.apache.spark.api.java">StorageLevels</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage"><span class="strong">StorageListener</span></a> - Class in <a href="./org/apache/spark/ui/storage/package-summary.html">org.apache.spark.ui.storage</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A SparkListener that prepares information to be displayed on the BlockManagerUI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#StorageListener(org.apache.spark.storage.StorageStatusListener)">StorageListener(StorageStatusListener)</a></span> - Constructor for class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage"><span class="strong">StorageStatus</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Storage information for each BlockManager.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#StorageStatus(org.apache.spark.storage.BlockManagerId, long)">StorageStatus(BlockManagerId, long)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatus.html#StorageStatus(org.apache.spark.storage.BlockManagerId, long, scala.collection.Map)">StorageStatus(BlockManagerId, long, Map&lt;BlockId, BlockStatus&gt;)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatus.html" title="class in org.apache.spark.storage">StorageStatus</a></dt>
<dd>
<div class="block">Create a storage status with an initial set of blocks, leaving the source unmodified.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#storageStatusList()">storageStatusList()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/exec/ExecutorsListener.html#storageStatusList()">storageStatusList()</a></span> - Method in class org.apache.spark.ui.exec.<a href="./org/apache/spark/ui/exec/ExecutorsListener.html" title="class in org.apache.spark.ui.exec">ExecutorsListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#storageStatusList()">storageStatusList()</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage"><span class="strong">StorageStatusListener</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A SparkListener that maintains executor storage status.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageStatusListener.html#StorageStatusListener()">StorageStatusListener()</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageStatusListener.html" title="class in org.apache.spark.storage">StorageStatusListener</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/ActorHelper.html#store(scala.collection.Iterator)">store(Iterator&lt;T&gt;)</a></span> - Method in interface org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver">ActorHelper</a></dt>
<dd>
<div class="block">Store an iterator of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/ActorHelper.html#store(java.nio.ByteBuffer)">store(ByteBuffer)</a></span> - Method in interface org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver">ActorHelper</a></dt>
<dd>
<div class="block">Store the bytes of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/ActorHelper.html#store(T)">store(T)</a></span> - Method in interface org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/ActorHelper.html" title="interface in org.apache.spark.streaming.receiver">ActorHelper</a></dt>
<dd>
<div class="block">Store a single item of received data to Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(T)">store(T)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store a single item of received data to Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.mutable.ArrayBuffer)">store(ArrayBuffer&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store an ArrayBuffer of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.mutable.ArrayBuffer, java.lang.Object)">store(ArrayBuffer&lt;T&gt;, Object)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store an ArrayBuffer of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.Iterator)">store(Iterator&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store an iterator of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(java.util.Iterator, java.lang.Object)">store(Iterator&lt;T&gt;, Object)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store an iterator of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(java.util.Iterator)">store(Iterator&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store an iterator of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(scala.collection.Iterator, java.lang.Object)">store(Iterator&lt;T&gt;, Object)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store an iterator of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(java.nio.ByteBuffer)">store(ByteBuffer)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store the bytes of received data as a data block into Spark's memory.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#store(java.nio.ByteBuffer, java.lang.Object)">store(ByteBuffer, Object)</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Store the bytes of received data as a data block into Spark's memory.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration"><span class="strong">Strategy</span></a> - Class in <a href="./org/apache/spark/mllib/tree/configuration/package-summary.html">org.apache.spark.mllib.tree.configuration</a></dt>
<dd>
<div class="block">:: Experimental ::
 Stores all the configuration options for tree construction</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#Strategy(scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int, int, int, scala.Enumeration.Value, scala.collection.immutable.Map, int)">Strategy(Enumeration.Value, Impurity, int, int, int, Enumeration.Value, Map&lt;Object, Object&gt;, int)</a></span> - Constructor for class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/configuration/Strategy.html#Strategy(scala.Enumeration.Value, org.apache.spark.mllib.tree.impurity.Impurity, int, int, int, java.util.Map)">Strategy(Enumeration.Value, Impurity, int, int, int, Map&lt;Integer, Integer&gt;)</a></span> - Constructor for class org.apache.spark.mllib.tree.configuration.<a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration">Strategy</a></dt>
<dd>
<div class="block">Java-friendly constructor for <a href="./org/apache/spark/mllib/tree/configuration/Strategy.html" title="class in org.apache.spark.mllib.tree.configuration"><code>Strategy</code></a></div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#STREAM()">STREAM()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage"><span class="strong">StreamBlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StreamBlockId.html#StreamBlockId(int, long)">StreamBlockId(int, long)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html#streamed()">streamed()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BroadcastNestedLoopJoin.html" title="class in org.apache.spark.sql.execution">BroadcastNestedLoopJoin</a></dt>
<dd>
<div class="block">BuildRight means the right relation <=> the broadcast relation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html#streamed()">streamed()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/LeftSemiJoinBNL.html" title="class in org.apache.spark.sql.execution">LeftSemiJoinBNL</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#streamedKeys()">streamedKeys()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#streamedPlan()">streamedPlan()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StreamBlockId.html#streamId()">streamId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/receiver/Receiver.html#streamId()">streamId()</a></span> - Method in class org.apache.spark.streaming.receiver.<a href="./org/apache/spark/streaming/receiver/Receiver.html" title="class in org.apache.spark.streaming.receiver">Receiver</a></dt>
<dd>
<div class="block">Get the unique identifier the receiver input stream that this
 receiver is associated with.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html#streamId()">streamId()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/ReceiverInfo.html" title="class in org.apache.spark.streaming.scheduler">ReceiverInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming"><span class="strong">StreamingContext</span></a> - Class in <a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a></dt>
<dd>
<div class="block">Main entry point for Spark Streaming functionality.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(org.apache.spark.SparkContext, org.apache.spark.streaming.Duration)">StreamingContext(SparkContext, Duration)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext using an existing SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(org.apache.spark.SparkConf, org.apache.spark.streaming.Duration)">StreamingContext(SparkConf, Duration)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext by providing the configuration necessary for a new SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String, java.lang.String, org.apache.spark.streaming.Duration, java.lang.String, scala.collection.Seq, scala.collection.Map)">StreamingContext(String, String, Duration, String, Seq&lt;String&gt;, Map&lt;String, String&gt;)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a StreamingContext by providing the details necessary for creating a new SparkContext.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String, org.apache.hadoop.conf.Configuration)">StreamingContext(String, Configuration)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Recreate a StreamingContext from a checkpoint file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#StreamingContext(java.lang.String)">StreamingContext(String)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Recreate a StreamingContext from a checkpoint file.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#StreamingContextState()">StreamingContextState()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Accessor for nested Scala object</div>
</dd>
<dt><a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression"><span class="strong">StreamingLinearAlgorithm</span></a>&lt;<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="type parameter in StreamingLinearAlgorithm">M</a> extends <a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a>,<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="type parameter in StreamingLinearAlgorithm">A</a> extends <a href="./org/apache/spark/mllib/regression/GeneralizedLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearAlgorithm</a>&lt;<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="type parameter in StreamingLinearAlgorithm">M</a>&gt;&gt; - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 StreamingLinearAlgorithm implements methods for continuously
 training a generalized linear model model on streaming data,
 and using it for prediction on (possibly different) streaming data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#StreamingLinearAlgorithm()">StreamingLinearAlgorithm()</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression"><span class="strong">StreamingLinearRegressionWithSGD</span></a> - Class in <a href="./org/apache/spark/mllib/regression/package-summary.html">org.apache.spark.mllib.regression</a></dt>
<dd>
<div class="block">Train or predict a linear regression model on streaming data.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#StreamingLinearRegressionWithSGD(double, int, double, org.apache.spark.mllib.linalg.Vector)">StreamingLinearRegressionWithSGD(double, int, double, Vector)</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html#StreamingLinearRegressionWithSGD()">StreamingLinearRegressionWithSGD()</a></span> - Constructor for class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">StreamingLinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Construct a StreamingLinearRegression object with default parameters:
 {stepSize: 0.1, numIterations: 50, miniBatchFraction: 1.0}.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListener.html" title="interface in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListener</span></a> - Interface in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 A listener interface for receiving information about an ongoing streaming
 computation.</div>
</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerBatchCompleted</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html#StreamingListenerBatchCompleted(org.apache.spark.streaming.scheduler.BatchInfo)">StreamingListenerBatchCompleted(BatchInfo)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchCompleted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchCompleted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerBatchStarted</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html#StreamingListenerBatchStarted(org.apache.spark.streaming.scheduler.BatchInfo)">StreamingListenerBatchStarted(BatchInfo)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchStarted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerBatchSubmitted</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html#StreamingListenerBatchSubmitted(org.apache.spark.streaming.scheduler.BatchInfo)">StreamingListenerBatchSubmitted(BatchInfo)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerBatchSubmitted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerBatchSubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerEvent.html" title="interface in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerEvent</span></a> - Interface in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Base trait for events related to StreamingListener</div>
</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerReceiverError</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html#StreamingListenerReceiverError(org.apache.spark.streaming.scheduler.ReceiverInfo)">StreamingListenerReceiverError(ReceiverInfo)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverError.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverError</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerReceiverStarted</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html#StreamingListenerReceiverStarted(org.apache.spark.streaming.scheduler.ReceiverInfo)">StreamingListenerReceiverStarted(ReceiverInfo)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStarted.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStarted</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html" title="class in org.apache.spark.streaming.scheduler"><span class="strong">StreamingListenerReceiverStopped</span></a> - Class in <a href="./org/apache/spark/streaming/scheduler/package-summary.html">org.apache.spark.streaming.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html#StreamingListenerReceiverStopped(org.apache.spark.streaming.scheduler.ReceiverInfo)">StreamingListenerReceiverStopped(ReceiverInfo)</a></span> - Constructor for class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/StreamingListenerReceiverStopped.html" title="class in org.apache.spark.streaming.scheduler">StreamingListenerReceiverStopped</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/HashJoin.html#streamSideKeyGenerator()">streamSideKeyGenerator()</a></span> - Method in interface org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/HashJoin.html" title="interface in org.apache.spark.sql.execution">HashJoin</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#stringToText(java.lang.String)">stringToText(String)</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#StringType">StringType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the StringType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/StringType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">StringType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing String values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#stringWritableConverter()">stringWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/StructField.html" title="class in org.apache.spark.sql.api.java"><span class="strong">StructField</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A StructField object represents a field in a StructType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/StructType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">StructType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing Rows.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/StageInfo.html#submissionTime()">submissionTime()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/StageInfo.html" title="class in org.apache.spark.scheduler">StageInfo</a></dt>
<dd>
<div class="block">When this stage was submitted from the DAGScheduler to a TaskScheduler.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#submissionTime()">submissionTime()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#submitJob(org.apache.spark.rdd.RDD, scala.Function1, scala.collection.Seq, scala.Function2, scala.Function0)">submitJob(RDD&lt;T&gt;, Function1&lt;Iterator&lt;T&gt;, U&gt;, Seq&lt;Object&gt;, Function2&lt;Object, U, BoxedUnit&gt;, Function0&lt;R&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">:: Experimental ::
 Submit a job for execution and return a FutureJob holding the result.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#subtract(org.apache.spark.api.java.JavaDoubleRDD)">subtract(JavaDoubleRDD)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#subtract(org.apache.spark.api.java.JavaDoubleRDD, int)">subtract(JavaDoubleRDD, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#subtract(org.apache.spark.api.java.JavaDoubleRDD, org.apache.spark.Partitioner)">subtract(JavaDoubleRDD, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#subtract(org.apache.spark.api.java.JavaPairRDD)">subtract(JavaPairRDD&lt;K, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#subtract(org.apache.spark.api.java.JavaPairRDD, int)">subtract(JavaPairRDD&lt;K, V&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#subtract(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">subtract(JavaPairRDD&lt;K, V&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#subtract(org.apache.spark.api.java.JavaRDD)">subtract(JavaRDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#subtract(org.apache.spark.api.java.JavaRDD, int)">subtract(JavaRDD&lt;T&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#subtract(org.apache.spark.api.java.JavaRDD, org.apache.spark.Partitioner)">subtract(JavaRDD&lt;T&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD)">subtract(RDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, int)">subtract(RDD&lt;T&gt;, int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">subtract(RDD&lt;T&gt;, Partitioner, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#subtract(org.apache.spark.sql.api.java.JavaSchemaRDD)">subtract(JavaSchemaRDD)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#subtract(org.apache.spark.sql.api.java.JavaSchemaRDD, int)">subtract(JavaSchemaRDD, int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#subtract(org.apache.spark.sql.api.java.JavaSchemaRDD, org.apache.spark.Partitioner)">subtract(JavaSchemaRDD, Partitioner)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Return an RDD with the elements from <code>this</code> that are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD)">subtract(RDD&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD, int)">subtract(RDD&lt;Row&gt;, int)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#subtract(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.math.Ordering)">subtract(RDD&lt;Row&gt;, Partitioner, Ordering&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#subtract(org.apache.spark.util.Vector)">subtract(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#subtractByKey(org.apache.spark.api.java.JavaPairRDD)">subtractByKey(JavaPairRDD&lt;K, W&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the pairs from <code>this</code> whose keys are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#subtractByKey(org.apache.spark.api.java.JavaPairRDD, int)">subtractByKey(JavaPairRDD&lt;K, W&gt;, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#subtractByKey(org.apache.spark.api.java.JavaPairRDD, org.apache.spark.Partitioner)">subtractByKey(JavaPairRDD&lt;K, W&gt;, Partitioner)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">subtractByKey(RDD&lt;Tuple2&lt;K, W&gt;&gt;, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD with the pairs from <code>this</code> whose keys are not in <code>other</code>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, int, scala.reflect.ClassTag)">subtractByKey(RDD&lt;Tuple2&lt;K, W&gt;&gt;, int, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#subtractByKey(org.apache.spark.rdd.RDD, org.apache.spark.Partitioner, scala.reflect.ClassTag)">subtractByKey(RDD&lt;Tuple2&lt;K, W&gt;&gt;, Partitioner, ClassTag&lt;W&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD with the pairs from `this` whose keys are not in `other`.</div>
</dd>
<dt><a href="./org/apache/spark/Success.html" title="class in org.apache.spark"><span class="strong">Success</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Task succeeded.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/Success.html#Success()">Success()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/Success.html" title="class in org.apache.spark">Success</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#successful()">successful()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sum()">sum()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Add up the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#sum()">sum()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Add up the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#sum()">sum()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#sum()">sum()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sumApprox(long, java.lang.Double)">sumApprox(long, Double)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate operation to return the sum within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#sumApprox(long)">sumApprox(long)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate operation to return the sum within a timeout.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#sumApprox(long, double)">sumApprox(long, double)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">:: Experimental ::
 Approximate operation to return the sum within a timeout.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/util/SVMDataGenerator.html" title="class in org.apache.spark.mllib.util"><span class="strong">SVMDataGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/util/package-summary.html">org.apache.spark.mllib.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generate sample data used for SVM.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/util/SVMDataGenerator.html#SVMDataGenerator()">SVMDataGenerator()</a></span> - Constructor for class org.apache.spark.mllib.util.<a href="./org/apache/spark/mllib/util/SVMDataGenerator.html" title="class in org.apache.spark.mllib.util">SVMDataGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification"><span class="strong">SVMModel</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Model for Support Vector Machines (SVMs).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMModel.html#SVMModel(org.apache.spark.mllib.linalg.Vector, double)">SVMModel(Vector, double)</a></span> - Constructor for class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification"><span class="strong">SVMWithSGD</span></a> - Class in <a href="./org/apache/spark/mllib/classification/package-summary.html">org.apache.spark.mllib.classification</a></dt>
<dd>
<div class="block">Train a Support Vector Machine (SVM) using Stochastic Gradient Descent.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html#SVMWithSGD()">SVMWithSGD()</a></span> - Constructor for class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</a></dt>
<dd>
<div class="block">Construct a SVM object with default parameters</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/env/EnvironmentListener.html#systemProperties()">systemProperties()</a></span> - Method in class org.apache.spark.ui.env.<a href="./org/apache/spark/ui/env/EnvironmentListener.html" title="class in org.apache.spark.ui.env">EnvironmentListener</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_T_">
<!--   -->
</a>
<h2 class="title">T</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/SerializableWritable.html#t()">t()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html#table()">table()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DescribeHiveTableCommand.html" title="class in org.apache.spark.sql.hive.execution">DescribeHiveTableCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html#table()">table()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="class in org.apache.spark.sql.hive.execution">InsertIntoHiveTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#table(java.lang.String)">table(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Returns the specified table as a SchemaRDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/CacheCommand.html#tableName()">tableName()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/CacheCommand.html" title="class in org.apache.spark.sql.execution">CacheCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html#tableName()">tableName()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/AnalyzeTable.html" title="class in org.apache.spark.sql.hive.execution">AnalyzeTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/execution/DropTable.html#tableName()">tableName()</a></span> - Method in class org.apache.spark.sql.hive.execution.<a href="./org/apache/spark/sql/hive/execution/DropTable.html" title="class in org.apache.spark.sql.hive.execution">DropTable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#tachyonFolderName()">tachyonFolderName()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockStatus.html#tachyonSize()">tachyonSize()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockStatus.html" title="class in org.apache.spark.storage">BlockStatus</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#tachyonSize()">tachyonSize()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#take(int)">take(int)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Take the first num elements of the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#take(int)">take(int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Take the first num elements of the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#take(int)">take(int)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#take(int)">take(int)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/AsyncRDDActions.html#takeAsync(int)">takeAsync(int)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/AsyncRDDActions.html" title="class in org.apache.spark.rdd">AsyncRDDActions</a></dt>
<dd>
<div class="block">Returns a future for retrieving the first num elements of the RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#takeOrdered(int, java.util.Comparator)">takeOrdered(int, Comparator&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Returns the first K elements from this RDD as defined by
 the specified Comparator[T] and maintains the order.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#takeOrdered(int)">takeOrdered(int)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Returns the first K elements from this RDD using the
 natural ordering for T while maintain the order.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#takeOrdered(int, scala.math.Ordering)">takeOrdered(int, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Returns the first K (smallest) elements from this RDD as defined by the specified
 implicit Ordering[T] and maintains the ordering.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution"><span class="strong">TakeOrdered</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Take the first limit elements as defined by the sortOrder.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/TakeOrdered.html#TakeOrdered(int, scala.collection.Seq, org.apache.spark.sql.execution.SparkPlan)">TakeOrdered(int, Seq&lt;SortOrder&gt;, SparkPlan)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/TakeOrdered.html" title="class in org.apache.spark.sql.execution">TakeOrdered</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#takeSample(boolean, int)">takeSample(boolean, int)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#takeSample(boolean, int, long)">takeSample(boolean, int, long)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#takeSample(boolean, int, long)">takeSample(boolean, int, long)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return a fixed-size sampled subset of this RDD in an array</div>
</dd>
<dt><a href="./org/apache/spark/util/TaskCompletionListener.html" title="interface in org.apache.spark.util"><span class="strong">TaskCompletionListener</span></a> - Interface in <a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark"><span class="strong">TaskContext</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Contextual information about a task which can be read or mutated during execution.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#TaskContext(int, int, long, boolean, org.apache.spark.executor.TaskMetrics)">TaskContext(int, int, long, boolean, TaskMetrics)</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/TaskEndReason.html" title="interface in org.apache.spark"><span class="strong">TaskEndReason</span></a> - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Various possible reasons why a task ended.</div>
</dd>
<dt><a href="./org/apache/spark/TaskFailedReason.html" title="interface in org.apache.spark"><span class="strong">TaskFailedReason</span></a> - Interface in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Various possible reasons why a task failed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#taskId()">taskId()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/TaskResultBlockId.html#taskId()">taskId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage">TaskResultBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#taskInfo()">taskInfo()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html#taskInfo()">taskInfo()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskGettingResult.html" title="class in org.apache.spark.scheduler">SparkListenerTaskGettingResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html#taskInfo()">taskInfo()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskStart.html" title="class in org.apache.spark.scheduler">SparkListenerTaskStart</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler"><span class="strong">TaskInfo</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Information about a running task attempt inside a TaskSet.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#TaskInfo(long, int, int, long, java.lang.String, java.lang.String, scala.Enumeration.Value, boolean)">TaskInfo(long, int, int, long, String, String, Enumeration.Value, boolean)</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/TaskKilled.html" title="class in org.apache.spark"><span class="strong">TaskKilled</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Task was killed intentionally and needs to be rescheduled.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskKilled.html#TaskKilled()">TaskKilled()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/TaskKilled.html" title="class in org.apache.spark">TaskKilled</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/TaskKilledException.html" title="class in org.apache.spark"><span class="strong">TaskKilledException</span></a> - Exception in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Exception thrown when a task is explicitly killed (i.e., task failure is expected).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskKilledException.html#TaskKilledException()">TaskKilledException()</a></span> - Constructor for exception org.apache.spark.<a href="./org/apache/spark/TaskKilledException.html" title="class in org.apache.spark">TaskKilledException</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskInfo.html#taskLocality()">taskLocality()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskInfo.html" title="class in org.apache.spark.scheduler">TaskInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler"><span class="strong">TaskLocality</span></a> - Class in <a href="./org/apache/spark/scheduler/package-summary.html">org.apache.spark.scheduler</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/TaskLocality.html#TaskLocality()">TaskLocality()</a></span> - Constructor for class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/TaskLocality.html" title="class in org.apache.spark.scheduler">TaskLocality</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html#taskMetrics()">taskMetrics()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerExecutorMetricsUpdate.html" title="class in org.apache.spark.scheduler">SparkListenerExecutorMetricsUpdate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#taskMetrics()">taskMetrics()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskContext.html#taskMetrics()">taskMetrics()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/TaskContext.html" title="class in org.apache.spark">TaskContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#TASKRESULT()">TASKRESULT()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage"><span class="strong">TaskResultBlockId</span></a> - Class in <a href="./org/apache/spark/storage/package-summary.html">org.apache.spark.storage</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/TaskResultBlockId.html#TaskResultBlockId(long)">TaskResultBlockId(long)</a></span> - Constructor for class org.apache.spark.storage.<a href="./org/apache/spark/storage/TaskResultBlockId.html" title="class in org.apache.spark.storage">TaskResultBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/TaskResultLost.html" title="class in org.apache.spark"><span class="strong">TaskResultLost</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 The task finished successfully, but the result was lost from the executor's block manager before
 it was fetched.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskResultLost.html#TaskResultLost()">TaskResultLost()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/TaskResultLost.html" title="class in org.apache.spark">TaskResultLost</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#taskScheduler()">taskScheduler()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html#taskType()">taskType()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerTaskEnd.html" title="class in org.apache.spark.scheduler">SparkListenerTaskEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#TEST()">TEST()</a></span> - Static method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/test/TestHive.html" title="class in org.apache.spark.sql.hive.test"><span class="strong">TestHive</span></a> - Class in <a href="./org/apache/spark/sql/hive/test/package-summary.html">org.apache.spark.sql.hive.test</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHive.html#TestHive()">TestHive()</a></span> - Constructor for class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHive.html" title="class in org.apache.spark.sql.hive.test">TestHive</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test"><span class="strong">TestHiveContext</span></a> - Class in <a href="./org/apache/spark/sql/hive/test/package-summary.html">org.apache.spark.sql.hive.test</a></dt>
<dd>
<div class="block">A locally running test instance of Spark's Hive execution engine.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#TestHiveContext(org.apache.spark.SparkContext)">TestHiveContext(SparkContext)</a></span> - Constructor for class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/test/TestHiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive.test"><span class="strong">TestHiveContext.QueryExecution</span></a> - Class in <a href="./org/apache/spark/sql/hive/test/package-summary.html">org.apache.spark.sql.hive.test</a></dt>
<dd>
<div class="block">Override QueryExecution with special debug workflow.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.QueryExecution.html#TestHiveContext.QueryExecution()">TestHiveContext.QueryExecution()</a></span> - Constructor for class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.QueryExecution.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext.QueryExecution</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html" title="class in org.apache.spark.sql.hive.test"><span class="strong">TestHiveContext.TestTable</span></a> - Class in <a href="./org/apache/spark/sql/hive/test/package-summary.html">org.apache.spark.sql.hive.test</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html#TestHiveContext.TestTable(java.lang.String, scala.collection.Seq)">TestHiveContext.TestTable(String, Seq&lt;Function0&lt;BoxedUnit&gt;&gt;)</a></span> - Constructor for class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.TestTable.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext.TestTable</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test"><span class="strong">TestResult</span></a>&lt;<a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="type parameter in TestResult">DF</a>&gt; - Interface in <a href="./org/apache/spark/mllib/stat/test/package-summary.html">org.apache.spark.mllib.stat.test</a></dt>
<dd>
<div class="block">:: Experimental ::
 Trait for hypothesis test results.</div>
</dd>
<dt><a href="./org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test"><span class="strong">TestSQLContext</span></a> - Class in <a href="./org/apache/spark/sql/test/package-summary.html">org.apache.spark.sql.test</a></dt>
<dd>
<div class="block">A SQLContext that can be used for local testing.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/test/TestSQLContext.html#TestSQLContext()">TestSQLContext()</a></span> - Constructor for class org.apache.spark.sql.test.<a href="./org/apache/spark/sql/test/TestSQLContext.html" title="class in org.apache.spark.sql.test">TestSQLContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#testTables()">testTables()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>
<div class="block">A list of test tables and the DDL required to initialize them.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#testTempDir()">testTempDir()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#textFile(java.lang.String)">textFile(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Read a text file from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI, and return it as an RDD of Strings.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#textFile(java.lang.String, int)">textFile(String, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Read a text file from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI, and return it as an RDD of Strings.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#textFile(java.lang.String, int)">textFile(String, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Read a text file from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI, and return it as an RDD of Strings.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#textFileStream(java.lang.String)">textFileStream(String)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create an input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as text files (using key as LongWritable, value
 as Text and input format as TextInputFormat).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#textFileStream(java.lang.String)">textFileStream(String)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a input stream that monitors a Hadoop-compatible filesystem
 for new files and reads them as text files (using key as LongWritable, value
 as Text and input format as TextInputFormat).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html#theta()">theta()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayesModel.html" title="class in org.apache.spark.mllib.classification">NaiveBayesModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Split.html#threshold()">threshold()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#thresholds()">thresholds()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Returns thresholds in descending order.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html#time()">time()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerApplicationEnd.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationEnd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html#time()">time()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SparkListenerApplicationStart.html" title="class in org.apache.spark.scheduler">SparkListenerApplicationStart</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming"><span class="strong">Time</span></a> - Class in <a href="./org/apache/spark/streaming/package-summary.html">org.apache.spark.streaming</a></dt>
<dd>
<div class="block">This is a simple class that represents an absolute instant of time.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#Time(long)">Time(long)</a></span> - Constructor for class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/DataType.html#TimestampType">TimestampType</a></span> - Static variable in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/DataType.html" title="class in org.apache.spark.sql.api.java">DataType</a></dt>
<dd>
<div class="block">Gets the TimestampType object.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/TimestampType.html" title="class in org.apache.spark.sql.api.java"><span class="strong">TimestampType</span></a> - Class in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">The data type representing java.sql.Timestamp values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#to(org.apache.spark.streaming.Time, org.apache.spark.streaming.Duration)">to(Time, Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#toArray()">toArray()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block"><span class="strong">Deprecated.</span>
<div class="block"><i>As of Spark 1.0.0, toArray() is deprecated, use <a href="./org/apache/spark/api/java/JavaRDDLike.html#collect()"><code>JavaRDDLike.collect()</code></a> instead</i></div>
</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseMatrix.html#toArray()">toArray()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#toArray()">toArray()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrix.html#toArray()">toArray()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</a></dt>
<dd>
<div class="block">Converts to a dense array in column major.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#toArray()">toArray()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#toArray()">toArray()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>
<div class="block">Converts the instance to a double array.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#toArray()">toArray()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an array that contains all of the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html#toBreeze()">toBreeze()</a></span> - Method in interface org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/DistributedMatrix.html" title="interface in org.apache.spark.mllib.linalg.distributed">DistributedMatrix</a></dt>
<dd>
<div class="block">Collects data and assembles a local dense breeze matrix (for test only).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrix.html#toBreeze()">toBreeze()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</a></dt>
<dd>
<div class="block">Converts to a breeze matrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vector.html#toBreeze()">toBreeze()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg">Vector</a></dt>
<dd>
<div class="block">Converts the instance to a breeze vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html#toDataType(java.lang.String)">toDataType(String)</a></span> - Static method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html" title="class in org.apache.spark.sql.hive">HiveMetastoreTypes</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#toDebugString()">toDebugString()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">A description of this RDD and its recursive dependencies for debugging.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#toDebugString()">toDebugString()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">A description of this RDD and its recursive dependencies for debugging.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkConf.html#toDebugString()">toDebugString()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkConf.html" title="class in org.apache.spark">SparkConf</a></dt>
<dd>
<div class="block">Return a string listing all keys and values, one per line.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExceptionFailure.html#toErrorString()">toErrorString()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ExceptionFailure.html" title="class in org.apache.spark">ExceptionFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ExecutorLostFailure.html#toErrorString()">toErrorString()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/ExecutorLostFailure.html" title="class in org.apache.spark">ExecutorLostFailure</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FetchFailed.html#toErrorString()">toErrorString()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/FetchFailed.html" title="class in org.apache.spark">FetchFailed</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Resubmitted.html#toErrorString()">toErrorString()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/Resubmitted.html" title="class in org.apache.spark">Resubmitted</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskFailedReason.html#toErrorString()">toErrorString()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/TaskFailedReason.html" title="interface in org.apache.spark">TaskFailedReason</a></dt>
<dd>
<div class="block">Error message displayed in the web UI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskKilled.html#toErrorString()">toErrorString()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/TaskKilled.html" title="class in org.apache.spark">TaskKilled</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/TaskResultLost.html#toErrorString()">toErrorString()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/TaskResultLost.html" title="class in org.apache.spark">TaskResultLost</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/UnknownReason.html#toErrorString()">toErrorString()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/UnknownReason.html" title="class in org.apache.spark">UnknownReason</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#toFormattedString()">toFormattedString()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#toIndexedRowMatrix()">toIndexedRowMatrix()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>
<div class="block">Converts to IndexedRowMatrix.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#toInt()">toInt()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#toJavaDStream()">toJavaDStream()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Convert to a JavaDStream</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#toJavaRDD()">toJavaRDD()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#toJavaSchemaRDD()">toJavaSchemaRDD()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Returns this RDD as a JavaSchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#toLocalIterator()">toLocalIterator()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Return an iterator that contains all of the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#toLocalIterator()">toLocalIterator()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return an iterator that contains all of the elements in this RDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html#toMetastoreType(org.apache.spark.sql.catalyst.types.DataType)">toMetastoreType(DataType)</a></span> - Static method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/HiveMetastoreTypes.html" title="class in org.apache.spark.sql.hive">HiveMetastoreTypes</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#top(int, java.util.Comparator)">top(int, Comparator&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Returns the top K elements from this RDD as defined by
 the specified Comparator[T].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#top(int)">top(int)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Returns the top K elements from this RDD using the
 natural ordering for T.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#top(int, scala.math.Ordering)">top(int, Ordering&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#toPairDStreamFunctions(org.apache.spark.streaming.dstream.DStream, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.math.Ordering)">toPairDStreamFunctions(DStream&lt;Tuple2&lt;K, V&gt;&gt;, ClassTag&lt;K&gt;, ClassTag&lt;V&gt;, Ordering&lt;K&gt;)</a></span> - Static method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#topNode()">topNode()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#toRDD(org.apache.spark.api.java.JavaDoubleRDD)">toRDD(JavaDoubleRDD)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#toRDD(org.apache.spark.api.java.JavaPairRDD)">toRDD(JavaPairRDD&lt;K, V&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#toRDD(org.apache.spark.api.java.JavaRDD)">toRDD(JavaRDD&lt;T&gt;)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html#toRowMatrix()">toRowMatrix()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/CoordinateMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">CoordinateMatrix</a></dt>
<dd>
<div class="block">Converts to RowMatrix, dropping row indices after grouping by row index.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html#toRowMatrix()">toRowMatrix()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRowMatrix</a></dt>
<dd>
<div class="block">Drops row indices and converts this matrix to a
 <a href="./org/apache/spark/mllib/linalg/distributed/RowMatrix.html" title="class in org.apache.spark.mllib.linalg.distributed"><code>RowMatrix</code></a>.</div>
</dd>
<dt><a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast"><span class="strong">TorrentBroadcastFactory</span></a> - Class in <a href="./org/apache/spark/broadcast/package-summary.html">org.apache.spark.broadcast</a></dt>
<dd>
<div class="block">A <a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast"><code>Broadcast</code></a> implementation that uses a BitTorrent-like
 protocol to do a distributed transfer of the broadcasted data to the executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#TorrentBroadcastFactory()">TorrentBroadcastFactory()</a></span> - Constructor for class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#toSchemaRDD()">toSchemaRDD()</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Returns this RDD as a SchemaRDD.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#toSparkContext(org.apache.spark.api.java.JavaSparkContext)">toSparkContext(JavaSparkContext)</a></span> - Static method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#toSplitInfo(java.lang.Class, java.lang.String, org.apache.hadoop.mapred.InputSplit)">toSplitInfo(Class&lt;?&gt;, String, InputSplit)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#toSplitInfo(java.lang.Class, java.lang.String, org.apache.hadoop.mapreduce.InputSplit)">toSplitInfo(Class&lt;?&gt;, String, InputSplit)</a></span> - Static method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#toString()">toString()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#toString()">toString()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/Broadcast.html#toString()">toString()</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Matrix.html#toString()">toString()</a></span> - Method in interface org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Matrix.html" title="interface in org.apache.spark.mllib.linalg">Matrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LabeledPoint.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LabeledPoint.html" title="class in org.apache.spark.mllib.regression">LabeledPoint</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/ChiSqTestResult.html" title="class in org.apache.spark.mllib.stat.test">ChiSqTestResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/test/TestResult.html#toString()">toString()</a></span> - Method in interface org.apache.spark.mllib.stat.test.<a href="./org/apache/spark/mllib/stat/test/TestResult.html" title="interface in org.apache.spark.mllib.stat.test">TestResult</a></dt>
<dd>
<div class="block">String explaining the hypothesis test result.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/DecisionTreeModel.html" title="class in org.apache.spark.mllib.tree.model">DecisionTreeModel</a></dt>
<dd>
<div class="block">Print full model.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/InformationGainStats.html" title="class in org.apache.spark.mllib.tree.model">InformationGainStats</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Node.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Node.html" title="class in org.apache.spark.mllib.tree.model">Node</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/model/Split.html#toString()">toString()</a></span> - Method in class org.apache.spark.mllib.tree.model.<a href="./org/apache/spark/mllib/tree/model/Split.html" title="class in org.apache.spark.mllib.tree.model">Split</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/BoundedDouble.html#toString()">toString()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/BoundedDouble.html" title="class in org.apache.spark.partial">BoundedDouble</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/partial/PartialResult.html#toString()">toString()</a></span> - Method in class org.apache.spark.partial.<a href="./org/apache/spark/partial/PartialResult.html" title="class in org.apache.spark.partial">PartialResult</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#toString()">toString()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/InputFormatInfo.html#toString()">toString()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/InputFormatInfo.html" title="class in org.apache.spark.scheduler">InputFormatInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#toString()">toString()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SerializableWritable.html#toString()">toString()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#toString()">toString()</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockId.html#toString()">toString()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockId.html" title="class in org.apache.spark.storage">BlockId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#toString()">toString()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/RDDInfo.html#toString()">toString()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/RDDInfo.html" title="class in org.apache.spark.storage">RDDInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#toString()">toString()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Duration.html#toString()">toString()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#toString()">toString()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#toString()">toString()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#toString()">toString()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#toString()">toString()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/scheduler/BatchInfo.html#totalDelay()">totalDelay()</a></span> - Method in class org.apache.spark.streaming.scheduler.<a href="./org/apache/spark/streaming/scheduler/BatchInfo.html" title="class in org.apache.spark.streaming.scheduler">BatchInfo</a></dt>
<dd>
<div class="block">Time taken for all the jobs of this batch to finish processing from the time they
 were submitted.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, org.apache.spark.mllib.linalg.Vector)">train(RDD&lt;LabeledPoint&gt;, int, double, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a logistic regression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a logistic regression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double)">train(RDD&lt;LabeledPoint&gt;, int, double)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a logistic regression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int)">train(RDD&lt;LabeledPoint&gt;, int)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionWithSGD.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a logistic regression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayes.html#train(org.apache.spark.rdd.RDD)">train(RDD&lt;LabeledPoint&gt;)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</a></dt>
<dd>
<div class="block">Trains a Naive Bayes model given an RDD of <code>(label, features)</code> pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/NaiveBayes.html#train(org.apache.spark.rdd.RDD, double)">train(RDD&lt;LabeledPoint&gt;, double)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/NaiveBayes.html" title="class in org.apache.spark.mllib.classification">NaiveBayes</a></dt>
<dd>
<div class="block">Trains a Naive Bayes model given an RDD of <code>(label, features)</code> pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double, org.apache.spark.mllib.linalg.Vector)">train(RDD&lt;LabeledPoint&gt;, int, double, double, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</a></dt>
<dd>
<div class="block">Train a SVM model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double, double)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</a></dt>
<dd>
<div class="block">Train a SVM model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</a></dt>
<dd>
<div class="block">Train a SVM model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMWithSGD.html#train(org.apache.spark.rdd.RDD, int)">train(RDD&lt;LabeledPoint&gt;, int)</a></span> - Static method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMWithSGD.html" title="class in org.apache.spark.mllib.classification">SVMWithSGD</a></dt>
<dd>
<div class="block">Train a SVM model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int, int, java.lang.String)">train(RDD&lt;Vector&gt;, int, int, int, String)</a></span> - Static method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Trains a k-means model using the given set of parameters.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int)">train(RDD&lt;Vector&gt;, int, int)</a></span> - Static method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Trains a k-means model using specified parameters and the default values for unspecified.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/clustering/KMeans.html#train(org.apache.spark.rdd.RDD, int, int, int)">train(RDD&lt;Vector&gt;, int, int, int)</a></span> - Static method in class org.apache.spark.mllib.clustering.<a href="./org/apache/spark/mllib/clustering/KMeans.html" title="class in org.apache.spark.mllib.clustering">KMeans</a></dt>
<dd>
<div class="block">Trains a k-means model using specified parameters and the default values for unspecified.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, double, int, long)">train(RDD&lt;Rating&gt;, int, int, double, int, long)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of ratings given by users to some products,
 in the form of (userID, productID, rating) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, double, int)">train(RDD&lt;Rating&gt;, int, int, double, int)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of ratings given by users to some products,
 in the form of (userID, productID, rating) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int, double)">train(RDD&lt;Rating&gt;, int, int, double)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of ratings given by users to some products,
 in the form of (userID, productID, rating) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#train(org.apache.spark.rdd.RDD, int, int)">train(RDD&lt;Rating&gt;, int, int)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of ratings given by users to some products,
 in the form of (userID, productID, rating) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double, org.apache.spark.mllib.linalg.Vector)">train(RDD&lt;LabeledPoint&gt;, int, double, double, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</a></dt>
<dd>
<div class="block">Train a Lasso model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double, double)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</a></dt>
<dd>
<div class="block">Train a Lasso model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</a></dt>
<dd>
<div class="block">Train a Lasso model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoWithSGD.html#train(org.apache.spark.rdd.RDD, int)">train(RDD&lt;LabeledPoint&gt;, int)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoWithSGD.html" title="class in org.apache.spark.mllib.regression">LassoWithSGD</a></dt>
<dd>
<div class="block">Train a Lasso model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, org.apache.spark.mllib.linalg.Vector)">train(RDD&lt;LabeledPoint&gt;, int, double, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a Linear Regression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a LinearRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double)">train(RDD&lt;LabeledPoint&gt;, int, double)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a LinearRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int)">train(RDD&lt;LabeledPoint&gt;, int)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">LinearRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a LinearRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double, org.apache.spark.mllib.linalg.Vector)">train(RDD&lt;LabeledPoint&gt;, int, double, double, double, Vector)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a RidgeRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double, double)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a RidgeRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int, double, double)">train(RDD&lt;LabeledPoint&gt;, int, double, double)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a RidgeRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html#train(org.apache.spark.rdd.RDD, int)">train(RDD&lt;LabeledPoint&gt;, int)</a></span> - Static method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionWithSGD.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionWithSGD</a></dt>
<dd>
<div class="block">Train a RidgeRegression model given an RDD of (label, features) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/DecisionTree.html#train(org.apache.spark.rdd.RDD)">train(RDD&lt;LabeledPoint&gt;)</a></span> - Method in class org.apache.spark.mllib.tree.<a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</a></dt>
<dd>
<div class="block">Method to train a decision tree model over an RDD</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/DecisionTree.html#trainClassifier(org.apache.spark.rdd.RDD, int, scala.collection.immutable.Map, java.lang.String, int, int)">trainClassifier(RDD&lt;LabeledPoint&gt;, int, Map&lt;Object, Object&gt;, String, int, int)</a></span> - Static method in class org.apache.spark.mllib.tree.<a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</a></dt>
<dd>
<div class="block">Method to train a decision tree model for binary or multiclass classification.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/DecisionTree.html#trainClassifier(org.apache.spark.api.java.JavaRDD, int, java.util.Map, java.lang.String, int, int)">trainClassifier(JavaRDD&lt;LabeledPoint&gt;, int, Map&lt;Integer, Integer&gt;, String, int, int)</a></span> - Static method in class org.apache.spark.mllib.tree.<a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</a></dt>
<dd>
<div class="block">Java-friendly API for <code>DecisionTree$.trainClassifier(org.apache.spark.rdd.RDD&lt;org.apache.spark.mllib.regression.LabeledPoint&gt;, int, scala.collection.immutable.Map&lt;java.lang.Object, java.lang.Object&gt;, java.lang.String, int, int)</code></div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int, double, int, double, long)">trainImplicit(RDD&lt;Rating&gt;, int, int, double, int, double, long)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of 'implicit preferences' given by users
 to some products, in the form of (userID, productID, preference) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int, double, int, double)">trainImplicit(RDD&lt;Rating&gt;, int, int, double, int, double)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of 'implicit preferences' given by users
 to some products, in the form of (userID, productID, preference) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int, double, double)">trainImplicit(RDD&lt;Rating&gt;, int, int, double, double)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of 'implicit preferences' given by users to
 some products, in the form of (userID, productID, preference) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/ALS.html#trainImplicit(org.apache.spark.rdd.RDD, int, int)">trainImplicit(RDD&lt;Rating&gt;, int, int)</a></span> - Static method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/ALS.html" title="class in org.apache.spark.mllib.recommendation">ALS</a></dt>
<dd>
<div class="block">Train a matrix factorization model given an RDD of 'implicit preferences' ratings given by
 users to some products, in the form of (userID, productID, rating) pairs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html#trainOn(org.apache.spark.streaming.dstream.DStream)">trainOn(DStream&lt;LabeledPoint&gt;)</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/StreamingLinearAlgorithm.html" title="class in org.apache.spark.mllib.regression">StreamingLinearAlgorithm</a></dt>
<dd>
<div class="block">Update the model by training on batches of data from a DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/DecisionTree.html#trainRegressor(org.apache.spark.rdd.RDD, scala.collection.immutable.Map, java.lang.String, int, int)">trainRegressor(RDD&lt;LabeledPoint&gt;, Map&lt;Object, Object&gt;, String, int, int)</a></span> - Static method in class org.apache.spark.mllib.tree.<a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</a></dt>
<dd>
<div class="block">Method to train a decision tree model for regression.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/DecisionTree.html#trainRegressor(org.apache.spark.api.java.JavaRDD, java.util.Map, java.lang.String, int, int)">trainRegressor(JavaRDD&lt;LabeledPoint&gt;, Map&lt;Integer, Integer&gt;, String, int, int)</a></span> - Static method in class org.apache.spark.mllib.tree.<a href="./org/apache/spark/mllib/tree/DecisionTree.html" title="class in org.apache.spark.mllib.tree">DecisionTree</a></dt>
<dd>
<div class="block">Java-friendly API for <code>DecisionTree$.trainRegressor(org.apache.spark.rdd.RDD&lt;org.apache.spark.mllib.regression.LabeledPoint&gt;, scala.collection.immutable.Map&lt;java.lang.Object, java.lang.Object&gt;, java.lang.String, int, int)</code></div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#transform(scala.collection.Iterable)">transform(Iterable&lt;Object&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>
<div class="block">Transforms the input document into a sparse term frequency vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#transform(java.lang.Iterable)">transform(Iterable&lt;?&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>
<div class="block">Transforms the input document into a sparse term frequency vector (Java version).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#transform(org.apache.spark.rdd.RDD)">transform(RDD&lt;D&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>
<div class="block">Transforms the input document to term frequency vectors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/HashingTF.html#transform(org.apache.spark.api.java.JavaRDD)">transform(JavaRDD&lt;D&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/HashingTF.html" title="class in org.apache.spark.mllib.feature">HashingTF</a></dt>
<dd>
<div class="block">Transforms the input document to term frequency vectors (Java version).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDFModel.html#transform(org.apache.spark.rdd.RDD)">transform(RDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</a></dt>
<dd>
<div class="block">Transforms term frequency (TF) vectors to TF-IDF vectors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/IDFModel.html#transform(org.apache.spark.api.java.JavaRDD)">transform(JavaRDD&lt;Vector&gt;)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/IDFModel.html" title="class in org.apache.spark.mllib.feature">IDFModel</a></dt>
<dd>
<div class="block">Transforms term frequency (TF) vectors to TF-IDF vectors (Java version).</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Normalizer.html#transform(org.apache.spark.mllib.linalg.Vector)">transform(Vector)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Normalizer.html" title="class in org.apache.spark.mllib.feature">Normalizer</a></dt>
<dd>
<div class="block">Applies unit length normalization on a vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScalerModel.html#transform(org.apache.spark.mllib.linalg.Vector)">transform(Vector)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</a></dt>
<dd>
<div class="block">Applies standardization transformation on a vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/VectorTransformer.html#transform(org.apache.spark.mllib.linalg.Vector)">transform(Vector)</a></span> - Method in interface org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature">VectorTransformer</a></dt>
<dd>
<div class="block">Applies transformation on a vector.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/VectorTransformer.html#transform(org.apache.spark.rdd.RDD)">transform(RDD&lt;Vector&gt;)</a></span> - Method in interface org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature">VectorTransformer</a></dt>
<dd>
<div class="block">Applies transformation on an RDD[Vector].</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2VecModel.html#transform(java.lang.String)">transform(String)</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature">Word2VecModel</a></dt>
<dd>
<div class="block">Transforms a word to its vector representation</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transform(org.apache.spark.api.java.function.Function)">transform(Function&lt;R, JavaRDD&lt;U&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transform(org.apache.spark.api.java.function.Function2)">transform(Function2&lt;R, Time, JavaRDD&lt;U&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#transform(java.util.List, org.apache.spark.api.java.function.Function2)">transform(List&lt;JavaDStream&lt;?&gt;&gt;, Function2&lt;List&lt;JavaRDD&lt;?&gt;&gt;, Time, JavaRDD&lt;T&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#transform(scala.Function1, scala.reflect.ClassTag)">transform(Function1&lt;RDD&lt;T&gt;, RDD&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#transform(scala.Function2, scala.reflect.ClassTag)">transform(Function2&lt;RDD&lt;T&gt;, Time, RDD&lt;U&gt;&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#transform(scala.collection.Seq, scala.Function2, scala.reflect.ClassTag)">transform(Seq&lt;DStream&lt;?&gt;&gt;, Function2&lt;Seq&lt;RDD&lt;?&gt;&gt;, Time, RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformToPair(org.apache.spark.api.java.function.Function)">transformToPair(Function&lt;R, JavaPairRDD&lt;K2, V2&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformToPair(org.apache.spark.api.java.function.Function2)">transformToPair(Function2&lt;R, Time, JavaPairRDD&lt;K2, V2&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#transformToPair(java.util.List, org.apache.spark.api.java.function.Function2)">transformToPair(List&lt;JavaDStream&lt;?&gt;&gt;, Function2&lt;List&lt;JavaRDD&lt;?&gt;&gt;, Time, JavaPairRDD&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a new DStream in which each RDD is generated by applying a function on RDDs of
 the DStreams.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWith(org.apache.spark.streaming.api.java.JavaDStream, org.apache.spark.api.java.function.Function3)">transformWith(JavaDStream&lt;U&gt;, Function3&lt;R, JavaRDD&lt;U&gt;, Time, JavaRDD&lt;W&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWith(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.api.java.function.Function3)">transformWith(JavaPairDStream&lt;K2, V2&gt;, Function3&lt;R, JavaPairRDD&lt;K2, V2&gt;, Time, JavaRDD&lt;W&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#transformWith(org.apache.spark.streaming.dstream.DStream, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">transformWith(DStream&lt;U&gt;, Function2&lt;RDD&lt;T&gt;, RDD&lt;U&gt;, RDD&lt;V&gt;&gt;, ClassTag&lt;U&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#transformWith(org.apache.spark.streaming.dstream.DStream, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag)">transformWith(DStream&lt;U&gt;, Function3&lt;RDD&lt;T&gt;, RDD&lt;U&gt;, Time, RDD&lt;V&gt;&gt;, ClassTag&lt;U&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWithToPair(org.apache.spark.streaming.api.java.JavaDStream, org.apache.spark.api.java.function.Function3)">transformWithToPair(JavaDStream&lt;U&gt;, Function3&lt;R, JavaRDD&lt;U&gt;, Time, JavaPairRDD&lt;K2, V2&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#transformWithToPair(org.apache.spark.streaming.api.java.JavaPairDStream, org.apache.spark.api.java.function.Function3)">transformWithToPair(JavaPairDStream&lt;K2, V2&gt;, Function3&lt;R, JavaPairRDD&lt;K2, V2&gt;, Time, JavaPairRDD&lt;K3, V3&gt;&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD is generated by applying a function
 on each RDD of 'this' DStream and 'other' DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#truePositiveRate(double)">truePositiveRate(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns true positive rate for a given label (category)</div>
</dd>
<dt><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter"><span class="strong">TwitterUtils</span></a> - Class in <a href="./org/apache/spark/streaming/twitter/package-summary.html">org.apache.spark.streaming.twitter</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/twitter/TwitterUtils.html#TwitterUtils()">TwitterUtils()</a></span> - Constructor for class org.apache.spark.streaming.twitter.<a href="./org/apache/spark/streaming/twitter/TwitterUtils.html" title="class in org.apache.spark.streaming.twitter">TwitterUtils</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_U_">
<!--   -->
</a>
<h2 class="title">U</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#U()">U()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html#udf()">udf()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/BatchPythonEvaluation.html" title="class in org.apache.spark.sql.execution">BatchPythonEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/EvaluatePython.html#udf()">udf()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/EvaluatePython.html" title="class in org.apache.spark.sql.execution">EvaluatePython</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF1.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF1</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF1.html" title="type parameter in UDF1">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF1.html" title="type parameter in UDF1">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 1 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF10.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF10</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF10.html" title="type parameter in UDF10">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 10 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF11.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF11</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF11.html" title="type parameter in UDF11">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 11 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF12.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF12</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF12.html" title="type parameter in UDF12">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 12 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF13.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF13</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF13.html" title="type parameter in UDF13">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 13 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF14.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF14</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF14.html" title="type parameter in UDF14">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 14 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF15.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF15</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF15.html" title="type parameter in UDF15">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 15 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF16.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF16</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF16.html" title="type parameter in UDF16">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 16 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF17.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF17</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">T17</a>,<a href="./org/apache/spark/sql/api/java/UDF17.html" title="type parameter in UDF17">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 17 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF18.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF18</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T17</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">T18</a>,<a href="./org/apache/spark/sql/api/java/UDF18.html" title="type parameter in UDF18">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 18 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF19.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF19</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T17</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T18</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">T19</a>,<a href="./org/apache/spark/sql/api/java/UDF19.html" title="type parameter in UDF19">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 19 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF2.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF2</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF2.html" title="type parameter in UDF2">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF2.html" title="type parameter in UDF2">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF2.html" title="type parameter in UDF2">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 2 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF20.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF20</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T17</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T18</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T19</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">T20</a>,<a href="./org/apache/spark/sql/api/java/UDF20.html" title="type parameter in UDF20">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 20 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF21.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF21</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T17</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T18</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T19</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T20</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">T21</a>,<a href="./org/apache/spark/sql/api/java/UDF21.html" title="type parameter in UDF21">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 21 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF22.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF22</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T10</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T11</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T12</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T13</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T14</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T15</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T16</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T17</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T18</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T19</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T20</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T21</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">T22</a>,<a href="./org/apache/spark/sql/api/java/UDF22.html" title="type parameter in UDF22">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 22 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF3.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF3</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF3.html" title="type parameter in UDF3">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 3 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF4.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF4</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF4.html" title="type parameter in UDF4">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 4 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF5.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF5</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF5.html" title="type parameter in UDF5">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 5 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF6.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF6</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF6.html" title="type parameter in UDF6">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 6 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF7.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF7</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF7.html" title="type parameter in UDF7">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 7 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF8.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF8</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF8.html" title="type parameter in UDF8">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 8 arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/api/java/UDF9.html" title="interface in org.apache.spark.sql.api.java"><span class="strong">UDF9</span></a>&lt;<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T1</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T2</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T3</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T4</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T5</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T6</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T7</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T8</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">T9</a>,<a href="./org/apache/spark/sql/api/java/UDF9.html" title="type parameter in UDF9">R</a>&gt; - Interface in <a href="./org/apache/spark/sql/api/java/package-summary.html">org.apache.spark.sql.api.java</a></dt>
<dd>
<div class="block">A Spark SQL UDF that has 9 arguments.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#ui()">ui()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#uiTab()">uiTab()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html#unbound()">unbound()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Aggregate.ComputedAggregate.html" title="class in org.apache.spark.sql.execution">Aggregate.ComputedAggregate</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/BroadcastFactory.html#unbroadcast(long, boolean, boolean)">unbroadcast(long, boolean, boolean)</a></span> - Method in interface org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/BroadcastFactory.html" title="interface in org.apache.spark.broadcast">BroadcastFactory</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html#unbroadcast(long, boolean, boolean)">unbroadcast(long, boolean, boolean)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/HttpBroadcastFactory.html" title="class in org.apache.spark.broadcast">HttpBroadcastFactory</a></dt>
<dd>
<div class="block">Remove all persisted state associated with the HTTP broadcast with the given ID.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html#unbroadcast(long, boolean, boolean)">unbroadcast(long, boolean, boolean)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/TorrentBroadcastFactory.html" title="class in org.apache.spark.broadcast">TorrentBroadcastFactory</a></dt>
<dd>
<div class="block">Remove all persisted state associated with the torrent broadcast with the given ID.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SQLContext.html#uncacheTable(java.lang.String)">uncacheTable(String)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></dt>
<dd>
<div class="block">Removes the specified table from the in-memory cache.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/SplitInfo.html#underlyingSplit()">underlyingSplit()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/SplitInfo.html" title="class in org.apache.spark.scheduler">SplitInfo</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random"><span class="strong">UniformGenerator</span></a> - Class in <a href="./org/apache/spark/mllib/random/package-summary.html">org.apache.spark.mllib.random</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Generates i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/UniformGenerator.html#UniformGenerator()">UniformGenerator()</a></span> - Constructor for class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/UniformGenerator.html" title="class in org.apache.spark.mllib.random">UniformGenerator</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)">uniformJavaRDD(JavaSparkContext, long, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Java-friendly version of <a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformRDD(org.apache.spark.SparkContext, long, int, long)"><code>RandomRDDs.uniformRDD(org.apache.spark.SparkContext, long, int, long)</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int)">uniformJavaRDD(JavaSparkContext, long, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><code>RandomRDDs.uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</code></a> with the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long)">uniformJavaRDD(JavaSparkContext, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)"><code>RandomRDDs.uniformJavaRDD(org.apache.spark.api.java.JavaSparkContext, long, int, long)</code></a> with the default number of partitions and the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)">uniformJavaVectorRDD(JavaSparkContext, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Java-friendly version of <a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformVectorRDD(org.apache.spark.SparkContext, long, int, int, long)"><code>RandomRDDs.uniformVectorRDD(org.apache.spark.SparkContext, long, int, int, long)</code></a>.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int)">uniformJavaVectorRDD(JavaSparkContext, long, int, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><code>RandomRDDs.uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</code></a> with the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int)">uniformJavaVectorRDD(JavaSparkContext, long, int)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)"><code>RandomRDDs.uniformJavaVectorRDD(org.apache.spark.api.java.JavaSparkContext, long, int, int, long)</code></a> with the default number of partitions and the default seed.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformRDD(org.apache.spark.SparkContext, long, int, long)">uniformRDD(SparkContext, long, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Generates an RDD comprised of i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/random/RandomRDDs.html#uniformVectorRDD(org.apache.spark.SparkContext, long, int, int, long)">uniformVectorRDD(SparkContext, long, int, int, long)</a></span> - Static method in class org.apache.spark.mllib.random.<a href="./org/apache/spark/mllib/random/RandomRDDs.html" title="class in org.apache.spark.mllib.random">RandomRDDs</a></dt>
<dd>
<div class="block">Generates an RDD[Vector] with vectors containing i.i.d.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#union(org.apache.spark.api.java.JavaDoubleRDD)">union(JavaDoubleRDD)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Return the union of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#union(org.apache.spark.api.java.JavaPairRDD)">union(JavaPairRDD&lt;K, V&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return the union of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#union(org.apache.spark.api.java.JavaRDD)">union(JavaRDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Return the union of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#union(org.apache.spark.api.java.JavaRDD, java.util.List)">union(JavaRDD&lt;T&gt;, List&lt;JavaRDD&lt;T&gt;&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Build the union of two or more RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#union(org.apache.spark.api.java.JavaPairRDD, java.util.List)">union(JavaPairRDD&lt;K, V&gt;, List&lt;JavaPairRDD&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Build the union of two or more RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#union(org.apache.spark.api.java.JavaDoubleRDD, java.util.List)">union(JavaDoubleRDD, List&lt;JavaDoubleRDD&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Build the union of two or more RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#union(org.apache.spark.rdd.RDD)">union(RDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Return the union of this RDD and another one.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#union(scala.collection.Seq, scala.reflect.ClassTag)">union(Seq&lt;RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Build the union of a list of RDDs.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#union(org.apache.spark.rdd.RDD, scala.collection.Seq, scala.reflect.ClassTag)">union(RDD&lt;T&gt;, Seq&lt;RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Build the union of a list of RDDs passed as variable-length arguments.</div>
</dd>
<dt><a href="./org/apache/spark/sql/execution/Union.html" title="class in org.apache.spark.sql.execution"><span class="strong">Union</span></a> - Class in <a href="./org/apache/spark/sql/execution/package-summary.html">org.apache.spark.sql.execution</a></dt>
<dd>
<div class="block">:: DeveloperApi ::</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Union.html#Union(scala.collection.Seq)">Union(Seq&lt;SparkPlan&gt;)</a></span> - Constructor for class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Union.html" title="class in org.apache.spark.sql.execution">Union</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#union(org.apache.spark.streaming.api.java.JavaDStream)">union(JavaDStream&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Return a new DStream by unifying data of another DStream with this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#union(org.apache.spark.streaming.api.java.JavaPairDStream)">union(JavaPairDStream&lt;K, V&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream by unifying data of another DStream with this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#union(org.apache.spark.streaming.api.java.JavaDStream, java.util.List)">union(JavaDStream&lt;T&gt;, List&lt;JavaDStream&lt;T&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a unified DStream from multiple DStreams of the same type and same slide duration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html#union(org.apache.spark.streaming.api.java.JavaPairDStream, java.util.List)">union(JavaPairDStream&lt;K, V&gt;, List&lt;JavaPairDStream&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaStreamingContext.html" title="class in org.apache.spark.streaming.api.java">JavaStreamingContext</a></dt>
<dd>
<div class="block">Create a unified DStream from multiple DStreams of the same type and same slide duration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#union(org.apache.spark.streaming.dstream.DStream)">union(DStream&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream by unifying data of another DStream with this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#union(scala.collection.Seq, scala.reflect.ClassTag)">union(Seq&lt;DStream&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>
<div class="block">Create a unified DStream from multiple DStreams of the same type and same slide duration.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#unionAll(org.apache.spark.sql.SchemaRDD)">unionAll(SchemaRDD)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Combines the tuples of two RDDs with the same schema, keeping duplicates.</div>
</dd>
<dt><a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd"><span class="strong">UnionRDD</span></a>&lt;<a href="./org/apache/spark/rdd/UnionRDD.html" title="type parameter in UnionRDD">T</a>&gt; - Class in <a href="./org/apache/spark/rdd/package-summary.html">org.apache.spark.rdd</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/UnionRDD.html#UnionRDD(org.apache.spark.SparkContext, scala.collection.Seq, scala.reflect.ClassTag)">UnionRDD(SparkContext, Seq&lt;RDD&lt;T&gt;&gt;, ClassTag&lt;T&gt;)</a></span> - Constructor for class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/UnionRDD.html" title="class in org.apache.spark.rdd">UnionRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StreamBlockId.html#uniqueId()">uniqueId()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StreamBlockId.html" title="class in org.apache.spark.storage">StreamBlockId</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/UnknownReason.html" title="class in org.apache.spark"><span class="strong">UnknownReason</span></a> - Class in <a href="./org/apache/spark/package-summary.html">org.apache.spark</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 We don't know why the task ended -- for example, because of a ClassNotFound exception when
 deserializing the task result.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/UnknownReason.html#UnknownReason()">UnknownReason()</a></span> - Constructor for class org.apache.spark.<a href="./org/apache/spark/UnknownReason.html" title="class in org.apache.spark">UnknownReason</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#unpersist()">unpersist()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#unpersist(boolean)">unpersist(boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#unpersist()">unpersist()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#unpersist(boolean)">unpersist(boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#unpersist()">unpersist()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#unpersist(boolean)">unpersist(boolean)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/Broadcast.html#unpersist()">unpersist()</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a></dt>
<dd>
<div class="block">Asynchronously delete cached copies of this broadcast on the executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/Broadcast.html#unpersist(boolean)">unpersist(boolean)</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a></dt>
<dd>
<div class="block">Delete cached copies of this broadcast on the executors.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html#unpersist()">unpersist()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/BinaryClassificationMetrics.html" title="class in org.apache.spark.mllib.evaluation">BinaryClassificationMetrics</a></dt>
<dd>
<div class="block">Unpersist intermediate RDDs used in the computation.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#unpersist(boolean)">unpersist(boolean)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#unpersist(boolean)">unpersist(boolean)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>
<div class="block">Mark the RDD as non-persistent, and remove all blocks for it from memory and disk.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/Time.html#until(org.apache.spark.streaming.Time, org.apache.spark.streaming.Duration)">until(Time, Duration)</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#update()">update()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/AggregateEvaluation.html#update()">update()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/AggregateEvaluation.html" title="class in org.apache.spark.sql.execution">AggregateEvaluation</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#update(T1, T2)">update(T1, T2)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>
<div class="block">Updates this pair with new values and returns itself</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/jobs/JobProgressListener.html#updateAggregateMetrics(org.apache.spark.ui.jobs.UIData.StageUIData, java.lang.String, org.apache.spark.executor.TaskMetrics, scala.Option)">updateAggregateMetrics(UIData.StageUIData, String, TaskMetrics, Option&lt;TaskMetrics&gt;)</a></span> - Method in class org.apache.spark.ui.jobs.<a href="./org/apache/spark/ui/jobs/JobProgressListener.html" title="class in org.apache.spark.ui.jobs">JobProgressListener</a></dt>
<dd>
<div class="block">Upon receiving new metrics for a task, updates the per-stage and per-executor-per-stage
 aggregate metrics by calculating deltas between the currently recorded metrics and the new
 metrics.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/optimization/Updater.html" title="class in org.apache.spark.mllib.optimization"><span class="strong">Updater</span></a> - Class in <a href="./org/apache/spark/mllib/optimization/package-summary.html">org.apache.spark.mllib.optimization</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Class used to perform steps (weight update) using Gradient Descent methods.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/optimization/Updater.html#Updater()">Updater()</a></span> - Constructor for class org.apache.spark.mllib.optimization.<a href="./org/apache/spark/mllib/optimization/Updater.html" title="class in org.apache.spark.mllib.optimization">Updater</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2)">updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2, int)">updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;, int)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#updateStateByKey(org.apache.spark.api.java.function.Function2, org.apache.spark.Partitioner)">updateStateByKey(Function2&lt;List&lt;V&gt;, Optional&lt;S&gt;, Optional&lt;S&gt;&gt;, Partitioner)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, scala.reflect.ClassTag)">updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, ClassTag&lt;S&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, int, scala.reflect.ClassTag)">updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, int, ClassTag&lt;S&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function2, org.apache.spark.Partitioner, scala.reflect.ClassTag)">updateStateByKey(Function2&lt;Seq&lt;V&gt;, Option&lt;S&gt;, Option&lt;S&gt;&gt;, Partitioner, ClassTag&lt;S&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey(scala.Function1, org.apache.spark.Partitioner, boolean, scala.reflect.ClassTag)">updateStateByKey(Function1&lt;Iterator&lt;Tuple3&lt;K, Seq&lt;V&gt;, Option&lt;S&gt;&gt;&gt;, Iterator&lt;Tuple2&lt;K, S&gt;&gt;&gt;, Partitioner, boolean, ClassTag&lt;S&gt;)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="class in org.apache.spark.streaming.dstream">PairDStreamFunctions</a></dt>
<dd>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#useDisk()">useDisk()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#useMemory()">useMemory()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#useOffHeap()">useOffHeap()</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/Rating.html#user()">user()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/Rating.html" title="class in org.apache.spark.mllib.recommendation">Rating</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/JobLogger.html#user()">user()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/JobLogger.html" title="class in org.apache.spark.scheduler">JobLogger</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html#userFeatures()">userFeatures()</a></span> - Method in class org.apache.spark.mllib.recommendation.<a href="./org/apache/spark/mllib/recommendation/MatrixFactorizationModel.html" title="class in org.apache.spark.mllib.recommendation">MatrixFactorizationModel</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_V_">
<!--   -->
</a>
<h2 class="title">V</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html#V()">V()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SingularValueDecomposition.html" title="class in org.apache.spark.mllib.linalg">SingularValueDecomposition</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#value()">value()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>
<div class="block">Access the accumulator's current value; only allowed on master.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/broadcast/Broadcast.html#value()">value()</a></span> - Method in class org.apache.spark.broadcast.<a href="./org/apache/spark/broadcast/Broadcast.html" title="class in org.apache.spark.broadcast">Broadcast</a></dt>
<dd>
<div class="block">Get the broadcasted value.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/ComplexFutureAction.html#value()">value()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/ComplexFutureAction.html" title="class in org.apache.spark">ComplexFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/FutureAction.html#value()">value()</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/FutureAction.html" title="interface in org.apache.spark">FutureAction</a></dt>
<dd>
<div class="block">The value of this Future.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html#value()">value()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/MatrixEntry.html" title="class in org.apache.spark.mllib.linalg.distributed">MatrixEntry</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/scheduler/AccumulableInfo.html#value()">value()</a></span> - Method in class org.apache.spark.scheduler.<a href="./org/apache/spark/scheduler/AccumulableInfo.html" title="class in org.apache.spark.scheduler">AccumulableInfo</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SerializableWritable.html#value()">value()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SerializableWritable.html" title="class in org.apache.spark">SerializableWritable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SimpleFutureAction.html#value()">value()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SimpleFutureAction.html" title="class in org.apache.spark">SimpleFutureAction</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/SetCommand.html#value()">value()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/SetCommand.html" title="class in org.apache.spark.sql.execution">SetCommand</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#values()">values()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>
<div class="block">Return an RDD with the values of each tuple.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseMatrix.html#values()">values()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseMatrix.html" title="class in org.apache.spark.mllib.linalg">DenseMatrix</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/DenseVector.html#values()">values()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/DenseVector.html" title="class in org.apache.spark.mllib.linalg">DenseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/SparseVector.html#values()">values()</a></span> - Method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/SparseVector.html" title="class in org.apache.spark.mllib.linalg">SparseVector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/PairRDDFunctions.html#values()">values()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/PairRDDFunctions.html" title="class in org.apache.spark.rdd">PairRDDFunctions</a></dt>
<dd>
<div class="block">Return an RDD with the values of each tuple.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#variance()">variance()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>
<div class="block">Compute the variance of this RDD's elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScalerModel.html#variance()">variance()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html#variance()">variance()</a></span> - Method in class org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateOnlineSummarizer.html" title="class in org.apache.spark.mllib.stat">MultivariateOnlineSummarizer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html#variance()">variance()</a></span> - Method in interface org.apache.spark.mllib.stat.<a href="./org/apache/spark/mllib/stat/MultivariateStatisticalSummary.html" title="interface in org.apache.spark.mllib.stat">MultivariateStatisticalSummary</a></dt>
<dd>
<div class="block">Sample variance vector.</div>
</dd>
<dt><a href="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity"><span class="strong">Variance</span></a> - Class in <a href="./org/apache/spark/mllib/tree/impurity/package-summary.html">org.apache.spark.mllib.tree.impurity</a></dt>
<dd>
<div class="block">:: Experimental ::
 Class for calculating variance during regression</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/tree/impurity/Variance.html#Variance()">Variance()</a></span> - Constructor for class org.apache.spark.mllib.tree.impurity.<a href="./org/apache/spark/mllib/tree/impurity/Variance.html" title="class in org.apache.spark.mllib.tree.impurity">Variance</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/DoubleRDDFunctions.html#variance()">variance()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/DoubleRDDFunctions.html" title="class in org.apache.spark.rdd">DoubleRDDFunctions</a></dt>
<dd>
<div class="block">Compute the variance of this RDD's elements.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/StatCounter.html#variance()">variance()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/StatCounter.html" title="class in org.apache.spark.util">StatCounter</a></dt>
<dd>
<div class="block">Return the variance of the values.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaHadoopRDD.html#vClassTag()">vClassTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaHadoopRDD.html" title="class in org.apache.spark.api.java">JavaHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html#vClassTag()">vClassTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaNewHadoopRDD.html" title="class in org.apache.spark.api.java">JavaNewHadoopRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#vClassTag()">vClassTag()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html#vClassTag()">vClassTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html#vClassTag()">vClassTag()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairReceiverInputDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairReceiverInputDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html#vector()">vector()</a></span> - Method in class org.apache.spark.mllib.linalg.distributed.<a href="./org/apache/spark/mllib/linalg/distributed/IndexedRow.html" title="class in org.apache.spark.mllib.linalg.distributed">IndexedRow</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/Vector.html" title="interface in org.apache.spark.mllib.linalg"><span class="strong">Vector</span></a> - Interface in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>
<div class="block">Represents a numeric vector, whose index type is Int and value type is Double.</div>
</dd>
<dt><a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util"><span class="strong">Vector</span></a> - Class in <a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#Vector(double[])">Vector(double[])</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/Vector.Multiplier.html" title="class in org.apache.spark.util"><span class="strong">Vector.Multiplier</span></a> - Class in <a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.Multiplier.html#Vector.Multiplier(double)">Vector.Multiplier(double)</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.Multiplier.html" title="class in org.apache.spark.util">Vector.Multiplier</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util"><span class="strong">Vector.VectorAccumParam$</span></a> - Class in <a href="./org/apache/spark/util/package-summary.html">org.apache.spark.util</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.VectorAccumParam$.html#Vector.VectorAccumParam$()">Vector.VectorAccumParam$()</a></span> - Constructor for class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg"><span class="strong">Vectors</span></a> - Class in <a href="./org/apache/spark/mllib/linalg/package-summary.html">org.apache.spark.mllib.linalg</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#Vectors()">Vectors()</a></span> - Constructor for class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/VectorTransformer.html" title="interface in org.apache.spark.mllib.feature"><span class="strong">VectorTransformer</span></a> - Interface in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: DeveloperApi ::
 Trait for transformation of a vector</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#version()">version()</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">The version of Spark on which this application is running.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#version()">version()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">The version of Spark on which this application is running.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#vManifest()">vManifest()</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/api/java/function/VoidFunction.html" title="interface in org.apache.spark.api.java.function"><span class="strong">VoidFunction</span></a>&lt;<a href="./org/apache/spark/api/java/function/VoidFunction.html" title="type parameter in VoidFunction">T</a>&gt; - Interface in <a href="./org/apache/spark/api/java/function/package-summary.html">org.apache.spark.api.java.function</a></dt>
<dd>
<div class="block">A function with no return value.</div>
</dd>
</dl>
<a name="_W_">
<!--   -->
</a>
<h2 class="title">W</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/streaming/StreamingContext.html#waiter()">waiter()</a></span> - Method in class org.apache.spark.streaming.<a href="./org/apache/spark/streaming/StreamingContext.html" title="class in org.apache.spark.streaming">StreamingContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/LocalHiveContext.html#warehousePath()">warehousePath()</a></span> - Method in class org.apache.spark.sql.hive.<a href="./org/apache/spark/sql/hive/LocalHiveContext.html" title="class in org.apache.spark.sql.hive">LocalHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/hive/test/TestHiveContext.html#warehousePath()">warehousePath()</a></span> - Method in class org.apache.spark.sql.hive.test.<a href="./org/apache/spark/sql/hive/test/TestHiveContext.html" title="class in org.apache.spark.sql.hive.test">TestHiveContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedFalsePositiveRate()">weightedFalsePositiveRate()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns weighted false positive rate</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedFMeasure(double)">weightedFMeasure(double)</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns weighted averaged f-measure</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedFMeasure()">weightedFMeasure()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns weighted averaged f1-measure</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedPrecision()">weightedPrecision()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns weighted averaged precision</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedRecall()">weightedRecall()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns weighted averaged recall
 (equals to precision, recall and f-measure)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html#weightedTruePositiveRate()">weightedTruePositiveRate()</a></span> - Method in class org.apache.spark.mllib.evaluation.<a href="./org/apache/spark/mllib/evaluation/MulticlassMetrics.html" title="class in org.apache.spark.mllib.evaluation">MulticlassMetrics</a></dt>
<dd>
<div class="block">Returns weighted true positive rate
 (equals to precision, recall and f-measure)</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html#weights()">weights()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/LogisticRegressionModel.html" title="class in org.apache.spark.mllib.classification">LogisticRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/classification/SVMModel.html#weights()">weights()</a></span> - Method in class org.apache.spark.mllib.classification.<a href="./org/apache/spark/mllib/classification/SVMModel.html" title="class in org.apache.spark.mllib.classification">SVMModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html#weights()">weights()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/GeneralizedLinearModel.html" title="class in org.apache.spark.mllib.regression">GeneralizedLinearModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LassoModel.html#weights()">weights()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LassoModel.html" title="class in org.apache.spark.mllib.regression">LassoModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html#weights()">weights()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/LinearRegressionModel.html" title="class in org.apache.spark.mllib.regression">LinearRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html#weights()">weights()</a></span> - Method in class org.apache.spark.mllib.regression.<a href="./org/apache/spark/mllib/regression/RidgeRegressionModel.html" title="class in org.apache.spark.mllib.regression">RidgeRegressionModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#where(org.apache.spark.sql.catalyst.expressions.Expression)">where(Expression)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Filters the output, only returning those rows where <code>condition</code> evaluates to true.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#where(scala.Symbol, scala.Function1)">where(Symbol, Function1&lt;T1, Object&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">Filters tuples using a function over the value of the specified column.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/SchemaRDD.html#where(scala.Function1)">where(Function1&lt;DynamicRow, Object&gt;)</a></span> - Method in class org.apache.spark.sql.<a href="./org/apache/spark/sql/SchemaRDD.html" title="class in org.apache.spark.sql">SchemaRDD</a></dt>
<dd>
<div class="block">:: Experimental ::
 Filters tuples using a function over a <code>Dynamic</code> version of a given Row.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#wholeTextFiles(java.lang.String, int)">wholeTextFiles(String, int)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Read a directory of text files from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaSparkContext.html#wholeTextFiles(java.lang.String)">wholeTextFiles(String)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaSparkContext.html" title="class in org.apache.spark.api.java">JavaSparkContext</a></dt>
<dd>
<div class="block">Read a directory of text files from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#wholeTextFiles(java.lang.String, int)">wholeTextFiles(String, int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>
<div class="block">Read a directory of text files from HDFS, a local file system (available on all nodes), or any
 Hadoop-supported file system URI.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#window(org.apache.spark.streaming.Duration)">window(Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#window(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">window(Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#window(org.apache.spark.streaming.Duration)">window(Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream which is computed based on windowed batches of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#window(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">window(Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>
<div class="block">Return a new DStream which is computed based on windowed batches of this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#window(org.apache.spark.streaming.Duration)">window(Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#window(org.apache.spark.streaming.Duration, org.apache.spark.streaming.Duration)">window(Duration, Duration)</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>
<div class="block">Return a new DStream in which each RDD contains all the elements in seen in a
 sliding window of time over this DStream.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScalerModel.html#withMean()">withMean()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/execution/Sample.html#withReplacement()">withReplacement()</a></span> - Method in class org.apache.spark.sql.execution.<a href="./org/apache/spark/sql/execution/Sample.html" title="class in org.apache.spark.sql.execution">Sample</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/StandardScalerModel.html#withStd()">withStd()</a></span> - Method in class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/StandardScalerModel.html" title="class in org.apache.spark.mllib.feature">StandardScalerModel</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature"><span class="strong">Word2Vec</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Word2Vec creates vector representation of words in a text corpus.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/feature/Word2Vec.html#Word2Vec()">Word2Vec()</a></span> - Constructor for class org.apache.spark.mllib.feature.<a href="./org/apache/spark/mllib/feature/Word2Vec.html" title="class in org.apache.spark.mllib.feature">Word2Vec</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/mllib/feature/Word2VecModel.html" title="class in org.apache.spark.mllib.feature"><span class="strong">Word2VecModel</span></a> - Class in <a href="./org/apache/spark/mllib/feature/package-summary.html">org.apache.spark.mllib.feature</a></dt>
<dd>
<div class="block">:: Experimental ::
 Word2Vec model</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaDoubleRDD.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;Double&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaDoubleRDD.html" title="class in org.apache.spark.api.java">JavaDoubleRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaPairRDD.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaPairRDD.html" title="class in org.apache.spark.api.java">JavaPairRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDD.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;T&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;Row&gt;)</a></span> - Method in class org.apache.spark.sql.api.java.<a href="./org/apache/spark/sql/api/java/JavaSchemaRDD.html" title="class in org.apache.spark.sql.api.java">JavaSchemaRDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStream.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;T&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStream.html" title="class in org.apache.spark.streaming.api.java">JavaDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;T&gt;)</a></span> - Method in interface org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaDStreamLike.html" title="interface in org.apache.spark.streaming.api.java">JavaDStreamLike</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html#wrapRDD(org.apache.spark.rdd.RDD)">wrapRDD(RDD&lt;Tuple2&lt;K, V&gt;&gt;)</a></span> - Method in class org.apache.spark.streaming.api.java.<a href="./org/apache/spark/streaming/api/java/JavaPairDStream.html" title="class in org.apache.spark.streaming.api.java">JavaPairDStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.html#writableWritableConverter()">writableWritableConverter()</a></span> - Static method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializationStream.html#writeAll(scala.collection.Iterator, scala.reflect.ClassTag)">writeAll(Iterator&lt;T&gt;, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/JavaSerializer.html#writeExternal(java.io.ObjectOutput)">writeExternal(ObjectOutput)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/JavaSerializer.html" title="class in org.apache.spark.serializer">JavaSerializer</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/BlockManagerId.html#writeExternal(java.io.ObjectOutput)">writeExternal(ObjectOutput)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/BlockManagerId.html" title="class in org.apache.spark.storage">BlockManagerId</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/storage/StorageLevel.html#writeExternal(java.io.ObjectOutput)">writeExternal(ObjectOutput)</a></span> - Method in class org.apache.spark.storage.<a href="./org/apache/spark/storage/StorageLevel.html" title="class in org.apache.spark.storage">StorageLevel</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html#writeExternal(java.io.ObjectOutput)">writeExternal(ObjectOutput)</a></span> - Method in class org.apache.spark.streaming.flume.<a href="./org/apache/spark/streaming/flume/SparkFlumeEvent.html" title="class in org.apache.spark.streaming.flume">SparkFlumeEvent</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/serializer/SerializationStream.html#writeObject(T, scala.reflect.ClassTag)">writeObject(T, ClassTag&lt;T&gt;)</a></span> - Method in class org.apache.spark.serializer.<a href="./org/apache/spark/serializer/SerializationStream.html" title="class in org.apache.spark.serializer">SerializationStream</a></dt>
<dd>&nbsp;</dd>
</dl>
<a name="_Z_">
<!--   -->
</a>
<h2 class="title">Z</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/Accumulable.html#zero()">zero()</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/Accumulable.html" title="class in org.apache.spark">Accumulable</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/AccumulableParam.html#zero(R)">zero(R)</a></span> - Method in interface org.apache.spark.<a href="./org/apache/spark/AccumulableParam.html" title="interface in org.apache.spark">AccumulableParam</a></dt>
<dd>
<div class="block">Return the "zero" (identity) value for an accumulator type, given its initial value.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html#zero(double)">zero(double)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.DoubleAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.DoubleAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html#zero(float)">zero(float)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.FloatAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.FloatAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html#zero(int)">zero(int)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.IntAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.IntAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html#zero(long)">zero(long)</a></span> - Method in class org.apache.spark.<a href="./org/apache/spark/SparkContext.LongAccumulatorParam$.html" title="class in org.apache.spark">SparkContext.LongAccumulatorParam$</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.VectorAccumParam$.html#zero(org.apache.spark.util.Vector)">zero(Vector)</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.VectorAccumParam$.html" title="class in org.apache.spark.util">Vector.VectorAccumParam$</a></dt>
<dd>&nbsp;</dd>
<dt><a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq"><span class="strong">ZeroMQUtils</span></a> - Class in <a href="./org/apache/spark/streaming/zeromq/package-summary.html">org.apache.spark.streaming.zeromq</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html#ZeroMQUtils()">ZeroMQUtils()</a></span> - Constructor for class org.apache.spark.streaming.zeromq.<a href="./org/apache/spark/streaming/zeromq/ZeroMQUtils.html" title="class in org.apache.spark.streaming.zeromq">ZeroMQUtils</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/mllib/linalg/Vectors.html#zeros(int)">zeros(int)</a></span> - Static method in class org.apache.spark.mllib.linalg.<a href="./org/apache/spark/mllib/linalg/Vectors.html" title="class in org.apache.spark.mllib.linalg">Vectors</a></dt>
<dd>
<div class="block">Creates a dense vector of all zeros.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/Vector.html#zeros(int)">zeros(int)</a></span> - Static method in class org.apache.spark.util.<a href="./org/apache/spark/util/Vector.html" title="class in org.apache.spark.util">Vector</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/streaming/dstream/DStream.html#zeroTime()">zeroTime()</a></span> - Method in class org.apache.spark.streaming.dstream.<a href="./org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#zip(org.apache.spark.api.java.JavaRDDLike)">zip(JavaRDDLike&lt;U, ?&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 second element in each RDD, etc.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zip(org.apache.spark.rdd.RDD, scala.reflect.ClassTag)">zip(RDD&lt;U&gt;, ClassTag&lt;U&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Zips this RDD with another one, returning key-value pairs with the first element in each RDD,
 second element in each RDD, etc.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#zipPartitions(org.apache.spark.api.java.JavaRDDLike, org.apache.spark.api.java.function.FlatMapFunction2)">zipPartitions(JavaRDDLike&lt;U, ?&gt;, FlatMapFunction2&lt;Iterator&lt;T&gt;, Iterator&lt;U&gt;, V&gt;)</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 applying a function to the zipped partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, boolean, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions(RDD&lt;B&gt;, boolean, Function2&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Zip this RDD's partitions with one (or more) RDD(s) and return a new RDD by
 applying a function to the zipped partitions.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, scala.Function2, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions(RDD&lt;B&gt;, Function2&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, boolean, Function3&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function3, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, Function3&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, boolean, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, RDD&lt;D&gt;, boolean, Function4&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;D&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;D&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipPartitions(org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, org.apache.spark.rdd.RDD, scala.Function4, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag, scala.reflect.ClassTag)">zipPartitions(RDD&lt;B&gt;, RDD&lt;C&gt;, RDD&lt;D&gt;, Function4&lt;Iterator&lt;T&gt;, Iterator&lt;B&gt;, Iterator&lt;C&gt;, Iterator&lt;D&gt;, Iterator&lt;V&gt;&gt;, ClassTag&lt;B&gt;, ClassTag&lt;C&gt;, ClassTag&lt;D&gt;, ClassTag&lt;V&gt;)</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#zipWithIndex()">zipWithIndex()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Zips this RDD with its element indices.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipWithIndex()">zipWithIndex()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Zips this RDD with its element indices.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/api/java/JavaRDDLike.html#zipWithUniqueId()">zipWithUniqueId()</a></span> - Method in interface org.apache.spark.api.java.<a href="./org/apache/spark/api/java/JavaRDDLike.html" title="interface in org.apache.spark.api.java">JavaRDDLike</a></dt>
<dd>
<div class="block">Zips this RDD with generated unique Long ids.</div>
</dd>
<dt><span class="strong"><a href="./org/apache/spark/rdd/RDD.html#zipWithUniqueId()">zipWithUniqueId()</a></span> - Method in class org.apache.spark.rdd.<a href="./org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a></dt>
<dd>
<div class="block">Zips this RDD with generated unique Long ids.</div>
</dd>
</dl>
<a name="___">
<!--   -->
</a>
<h2 class="title">_</h2>
<dl>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#_1()">_1()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/util/MutablePair.html#_2()">_2()</a></span> - Method in class org.apache.spark.util.<a href="./org/apache/spark/util/MutablePair.html" title="class in org.apache.spark.util">MutablePair</a></dt>
<dd>&nbsp;</dd>
<dt><span class="strong"><a href="./org/apache/spark/ui/storage/StorageListener.html#_rddInfoMap()">_rddInfoMap()</a></span> - Method in class org.apache.spark.ui.storage.<a href="./org/apache/spark/ui/storage/StorageListener.html" title="class in org.apache.spark.ui.storage">StorageListener</a></dt>
<dd>&nbsp;</dd>
</dl>
<a href="#_A_">A</a>&nbsp;<a href="#_B_">B</a>&nbsp;<a href="#_C_">C</a>&nbsp;<a href="#_D_">D</a>&nbsp;<a href="#_E_">E</a>&nbsp;<a href="#_F_">F</a>&nbsp;<a href="#_G_">G</a>&nbsp;<a href="#_H_">H</a>&nbsp;<a href="#_I_">I</a>&nbsp;<a href="#_J_">J</a>&nbsp;<a href="#_K_">K</a>&nbsp;<a href="#_L_">L</a>&nbsp;<a href="#_M_">M</a>&nbsp;<a href="#_N_">N</a>&nbsp;<a href="#_O_">O</a>&nbsp;<a href="#_P_">P</a>&nbsp;<a href="#_Q_">Q</a>&nbsp;<a href="#_R_">R</a>&nbsp;<a href="#_S_">S</a>&nbsp;<a href="#_T_">T</a>&nbsp;<a href="#_U_">U</a>&nbsp;<a href="#_V_">V</a>&nbsp;<a href="#_W_">W</a>&nbsp;<a href="#_Z_">Z</a>&nbsp;<a href="#___">_</a>&nbsp;</div>
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="./overview-summary.html">Overview</a></li>
<li>Package</li>
<li>Class</li>
<li><a href="./overview-tree.html">Tree</a></li>
<li><a href="./deprecated-list.html">Deprecated</a></li>
<li class="navBarCell1Rev">Index</li>
<li><a href="./help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="./index.html?index-all.html" target="_top">Frames</a></li>
<li><a href="index-all.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="./allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
