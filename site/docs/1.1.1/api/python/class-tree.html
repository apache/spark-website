<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>Class Hierarchy</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th bgcolor="#70b0f0" class="navbar-select"
          >&nbsp;&nbsp;&nbsp;Trees&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.1.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">&nbsp;</td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="class-tree.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<center><b>
 [ <a href="module-tree.html">Module Hierarchy</a>
 | <a href="class-tree.html">Class Hierarchy</a> ]
</b></center><br />
<h1 class="epydoc">Class Hierarchy</h1>
<ul class="nomargin-top">
    <li> <strong class="uidlink">SocketServer.BaseServer</strong>:
      <em class="summary">Base class for server classes.</em>
    </li>
    <li> <strong class="uidlink">collections.Iterable</strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.util.MLUtils-class.html">pyspark.mllib.util.MLUtils</a></strong>:
      <em class="summary">Helper methods to load, save and pre-process data used in MLlib.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.random.RandomRDDs-class.html">pyspark.mllib.random.RandomRDDs</a></strong>:
      <em class="summary">Generator methods for creating RDDs comprised of i.i.d samples from
        some distribution.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.sql.SQLContext-class.html">pyspark.sql.SQLContext</a></strong>:
      <em class="summary">Main entry point for SparkSQL functionality.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.storagelevel.StorageLevel-class.html">pyspark.storagelevel.StorageLevel</a></strong>:
      <em class="summary">Flags for controlling the storage of an RDD.</em>
    </li>
    <li> <strong class="uidlink">object</strong>:
      <em class="summary">The most base type</em>
    <ul>
    <li> <strong class="uidlink"><a href="pyspark.mllib.recommendation.ALS-class.html">pyspark.mllib.recommendation.ALS</a></strong>:
      <em class="summary">Alternating Least Squares matrix factorization.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.accumulators.Accumulator-class.html">pyspark.accumulators.Accumulator</a></strong>:
      <em class="summary">A shared variable that can be accumulated, i.e., has a commutative 
        and associative &quot;add&quot; operation.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.accumulators.AccumulatorParam-class.html">pyspark.accumulators.AccumulatorParam</a></strong>:
      <em class="summary">Helper object that defines how to accumulate values of a given 
        type.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.broadcast.Broadcast-class.html">pyspark.broadcast.Broadcast</a></strong>:
      <em class="summary">A broadcast variable created with <a 
        href="pyspark.context.SparkContext-class.html#broadcast" 
        class="link">SparkContext.broadcast()</a>.</em>
    </li>
    <li> <strong class="uidlink">pyspark.sql.DataType</strong>:
      <em class="summary">Spark SQL DataType</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.tree.DecisionTree-class.html">pyspark.mllib.tree.DecisionTree</a></strong>:
      <em class="summary">Learning algorithm for a decision tree model
for classification or regression.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.tree.DecisionTreeModel-class.html">pyspark.mllib.tree.DecisionTreeModel</a></strong>:
      <em class="summary">A decision tree model for classification or regression.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.clustering.KMeans-class.html">pyspark.mllib.clustering.KMeans</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.clustering.KMeansModel-class.html">pyspark.mllib.clustering.KMeansModel</a></strong>:
      <em class="summary">A clustering model derived from the k-means method.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.regression.LabeledPoint-class.html">pyspark.mllib.regression.LabeledPoint</a></strong>:
      <em class="summary">The features and labels of a data point.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.regression.LassoWithSGD-class.html">pyspark.mllib.regression.LassoWithSGD</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.regression.LinearModel-class.html">pyspark.mllib.regression.LinearModel</a></strong>:
      <em class="summary">A linear model that has a vector of coefficients and an intercept.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.regression.LinearRegressionWithSGD-class.html">pyspark.mllib.regression.LinearRegressionWithSGD</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.classification.LogisticRegressionWithSGD-class.html">pyspark.mllib.classification.LogisticRegressionWithSGD</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.recommendation.MatrixFactorizationModel-class.html">pyspark.mllib.recommendation.MatrixFactorizationModel</a></strong>:
      <em class="summary">A matrix factorisation model trained by regularized alternating 
        least-squares.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.stat.MultivariateStatisticalSummary-class.html">pyspark.mllib.stat.MultivariateStatisticalSummary</a></strong>:
      <em class="summary">Trait for multivariate statistical summary of a data matrix.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.classification.NaiveBayes-class.html">pyspark.mllib.classification.NaiveBayes</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.classification.NaiveBayesModel-class.html">pyspark.mllib.classification.NaiveBayesModel</a></strong>:
      <em class="summary">Model for Naive Bayes classifiers.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.rdd.RDD-class.html">pyspark.rdd.RDD</a></strong>:
      <em class="summary">A Resilient Distributed Dataset (RDD), the basic abstraction in 
        Spark.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.regression.RidgeRegressionWithSGD-class.html">pyspark.mllib.regression.RidgeRegressionWithSGD</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.classification.SVMWithSGD-class.html">pyspark.mllib.classification.SVMWithSGD</a></strong>
    </li>
    <li> <strong class="uidlink">pyspark.serializers.Serializer</strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.conf.SparkConf-class.html">pyspark.conf.SparkConf</a></strong>:
      <em class="summary">Configuration for a Spark application.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.context.SparkContext-class.html">pyspark.context.SparkContext</a></strong>:
      <em class="summary">Main entry point for Spark functionality.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.files.SparkFiles-class.html">pyspark.files.SparkFiles</a></strong>:
      <em class="summary">Resolves paths to files added through <a 
        href="pyspark.context.SparkContext-class.html#addFile" 
        class="link">SparkContext.addFile()</a>.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.linalg.SparseVector-class.html">pyspark.mllib.linalg.SparseVector</a></strong>:
      <em class="summary">A simple sparse vector class for passing data to MLlib.</em>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.statcounter.StatCounter-class.html">pyspark.statcounter.StatCounter</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.stat.Statistics-class.html">pyspark.mllib.stat.Statistics</a></strong>
    </li>
    <li> <strong class="uidlink"><a href="pyspark.mllib.linalg.Vectors-class.html">pyspark.mllib.linalg.Vectors</a></strong>:
      <em class="summary">Factory methods for working with vectors.</em>
    </li>
    <li> <strong class="uidlink">tuple</strong>:
      <em class="summary">tuple() -&gt; empty tuple tuple(iterable) -&gt; tuple initialized 
        from iterable's items</em>
    </li>
    <li> <strong class="uidlink">type</strong>:
      <em class="summary">type(object) -&gt; the object's type type(name, bases, dict) -&gt; 
        a new type</em>
    </li>
    </ul>
    </li>
</ul>
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th bgcolor="#70b0f0" class="navbar-select"
          >&nbsp;&nbsp;&nbsp;Trees&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.1.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Mon Nov 24 15:21:12 2014
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
