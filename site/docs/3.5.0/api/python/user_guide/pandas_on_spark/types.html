
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>Type Support in Pandas API on Spark &#8212; PySpark 3.5.0 documentation</title>
    
    <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="../../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/pyspark.css" />
    
    <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/types.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Type Hints in Pandas API on Spark" href="typehints.html" />
    <link rel="prev" title="Transform and apply a function" href="transform_apply.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/spark-logo-reverse.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../index.html">
  Overview
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  User Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../development/index.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../migration_guide/index.html">
  Migration Guides
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../python_packaging.html">
   Python Package Management
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../sql/index.html">
   Spark SQL
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../sql/arrow_pandas.html">
     Apache Arrow in PySpark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sql/python_udtf.html">
     Python User-defined Table Functions (UDTFs)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Pandas API on Spark
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="options.html">
     Options and settings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pandas_pyspark.html">
     From/to pandas and PySpark DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transform_apply.html">
     Transform and apply a function
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Type Support in Pandas API on Spark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="typehints.html">
     Type Hints in Pandas API on Spark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="from_to_dbms.html">
     From/to other DBMSes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="best_practices.html">
     Best Practices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="supported_pandas_api.html">
     Supported pandas API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="faq.html">
     FAQ
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#type-casting-between-pyspark-and-pandas-api-on-spark">
   Type casting between PySpark and pandas API on Spark
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#type-casting-between-pandas-and-pandas-api-on-spark">
   Type casting between pandas and pandas API on Spark
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#internal-type-mapping">
   Internal type mapping
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="type-support-in-pandas-api-on-spark">
<h1>Type Support in Pandas API on Spark<a class="headerlink" href="#type-support-in-pandas-api-on-spark" title="Permalink to this headline">¶</a></h1>
<p>In this chapter, we will briefly show you how data types change when converting pandas-on-Spark DataFrame from/to PySpark DataFrame or pandas DataFrame.</p>
<div class="section" id="type-casting-between-pyspark-and-pandas-api-on-spark">
<h2>Type casting between PySpark and pandas API on Spark<a class="headerlink" href="#type-casting-between-pyspark-and-pandas-api-on-spark" title="Permalink to this headline">¶</a></h2>
<p>When converting a pandas-on-Spark DataFrame from/to PySpark DataFrame, the data types are automatically casted to the appropriate type.</p>
<p>The example below shows how data types are casted from PySpark DataFrame to pandas-on-Spark DataFrame.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Create a PySpark DataFrame</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
<span class="o">...</span>     <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Decimal</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">27</span><span class="p">),</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">27</span><span class="p">)),</span>
<span class="o">...</span> <span class="p">],</span> <span class="s1">&#39;tinyint tinyint, decimal decimal, float float, double double, integer integer, long long, short short, timestamp timestamp, string string, boolean boolean, date date&#39;</span><span class="p">)</span>

<span class="c1"># 2. Check the PySpark data types</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span>
<span class="n">DataFrame</span><span class="p">[</span><span class="n">tinyint</span><span class="p">:</span> <span class="n">tinyint</span><span class="p">,</span> <span class="n">decimal</span><span class="p">:</span> <span class="n">decimal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="nb">float</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">double</span><span class="p">:</span> <span class="n">double</span><span class="p">,</span> <span class="n">integer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">long</span><span class="p">:</span> <span class="n">bigint</span><span class="p">,</span> <span class="n">short</span><span class="p">:</span> <span class="n">smallint</span><span class="p">,</span> <span class="n">timestamp</span><span class="p">:</span> <span class="n">timestamp</span><span class="p">,</span> <span class="n">string</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span> <span class="n">boolean</span><span class="p">:</span> <span class="n">boolean</span><span class="p">,</span> <span class="n">date</span><span class="p">:</span> <span class="n">date</span><span class="p">]</span>

<span class="c1"># 3. Convert PySpark DataFrame to pandas-on-Spark DataFrame</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span> <span class="o">=</span> <span class="n">sdf</span><span class="o">.</span><span class="n">pandas_api</span><span class="p">()</span>

<span class="c1"># 4. Check the pandas-on-Spark data types</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span><span class="o">.</span><span class="n">dtypes</span>
<span class="n">tinyint</span>                <span class="n">int8</span>
<span class="n">decimal</span>              <span class="nb">object</span>
<span class="nb">float</span>               <span class="n">float32</span>
<span class="n">double</span>              <span class="n">float64</span>
<span class="n">integer</span>               <span class="n">int32</span>
<span class="n">long</span>                  <span class="n">int64</span>
<span class="n">short</span>                 <span class="n">int16</span>
<span class="n">timestamp</span>    <span class="n">datetime64</span><span class="p">[</span><span class="n">ns</span><span class="p">]</span>
<span class="n">string</span>               <span class="nb">object</span>
<span class="n">boolean</span>                <span class="nb">bool</span>
<span class="n">date</span>                 <span class="nb">object</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</pre></div>
</div>
<p>The example below shows how data types are casted from pandas-on-Spark DataFrame to PySpark DataFrame.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Create a pandas-on-Spark DataFrame</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span> <span class="o">=</span> <span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;int8&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;bool&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">],</span> <span class="s2">&quot;float32&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="s2">&quot;float64&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="s2">&quot;int32&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;int64&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;int16&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;datetime&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">27</span><span class="p">)],</span> <span class="s2">&quot;object_string&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;1&quot;</span><span class="p">],</span> <span class="s2">&quot;object_decimal&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">decimal</span><span class="o">.</span><span class="n">Decimal</span><span class="p">(</span><span class="s2">&quot;1.1&quot;</span><span class="p">)],</span> <span class="s2">&quot;object_date&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">27</span><span class="p">)]})</span>

<span class="c1"># 2. Type casting by using `astype`</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;int8&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;int8&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int8&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;int16&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;int16&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int16&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;int32&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;int32&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;float32&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">psdf</span><span class="p">[</span><span class="s1">&#39;float32&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

<span class="c1"># 3. Check the pandas-on-Spark data types</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">psdf</span><span class="o">.</span><span class="n">dtypes</span>
<span class="n">int8</span>                        <span class="n">int8</span>
<span class="nb">bool</span>                        <span class="nb">bool</span>
<span class="n">float32</span>                  <span class="n">float32</span>
<span class="n">float64</span>                  <span class="n">float64</span>
<span class="n">int32</span>                      <span class="n">int32</span>
<span class="n">int64</span>                      <span class="n">int64</span>
<span class="n">int16</span>                      <span class="n">int16</span>
<span class="n">datetime</span>          <span class="n">datetime64</span><span class="p">[</span><span class="n">ns</span><span class="p">]</span>
<span class="n">object_string</span>             <span class="nb">object</span>
<span class="n">object_decimal</span>            <span class="nb">object</span>
<span class="n">object_date</span>               <span class="nb">object</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>

<span class="c1"># 4. Convert pandas-on-Spark DataFrame to PySpark DataFrame</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span> <span class="o">=</span> <span class="n">psdf</span><span class="o">.</span><span class="n">to_spark</span><span class="p">()</span>

<span class="c1"># 5. Check the PySpark data types</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">sdf</span>
<span class="n">DataFrame</span><span class="p">[</span><span class="n">int8</span><span class="p">:</span> <span class="n">tinyint</span><span class="p">,</span> <span class="nb">bool</span><span class="p">:</span> <span class="n">boolean</span><span class="p">,</span> <span class="n">float32</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">float64</span><span class="p">:</span> <span class="n">double</span><span class="p">,</span> <span class="n">int32</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">int64</span><span class="p">:</span> <span class="n">bigint</span><span class="p">,</span> <span class="n">int16</span><span class="p">:</span> <span class="n">smallint</span><span class="p">,</span> <span class="n">datetime</span><span class="p">:</span> <span class="n">timestamp</span><span class="p">,</span> <span class="n">object_string</span><span class="p">:</span> <span class="n">string</span><span class="p">,</span> <span class="n">object_decimal</span><span class="p">:</span> <span class="n">decimal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">object_date</span><span class="p">:</span> <span class="n">date</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="type-casting-between-pandas-and-pandas-api-on-spark">
<h2>Type casting between pandas and pandas API on Spark<a class="headerlink" href="#type-casting-between-pandas-and-pandas-api-on-spark" title="Permalink to this headline">¶</a></h2>
<p>When converting pandas-on-Spark DataFrame to pandas DataFrame, the data types are basically the same as pandas.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert pandas-on-Spark DataFrame to pandas DataFrame</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pdf</span> <span class="o">=</span> <span class="n">psdf</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

<span class="c1"># Check the pandas data types</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pdf</span><span class="o">.</span><span class="n">dtypes</span>
<span class="n">int8</span>                        <span class="n">int8</span>
<span class="nb">bool</span>                        <span class="nb">bool</span>
<span class="n">float32</span>                  <span class="n">float32</span>
<span class="n">float64</span>                  <span class="n">float64</span>
<span class="n">int32</span>                      <span class="n">int32</span>
<span class="n">int64</span>                      <span class="n">int64</span>
<span class="n">int16</span>                      <span class="n">int16</span>
<span class="n">datetime</span>          <span class="n">datetime64</span><span class="p">[</span><span class="n">ns</span><span class="p">]</span>
<span class="n">object_string</span>             <span class="nb">object</span>
<span class="n">object_decimal</span>            <span class="nb">object</span>
<span class="n">object_date</span>               <span class="nb">object</span>
<span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</pre></div>
</div>
<p>However, there are several data types only provided by pandas.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># pd.Catrgorical type is not supported in pandas API on Spark yet.</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])])</span>
<span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
<span class="o">...</span>
<span class="n">pyarrow</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">ArrowInvalid</span><span class="p">:</span> <span class="n">Could</span> <span class="ow">not</span> <span class="n">convert</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">Categories</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">int64</span><span class="p">):</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="k">with</span> <span class="nb">type</span> <span class="n">Categorical</span><span class="p">:</span> <span class="n">did</span> <span class="ow">not</span> <span class="n">recognize</span> <span class="n">Python</span> <span class="n">value</span> <span class="nb">type</span> <span class="n">when</span> <span class="n">inferring</span> <span class="n">an</span> <span class="n">Arrow</span> <span class="n">data</span> <span class="nb">type</span>
</pre></div>
</div>
<p>These kinds of pandas specific data types below are not currently supported in the pandas API on Spark but planned to be supported.</p>
<ul class="simple">
<li><p>pd.Timedelta</p></li>
<li><p>pd.Categorical</p></li>
<li><p>pd.CategoricalDtype</p></li>
</ul>
<p>The pandas specific data types below are not planned to be supported in the pandas API on Spark yet.</p>
<ul class="simple">
<li><p>pd.SparseDtype</p></li>
<li><p>pd.DatetimeTZDtype</p></li>
<li><p>pd.UInt*Dtype</p></li>
<li><p>pd.BooleanDtype</p></li>
<li><p>pd.StringDtype</p></li>
</ul>
</div>
<div class="section" id="internal-type-mapping">
<h2>Internal type mapping<a class="headerlink" href="#internal-type-mapping" title="Permalink to this headline">¶</a></h2>
<p>The table below shows which NumPy data types are matched to which PySpark data types internally in the pandas API on Spark.</p>
<table class="table">
<colgroup>
<col style="width: 36%" />
<col style="width: 64%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>NumPy</p></th>
<th class="head"><p>PySpark</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>np.character</p></td>
<td><p>BinaryType</p></td>
</tr>
<tr class="row-odd"><td><p>np.bytes_</p></td>
<td><p>BinaryType</p></td>
</tr>
<tr class="row-even"><td><p>np.string_</p></td>
<td><p>BinaryType</p></td>
</tr>
<tr class="row-odd"><td><p>np.int8</p></td>
<td><p>ByteType</p></td>
</tr>
<tr class="row-even"><td><p>np.byte</p></td>
<td><p>ByteType</p></td>
</tr>
<tr class="row-odd"><td><p>np.int16</p></td>
<td><p>ShortType</p></td>
</tr>
<tr class="row-even"><td><p>np.int32</p></td>
<td><p>IntegerType</p></td>
</tr>
<tr class="row-odd"><td><p>np.int64</p></td>
<td><p>LongType</p></td>
</tr>
<tr class="row-even"><td><p>np.float32</p></td>
<td><p>FloatType</p></td>
</tr>
<tr class="row-odd"><td><p>np.float64</p></td>
<td><p>DoubleType</p></td>
</tr>
<tr class="row-even"><td><p>np.unicode_</p></td>
<td><p>StringType</p></td>
</tr>
<tr class="row-odd"><td><p>np.datetime64</p></td>
<td><p>TimestampType</p></td>
</tr>
<tr class="row-even"><td><p>np.ndarray</p></td>
<td><p>ArrayType(StringType())</p></td>
</tr>
</tbody>
</table>
<p>The table below shows which Python data types are matched to which PySpark data types internally in pandas API on Spark.</p>
<table class="table">
<colgroup>
<col style="width: 47%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Python</p></th>
<th class="head"><p>PySpark</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>bytes</p></td>
<td><p>BinaryType</p></td>
</tr>
<tr class="row-odd"><td><p>int</p></td>
<td><p>LongType</p></td>
</tr>
<tr class="row-even"><td><p>float</p></td>
<td><p>DoubleType</p></td>
</tr>
<tr class="row-odd"><td><p>str</p></td>
<td><p>StringType</p></td>
</tr>
<tr class="row-even"><td><p>bool</p></td>
<td><p>BooleanType</p></td>
</tr>
<tr class="row-odd"><td><p>datetime.datetime</p></td>
<td><p>TimestampType</p></td>
</tr>
<tr class="row-even"><td><p>datetime.date</p></td>
<td><p>DateType</p></td>
</tr>
<tr class="row-odd"><td><p>decimal.Decimal</p></td>
<td><p>DecimalType(38, 18)</p></td>
</tr>
</tbody>
</table>
<p>For decimal type, pandas API on Spark uses Spark’s system default precision and scale.</p>
<p>You can check this mapping by using the <cite>as_spark_type</cite> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">typing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.pandas.typedef</span> <span class="kn">import</span> <span class="n">as_spark_type</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">as_spark_type</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="go">LongType</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">as_spark_type</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">IntegerType</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">as_spark_type</span><span class="p">(</span><span class="n">typing</span><span class="o">.</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">])</span>
<span class="go">ArrayType(DoubleType,true)</span>
</pre></div>
</div>
<p>You can also check the underlying PySpark data type of <cite>Series</cite> or schema of <cite>DataFrame</cite> by using Spark accessor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">data_type</span>
<span class="go">DoubleType</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="s2">&quot;welcome&quot;</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">,</span> <span class="s2">&quot;pandas-on-Spark&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">data_type</span>
<span class="go">StringType</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]])</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">data_type</span>
<span class="go">ArrayType(BooleanType,true)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;d&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="s2">&quot;s&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;welcome&quot;</span><span class="p">,</span> <span class="s2">&quot;to&quot;</span><span class="p">,</span> <span class="s2">&quot;pandas-on-Spark&quot;</span><span class="p">],</span> <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]})</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">print_schema</span><span class="p">()</span>
<span class="go">root</span>
<span class="go"> |-- d: double (nullable = false)</span>
<span class="go"> |-- s: string (nullable = false)</span>
<span class="go"> |-- b: boolean (nullable = false)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Pandas API on Spark currently does not support multiple types of data in a single column.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ps</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;A&quot;</span><span class="p">])</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="c">...</span>
<span class="gr">TypeError</span>: <span class="n">an integer is required (got type str)</span>
</pre></div>
</div>
</div>
</div>
</div>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="transform_apply.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Transform and apply a function</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="typehints.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Type Hints in Pandas API on Spark</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright .<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>