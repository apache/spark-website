
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>pyspark.ml.deepspeed.deepspeed_distributor &#8212; PySpark 3.5.0 documentation</title>
    
    <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="../../../../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/pyspark.css" />
    
    <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/language_data.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/deepspeed/deepspeed_distributor.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
    <!-- Matomo -->
    <script type="text/javascript">
        var _paq = window._paq = window._paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(["disableCookies"]);
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
            var u="https://analytics.apache.org/";
            _paq.push(['setTrackerUrl', u+'matomo.php']);
            _paq.push(['setSiteId', '40']);
            var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
            g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
        })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/spark-logo-reverse.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../index.html">
  Overview
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../user_guide/index.html">
  User Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../development/index.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../migration_guide/index.html">
  Migration Guides
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for pyspark.ml.deepspeed.deepspeed_distributor</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c1"># contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c1"># this work for additional information regarding copyright ownership.</span>
<span class="c1"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c1"># (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c1"># the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.ml.torch.distributor</span> <span class="kn">import</span> <span class="n">TorchDistributor</span>


<div class="viewcode-block" id="DeepspeedTorchDistributor"><a class="viewcode-back" href="../../../../reference/api/pyspark.ml.deepspeed.deepspeed_distributor.DeepspeedTorchDistributor.html#pyspark.ml.deepspeed.deepspeed_distributor.DeepspeedTorchDistributor">[docs]</a><span class="k">class</span> <span class="nc">DeepspeedTorchDistributor</span><span class="p">(</span><span class="n">TorchDistributor</span><span class="p">):</span>

    <span class="n">_DEEPSPEED_SSL_CONF</span> <span class="o">=</span> <span class="s2">&quot;deepspeed.spark.distributor.ignoreSsl&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">numGpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">nnodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">localMode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">useGpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">deepspeedConfig</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This class is used to run deepspeed training workloads with spark clusters.</span>
<span class="sd">        The user has the option to specify the number of gpus per node</span>
<span class="sd">        and the number of nodes (the same as if running from terminal),</span>
<span class="sd">        as well as specify a deepspeed configuration file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        numGpus: int</span>
<span class="sd">            The number of GPUs to use per node (analagous to num_gpus in deepspeed command).</span>
<span class="sd">        nnodes: int</span>
<span class="sd">            The number of nodes that should be used for the run.</span>
<span class="sd">        localMode: bool</span>
<span class="sd">            Whether or not to run the training in a distributed fashion or just locally.</span>
<span class="sd">        useGpu: bool</span>
<span class="sd">            Boolean flag to determine whether to utilize gpus.</span>
<span class="sd">        deepspeedConfig: Union[Dict[str,Any], str] or None:</span>
<span class="sd">            The configuration file to be used for launching the deepspeed application.</span>
<span class="sd">            If it&#39;s a dictionary containing the parameters, then we will create the file.</span>
<span class="sd">            If None, deepspeed will fall back to default parameters.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        Run Deepspeed training function on a single node</span>

<span class="sd">        &gt;&gt;&gt; def train(learning_rate):</span>
<span class="sd">        ...     import deepspeed</span>
<span class="sd">        ...     # rest of training function</span>
<span class="sd">        ...     return model</span>
<span class="sd">        &gt;&gt;&gt; distributor = DeepspeedTorchDistributor(</span>
<span class="sd">        ...     numGpus=4,</span>
<span class="sd">        ...     nnodes=1,</span>
<span class="sd">        ...     useGpu=True,</span>
<span class="sd">        ...     localMode=True,</span>
<span class="sd">        ...     deepspeedConfig=&quot;path/to/config.json&quot;)</span>
<span class="sd">        &gt;&gt;&gt; output = distributor.run(train, 0.01)</span>

<span class="sd">        Run Deepspeed training function on multiple nodes</span>

<span class="sd">        &gt;&gt;&gt; distributor = DeepspeedTorchDistributor(</span>
<span class="sd">        ...     numGpus=4,</span>
<span class="sd">        ...     nnodes=3,</span>
<span class="sd">        ...     useGpu=True,</span>
<span class="sd">        ...     localMode=False,</span>
<span class="sd">        ...     deepspeedConfig=&quot;path/to/config.json&quot;)</span>
<span class="sd">        &gt;&gt;&gt; output = distributor.run(train, 0.01)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_processes</span> <span class="o">=</span> <span class="n">numGpus</span> <span class="o">*</span> <span class="n">nnodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deepspeed_config</span> <span class="o">=</span> <span class="n">deepspeedConfig</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">num_processes</span><span class="p">,</span>
            <span class="n">localMode</span><span class="p">,</span>
            <span class="n">useGpu</span><span class="p">,</span>
            <span class="n">_ssl_conf</span><span class="o">=</span><span class="n">DeepspeedTorchDistributor</span><span class="o">.</span><span class="n">_DEEPSPEED_SSL_CONF</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cleanup_deepspeed_conf</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_deepspeed_config_path</span><span class="p">(</span><span class="n">deepspeed_config</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">deepspeed_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w+&quot;</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s2">&quot;.json&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">deepspeed_config</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">file</span><span class="o">.</span><span class="n">name</span>
        <span class="n">deepspeed_config_path</span> <span class="o">=</span> <span class="n">deepspeed_config</span>
        <span class="c1"># Empty value means the deepspeed will fall back to default settings.</span>
        <span class="k">if</span> <span class="n">deepspeed_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;&quot;</span>
        <span class="k">return</span> <span class="n">deepspeed_config_path</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_create_torchrun_command</span><span class="p">(</span>
        <span class="n">input_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">train_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">local_mode</span> <span class="o">=</span> <span class="n">input_params</span><span class="p">[</span><span class="s2">&quot;local_mode&quot;</span><span class="p">]</span>
        <span class="n">num_processes</span> <span class="o">=</span> <span class="n">input_params</span><span class="p">[</span><span class="s2">&quot;num_processes&quot;</span><span class="p">]</span>
        <span class="n">deepspeed_config</span> <span class="o">=</span> <span class="n">input_params</span><span class="p">[</span><span class="s2">&quot;deepspeed_config&quot;</span><span class="p">]</span>
        <span class="n">deepspeed_config_path</span> <span class="o">=</span> <span class="n">DeepspeedTorchDistributor</span><span class="o">.</span><span class="n">_get_deepspeed_config_path</span><span class="p">(</span>
            <span class="n">deepspeed_config</span>
        <span class="p">)</span>
        <span class="n">torchrun_args</span><span class="p">,</span> <span class="n">processes_per_node</span> <span class="o">=</span> <span class="n">TorchDistributor</span><span class="o">.</span><span class="n">_get_torchrun_args</span><span class="p">(</span>
            <span class="n">local_mode</span><span class="p">,</span> <span class="n">num_processes</span>
        <span class="p">)</span>
        <span class="n">args_string</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">args</span><span class="p">))</span>
        <span class="n">command_to_run</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span>
            <span class="s2">&quot;-m&quot;</span><span class="p">,</span>
            <span class="s2">&quot;torch.distributed.run&quot;</span><span class="p">,</span>
            <span class="o">*</span><span class="n">torchrun_args</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;--nproc_per_node=</span><span class="si">{</span><span class="n">processes_per_node</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">train_path</span><span class="p">,</span>
            <span class="o">*</span><span class="n">args_string</span><span class="p">,</span>
            <span class="s2">&quot;--deepspeed&quot;</span><span class="p">,</span>
        <span class="p">]</span>

        <span class="c1"># Don&#39;t have the deepspeed_config argument if no path is provided or no parameters set</span>
        <span class="k">if</span> <span class="n">deepspeed_config_path</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">command_to_run</span>
        <span class="k">return</span> <span class="n">command_to_run</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;--deepspeed_config&quot;</span><span class="p">,</span> <span class="n">deepspeed_config_path</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_run_training_on_pytorch_file</span><span class="p">(</span>
        <span class="n">input_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">train_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;DeepspeedTorchDistributor with pytorch file doesn&#39;t support keyword arguments&quot;</span>
            <span class="p">)</span>

        <span class="n">log_streaming_client</span> <span class="o">=</span> <span class="n">input_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;log_streaming_client&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">training_command</span> <span class="o">=</span> <span class="n">DeepspeedTorchDistributor</span><span class="o">.</span><span class="n">_create_torchrun_command</span><span class="p">(</span>
            <span class="n">input_params</span><span class="p">,</span> <span class="n">train_path</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span>
        <span class="p">)</span>
        <span class="n">DeepspeedTorchDistributor</span><span class="o">.</span><span class="n">_execute_command</span><span class="p">(</span>
            <span class="n">training_command</span><span class="p">,</span> <span class="n">log_streaming_client</span><span class="o">=</span><span class="n">log_streaming_client</span>
        <span class="p">)</span>

<div class="viewcode-block" id="DeepspeedTorchDistributor.run"><a class="viewcode-back" href="../../../../reference/api/pyspark.ml.deepspeed.deepspeed_distributor.DeepspeedTorchDistributor.html#pyspark.ml.deepspeed.deepspeed_distributor.DeepspeedTorchDistributor.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_object</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
        <span class="c1"># If the &quot;train_object&quot; is a string, then we assume it&#39;s a filepath.</span>
        <span class="c1"># Otherwise, we assume it&#39;s a function.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span>
            <span class="n">train_object</span><span class="p">,</span> <span class="n">DeepspeedTorchDistributor</span><span class="o">.</span><span class="n">_run_training_on_pytorch_file</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span></div></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright .<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>