
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>pyspark.sql.protobuf.functions &#8212; PySpark 3.5.0 documentation</title>
    
    <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="../../../../_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/pyspark.css" />
    
    <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/language_data.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="canonical" href="https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/protobuf/functions.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../index.html">
  <img src="../../../../_static/spark-logo-reverse.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../index.html">
  Overview
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../user_guide/index.html">
  User Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../reference/index.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../development/index.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../migration_guide/index.html">
  Migration Guides
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for pyspark.sql.protobuf.functions</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c1"># contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c1"># this work for additional information regarding copyright ownership.</span>
<span class="c1"># The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c1"># (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c1"># the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A collections of builtin protobuf functions</span>
<span class="sd">&quot;&quot;&quot;</span>


<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">from</span> <span class="nn">py4j.java_gateway</span> <span class="kn">import</span> <span class="n">JVMView</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.column</span> <span class="kn">import</span> <span class="n">Column</span><span class="p">,</span> <span class="n">_to_java_column</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.utils</span> <span class="kn">import</span> <span class="n">get_active_spark_context</span><span class="p">,</span> <span class="n">try_remote_protobuf_functions</span>
<span class="kn">from</span> <span class="nn">pyspark.util</span> <span class="kn">import</span> <span class="n">_print_missing_jar</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql._typing</span> <span class="kn">import</span> <span class="n">ColumnOrName</span>


<div class="viewcode-block" id="from_protobuf"><a class="viewcode-back" href="../../../../reference/pyspark.sql/api/pyspark.sql.protobuf.functions.from_protobuf.html#pyspark.sql.protobuf.functions.from_protobuf">[docs]</a><span class="nd">@try_remote_protobuf_functions</span>
<span class="k">def</span> <span class="nf">from_protobuf</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;ColumnOrName&quot;</span><span class="p">,</span>
    <span class="n">messageName</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">descFilePath</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">binaryDescriptorSet</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Column</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a binary column of Protobuf format into its corresponding catalyst value.</span>
<span class="sd">    The Protobuf definition is provided in one of these ways:</span>

<span class="sd">       - Protobuf descriptor file: E.g. a descriptor file created with</span>
<span class="sd">          `protoc --include_imports --descriptor_set_out=abc.desc abc.proto`</span>
<span class="sd">       - Protobuf descriptor as binary: Rather than file path as in previous option,</span>
<span class="sd">         we can provide the binary content of the file. This allows flexibility in how the</span>
<span class="sd">         descriptor set is created and fetched.</span>
<span class="sd">       - Jar containing Protobuf Java class: The jar containing Java class should be shaded.</span>
<span class="sd">         Specifically, `com.google.protobuf.*` should be shaded to</span>
<span class="sd">         `org.sparkproject.spark_protobuf.protobuf.*`.</span>
<span class="sd">         https://github.com/rangadi/shaded-protobuf-classes is useful to create shaded jar from</span>
<span class="sd">         Protobuf files. The jar file can be added with spark-submit option --jars.</span>

<span class="sd">    .. versionadded:: 3.4.0</span>

<span class="sd">    .. versionchanged:: 3.5.0</span>
<span class="sd">        Supports `binaryDescriptorSet` arg to pass binary descriptor directly.</span>
<span class="sd">        Supports Spark Connect.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : :class:`~pyspark.sql.Column` or str</span>
<span class="sd">        the binary column.</span>
<span class="sd">    messageName: str, optional</span>
<span class="sd">        the protobuf message name to look for in descriptor file, or</span>
<span class="sd">        The Protobuf class name when descFilePath parameter is not set.</span>
<span class="sd">        E.g. `com.example.protos.ExampleEvent`.</span>
<span class="sd">    descFilePath : str, optional</span>
<span class="sd">        The Protobuf descriptor file.</span>
<span class="sd">    options : dict, optional</span>
<span class="sd">        options to control how the protobuf record is parsed.</span>
<span class="sd">    binaryDescriptorSet: bytes, optional</span>
<span class="sd">        The Protobuf `FileDescriptorSet` serialized as binary.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Protobuf functionality is provided as an pluggable external module.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tempfile</span>
<span class="sd">    &gt;&gt;&gt; data = [(&quot;1&quot;, (2, &quot;Alice&quot;, 109200))]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;key STRING, value STRUCT&lt;age: INTEGER, name: STRING, score: LONG&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; desc_hex = str(&#39;0ACE010A41636F6E6E6563746F722F70726F746F6275662F7372632F746573742F726&#39;</span>
<span class="sd">    ...    &#39;5736F75726365732F70726F746F6275662F7079737061726B5F746573742E70726F746F121D6F72672E61&#39;</span>
<span class="sd">    ...    &#39;70616368652E737061726B2E73716C2E70726F746F627566224B0A0D53696D706C654D657373616765121&#39;</span>
<span class="sd">    ...    &#39;00A03616765180120012805520361676512120A046E616D6518022001280952046E616D6512140A057363&#39;</span>
<span class="sd">    ...    &#39;6F7265180320012803520573636F72654215421353696D706C654D65737361676550726F746F736206707&#39;</span>
<span class="sd">    ...    &#39;26F746F33&#39;)</span>
<span class="sd">    &gt;&gt;&gt; # Writing a protobuf description into a file, generated by using</span>
<span class="sd">    &gt;&gt;&gt; # connector/protobuf/src/test/resources/protobuf/pyspark_test.proto file</span>
<span class="sd">    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:</span>
<span class="sd">    ...     desc_file_path = &quot;%s/pyspark_test.desc&quot; % tmp_dir</span>
<span class="sd">    ...     with open(desc_file_path, &quot;wb&quot;) as f:</span>
<span class="sd">    ...         _ = f.write(bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...         f.flush()</span>
<span class="sd">    ...         message_name = &#39;SimpleMessage&#39;</span>
<span class="sd">    ...         proto_df = df.select(</span>
<span class="sd">    ...             to_protobuf(df.value, message_name, desc_file_path).alias(&quot;value&quot;))</span>
<span class="sd">    ...         proto_df.show(truncate=False)</span>
<span class="sd">    ...         proto_df_1 = proto_df.select( # With file name for descriptor</span>
<span class="sd">    ...             from_protobuf(proto_df.value, message_name, desc_file_path).alias(&quot;value&quot;))</span>
<span class="sd">    ...         proto_df_1.show(truncate=False)</span>
<span class="sd">    ...         proto_df_2 = proto_df.select( # With binary for descriptor</span>
<span class="sd">    ...             from_protobuf(proto_df.value, message_name,</span>
<span class="sd">    ...                           binaryDescriptorSet = bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...             .alias(&quot;value&quot;))</span>
<span class="sd">    ...         proto_df_2.show(truncate=False)</span>
<span class="sd">    +----------------------------------------+</span>
<span class="sd">    |value                                   |</span>
<span class="sd">    +----------------------------------------+</span>
<span class="sd">    |[08 02 12 05 41 6C 69 63 65 18 90 D5 06]|</span>
<span class="sd">    +----------------------------------------+</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |value             |</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |{2, Alice, 109200}|</span>
<span class="sd">    +------------------+</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |value             |</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |{2, Alice, 109200}|</span>
<span class="sd">    +------------------+</span>
<span class="sd">    &gt;&gt;&gt; data = [([(1668035962, 2020)])]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;value struct&lt;seconds: LONG, nanos: INT&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; message_class_name = &quot;org.sparkproject.spark_protobuf.protobuf.Timestamp&quot;</span>
<span class="sd">    &gt;&gt;&gt; to_proto_df = df.select(to_protobuf(df.value, message_class_name).alias(&quot;value&quot;))</span>
<span class="sd">    &gt;&gt;&gt; from_proto_df = to_proto_df.select(</span>
<span class="sd">    ...     from_protobuf(to_proto_df.value, message_class_name).alias(&quot;value&quot;))</span>
<span class="sd">    &gt;&gt;&gt; from_proto_df.show(truncate=False)</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |value             |</span>
<span class="sd">    +------------------+</span>
<span class="sd">    |{1668035962, 2020}|</span>
<span class="sd">    +------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sc</span> <span class="o">=</span> <span class="n">get_active_spark_context</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">binary_proto</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">binaryDescriptorSet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">binaryDescriptorSet</span>
        <span class="k">elif</span> <span class="n">descFilePath</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">_read_descriptor_set_file</span><span class="p">(</span><span class="n">descFilePath</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">binary_proto</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">from_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">binary_proto</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">from_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;&#39;JavaPackage&#39; object is not callable&quot;</span><span class="p">:</span>
            <span class="n">_print_missing_jar</span><span class="p">(</span><span class="s2">&quot;Protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
        <span class="k">raise</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span></div>


<div class="viewcode-block" id="to_protobuf"><a class="viewcode-back" href="../../../../reference/pyspark.sql/api/pyspark.sql.protobuf.functions.to_protobuf.html#pyspark.sql.protobuf.functions.to_protobuf">[docs]</a><span class="nd">@try_remote_protobuf_functions</span>
<span class="k">def</span> <span class="nf">to_protobuf</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;ColumnOrName&quot;</span><span class="p">,</span>
    <span class="n">messageName</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">descFilePath</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">binaryDescriptorSet</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Column</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a column into binary of protobuf format. The Protobuf definition is provided in one</span>
<span class="sd">    of these ways:</span>

<span class="sd">       - Protobuf descriptor file: E.g. a descriptor file created with</span>
<span class="sd">          `protoc --include_imports --descriptor_set_out=abc.desc abc.proto`</span>
<span class="sd">       - Protobuf descriptor as binary: Rather than file path as in previous option,</span>
<span class="sd">         we can provide the binary content of the file. This allows flexibility in how the</span>
<span class="sd">         descriptor set is created and fetched.</span>
<span class="sd">       - Jar containing Protobuf Java class: The jar containing Java class should be shaded.</span>
<span class="sd">         Specifically, `com.google.protobuf.*` should be shaded to</span>
<span class="sd">         `org.sparkproject.spark_protobuf.protobuf.*`.</span>
<span class="sd">         https://github.com/rangadi/shaded-protobuf-classes is useful to create shaded jar from</span>
<span class="sd">         Protobuf files. The jar file can be added with spark-submit option --jars.</span>

<span class="sd">    .. versionadded:: 3.4.0</span>

<span class="sd">    .. versionchanged:: 3.5.0</span>
<span class="sd">        Supports `binaryDescriptorSet` arg to pass binary descriptor directly.</span>
<span class="sd">        Supports Spark Connect.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : :class:`~pyspark.sql.Column` or str</span>
<span class="sd">        the data column.</span>
<span class="sd">    messageName: str, optional</span>
<span class="sd">        the protobuf message name to look for in descriptor file, or</span>
<span class="sd">        The Protobuf class name when descFilePath parameter is not set.</span>
<span class="sd">        E.g. `com.example.protos.ExampleEvent`.</span>
<span class="sd">    descFilePath : str, optional</span>
<span class="sd">        the Protobuf descriptor file.</span>
<span class="sd">    options : dict, optional</span>
<span class="sd">    binaryDescriptorSet: bytes, optional</span>
<span class="sd">        The Protobuf `FileDescriptorSet` serialized as binary.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Protobuf functionality is provided as a pluggable external module</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import tempfile</span>
<span class="sd">    &gt;&gt;&gt; data = [([(2, &quot;Alice&quot;, 13093020)])]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;value struct&lt;age: INTEGER, name: STRING, score: LONG&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; desc_hex = str(&#39;0ACE010A41636F6E6E6563746F722F70726F746F6275662F7372632F746573742F726&#39;</span>
<span class="sd">    ...    &#39;5736F75726365732F70726F746F6275662F7079737061726B5F746573742E70726F746F121D6F72672E61&#39;</span>
<span class="sd">    ...    &#39;70616368652E737061726B2E73716C2E70726F746F627566224B0A0D53696D706C654D657373616765121&#39;</span>
<span class="sd">    ...    &#39;00A03616765180120012805520361676512120A046E616D6518022001280952046E616D6512140A057363&#39;</span>
<span class="sd">    ...    &#39;6F7265180320012803520573636F72654215421353696D706C654D65737361676550726F746F736206707&#39;</span>
<span class="sd">    ...    &#39;26F746F33&#39;)</span>
<span class="sd">    &gt;&gt;&gt; # Writing a protobuf description into a file, generated by using</span>
<span class="sd">    &gt;&gt;&gt; # connector/protobuf/src/test/resources/protobuf/pyspark_test.proto file</span>
<span class="sd">    &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:</span>
<span class="sd">    ...     desc_file_path = &quot;%s/pyspark_test.desc&quot; % tmp_dir</span>
<span class="sd">    ...     with open(desc_file_path, &quot;wb&quot;) as f:</span>
<span class="sd">    ...         _ = f.write(bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...         f.flush()</span>
<span class="sd">    ...         message_name = &#39;SimpleMessage&#39;</span>
<span class="sd">    ...         proto_df = df.select( # With file name for descriptor</span>
<span class="sd">    ...             to_protobuf(df.value, message_name, desc_file_path).alias(&quot;suite&quot;))</span>
<span class="sd">    ...         proto_df.show(truncate=False)</span>
<span class="sd">    ...         proto_df_2 = df.select( # With binary for descriptor</span>
<span class="sd">    ...             to_protobuf(df.value, message_name,</span>
<span class="sd">    ...                         binaryDescriptorSet=bytearray.fromhex(desc_hex))</span>
<span class="sd">    ...             .alias(&quot;suite&quot;))</span>
<span class="sd">    ...         proto_df_2.show(truncate=False)</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |suite                                      |</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |[08 02 12 05 41 6C 69 63 65 18 9C 91 9F 06]|</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |suite                                      |</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    |[08 02 12 05 41 6C 69 63 65 18 9C 91 9F 06]|</span>
<span class="sd">    +-------------------------------------------+</span>
<span class="sd">    &gt;&gt;&gt; data = [([(1668035962, 2020)])]</span>
<span class="sd">    &gt;&gt;&gt; ddl_schema = &quot;value struct&lt;seconds: LONG, nanos: INT&gt;&quot;</span>
<span class="sd">    &gt;&gt;&gt; df = spark.createDataFrame(data, ddl_schema)</span>
<span class="sd">    &gt;&gt;&gt; message_class_name = &quot;org.sparkproject.spark_protobuf.protobuf.Timestamp&quot;</span>
<span class="sd">    &gt;&gt;&gt; proto_df = df.select(to_protobuf(df.value, message_class_name).alias(&quot;suite&quot;))</span>
<span class="sd">    &gt;&gt;&gt; proto_df.show(truncate=False)</span>
<span class="sd">    +----------------------------+</span>
<span class="sd">    |suite                       |</span>
<span class="sd">    +----------------------------+</span>
<span class="sd">    |[08 FA EA B0 9B 06 10 E4 0F]|</span>
<span class="sd">    +----------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sc</span> <span class="o">=</span> <span class="n">get_active_spark_context</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">binary_proto</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">binaryDescriptorSet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">binaryDescriptorSet</span>
        <span class="k">elif</span> <span class="n">descFilePath</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">binary_proto</span> <span class="o">=</span> <span class="n">_read_descriptor_set_file</span><span class="p">(</span><span class="n">descFilePath</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">binary_proto</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">to_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">binary_proto</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">jc</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">JVMView</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">_jvm</span><span class="p">)</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">to_protobuf</span><span class="p">(</span>
                <span class="n">_to_java_column</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">messageName</span><span class="p">,</span> <span class="n">options</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="p">)</span>

    <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;&#39;JavaPackage&#39; object is not callable&quot;</span><span class="p">:</span>
            <span class="n">_print_missing_jar</span><span class="p">(</span><span class="s2">&quot;Protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;protobuf&quot;</span><span class="p">,</span> <span class="n">sc</span><span class="o">.</span><span class="n">version</span><span class="p">)</span>
        <span class="k">raise</span>
    <span class="k">return</span> <span class="n">Column</span><span class="p">(</span><span class="n">jc</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_read_descriptor_set_file</span><span class="p">(</span><span class="n">filePath</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
    <span class="c1"># TODO(SPARK-43847): Throw structured errors like &quot;PROTOBUF_DESCRIPTOR_FILE_NOT_FOUND&quot; etc.</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filePath</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_test</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">sys</span>
    <span class="kn">from</span> <span class="nn">pyspark.testing.utils</span> <span class="kn">import</span> <span class="n">search_jar</span>

    <span class="n">protobuf_jar</span> <span class="o">=</span> <span class="n">search_jar</span><span class="p">(</span><span class="s2">&quot;connector/protobuf&quot;</span><span class="p">,</span> <span class="s2">&quot;spark-protobuf-assembly-&quot;</span><span class="p">,</span> <span class="s2">&quot;spark-protobuf&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">protobuf_jar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Skipping all Protobuf Python tests as the optional Protobuf project was &quot;</span>
            <span class="s2">&quot;not compiled into a JAR. To run these tests, &quot;</span>
            <span class="s2">&quot;you need to build Spark with &#39;build/sbt package&#39; or &quot;</span>
            <span class="s2">&quot;&#39;build/mvn package&#39; before running this test.&quot;</span>
        <span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">existing_args</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PYSPARK_SUBMIT_ARGS&quot;</span><span class="p">,</span> <span class="s2">&quot;pyspark-shell&quot;</span><span class="p">)</span>
        <span class="n">jars_args</span> <span class="o">=</span> <span class="s2">&quot;--jars </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">protobuf_jar</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYSPARK_SUBMIT_ARGS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">jars_args</span><span class="p">,</span> <span class="n">existing_args</span><span class="p">])</span>

    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
    <span class="kn">import</span> <span class="nn">pyspark.sql.protobuf.functions</span>

    <span class="n">globs</span> <span class="o">=</span> <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="s2">&quot;local[2]&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;sql.protobuf.functions tests&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">globs</span><span class="p">[</span><span class="s2">&quot;spark&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spark</span>
    <span class="p">(</span><span class="n">failure_count</span><span class="p">,</span> <span class="n">test_count</span><span class="p">)</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">(</span>
        <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">functions</span><span class="p">,</span>
        <span class="n">globs</span><span class="o">=</span><span class="n">globs</span><span class="p">,</span>
        <span class="n">optionflags</span><span class="o">=</span><span class="n">doctest</span><span class="o">.</span><span class="n">ELLIPSIS</span> <span class="o">|</span> <span class="n">doctest</span><span class="o">.</span><span class="n">NORMALIZE_WHITESPACE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">failure_count</span><span class="p">:</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">_test</span><span class="p">()</span>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright .<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.0.4.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>