
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>MLlib: Main Guide - Spark 2.0.1 Documentation</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="http://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html">
                      <img src="img/spark-logo-hd.png" style="height:50px;"/></a><span class="version">2.0.1</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">Overview</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Programming Guides<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">Quick Start</a></li>
                                <li><a href="programming-guide.html">Spark Programming Guide</a></li>
                                <li class="divider"></li>
                                <li><a href="streaming-programming-guide.html">Spark Streaming</a></li>
                                <li><a href="sql-programming-guide.html">DataFrames, Datasets and SQL</a></li>
                                <li><a href="structured-streaming-programming-guide.html">Structured Streaming</a></li>
                                <li><a href="ml-guide.html">MLlib (Machine Learning)</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX (Graph Processing)</a></li>
                                <li><a href="sparkr.html">SparkR (R on Spark)</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Docs<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">Scala</a></li>
                                <li><a href="api/java/index.html">Java</a></li>
                                <li><a href="api/python/index.html">Python</a></li>
                                <li><a href="api/R/index.html">R</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Deploying<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">Overview</a></li>
                                <li><a href="submitting-applications.html">Submitting Applications</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark Standalone</a></li>
                                <li><a href="running-on-mesos.html">Mesos</a></li>
                                <li><a href="running-on-yarn.html">YARN</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">More<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">Configuration</a></li>
                                <li><a href="monitoring.html">Monitoring</a></li>
                                <li><a href="tuning.html">Tuning Guide</a></li>
                                <li><a href="job-scheduling.html">Job Scheduling</a></li>
                                <li><a href="security.html">Security</a></li>
                                <li><a href="hardware-provisioning.html">Hardware Provisioning</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">Building Spark</a></li>
                                <li><a href="https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark">Contributing to Spark</a></li>
                                <li><a href="https://cwiki.apache.org/confluence/display/SPARK/Third+Party+Projects">Third Party Projects</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.0.1</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib: Main Guide</a></h3>
        
<ul>

    <li>
        <a href="ml-pipeline.html">
            
                Pipelines
            
        </a>
    </li>
    

    <li>
        <a href="ml-features.html">
            
                Extracting, transforming and selecting features
            
        </a>
    </li>
    

    <li>
        <a href="ml-classification-regression.html">
            
                Classification and Regression
            
        </a>
    </li>
    

    <li>
        <a href="ml-clustering.html">
            
                Clustering
            
        </a>
    </li>
    

    <li>
        <a href="ml-collaborative-filtering.html">
            
                Collaborative filtering
            
        </a>
    </li>
    

    <li>
        <a href="ml-tuning.html">
            
                Model selection and tuning
            
        </a>
    </li>
    

    <li>
        <a href="ml-advanced.html">
            
                Advanced topics
            
        </a>
    </li>
    

</ul>

        <h3><a href="mllib-guide.html">MLlib: RDD-based API Guide</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">
            
                Data types
            
        </a>
    </li>
    

    <li>
        <a href="mllib-statistics.html">
            
                Basic statistics
            
        </a>
    </li>
    

    <li>
        <a href="mllib-classification-regression.html">
            
                Classification and regression
            
        </a>
    </li>
    

    <li>
        <a href="mllib-collaborative-filtering.html">
            
                Collaborative filtering
            
        </a>
    </li>
    

    <li>
        <a href="mllib-clustering.html">
            
                Clustering
            
        </a>
    </li>
    

    <li>
        <a href="mllib-dimensionality-reduction.html">
            
                Dimensionality reduction
            
        </a>
    </li>
    

    <li>
        <a href="mllib-feature-extraction.html">
            
                Feature extraction and transformation
            
        </a>
    </li>
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">
            
                Frequent pattern mining
            
        </a>
    </li>
    

    <li>
        <a href="mllib-evaluation-metrics.html">
            
                Evaluation metrics
            
        </a>
    </li>
    

    <li>
        <a href="mllib-pmml-model-export.html">
            
                PMML model export
            
        </a>
    </li>
    

    <li>
        <a href="mllib-optimization.html">
            
                Optimization (developer)
            
        </a>
    </li>
    

</ul>

    </div>
</div>
                <input id="nav-trigger" class="nav-trigger" checked type="checkbox">
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">Machine Learning Library (MLlib) Guide</h1>
                    

                    <p>MLlib is Spark&#8217;s machine learning (ML) library.
Its goal is to make practical machine learning scalable and easy.
At a high level, it provides tools such as:</p>

<ul>
  <li>ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering</li>
  <li>Featurization: feature extraction, transformation, dimensionality reduction, and selection</li>
  <li>Pipelines: tools for constructing, evaluating, and tuning ML Pipelines</li>
  <li>Persistence: saving and load algorithms, models, and Pipelines</li>
  <li>Utilities: linear algebra, statistics, data handling, etc.</li>
</ul>

<h1 id="announcement-dataframe-based-api-is-primary-api">Announcement: DataFrame-based API is primary API</h1>

<p><strong>The MLlib RDD-based API is now in maintenance mode.</strong></p>

<p>As of Spark 2.0, the <a href="programming-guide.html#resilient-distributed-datasets-rdds">RDD</a>-based APIs in the <code>spark.mllib</code> package have entered maintenance mode.
The primary Machine Learning API for Spark is now the <a href="sql-programming-guide.html">DataFrame</a>-based API in the <code>spark.ml</code> package.</p>

<p><em>What are the implications?</em></p>

<ul>
  <li>MLlib will still support the RDD-based API in <code>spark.mllib</code> with bug fixes.</li>
  <li>MLlib will not add new features to the RDD-based API.</li>
  <li>In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.</li>
  <li>After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.</li>
  <li>The RDD-based API is expected to be removed in Spark 3.0.</li>
</ul>

<p><em>Why is MLlib switching to the DataFrame-based API?</em></p>

<ul>
  <li>DataFrames provide a more user-friendly API than RDDs.  The many benefits of DataFrames include Spark Datasources, SQL/DataFrame queries, Tungsten and Catalyst optimizations, and uniform APIs across languages.</li>
  <li>The DataFrame-based API for MLlib provides a uniform API across ML algorithms and across multiple languages.</li>
  <li>DataFrames facilitate practical ML Pipelines, particularly feature transformations.  See the <a href="ml-pipeline.html">Pipelines guide</a> for details.</li>
</ul>

<h1 id="dependencies">Dependencies</h1>

<p>MLlib uses the linear algebra package <a href="http://www.scalanlp.org/">Breeze</a>, which depends on
<a href="https://github.com/fommil/netlib-java">netlib-java</a> for optimised numerical processing.
If native libraries<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> are not available at runtime, you will see a warning message and a pure JVM
implementation will be used instead.</p>

<p>Due to licensing issues with runtime proprietary binaries, we do not include <code>netlib-java</code>&#8217;s native
proxies by default.
To configure <code>netlib-java</code> / Breeze to use system optimised binaries, include
<code>com.github.fommil.netlib:all:1.1.2</code> (or build Spark with <code>-Pnetlib-lgpl</code>) as a dependency of your
project and read the <a href="https://github.com/fommil/netlib-java">netlib-java</a> documentation for your
platform&#8217;s additional installation instructions.</p>

<p>To use MLlib in Python, you will need <a href="http://www.numpy.org">NumPy</a> version 1.4 or newer.</p>

<h1 id="migration-guide">Migration guide</h1>

<p>MLlib is under active development.
The APIs marked <code>Experimental</code>/<code>DeveloperApi</code> may change in future releases,
and the migration guide below will explain all changes between releases.</p>

<h2 id="from-16-to-20">From 1.6 to 2.0</h2>

<h3 id="breaking-changes">Breaking changes</h3>

<p>There were several breaking changes in Spark 2.0, which are outlined below.</p>

<p><strong>Linear algebra classes for DataFrame-based APIs</strong></p>

<p>Spark&#8217;s linear algebra dependencies were moved to a new project, <code>mllib-local</code> 
(see <a href="https://issues.apache.org/jira/browse/SPARK-13944">SPARK-13944</a>). 
As part of this change, the linear algebra classes were copied to a new package, <code>spark.ml.linalg</code>. 
The DataFrame-based APIs in <code>spark.ml</code> now depend on the <code>spark.ml.linalg</code> classes, 
leading to a few breaking changes, predominantly in various model classes 
(see <a href="https://issues.apache.org/jira/browse/SPARK-14810">SPARK-14810</a> for a full list).</p>

<p><strong>Note:</strong> the RDD-based APIs in <code>spark.mllib</code> continue to depend on the previous package <code>spark.mllib.linalg</code>.</p>

<p><em>Converting vectors and matrices</em></p>

<p>While most pipeline components support backward compatibility for loading, 
some existing <code>DataFrames</code> and pipelines in Spark versions prior to 2.0, that contain vector or matrix 
columns, may need to be migrated to the new <code>spark.ml</code> vector and matrix types. 
Utilities for converting <code>DataFrame</code> columns from <code>spark.mllib.linalg</code> to <code>spark.ml.linalg</code> types
(and vice versa) can be found in <code>spark.mllib.util.MLUtils</code>.</p>

<p>There are also utility methods available for converting single instances of 
vectors and matrices. Use the <code>asML</code> method on a <code>mllib.linalg.Vector</code> / <code>mllib.linalg.Matrix</code>
for converting to <code>ml.linalg</code> types, and 
<code>mllib.linalg.Vectors.fromML</code> / <code>mllib.linalg.Matrices.fromML</code> 
for converting to <code>mllib.linalg</code> types.</p>

<div class="codetabs">
<div data-lang="scala">

    <div class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span>

<span class="c1">// convert DataFrame columns</span>
<span class="k">val</span> <span class="n">convertedVecDF</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">convertVectorColumnsToML</span><span class="o">(</span><span class="n">vecDF</span><span class="o">)</span>
<span class="k">val</span> <span class="n">convertedMatrixDF</span> <span class="k">=</span> <span class="nc">MLUtils</span><span class="o">.</span><span class="n">convertMatrixColumnsToML</span><span class="o">(</span><span class="n">matrixDF</span><span class="o">)</span>
<span class="c1">// convert a single vector or matrix</span>
<span class="k">val</span> <span class="n">mlVec</span><span class="k">:</span> <span class="kt">org.apache.spark.ml.linalg.Vector</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="n">asML</span>
<span class="k">val</span> <span class="n">mlMat</span><span class="k">:</span> <span class="kt">org.apache.spark.ml.linalg.Matrix</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="n">asML</span></code></pre></div>

    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.mllib.util.MLUtils$"><code>MLUtils</code> Scala docs</a> for further detail.</p>
  </div>

<div data-lang="java">

    <div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.mllib.util.MLUtils</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>

<span class="c1">// convert DataFrame columns</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">convertedVecDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">convertVectorColumnsToML</span><span class="o">(</span><span class="n">vecDF</span><span class="o">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">convertedMatrixDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="na">convertMatrixColumnsToML</span><span class="o">(</span><span class="n">matrixDF</span><span class="o">);</span>
<span class="c1">// convert a single vector or matrix</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">ml</span><span class="o">.</span><span class="na">linalg</span><span class="o">.</span><span class="na">Vector</span> <span class="n">mlVec</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="na">asML</span><span class="o">();</span>
<span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">spark</span><span class="o">.</span><span class="na">ml</span><span class="o">.</span><span class="na">linalg</span><span class="o">.</span><span class="na">Matrix</span> <span class="n">mlMat</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="na">asML</span><span class="o">();</span></code></pre></div>

    <p>Refer to the <a href="api/java/org/apache/spark/mllib/util/MLUtils.html"><code>MLUtils</code> Java docs</a> for further detail.</p>
  </div>

<div data-lang="python">

    <div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">pyspark.mllib.util</span> <span class="kn">import</span> <span class="n">MLUtils</span>

<span class="c"># convert DataFrame columns</span>
<span class="n">convertedVecDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="n">convertVectorColumnsToML</span><span class="p">(</span><span class="n">vecDF</span><span class="p">)</span>
<span class="n">convertedMatrixDF</span> <span class="o">=</span> <span class="n">MLUtils</span><span class="o">.</span><span class="n">convertMatrixColumnsToML</span><span class="p">(</span><span class="n">matrixDF</span><span class="p">)</span>
<span class="c"># convert a single vector or matrix</span>
<span class="n">mlVec</span> <span class="o">=</span> <span class="n">mllibVec</span><span class="o">.</span><span class="n">asML</span><span class="p">()</span>
<span class="n">mlMat</span> <span class="o">=</span> <span class="n">mllibMat</span><span class="o">.</span><span class="n">asML</span><span class="p">()</span></code></pre></div>

    <p>Refer to the <a href="api/python/pyspark.mllib.html#pyspark.mllib.util.MLUtils"><code>MLUtils</code> Python docs</a> for further detail.</p>
  </div>
</div>

<p><strong>Deprecated methods removed</strong></p>

<p>Several deprecated methods were removed in the <code>spark.mllib</code> and <code>spark.ml</code> packages:</p>

<ul>
  <li><code>setScoreCol</code> in <code>ml.evaluation.BinaryClassificationEvaluator</code></li>
  <li><code>weights</code> in <code>LinearRegression</code> and <code>LogisticRegression</code> in <code>spark.ml</code></li>
  <li><code>setMaxNumIterations</code> in <code>mllib.optimization.LBFGS</code> (marked as <code>DeveloperApi</code>)</li>
  <li><code>treeReduce</code> and <code>treeAggregate</code> in <code>mllib.rdd.RDDFunctions</code> (these functions are available on <code>RDD</code>s directly, and were marked as <code>DeveloperApi</code>)</li>
  <li><code>defaultStategy</code> in <code>mllib.tree.configuration.Strategy</code></li>
  <li><code>build</code> in <code>mllib.tree.Node</code></li>
  <li>libsvm loaders for multiclass and load/save labeledData methods in <code>mllib.util.MLUtils</code></li>
</ul>

<p>A full list of breaking changes can be found at <a href="https://issues.apache.org/jira/browse/SPARK-14810">SPARK-14810</a>.</p>

<h3 id="deprecations-and-changes-of-behavior">Deprecations and changes of behavior</h3>

<p><strong>Deprecations</strong></p>

<p>Deprecations in the <code>spark.mllib</code> and <code>spark.ml</code> packages include:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14984">SPARK-14984</a>:
 In <code>spark.ml.regression.LinearRegressionSummary</code>, the <code>model</code> field has been deprecated.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13784">SPARK-13784</a>:
 In <code>spark.ml.regression.RandomForestRegressionModel</code> and <code>spark.ml.classification.RandomForestClassificationModel</code>,
 the <code>numTrees</code> parameter has been deprecated in favor of <code>getNumTrees</code> method.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13761">SPARK-13761</a>:
 In <code>spark.ml.param.Params</code>, the <code>validateParams</code> method has been deprecated.
 We move all functionality in overridden methods to the corresponding <code>transformSchema</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14829">SPARK-14829</a>:
 In <code>spark.mllib</code> package, <code>LinearRegressionWithSGD</code>, <code>LassoWithSGD</code>, <code>RidgeRegressionWithSGD</code> and <code>LogisticRegressionWithSGD</code> have been deprecated.
 We encourage users to use <code>spark.ml.regression.LinearRegresson</code> and <code>spark.ml.classification.LogisticRegresson</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14900">SPARK-14900</a>:
 In <code>spark.mllib.evaluation.MulticlassMetrics</code>, the parameters <code>precision</code>, <code>recall</code> and <code>fMeasure</code> have been deprecated in favor of <code>accuracy</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-15644">SPARK-15644</a>:
 In <code>spark.ml.util.MLReader</code> and <code>spark.ml.util.MLWriter</code>, the <code>context</code> method has been deprecated in favor of <code>session</code>.</li>
  <li>In <code>spark.ml.feature.ChiSqSelectorModel</code>, the <code>setLabelCol</code> method has been deprecated since it was not used by <code>ChiSqSelectorModel</code>.</li>
</ul>

<p><strong>Changes of behavior</strong></p>

<p>Changes of behavior in the <code>spark.mllib</code> and <code>spark.ml</code> packages include:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-7780">SPARK-7780</a>:
 <code>spark.mllib.classification.LogisticRegressionWithLBFGS</code> directly calls <code>spark.ml.classification.LogisticRegresson</code> for binary classification now.
 This will introduce the following behavior changes for <code>spark.mllib.classification.LogisticRegressionWithLBFGS</code>:
    <ul>
      <li>The intercept will not be regularized when training binary classification model with L1/L2 Updater.</li>
      <li>If users set without regularization, training with or without feature scaling will return the same solution by the same convergence rate.</li>
    </ul>
  </li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13429">SPARK-13429</a>:
 In order to provide better and consistent result with <code>spark.ml.classification.LogisticRegresson</code>,
 the default value of <code>spark.mllib.classification.LogisticRegressionWithLBFGS</code>: <code>convergenceTol</code> has been changed from 1E-4 to 1E-6.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-12363">SPARK-12363</a>:
 Fix a bug of <code>PowerIterationClustering</code> which will likely change its result.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13048">SPARK-13048</a>:
 <code>LDA</code> using the <code>EM</code> optimizer will keep the last checkpoint by default, if checkpointing is being used.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-12153">SPARK-12153</a>:
 <code>Word2Vec</code> now respects sentence boundaries. Previously, it did not handle them correctly.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-10574">SPARK-10574</a>:
 <code>HashingTF</code> uses <code>MurmurHash3</code> as default hash algorithm in both <code>spark.ml</code> and <code>spark.mllib</code>.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14768">SPARK-14768</a>:
 The <code>expectedType</code> argument for PySpark <code>Param</code> was removed.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-14931">SPARK-14931</a>:
 Some default <code>Param</code> values, which were mismatched between pipelines in Scala and Python, have been changed.</li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-13600">SPARK-13600</a>:
 <code>QuantileDiscretizer</code> now uses <code>spark.sql.DataFrameStatFunctions.approxQuantile</code> to find splits (previously used custom sampling logic).
 The output buckets will differ for same input data and params.</li>
</ul>

<h2 id="previous-spark-versions">Previous Spark versions</h2>

<p>Earlier migration guides are archived <a href="ml-migration-guides.html">on this page</a>.</p>

<hr />
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>To learn more about the benefits and background of system optimised natives, you may wish to
watch Sam Halliday&#8217;s ScalaX talk on <a href="http://fommil.github.io/scalax14/#/">High Performance Linear Algebra in Scala</a>. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.8.0.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    </body>
</html>
