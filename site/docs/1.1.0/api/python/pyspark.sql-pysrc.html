<?xml version="1.0" encoding="ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>pyspark.sql</title>
  <link rel="stylesheet" href="epydoc.css" type="text/css" />
  <script type="text/javascript" src="epydoc.js"></script>
</head>

<body bgcolor="white" text="black" link="blue" vlink="#204080"
      alink="#204080">
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.1.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table width="100%" cellpadding="0" cellspacing="0">
  <tr valign="top">
    <td width="100%">
      <span class="breadcrumbs">
        <a href="pyspark-module.html">Package&nbsp;pyspark</a> ::
        Module&nbsp;sql
      </span>
    </td>
    <td>
      <table cellpadding="0" cellspacing="0">
        <!-- hide/show private -->
        <tr><td align="right"><span class="options"
            >[<a href="frames.html" target="_top">frames</a
            >]&nbsp;|&nbsp;<a href="pyspark.sql-pysrc.html"
            target="_top">no&nbsp;frames</a>]</span></td></tr>
      </table>
    </td>
  </tr>
</table>
<h1 class="epydoc">Source Code for <a href="pyspark.sql-module.html">Module pyspark.sql</a></h1>
<pre class="py-src">
<a name="L1"></a><tt class="py-lineno">   1</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L2"></a><tt class="py-lineno">   2</tt>  <tt class="py-line"><tt class="py-comment"># Licensed to the Apache Software Foundation (ASF) under one or more</tt> </tt>
<a name="L3"></a><tt class="py-lineno">   3</tt>  <tt class="py-line"><tt class="py-comment"># contributor license agreements.  See the NOTICE file distributed with</tt> </tt>
<a name="L4"></a><tt class="py-lineno">   4</tt>  <tt class="py-line"><tt class="py-comment"># this work for additional information regarding copyright ownership.</tt> </tt>
<a name="L5"></a><tt class="py-lineno">   5</tt>  <tt class="py-line"><tt class="py-comment"># The ASF licenses this file to You under the Apache License, Version 2.0</tt> </tt>
<a name="L6"></a><tt class="py-lineno">   6</tt>  <tt class="py-line"><tt class="py-comment"># (the "License"); you may not use this file except in compliance with</tt> </tt>
<a name="L7"></a><tt class="py-lineno">   7</tt>  <tt class="py-line"><tt class="py-comment"># the License.  You may obtain a copy of the License at</tt> </tt>
<a name="L8"></a><tt class="py-lineno">   8</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L9"></a><tt class="py-lineno">   9</tt>  <tt class="py-line"><tt class="py-comment">#    http://www.apache.org/licenses/LICENSE-2.0</tt> </tt>
<a name="L10"></a><tt class="py-lineno">  10</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L11"></a><tt class="py-lineno">  11</tt>  <tt class="py-line"><tt class="py-comment"># Unless required by applicable law or agreed to in writing, software</tt> </tt>
<a name="L12"></a><tt class="py-lineno">  12</tt>  <tt class="py-line"><tt class="py-comment"># distributed under the License is distributed on an "AS IS" BASIS,</tt> </tt>
<a name="L13"></a><tt class="py-lineno">  13</tt>  <tt class="py-line"><tt class="py-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</tt> </tt>
<a name="L14"></a><tt class="py-lineno">  14</tt>  <tt class="py-line"><tt class="py-comment"># See the License for the specific language governing permissions and</tt> </tt>
<a name="L15"></a><tt class="py-lineno">  15</tt>  <tt class="py-line"><tt class="py-comment"># limitations under the License.</tt> </tt>
<a name="L16"></a><tt class="py-lineno">  16</tt>  <tt class="py-line"><tt class="py-comment">#</tt> </tt>
<a name="L17"></a><tt class="py-lineno">  17</tt>  <tt class="py-line"> </tt>
<a name="L18"></a><tt class="py-lineno">  18</tt>  <tt class="py-line"> </tt>
<a name="L19"></a><tt class="py-lineno">  19</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">sys</tt> </tt>
<a name="L20"></a><tt class="py-lineno">  20</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">types</tt> </tt>
<a name="L21"></a><tt class="py-lineno">  21</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">itertools</tt> </tt>
<a name="L22"></a><tt class="py-lineno">  22</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">warnings</tt> </tt>
<a name="L23"></a><tt class="py-lineno">  23</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">decimal</tt> </tt>
<a name="L24"></a><tt class="py-lineno">  24</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">datetime</tt> </tt>
<a name="L25"></a><tt class="py-lineno">  25</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">keyword</tt> </tt>
<a name="L26"></a><tt class="py-lineno">  26</tt>  <tt class="py-line"><tt class="py-keyword">import</tt> <tt class="py-name">warnings</tt> </tt>
<a name="L27"></a><tt class="py-lineno">  27</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">array</tt> <tt class="py-keyword">import</tt> <tt class="py-name">array</tt> </tt>
<a name="L28"></a><tt class="py-lineno">  28</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">operator</tt> <tt class="py-keyword">import</tt> <tt class="py-name">itemgetter</tt> </tt>
<a name="L29"></a><tt class="py-lineno">  29</tt>  <tt class="py-line"> </tt>
<a name="L30"></a><tt class="py-lineno">  30</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-0" class="py-name" targets="Package pyspark=pyspark-module.html"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-0', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-1" class="py-name" targets="Module pyspark.rdd=pyspark.rdd-module.html"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-1', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-keyword">import</tt> <tt id="link-2" class="py-name" targets="Class pyspark.rdd.RDD=pyspark.rdd.RDD-class.html"><a title="pyspark.rdd.RDD" class="py-name" href="#" onclick="return doclink('link-2', 'RDD', 'link-2');">RDD</a></tt><tt class="py-op">,</tt> <tt class="py-name">PipelinedRDD</tt> </tt>
<a name="L31"></a><tt class="py-lineno">  31</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt id="link-3" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-3', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-4" class="py-name" targets="Module pyspark.serializers=pyspark.serializers-module.html"><a title="pyspark.serializers" class="py-name" href="#" onclick="return doclink('link-4', 'serializers', 'link-4');">serializers</a></tt> <tt class="py-keyword">import</tt> <tt class="py-name">BatchedSerializer</tt><tt class="py-op">,</tt> <tt id="link-5" class="py-name" targets="Class pyspark.serializers.PickleSerializer=pyspark.serializers.PickleSerializer-class.html"><a title="pyspark.serializers.PickleSerializer" class="py-name" href="#" onclick="return doclink('link-5', 'PickleSerializer', 'link-5');">PickleSerializer</a></tt><tt class="py-op">,</tt> <tt class="py-name">CloudPickleSerializer</tt> </tt>
<a name="L32"></a><tt class="py-lineno">  32</tt>  <tt class="py-line"> </tt>
<a name="L33"></a><tt class="py-lineno">  33</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">itertools</tt> <tt class="py-keyword">import</tt> <tt class="py-name">chain</tt><tt class="py-op">,</tt> <tt class="py-name">ifilter</tt><tt class="py-op">,</tt> <tt class="py-name">imap</tt> </tt>
<a name="L34"></a><tt class="py-lineno">  34</tt>  <tt class="py-line"> </tt>
<a name="L35"></a><tt class="py-lineno">  35</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">py4j</tt><tt class="py-op">.</tt><tt class="py-name">protocol</tt> <tt class="py-keyword">import</tt> <tt class="py-name">Py4JError</tt> </tt>
<a name="L36"></a><tt class="py-lineno">  36</tt>  <tt class="py-line"><tt class="py-keyword">from</tt> <tt class="py-name">py4j</tt><tt class="py-op">.</tt><tt class="py-name">java_collections</tt> <tt class="py-keyword">import</tt> <tt class="py-name">ListConverter</tt><tt class="py-op">,</tt> <tt class="py-name">MapConverter</tt> </tt>
<a name="L37"></a><tt class="py-lineno">  37</tt>  <tt class="py-line"> </tt>
<a name="L38"></a><tt class="py-lineno">  38</tt>  <tt class="py-line"> </tt>
<a name="L39"></a><tt class="py-lineno">  39</tt>  <tt class="py-line"><tt class="py-name">__all__</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt> </tt>
<a name="L40"></a><tt class="py-lineno">  40</tt>  <tt class="py-line">    <tt class="py-string">"StringType"</tt><tt class="py-op">,</tt> <tt class="py-string">"BinaryType"</tt><tt class="py-op">,</tt> <tt class="py-string">"BooleanType"</tt><tt class="py-op">,</tt> <tt class="py-string">"TimestampType"</tt><tt class="py-op">,</tt> <tt class="py-string">"DecimalType"</tt><tt class="py-op">,</tt> </tt>
<a name="L41"></a><tt class="py-lineno">  41</tt>  <tt class="py-line">    <tt class="py-string">"DoubleType"</tt><tt class="py-op">,</tt> <tt class="py-string">"FloatType"</tt><tt class="py-op">,</tt> <tt class="py-string">"ByteType"</tt><tt class="py-op">,</tt> <tt class="py-string">"IntegerType"</tt><tt class="py-op">,</tt> <tt class="py-string">"LongType"</tt><tt class="py-op">,</tt> </tt>
<a name="L42"></a><tt class="py-lineno">  42</tt>  <tt class="py-line">    <tt class="py-string">"ShortType"</tt><tt class="py-op">,</tt> <tt class="py-string">"ArrayType"</tt><tt class="py-op">,</tt> <tt class="py-string">"MapType"</tt><tt class="py-op">,</tt> <tt class="py-string">"StructField"</tt><tt class="py-op">,</tt> <tt class="py-string">"StructType"</tt><tt class="py-op">,</tt> </tt>
<a name="L43"></a><tt class="py-lineno">  43</tt>  <tt class="py-line">    <tt class="py-string">"SQLContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"HiveContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"LocalHiveContext"</tt><tt class="py-op">,</tt> <tt class="py-string">"TestHiveContext"</tt><tt class="py-op">,</tt> </tt>
<a name="L44"></a><tt class="py-lineno">  44</tt>  <tt class="py-line">    <tt class="py-string">"SchemaRDD"</tt><tt class="py-op">,</tt> <tt class="py-string">"Row"</tt><tt class="py-op">]</tt> </tt>
<a name="DataType"></a><div id="DataType-def"><a name="L45"></a><tt class="py-lineno">  45</tt>  <tt class="py-line"> </tt>
<a name="L46"></a><tt class="py-lineno">  46</tt>  <tt class="py-line"> </tt>
<a name="L47"></a><tt class="py-lineno">  47</tt> <a class="py-toggle" href="#" id="DataType-toggle" onclick="return toggle('DataType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.DataType-class.html">DataType</a><tt class="py-op">(</tt><tt class="py-base-class">object</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DataType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="DataType-expanded"><a name="L48"></a><tt class="py-lineno">  48</tt>  <tt class="py-line"> </tt>
<a name="L49"></a><tt class="py-lineno">  49</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL DataType"""</tt> </tt>
<a name="L50"></a><tt class="py-lineno">  50</tt>  <tt class="py-line"> </tt>
<a name="DataType.__repr__"></a><div id="DataType.__repr__-def"><a name="L51"></a><tt class="py-lineno">  51</tt> <a class="py-toggle" href="#" id="DataType.__repr__-toggle" onclick="return toggle('DataType.__repr__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.DataType-class.html#__repr__">__repr__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DataType.__repr__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="DataType.__repr__-expanded"><a name="L52"></a><tt class="py-lineno">  52</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">.</tt><tt class="py-name">__name__</tt> </tt>
</div><a name="L53"></a><tt class="py-lineno">  53</tt>  <tt class="py-line"> </tt>
<a name="DataType.__hash__"></a><div id="DataType.__hash__-def"><a name="L54"></a><tt class="py-lineno">  54</tt> <a class="py-toggle" href="#" id="DataType.__hash__-toggle" onclick="return toggle('DataType.__hash__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.DataType-class.html#__hash__">__hash__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DataType.__hash__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="DataType.__hash__-expanded"><a name="L55"></a><tt class="py-lineno">  55</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">hash</tt><tt class="py-op">(</tt><tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L56"></a><tt class="py-lineno">  56</tt>  <tt class="py-line"> </tt>
<a name="DataType.__eq__"></a><div id="DataType.__eq__-def"><a name="L57"></a><tt class="py-lineno">  57</tt> <a class="py-toggle" href="#" id="DataType.__eq__-toggle" onclick="return toggle('DataType.__eq__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.DataType-class.html#__eq__">__eq__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DataType.__eq__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="DataType.__eq__-expanded"><a name="L58"></a><tt class="py-lineno">  58</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> </tt>
<a name="L59"></a><tt class="py-lineno">  59</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt> <tt class="py-op">==</tt> <tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt><tt class="py-op">)</tt> </tt>
</div><a name="L60"></a><tt class="py-lineno">  60</tt>  <tt class="py-line"> </tt>
<a name="DataType.__ne__"></a><div id="DataType.__ne__-def"><a name="L61"></a><tt class="py-lineno">  61</tt> <a class="py-toggle" href="#" id="DataType.__ne__-toggle" onclick="return toggle('DataType.__ne__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.DataType-class.html#__ne__">__ne__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DataType.__ne__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="DataType.__ne__-expanded"><a name="L62"></a><tt class="py-lineno">  62</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">not</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-6" class="py-name" targets="Method pyspark.mllib.linalg.SparseVector.__eq__()=pyspark.mllib.linalg.SparseVector-class.html#__eq__"><a title="pyspark.mllib.linalg.SparseVector.__eq__" class="py-name" href="#" onclick="return doclink('link-6', '__eq__', 'link-6');">__eq__</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L63"></a><tt class="py-lineno">  63</tt>  <tt class="py-line"> </tt>
<a name="PrimitiveTypeSingleton"></a><div id="PrimitiveTypeSingleton-def"><a name="L64"></a><tt class="py-lineno">  64</tt>  <tt class="py-line"> </tt>
<a name="L65"></a><tt class="py-lineno">  65</tt> <a class="py-toggle" href="#" id="PrimitiveTypeSingleton-toggle" onclick="return toggle('PrimitiveTypeSingleton');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.PrimitiveTypeSingleton-class.html">PrimitiveTypeSingleton</a><tt class="py-op">(</tt><tt class="py-base-class">type</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PrimitiveTypeSingleton-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="PrimitiveTypeSingleton-expanded"><a name="L66"></a><tt class="py-lineno">  66</tt>  <tt class="py-line"> </tt>
<a name="L67"></a><tt class="py-lineno">  67</tt>  <tt class="py-line">    <tt class="py-docstring">"""Metaclass for PrimitiveType"""</tt> </tt>
<a name="L68"></a><tt class="py-lineno">  68</tt>  <tt class="py-line"> </tt>
<a name="L69"></a><tt class="py-lineno">  69</tt>  <tt class="py-line">    <tt id="link-7" class="py-name" targets="Variable pyspark.sql.PrimitiveTypeSingleton._instances=pyspark.sql.PrimitiveTypeSingleton-class.html#_instances"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-7', '_instances', 'link-7');">_instances</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-op">}</tt> </tt>
<a name="L70"></a><tt class="py-lineno">  70</tt>  <tt class="py-line"> </tt>
<a name="PrimitiveTypeSingleton.__call__"></a><div id="PrimitiveTypeSingleton.__call__-def"><a name="L71"></a><tt class="py-lineno">  71</tt> <a class="py-toggle" href="#" id="PrimitiveTypeSingleton.__call__-toggle" onclick="return toggle('PrimitiveTypeSingleton.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.PrimitiveTypeSingleton-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">cls</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PrimitiveTypeSingleton.__call__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="PrimitiveTypeSingleton.__call__-expanded"><a name="L72"></a><tt class="py-lineno">  72</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">cls</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt class="py-name">cls</tt><tt class="py-op">.</tt><tt id="link-8" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-8', '_instances', 'link-7');">_instances</a></tt><tt class="py-op">:</tt> </tt>
<a name="L73"></a><tt class="py-lineno">  73</tt>  <tt class="py-line">            <tt class="py-name">cls</tt><tt class="py-op">.</tt><tt id="link-9" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-9', '_instances', 'link-7');">_instances</a></tt><tt class="py-op">[</tt><tt class="py-name">cls</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">super</tt><tt class="py-op">(</tt><tt id="link-10" class="py-name" targets="Class pyspark.sql.PrimitiveTypeSingleton=pyspark.sql.PrimitiveTypeSingleton-class.html"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-10', 'PrimitiveTypeSingleton', 'link-10');">PrimitiveTypeSingleton</a></tt><tt class="py-op">,</tt> <tt class="py-name">cls</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-11" class="py-name" targets="Method pyspark.sql.PrimitiveTypeSingleton.__call__()=pyspark.sql.PrimitiveTypeSingleton-class.html#__call__,Method pyspark.sql.Row.__call__()=pyspark.sql.Row-class.html#__call__"><a title="pyspark.sql.PrimitiveTypeSingleton.__call__
pyspark.sql.Row.__call__" class="py-name" href="#" onclick="return doclink('link-11', '__call__', 'link-11');">__call__</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L74"></a><tt class="py-lineno">  74</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">cls</tt><tt class="py-op">.</tt><tt id="link-12" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton._instances" class="py-name" href="#" onclick="return doclink('link-12', '_instances', 'link-7');">_instances</a></tt><tt class="py-op">[</tt><tt class="py-name">cls</tt><tt class="py-op">]</tt> </tt>
</div></div><a name="L75"></a><tt class="py-lineno">  75</tt>  <tt class="py-line"> </tt>
<a name="PrimitiveType"></a><div id="PrimitiveType-def"><a name="L76"></a><tt class="py-lineno">  76</tt>  <tt class="py-line"> </tt>
<a name="L77"></a><tt class="py-lineno">  77</tt> <a class="py-toggle" href="#" id="PrimitiveType-toggle" onclick="return toggle('PrimitiveType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.PrimitiveType-class.html">PrimitiveType</a><tt class="py-op">(</tt><tt class="py-base-class">DataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PrimitiveType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="PrimitiveType-expanded"><a name="L78"></a><tt class="py-lineno">  78</tt>  <tt class="py-line"> </tt>
<a name="L79"></a><tt class="py-lineno">  79</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL PrimitiveType"""</tt> </tt>
<a name="L80"></a><tt class="py-lineno">  80</tt>  <tt class="py-line"> </tt>
<a name="L81"></a><tt class="py-lineno">  81</tt>  <tt class="py-line">    <tt class="py-name">__metaclass__</tt> <tt class="py-op">=</tt> <tt id="link-13" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-13', 'PrimitiveTypeSingleton', 'link-10');">PrimitiveTypeSingleton</a></tt> </tt>
<a name="L82"></a><tt class="py-lineno">  82</tt>  <tt class="py-line"> </tt>
<a name="PrimitiveType.__eq__"></a><div id="PrimitiveType.__eq__-def"><a name="L83"></a><tt class="py-lineno">  83</tt> <a class="py-toggle" href="#" id="PrimitiveType.__eq__-toggle" onclick="return toggle('PrimitiveType.__eq__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.PrimitiveType-class.html#__eq__">__eq__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="PrimitiveType.__eq__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="PrimitiveType.__eq__-expanded"><a name="L84"></a><tt class="py-lineno">  84</tt>  <tt class="py-line">        <tt class="py-comment"># because they should be the same object</tt> </tt>
<a name="L85"></a><tt class="py-lineno">  85</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> <tt class="py-keyword">is</tt> <tt class="py-name">other</tt> </tt>
</div></div><a name="L86"></a><tt class="py-lineno">  86</tt>  <tt class="py-line"> </tt>
<a name="StringType"></a><div id="StringType-def"><a name="L87"></a><tt class="py-lineno">  87</tt>  <tt class="py-line"> </tt>
<a name="L88"></a><tt class="py-lineno">  88</tt> <a class="py-toggle" href="#" id="StringType-toggle" onclick="return toggle('StringType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.StringType-class.html">StringType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StringType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="StringType-expanded"><a name="L89"></a><tt class="py-lineno">  89</tt>  <tt class="py-line"> </tt>
<a name="L90"></a><tt class="py-lineno">  90</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL StringType</tt> </tt>
<a name="L91"></a><tt class="py-lineno">  91</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L92"></a><tt class="py-lineno">  92</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing string values.</tt> </tt>
<a name="L93"></a><tt class="py-lineno">  93</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L94"></a><tt class="py-lineno">  94</tt>  <tt class="py-line"> </tt>
<a name="BinaryType"></a><div id="BinaryType-def"><a name="L95"></a><tt class="py-lineno">  95</tt>  <tt class="py-line"> </tt>
<a name="L96"></a><tt class="py-lineno">  96</tt> <a class="py-toggle" href="#" id="BinaryType-toggle" onclick="return toggle('BinaryType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.BinaryType-class.html">BinaryType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="BinaryType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="BinaryType-expanded"><a name="L97"></a><tt class="py-lineno">  97</tt>  <tt class="py-line"> </tt>
<a name="L98"></a><tt class="py-lineno">  98</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL BinaryType</tt> </tt>
<a name="L99"></a><tt class="py-lineno">  99</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L100"></a><tt class="py-lineno"> 100</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing bytearray values.</tt> </tt>
<a name="L101"></a><tt class="py-lineno"> 101</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L102"></a><tt class="py-lineno"> 102</tt>  <tt class="py-line"> </tt>
<a name="BooleanType"></a><div id="BooleanType-def"><a name="L103"></a><tt class="py-lineno"> 103</tt>  <tt class="py-line"> </tt>
<a name="L104"></a><tt class="py-lineno"> 104</tt> <a class="py-toggle" href="#" id="BooleanType-toggle" onclick="return toggle('BooleanType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.BooleanType-class.html">BooleanType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="BooleanType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="BooleanType-expanded"><a name="L105"></a><tt class="py-lineno"> 105</tt>  <tt class="py-line"> </tt>
<a name="L106"></a><tt class="py-lineno"> 106</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL BooleanType</tt> </tt>
<a name="L107"></a><tt class="py-lineno"> 107</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L108"></a><tt class="py-lineno"> 108</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing bool values.</tt> </tt>
<a name="L109"></a><tt class="py-lineno"> 109</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L110"></a><tt class="py-lineno"> 110</tt>  <tt class="py-line"> </tt>
<a name="TimestampType"></a><div id="TimestampType-def"><a name="L111"></a><tt class="py-lineno"> 111</tt>  <tt class="py-line"> </tt>
<a name="L112"></a><tt class="py-lineno"> 112</tt> <a class="py-toggle" href="#" id="TimestampType-toggle" onclick="return toggle('TimestampType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.TimestampType-class.html">TimestampType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TimestampType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="TimestampType-expanded"><a name="L113"></a><tt class="py-lineno"> 113</tt>  <tt class="py-line"> </tt>
<a name="L114"></a><tt class="py-lineno"> 114</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL TimestampType</tt> </tt>
<a name="L115"></a><tt class="py-lineno"> 115</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L116"></a><tt class="py-lineno"> 116</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing datetime.datetime values.</tt> </tt>
<a name="L117"></a><tt class="py-lineno"> 117</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L118"></a><tt class="py-lineno"> 118</tt>  <tt class="py-line"> </tt>
<a name="DecimalType"></a><div id="DecimalType-def"><a name="L119"></a><tt class="py-lineno"> 119</tt>  <tt class="py-line"> </tt>
<a name="L120"></a><tt class="py-lineno"> 120</tt> <a class="py-toggle" href="#" id="DecimalType-toggle" onclick="return toggle('DecimalType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.DecimalType-class.html">DecimalType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DecimalType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="DecimalType-expanded"><a name="L121"></a><tt class="py-lineno"> 121</tt>  <tt class="py-line"> </tt>
<a name="L122"></a><tt class="py-lineno"> 122</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL DecimalType</tt> </tt>
<a name="L123"></a><tt class="py-lineno"> 123</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L124"></a><tt class="py-lineno"> 124</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing decimal.Decimal values.</tt> </tt>
<a name="L125"></a><tt class="py-lineno"> 125</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L126"></a><tt class="py-lineno"> 126</tt>  <tt class="py-line"> </tt>
<a name="DoubleType"></a><div id="DoubleType-def"><a name="L127"></a><tt class="py-lineno"> 127</tt>  <tt class="py-line"> </tt>
<a name="L128"></a><tt class="py-lineno"> 128</tt> <a class="py-toggle" href="#" id="DoubleType-toggle" onclick="return toggle('DoubleType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.DoubleType-class.html">DoubleType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="DoubleType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="DoubleType-expanded"><a name="L129"></a><tt class="py-lineno"> 129</tt>  <tt class="py-line"> </tt>
<a name="L130"></a><tt class="py-lineno"> 130</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL DoubleType</tt> </tt>
<a name="L131"></a><tt class="py-lineno"> 131</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L132"></a><tt class="py-lineno"> 132</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing float values.</tt> </tt>
<a name="L133"></a><tt class="py-lineno"> 133</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L134"></a><tt class="py-lineno"> 134</tt>  <tt class="py-line"> </tt>
<a name="FloatType"></a><div id="FloatType-def"><a name="L135"></a><tt class="py-lineno"> 135</tt>  <tt class="py-line"> </tt>
<a name="L136"></a><tt class="py-lineno"> 136</tt> <a class="py-toggle" href="#" id="FloatType-toggle" onclick="return toggle('FloatType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.FloatType-class.html">FloatType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="FloatType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="FloatType-expanded"><a name="L137"></a><tt class="py-lineno"> 137</tt>  <tt class="py-line"> </tt>
<a name="L138"></a><tt class="py-lineno"> 138</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL FloatType</tt> </tt>
<a name="L139"></a><tt class="py-lineno"> 139</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L140"></a><tt class="py-lineno"> 140</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing single precision floating-point values.</tt> </tt>
<a name="L141"></a><tt class="py-lineno"> 141</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L142"></a><tt class="py-lineno"> 142</tt>  <tt class="py-line"> </tt>
<a name="ByteType"></a><div id="ByteType-def"><a name="L143"></a><tt class="py-lineno"> 143</tt>  <tt class="py-line"> </tt>
<a name="L144"></a><tt class="py-lineno"> 144</tt> <a class="py-toggle" href="#" id="ByteType-toggle" onclick="return toggle('ByteType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.ByteType-class.html">ByteType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ByteType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="ByteType-expanded"><a name="L145"></a><tt class="py-lineno"> 145</tt>  <tt class="py-line"> </tt>
<a name="L146"></a><tt class="py-lineno"> 146</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL ByteType</tt> </tt>
<a name="L147"></a><tt class="py-lineno"> 147</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L148"></a><tt class="py-lineno"> 148</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing int values with 1 singed byte.</tt> </tt>
<a name="L149"></a><tt class="py-lineno"> 149</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L150"></a><tt class="py-lineno"> 150</tt>  <tt class="py-line"> </tt>
<a name="IntegerType"></a><div id="IntegerType-def"><a name="L151"></a><tt class="py-lineno"> 151</tt>  <tt class="py-line"> </tt>
<a name="L152"></a><tt class="py-lineno"> 152</tt> <a class="py-toggle" href="#" id="IntegerType-toggle" onclick="return toggle('IntegerType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.IntegerType-class.html">IntegerType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="IntegerType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="IntegerType-expanded"><a name="L153"></a><tt class="py-lineno"> 153</tt>  <tt class="py-line"> </tt>
<a name="L154"></a><tt class="py-lineno"> 154</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL IntegerType</tt> </tt>
<a name="L155"></a><tt class="py-lineno"> 155</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L156"></a><tt class="py-lineno"> 156</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing int values.</tt> </tt>
<a name="L157"></a><tt class="py-lineno"> 157</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L158"></a><tt class="py-lineno"> 158</tt>  <tt class="py-line"> </tt>
<a name="LongType"></a><div id="LongType-def"><a name="L159"></a><tt class="py-lineno"> 159</tt>  <tt class="py-line"> </tt>
<a name="L160"></a><tt class="py-lineno"> 160</tt> <a class="py-toggle" href="#" id="LongType-toggle" onclick="return toggle('LongType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.LongType-class.html">LongType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LongType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="LongType-expanded"><a name="L161"></a><tt class="py-lineno"> 161</tt>  <tt class="py-line"> </tt>
<a name="L162"></a><tt class="py-lineno"> 162</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL LongType</tt> </tt>
<a name="L163"></a><tt class="py-lineno"> 163</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L164"></a><tt class="py-lineno"> 164</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing long values. If the any value is</tt> </tt>
<a name="L165"></a><tt class="py-lineno"> 165</tt>  <tt class="py-line"><tt class="py-docstring">    beyond the range of [-9223372036854775808, 9223372036854775807],</tt> </tt>
<a name="L166"></a><tt class="py-lineno"> 166</tt>  <tt class="py-line"><tt class="py-docstring">    please use DecimalType.</tt> </tt>
<a name="L167"></a><tt class="py-lineno"> 167</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L168"></a><tt class="py-lineno"> 168</tt>  <tt class="py-line"> </tt>
<a name="ShortType"></a><div id="ShortType-def"><a name="L169"></a><tt class="py-lineno"> 169</tt>  <tt class="py-line"> </tt>
<a name="L170"></a><tt class="py-lineno"> 170</tt> <a class="py-toggle" href="#" id="ShortType-toggle" onclick="return toggle('ShortType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.ShortType-class.html">ShortType</a><tt class="py-op">(</tt><tt class="py-base-class">PrimitiveType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ShortType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="ShortType-expanded"><a name="L171"></a><tt class="py-lineno"> 171</tt>  <tt class="py-line"> </tt>
<a name="L172"></a><tt class="py-lineno"> 172</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL ShortType</tt> </tt>
<a name="L173"></a><tt class="py-lineno"> 173</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L174"></a><tt class="py-lineno"> 174</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing int values with 2 signed bytes.</tt> </tt>
<a name="L175"></a><tt class="py-lineno"> 175</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
</div><a name="L176"></a><tt class="py-lineno"> 176</tt>  <tt class="py-line"> </tt>
<a name="ArrayType"></a><div id="ArrayType-def"><a name="L177"></a><tt class="py-lineno"> 177</tt>  <tt class="py-line"> </tt>
<a name="L178"></a><tt class="py-lineno"> 178</tt> <a class="py-toggle" href="#" id="ArrayType-toggle" onclick="return toggle('ArrayType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html">ArrayType</a><tt class="py-op">(</tt><tt class="py-base-class">DataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="ArrayType-expanded"><a name="L179"></a><tt class="py-lineno"> 179</tt>  <tt class="py-line"> </tt>
<a name="L180"></a><tt class="py-lineno"> 180</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL ArrayType</tt> </tt>
<a name="L181"></a><tt class="py-lineno"> 181</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L182"></a><tt class="py-lineno"> 182</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing list values. An ArrayType object</tt> </tt>
<a name="L183"></a><tt class="py-lineno"> 183</tt>  <tt class="py-line"><tt class="py-docstring">    comprises two fields, elementType (a DataType) and containsNull (a bool).</tt> </tt>
<a name="L184"></a><tt class="py-lineno"> 184</tt>  <tt class="py-line"><tt class="py-docstring">    The field of elementType is used to specify the type of array elements.</tt> </tt>
<a name="L185"></a><tt class="py-lineno"> 185</tt>  <tt class="py-line"><tt class="py-docstring">    The field of containsNull is used to specify if the array has None values.</tt> </tt>
<a name="L186"></a><tt class="py-lineno"> 186</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L187"></a><tt class="py-lineno"> 187</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L188"></a><tt class="py-lineno"> 188</tt>  <tt class="py-line"> </tt>
<a name="ArrayType.__init__"></a><div id="ArrayType.__init__-def"><a name="L189"></a><tt class="py-lineno"> 189</tt> <a class="py-toggle" href="#" id="ArrayType.__init__-toggle" onclick="return toggle('ArrayType.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">elementType</tt><tt class="py-op">,</tt> <tt class="py-param">containsNull</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ArrayType.__init__-expanded"><a name="L190"></a><tt class="py-lineno"> 190</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates an ArrayType</tt> </tt>
<a name="L191"></a><tt class="py-lineno"> 191</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L192"></a><tt class="py-lineno"> 192</tt>  <tt class="py-line"><tt class="py-docstring">        :param elementType: the data type of elements.</tt> </tt>
<a name="L193"></a><tt class="py-lineno"> 193</tt>  <tt class="py-line"><tt class="py-docstring">        :param containsNull: indicates whether the list contains None values.</tt> </tt>
<a name="L194"></a><tt class="py-lineno"> 194</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L195"></a><tt class="py-lineno"> 195</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ArrayType(StringType) == ArrayType(StringType, True)</tt> </tt>
<a name="L196"></a><tt class="py-lineno"> 196</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L197"></a><tt class="py-lineno"> 197</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ArrayType(StringType, False) == ArrayType(StringType)</tt> </tt>
<a name="L198"></a><tt class="py-lineno"> 198</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L199"></a><tt class="py-lineno"> 199</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L200"></a><tt class="py-lineno"> 200</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt> <tt class="py-op">=</tt> <tt class="py-name">elementType</tt> </tt>
<a name="L201"></a><tt class="py-lineno"> 201</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">containsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">containsNull</tt> </tt>
</div><a name="L202"></a><tt class="py-lineno"> 202</tt>  <tt class="py-line"> </tt>
<a name="ArrayType.__str__"></a><div id="ArrayType.__str__-def"><a name="L203"></a><tt class="py-lineno"> 203</tt> <a class="py-toggle" href="#" id="ArrayType.__str__-toggle" onclick="return toggle('ArrayType.__str__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.ArrayType-class.html#__str__">__str__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="ArrayType.__str__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="ArrayType.__str__-expanded"><a name="L204"></a><tt class="py-lineno"> 204</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"ArrayType(%s,%s)"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">,</tt> </tt>
<a name="L205"></a><tt class="py-lineno"> 205</tt>  <tt class="py-line">                                     <tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">containsNull</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L206"></a><tt class="py-lineno"> 206</tt>  <tt class="py-line"> </tt>
<a name="MapType"></a><div id="MapType-def"><a name="L207"></a><tt class="py-lineno"> 207</tt>  <tt class="py-line"> </tt>
<a name="L208"></a><tt class="py-lineno"> 208</tt> <a class="py-toggle" href="#" id="MapType-toggle" onclick="return toggle('MapType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html">MapType</a><tt class="py-op">(</tt><tt class="py-base-class">DataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="MapType-expanded"><a name="L209"></a><tt class="py-lineno"> 209</tt>  <tt class="py-line"> </tt>
<a name="L210"></a><tt class="py-lineno"> 210</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL MapType</tt> </tt>
<a name="L211"></a><tt class="py-lineno"> 211</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L212"></a><tt class="py-lineno"> 212</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing dict values. A MapType object comprises</tt> </tt>
<a name="L213"></a><tt class="py-lineno"> 213</tt>  <tt class="py-line"><tt class="py-docstring">    three fields, keyType (a DataType), valueType (a DataType) and</tt> </tt>
<a name="L214"></a><tt class="py-lineno"> 214</tt>  <tt class="py-line"><tt class="py-docstring">    valueContainsNull (a bool).</tt> </tt>
<a name="L215"></a><tt class="py-lineno"> 215</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L216"></a><tt class="py-lineno"> 216</tt>  <tt class="py-line"><tt class="py-docstring">    The field of keyType is used to specify the type of keys in the map.</tt> </tt>
<a name="L217"></a><tt class="py-lineno"> 217</tt>  <tt class="py-line"><tt class="py-docstring">    The field of valueType is used to specify the type of values in the map.</tt> </tt>
<a name="L218"></a><tt class="py-lineno"> 218</tt>  <tt class="py-line"><tt class="py-docstring">    The field of valueContainsNull is used to specify if values of this</tt> </tt>
<a name="L219"></a><tt class="py-lineno"> 219</tt>  <tt class="py-line"><tt class="py-docstring">    map has None values.</tt> </tt>
<a name="L220"></a><tt class="py-lineno"> 220</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L221"></a><tt class="py-lineno"> 221</tt>  <tt class="py-line"><tt class="py-docstring">    For values of a MapType column, keys are not allowed to have None values.</tt> </tt>
<a name="L222"></a><tt class="py-lineno"> 222</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L223"></a><tt class="py-lineno"> 223</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L224"></a><tt class="py-lineno"> 224</tt>  <tt class="py-line"> </tt>
<a name="MapType.__init__"></a><div id="MapType.__init__-def"><a name="L225"></a><tt class="py-lineno"> 225</tt> <a class="py-toggle" href="#" id="MapType.__init__-toggle" onclick="return toggle('MapType.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">keyType</tt><tt class="py-op">,</tt> <tt class="py-param">valueType</tt><tt class="py-op">,</tt> <tt class="py-param">valueContainsNull</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="MapType.__init__-expanded"><a name="L226"></a><tt class="py-lineno"> 226</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a MapType</tt> </tt>
<a name="L227"></a><tt class="py-lineno"> 227</tt>  <tt class="py-line"><tt class="py-docstring">        :param keyType: the data type of keys.</tt> </tt>
<a name="L228"></a><tt class="py-lineno"> 228</tt>  <tt class="py-line"><tt class="py-docstring">        :param valueType: the data type of values.</tt> </tt>
<a name="L229"></a><tt class="py-lineno"> 229</tt>  <tt class="py-line"><tt class="py-docstring">        :param valueContainsNull: indicates whether values contains</tt> </tt>
<a name="L230"></a><tt class="py-lineno"> 230</tt>  <tt class="py-line"><tt class="py-docstring">        null values.</tt> </tt>
<a name="L231"></a><tt class="py-lineno"> 231</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L232"></a><tt class="py-lineno"> 232</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; (MapType(StringType, IntegerType)</tt> </tt>
<a name="L233"></a><tt class="py-lineno"> 233</tt>  <tt class="py-line"><tt class="py-docstring">        ...        == MapType(StringType, IntegerType, True))</tt> </tt>
<a name="L234"></a><tt class="py-lineno"> 234</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L235"></a><tt class="py-lineno"> 235</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; (MapType(StringType, IntegerType, False)</tt> </tt>
<a name="L236"></a><tt class="py-lineno"> 236</tt>  <tt class="py-line"><tt class="py-docstring">        ...        == MapType(StringType, FloatType))</tt> </tt>
<a name="L237"></a><tt class="py-lineno"> 237</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L238"></a><tt class="py-lineno"> 238</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L239"></a><tt class="py-lineno"> 239</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt> <tt class="py-op">=</tt> <tt class="py-name">keyType</tt> </tt>
<a name="L240"></a><tt class="py-lineno"> 240</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt> <tt class="py-op">=</tt> <tt class="py-name">valueType</tt> </tt>
<a name="L241"></a><tt class="py-lineno"> 241</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueContainsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">valueContainsNull</tt> </tt>
</div><a name="L242"></a><tt class="py-lineno"> 242</tt>  <tt class="py-line"> </tt>
<a name="MapType.__repr__"></a><div id="MapType.__repr__-def"><a name="L243"></a><tt class="py-lineno"> 243</tt> <a class="py-toggle" href="#" id="MapType.__repr__-toggle" onclick="return toggle('MapType.__repr__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.MapType-class.html#__repr__">__repr__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="MapType.__repr__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="MapType.__repr__-expanded"><a name="L244"></a><tt class="py-lineno"> 244</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"MapType(%s,%s,%s)"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">,</tt> </tt>
<a name="L245"></a><tt class="py-lineno"> 245</tt>  <tt class="py-line">                                      <tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">valueContainsNull</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L246"></a><tt class="py-lineno"> 246</tt>  <tt class="py-line"> </tt>
<a name="StructField"></a><div id="StructField-def"><a name="L247"></a><tt class="py-lineno"> 247</tt>  <tt class="py-line"> </tt>
<a name="L248"></a><tt class="py-lineno"> 248</tt> <a class="py-toggle" href="#" id="StructField-toggle" onclick="return toggle('StructField');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html">StructField</a><tt class="py-op">(</tt><tt class="py-base-class">DataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="StructField-expanded"><a name="L249"></a><tt class="py-lineno"> 249</tt>  <tt class="py-line"> </tt>
<a name="L250"></a><tt class="py-lineno"> 250</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL StructField</tt> </tt>
<a name="L251"></a><tt class="py-lineno"> 251</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L252"></a><tt class="py-lineno"> 252</tt>  <tt class="py-line"><tt class="py-docstring">    Represents a field in a StructType.</tt> </tt>
<a name="L253"></a><tt class="py-lineno"> 253</tt>  <tt class="py-line"><tt class="py-docstring">    A StructField object comprises three fields, name (a string),</tt> </tt>
<a name="L254"></a><tt class="py-lineno"> 254</tt>  <tt class="py-line"><tt class="py-docstring">    dataType (a DataType) and nullable (a bool). The field of name</tt> </tt>
<a name="L255"></a><tt class="py-lineno"> 255</tt>  <tt class="py-line"><tt class="py-docstring">    is the name of a StructField. The field of dataType specifies</tt> </tt>
<a name="L256"></a><tt class="py-lineno"> 256</tt>  <tt class="py-line"><tt class="py-docstring">    the data type of a StructField.</tt> </tt>
<a name="L257"></a><tt class="py-lineno"> 257</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L258"></a><tt class="py-lineno"> 258</tt>  <tt class="py-line"><tt class="py-docstring">    The field of nullable specifies if values of a StructField can</tt> </tt>
<a name="L259"></a><tt class="py-lineno"> 259</tt>  <tt class="py-line"><tt class="py-docstring">    contain None values.</tt> </tt>
<a name="L260"></a><tt class="py-lineno"> 260</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L261"></a><tt class="py-lineno"> 261</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L262"></a><tt class="py-lineno"> 262</tt>  <tt class="py-line"> </tt>
<a name="StructField.__init__"></a><div id="StructField.__init__-def"><a name="L263"></a><tt class="py-lineno"> 263</tt> <a class="py-toggle" href="#" id="StructField.__init__-toggle" onclick="return toggle('StructField.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">name</tt><tt class="py-op">,</tt> <tt class="py-param">dataType</tt><tt class="py-op">,</tt> <tt class="py-param">nullable</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructField.__init__-expanded"><a name="L264"></a><tt class="py-lineno"> 264</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a StructField</tt> </tt>
<a name="L265"></a><tt class="py-lineno"> 265</tt>  <tt class="py-line"><tt class="py-docstring">        :param name: the name of this field.</tt> </tt>
<a name="L266"></a><tt class="py-lineno"> 266</tt>  <tt class="py-line"><tt class="py-docstring">        :param dataType: the data type of this field.</tt> </tt>
<a name="L267"></a><tt class="py-lineno"> 267</tt>  <tt class="py-line"><tt class="py-docstring">        :param nullable: indicates whether values of this field</tt> </tt>
<a name="L268"></a><tt class="py-lineno"> 268</tt>  <tt class="py-line"><tt class="py-docstring">                         can be null.</tt> </tt>
<a name="L269"></a><tt class="py-lineno"> 269</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L270"></a><tt class="py-lineno"> 270</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; (StructField("f1", StringType, True)</tt> </tt>
<a name="L271"></a><tt class="py-lineno"> 271</tt>  <tt class="py-line"><tt class="py-docstring">        ...      == StructField("f1", StringType, True))</tt> </tt>
<a name="L272"></a><tt class="py-lineno"> 272</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L273"></a><tt class="py-lineno"> 273</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; (StructField("f1", StringType, True)</tt> </tt>
<a name="L274"></a><tt class="py-lineno"> 274</tt>  <tt class="py-line"><tt class="py-docstring">        ...      == StructField("f2", StringType, True))</tt> </tt>
<a name="L275"></a><tt class="py-lineno"> 275</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L276"></a><tt class="py-lineno"> 276</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L277"></a><tt class="py-lineno"> 277</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-14" class="py-name" targets="Method pyspark.rdd.RDD.name()=pyspark.rdd.RDD-class.html#name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-14', 'name', 'link-14');">name</a></tt> <tt class="py-op">=</tt> <tt id="link-15" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-15', 'name', 'link-14');">name</a></tt> </tt>
<a name="L278"></a><tt class="py-lineno"> 278</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt> <tt class="py-op">=</tt> <tt class="py-name">dataType</tt> </tt>
<a name="L279"></a><tt class="py-lineno"> 279</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">nullable</tt> <tt class="py-op">=</tt> <tt class="py-name">nullable</tt> </tt>
</div><a name="L280"></a><tt class="py-lineno"> 280</tt>  <tt class="py-line"> </tt>
<a name="StructField.__repr__"></a><div id="StructField.__repr__-def"><a name="L281"></a><tt class="py-lineno"> 281</tt> <a class="py-toggle" href="#" id="StructField.__repr__-toggle" onclick="return toggle('StructField.__repr__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructField-class.html#__repr__">__repr__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructField.__repr__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructField.__repr__-expanded"><a name="L282"></a><tt class="py-lineno"> 282</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-string">"StructField(%s,%s,%s)"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-16" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-16', 'name', 'link-14');">name</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> </tt>
<a name="L283"></a><tt class="py-lineno"> 283</tt>  <tt class="py-line">                                          <tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">nullable</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L284"></a><tt class="py-lineno"> 284</tt>  <tt class="py-line"> </tt>
<a name="StructType"></a><div id="StructType-def"><a name="L285"></a><tt class="py-lineno"> 285</tt>  <tt class="py-line"> </tt>
<a name="L286"></a><tt class="py-lineno"> 286</tt> <a class="py-toggle" href="#" id="StructType-toggle" onclick="return toggle('StructType');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html">StructType</a><tt class="py-op">(</tt><tt class="py-base-class">DataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="StructType-expanded"><a name="L287"></a><tt class="py-lineno"> 287</tt>  <tt class="py-line"> </tt>
<a name="L288"></a><tt class="py-lineno"> 288</tt>  <tt class="py-line">    <tt class="py-docstring">"""Spark SQL StructType</tt> </tt>
<a name="L289"></a><tt class="py-lineno"> 289</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L290"></a><tt class="py-lineno"> 290</tt>  <tt class="py-line"><tt class="py-docstring">    The data type representing rows.</tt> </tt>
<a name="L291"></a><tt class="py-lineno"> 291</tt>  <tt class="py-line"><tt class="py-docstring">    A StructType object comprises a list of L{StructField}s.</tt> </tt>
<a name="L292"></a><tt class="py-lineno"> 292</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L293"></a><tt class="py-lineno"> 293</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L294"></a><tt class="py-lineno"> 294</tt>  <tt class="py-line"> </tt>
<a name="StructType.__init__"></a><div id="StructType.__init__-def"><a name="L295"></a><tt class="py-lineno"> 295</tt> <a class="py-toggle" href="#" id="StructType.__init__-toggle" onclick="return toggle('StructType.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructType.__init__-expanded"><a name="L296"></a><tt class="py-lineno"> 296</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a StructType</tt> </tt>
<a name="L297"></a><tt class="py-lineno"> 297</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L298"></a><tt class="py-lineno"> 298</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 = StructType([StructField("f1", StringType, True)])</tt> </tt>
<a name="L299"></a><tt class="py-lineno"> 299</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct2 = StructType([StructField("f1", StringType, True)])</tt> </tt>
<a name="L300"></a><tt class="py-lineno"> 300</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 == struct2</tt> </tt>
<a name="L301"></a><tt class="py-lineno"> 301</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L302"></a><tt class="py-lineno"> 302</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 = StructType([StructField("f1", StringType, True)])</tt> </tt>
<a name="L303"></a><tt class="py-lineno"> 303</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct2 = StructType([StructField("f1", StringType, True),</tt> </tt>
<a name="L304"></a><tt class="py-lineno"> 304</tt>  <tt class="py-line"><tt class="py-docstring">        ...   [StructField("f2", IntegerType, False)]])</tt> </tt>
<a name="L305"></a><tt class="py-lineno"> 305</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; struct1 == struct2</tt> </tt>
<a name="L306"></a><tt class="py-lineno"> 306</tt>  <tt class="py-line"><tt class="py-docstring">        False</tt> </tt>
<a name="L307"></a><tt class="py-lineno"> 307</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L308"></a><tt class="py-lineno"> 308</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-name">fields</tt> </tt>
</div><a name="L309"></a><tt class="py-lineno"> 309</tt>  <tt class="py-line"> </tt>
<a name="StructType.__repr__"></a><div id="StructType.__repr__-def"><a name="L310"></a><tt class="py-lineno"> 310</tt> <a class="py-toggle" href="#" id="StructType.__repr__-toggle" onclick="return toggle('StructType.__repr__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.StructType-class.html#__repr__">__repr__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="StructType.__repr__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="StructType.__repr__-expanded"><a name="L311"></a><tt class="py-lineno"> 311</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-string">"StructType(List(%s))"</tt> <tt class="py-op">%</tt> </tt>
<a name="L312"></a><tt class="py-lineno"> 312</tt>  <tt class="py-line">                <tt class="py-string">","</tt><tt class="py-op">.</tt><tt id="link-17" class="py-name" targets="Method pyspark.rdd.RDD.join()=pyspark.rdd.RDD-class.html#join"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-17', 'join', 'link-17');">join</a></tt><tt class="py-op">(</tt><tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">field</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">field</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L313"></a><tt class="py-lineno"> 313</tt>  <tt class="py-line"> </tt>
<a name="_parse_datatype_list"></a><div id="_parse_datatype_list-def"><a name="L314"></a><tt class="py-lineno"> 314</tt>  <tt class="py-line"> </tt>
<a name="L315"></a><tt class="py-lineno"> 315</tt> <a class="py-toggle" href="#" id="_parse_datatype_list-toggle" onclick="return toggle('_parse_datatype_list');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_parse_datatype_list">_parse_datatype_list</a><tt class="py-op">(</tt><tt class="py-param">datatype_list_string</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_parse_datatype_list-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_parse_datatype_list-expanded"><a name="L316"></a><tt class="py-lineno"> 316</tt>  <tt class="py-line">    <tt class="py-docstring">"""Parses a list of comma separated data types."""</tt> </tt>
<a name="L317"></a><tt class="py-lineno"> 317</tt>  <tt class="py-line">    <tt class="py-name">index</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L318"></a><tt class="py-lineno"> 318</tt>  <tt class="py-line">    <tt class="py-name">datatype_list</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L319"></a><tt class="py-lineno"> 319</tt>  <tt class="py-line">    <tt class="py-name">start</tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L320"></a><tt class="py-lineno"> 320</tt>  <tt class="py-line">    <tt id="link-18" class="py-name" targets="Method pyspark.mllib.tree.DecisionTreeModel.depth()=pyspark.mllib.tree.DecisionTreeModel-class.html#depth"><a title="pyspark.mllib.tree.DecisionTreeModel.depth" class="py-name" href="#" onclick="return doclink('link-18', 'depth', 'link-18');">depth</a></tt> <tt class="py-op">=</tt> <tt class="py-number">0</tt> </tt>
<a name="L321"></a><tt class="py-lineno"> 321</tt>  <tt class="py-line">    <tt class="py-keyword">while</tt> <tt class="py-name">index</tt> <tt class="py-op">&lt;</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">datatype_list_string</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L322"></a><tt class="py-lineno"> 322</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-19" class="py-name"><a title="pyspark.mllib.tree.DecisionTreeModel.depth" class="py-name" href="#" onclick="return doclink('link-19', 'depth', 'link-18');">depth</a></tt> <tt class="py-op">==</tt> <tt class="py-number">0</tt> <tt class="py-keyword">and</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">","</tt><tt class="py-op">:</tt> </tt>
<a name="L323"></a><tt class="py-lineno"> 323</tt>  <tt class="py-line">            <tt class="py-name">datatype_string</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">start</tt><tt class="py-op">:</tt><tt class="py-name">index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L324"></a><tt class="py-lineno"> 324</tt>  <tt class="py-line">            <tt class="py-name">datatype_list</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L325"></a><tt class="py-lineno"> 325</tt>  <tt class="py-line">            <tt class="py-name">start</tt> <tt class="py-op">=</tt> <tt class="py-name">index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt> </tt>
<a name="L326"></a><tt class="py-lineno"> 326</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">"("</tt><tt class="py-op">:</tt> </tt>
<a name="L327"></a><tt class="py-lineno"> 327</tt>  <tt class="py-line">            <tt id="link-20" class="py-name"><a title="pyspark.mllib.tree.DecisionTreeModel.depth" class="py-name" href="#" onclick="return doclink('link-20', 'depth', 'link-18');">depth</a></tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L328"></a><tt class="py-lineno"> 328</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> <tt class="py-op">==</tt> <tt class="py-string">")"</tt><tt class="py-op">:</tt> </tt>
<a name="L329"></a><tt class="py-lineno"> 329</tt>  <tt class="py-line">            <tt id="link-21" class="py-name"><a title="pyspark.mllib.tree.DecisionTreeModel.depth" class="py-name" href="#" onclick="return doclink('link-21', 'depth', 'link-18');">depth</a></tt> <tt class="py-op">-=</tt> <tt class="py-number">1</tt> </tt>
<a name="L330"></a><tt class="py-lineno"> 330</tt>  <tt class="py-line"> </tt>
<a name="L331"></a><tt class="py-lineno"> 331</tt>  <tt class="py-line">        <tt class="py-name">index</tt> <tt class="py-op">+=</tt> <tt class="py-number">1</tt> </tt>
<a name="L332"></a><tt class="py-lineno"> 332</tt>  <tt class="py-line"> </tt>
<a name="L333"></a><tt class="py-lineno"> 333</tt>  <tt class="py-line">    <tt class="py-comment"># Handle the last data type</tt> </tt>
<a name="L334"></a><tt class="py-lineno"> 334</tt>  <tt class="py-line">    <tt class="py-name">datatype_string</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_list_string</tt><tt class="py-op">[</tt><tt class="py-name">start</tt><tt class="py-op">:</tt><tt class="py-name">index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L335"></a><tt class="py-lineno"> 335</tt>  <tt class="py-line">    <tt class="py-name">datatype_list</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L336"></a><tt class="py-lineno"> 336</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">datatype_list</tt> </tt>
</div><a name="L337"></a><tt class="py-lineno"> 337</tt>  <tt class="py-line"> </tt>
<a name="L338"></a><tt class="py-lineno"> 338</tt>  <tt class="py-line"> </tt>
<a name="L339"></a><tt class="py-lineno"> 339</tt>  <tt class="py-line"><tt id="link-22" class="py-name" targets="Variable pyspark.sql._all_primitive_types=pyspark.sql-module.html#_all_primitive_types"><a title="pyspark.sql._all_primitive_types" class="py-name" href="#" onclick="return doclink('link-22', '_all_primitive_types', 'link-22');">_all_primitive_types</a></tt> <tt class="py-op">=</tt> <tt class="py-name">dict</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt class="py-name">globals</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">iteritems</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L340"></a><tt class="py-lineno"> 340</tt>  <tt class="py-line">                            <tt class="py-keyword">if</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">)</tt> <tt class="py-keyword">is</tt> <tt id="link-23" class="py-name"><a title="pyspark.sql.PrimitiveTypeSingleton" class="py-name" href="#" onclick="return doclink('link-23', 'PrimitiveTypeSingleton', 'link-10');">PrimitiveTypeSingleton</a></tt> <tt class="py-keyword">and</tt> <tt class="py-name">v</tt><tt class="py-op">.</tt><tt class="py-name">__base__</tt> <tt class="py-op">==</tt> <tt class="py-name">PrimitiveType</tt><tt class="py-op">)</tt> </tt>
<a name="_parse_datatype_string"></a><div id="_parse_datatype_string-def"><a name="L341"></a><tt class="py-lineno"> 341</tt>  <tt class="py-line"> </tt>
<a name="L342"></a><tt class="py-lineno"> 342</tt>  <tt class="py-line"> </tt>
<a name="L343"></a><tt class="py-lineno"> 343</tt> <a class="py-toggle" href="#" id="_parse_datatype_string-toggle" onclick="return toggle('_parse_datatype_string');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_parse_datatype_string">_parse_datatype_string</a><tt class="py-op">(</tt><tt class="py-param">datatype_string</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_parse_datatype_string-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_parse_datatype_string-expanded"><a name="L344"></a><tt class="py-lineno"> 344</tt>  <tt class="py-line">    <tt class="py-docstring">"""Parses the given data type string.</tt> </tt>
<a name="L345"></a><tt class="py-lineno"> 345</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L346"></a><tt class="py-lineno"> 346</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; def check_datatype(datatype):</tt> </tt>
<a name="L347"></a><tt class="py-lineno"> 347</tt>  <tt class="py-line"><tt class="py-docstring">    ...     scala_datatype = sqlCtx._ssql_ctx.parseDataType(str(datatype))</tt> </tt>
<a name="L348"></a><tt class="py-lineno"> 348</tt>  <tt class="py-line"><tt class="py-docstring">    ...     python_datatype = _parse_datatype_string(</tt> </tt>
<a name="L349"></a><tt class="py-lineno"> 349</tt>  <tt class="py-line"><tt class="py-docstring">    ...                          scala_datatype.toString())</tt> </tt>
<a name="L350"></a><tt class="py-lineno"> 350</tt>  <tt class="py-line"><tt class="py-docstring">    ...     return datatype == python_datatype</tt> </tt>
<a name="L351"></a><tt class="py-lineno"> 351</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; all(check_datatype(cls()) for cls in _all_primitive_types.values())</tt> </tt>
<a name="L352"></a><tt class="py-lineno"> 352</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L353"></a><tt class="py-lineno"> 353</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Simple ArrayType.</tt> </tt>
<a name="L354"></a><tt class="py-lineno"> 354</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; simple_arraytype = ArrayType(StringType(), True)</tt> </tt>
<a name="L355"></a><tt class="py-lineno"> 355</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(simple_arraytype)</tt> </tt>
<a name="L356"></a><tt class="py-lineno"> 356</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L357"></a><tt class="py-lineno"> 357</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Simple MapType.</tt> </tt>
<a name="L358"></a><tt class="py-lineno"> 358</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; simple_maptype = MapType(StringType(), LongType())</tt> </tt>
<a name="L359"></a><tt class="py-lineno"> 359</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(simple_maptype)</tt> </tt>
<a name="L360"></a><tt class="py-lineno"> 360</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L361"></a><tt class="py-lineno"> 361</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Simple StructType.</tt> </tt>
<a name="L362"></a><tt class="py-lineno"> 362</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; simple_structtype = StructType([</tt> </tt>
<a name="L363"></a><tt class="py-lineno"> 363</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("a", DecimalType(), False),</tt> </tt>
<a name="L364"></a><tt class="py-lineno"> 364</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("b", BooleanType(), True),</tt> </tt>
<a name="L365"></a><tt class="py-lineno"> 365</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("c", LongType(), True),</tt> </tt>
<a name="L366"></a><tt class="py-lineno"> 366</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("d", BinaryType(), False)])</tt> </tt>
<a name="L367"></a><tt class="py-lineno"> 367</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(simple_structtype)</tt> </tt>
<a name="L368"></a><tt class="py-lineno"> 368</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L369"></a><tt class="py-lineno"> 369</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Complex StructType.</tt> </tt>
<a name="L370"></a><tt class="py-lineno"> 370</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; complex_structtype = StructType([</tt> </tt>
<a name="L371"></a><tt class="py-lineno"> 371</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("simpleArray", simple_arraytype, True),</tt> </tt>
<a name="L372"></a><tt class="py-lineno"> 372</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("simpleMap", simple_maptype, True),</tt> </tt>
<a name="L373"></a><tt class="py-lineno"> 373</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("simpleStruct", simple_structtype, True),</tt> </tt>
<a name="L374"></a><tt class="py-lineno"> 374</tt>  <tt class="py-line"><tt class="py-docstring">    ...     StructField("boolean", BooleanType(), False)])</tt> </tt>
<a name="L375"></a><tt class="py-lineno"> 375</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(complex_structtype)</tt> </tt>
<a name="L376"></a><tt class="py-lineno"> 376</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L377"></a><tt class="py-lineno"> 377</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Complex ArrayType.</tt> </tt>
<a name="L378"></a><tt class="py-lineno"> 378</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; complex_arraytype = ArrayType(complex_structtype, True)</tt> </tt>
<a name="L379"></a><tt class="py-lineno"> 379</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(complex_arraytype)</tt> </tt>
<a name="L380"></a><tt class="py-lineno"> 380</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L381"></a><tt class="py-lineno"> 381</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; # Complex MapType.</tt> </tt>
<a name="L382"></a><tt class="py-lineno"> 382</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; complex_maptype = MapType(complex_structtype,</tt> </tt>
<a name="L383"></a><tt class="py-lineno"> 383</tt>  <tt class="py-line"><tt class="py-docstring">    ...                           complex_arraytype, False)</tt> </tt>
<a name="L384"></a><tt class="py-lineno"> 384</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; check_datatype(complex_maptype)</tt> </tt>
<a name="L385"></a><tt class="py-lineno"> 385</tt>  <tt class="py-line"><tt class="py-docstring">    True</tt> </tt>
<a name="L386"></a><tt class="py-lineno"> 386</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L387"></a><tt class="py-lineno"> 387</tt>  <tt class="py-line">    <tt class="py-name">index</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_string</tt><tt class="py-op">.</tt><tt class="py-name">find</tt><tt class="py-op">(</tt><tt class="py-string">"("</tt><tt class="py-op">)</tt> </tt>
<a name="L388"></a><tt class="py-lineno"> 388</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">index</tt> <tt class="py-op">==</tt> <tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">:</tt> </tt>
<a name="L389"></a><tt class="py-lineno"> 389</tt>  <tt class="py-line">        <tt class="py-comment"># It is a primitive type.</tt> </tt>
<a name="L390"></a><tt class="py-lineno"> 390</tt>  <tt class="py-line">        <tt class="py-name">index</tt> <tt class="py-op">=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt> </tt>
<a name="L391"></a><tt class="py-lineno"> 391</tt>  <tt class="py-line">    <tt class="py-name">type_or_field</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_string</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">index</tt><tt class="py-op">]</tt> </tt>
<a name="L392"></a><tt class="py-lineno"> 392</tt>  <tt class="py-line">    <tt class="py-name">rest_part</tt> <tt class="py-op">=</tt> <tt class="py-name">datatype_string</tt><tt class="py-op">[</tt><tt class="py-name">index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">datatype_string</tt><tt class="py-op">)</tt> <tt class="py-op">-</tt> <tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L393"></a><tt class="py-lineno"> 393</tt>  <tt class="py-line"> </tt>
<a name="L394"></a><tt class="py-lineno"> 394</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">type_or_field</tt> <tt class="py-keyword">in</tt> <tt id="link-24" class="py-name"><a title="pyspark.sql._all_primitive_types" class="py-name" href="#" onclick="return doclink('link-24', '_all_primitive_types', 'link-22');">_all_primitive_types</a></tt><tt class="py-op">:</tt> </tt>
<a name="L395"></a><tt class="py-lineno"> 395</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-25" class="py-name"><a title="pyspark.sql._all_primitive_types" class="py-name" href="#" onclick="return doclink('link-25', '_all_primitive_types', 'link-22');">_all_primitive_types</a></tt><tt class="py-op">[</tt><tt class="py-name">type_or_field</tt><tt class="py-op">]</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L396"></a><tt class="py-lineno"> 396</tt>  <tt class="py-line"> </tt>
<a name="L397"></a><tt class="py-lineno"> 397</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"ArrayType"</tt><tt class="py-op">:</tt> </tt>
<a name="L398"></a><tt class="py-lineno"> 398</tt>  <tt class="py-line">        <tt class="py-name">last_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">rfind</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L399"></a><tt class="py-lineno"> 399</tt>  <tt class="py-line">        <tt class="py-name">containsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L400"></a><tt class="py-lineno"> 400</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">last_comma_index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">"false"</tt><tt class="py-op">:</tt> </tt>
<a name="L401"></a><tt class="py-lineno"> 401</tt>  <tt class="py-line">            <tt class="py-name">containsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L402"></a><tt class="py-lineno"> 402</tt>  <tt class="py-line">        <tt class="py-name">elementType</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt> </tt>
<a name="L403"></a><tt class="py-lineno"> 403</tt>  <tt class="py-line">            <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L404"></a><tt class="py-lineno"> 404</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-26" class="py-name" targets="Class pyspark.sql.ArrayType=pyspark.sql.ArrayType-class.html"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-26', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">(</tt><tt class="py-name">elementType</tt><tt class="py-op">,</tt> <tt class="py-name">containsNull</tt><tt class="py-op">)</tt> </tt>
<a name="L405"></a><tt class="py-lineno"> 405</tt>  <tt class="py-line"> </tt>
<a name="L406"></a><tt class="py-lineno"> 406</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"MapType"</tt><tt class="py-op">:</tt> </tt>
<a name="L407"></a><tt class="py-lineno"> 407</tt>  <tt class="py-line">        <tt class="py-name">last_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">rfind</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L408"></a><tt class="py-lineno"> 408</tt>  <tt class="py-line">        <tt class="py-name">valueContainsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L409"></a><tt class="py-lineno"> 409</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">last_comma_index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">"false"</tt><tt class="py-op">:</tt> </tt>
<a name="L410"></a><tt class="py-lineno"> 410</tt>  <tt class="py-line">            <tt class="py-name">valueContainsNull</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L411"></a><tt class="py-lineno"> 411</tt>  <tt class="py-line">        <tt class="py-name">keyType</tt><tt class="py-op">,</tt> <tt class="py-name">valueType</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_list</tt><tt class="py-op">(</tt> </tt>
<a name="L412"></a><tt class="py-lineno"> 412</tt>  <tt class="py-line">            <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L413"></a><tt class="py-lineno"> 413</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-27" class="py-name" targets="Class pyspark.sql.MapType=pyspark.sql.MapType-class.html"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-27', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">(</tt><tt class="py-name">keyType</tt><tt class="py-op">,</tt> <tt class="py-name">valueType</tt><tt class="py-op">,</tt> <tt class="py-name">valueContainsNull</tt><tt class="py-op">)</tt> </tt>
<a name="L414"></a><tt class="py-lineno"> 414</tt>  <tt class="py-line"> </tt>
<a name="L415"></a><tt class="py-lineno"> 415</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"StructField"</tt><tt class="py-op">:</tt> </tt>
<a name="L416"></a><tt class="py-lineno"> 416</tt>  <tt class="py-line">        <tt class="py-name">first_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">find</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L417"></a><tt class="py-lineno"> 417</tt>  <tt class="py-line">        <tt id="link-28" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-28', 'name', 'link-14');">name</a></tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">first_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L418"></a><tt class="py-lineno"> 418</tt>  <tt class="py-line">        <tt class="py-name">last_comma_index</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">rfind</tt><tt class="py-op">(</tt><tt class="py-string">","</tt><tt class="py-op">)</tt> </tt>
<a name="L419"></a><tt class="py-lineno"> 419</tt>  <tt class="py-line">        <tt class="py-name">nullable</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L420"></a><tt class="py-lineno"> 420</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">last_comma_index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">lower</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-string">"false"</tt><tt class="py-op">:</tt> </tt>
<a name="L421"></a><tt class="py-lineno"> 421</tt>  <tt class="py-line">            <tt class="py-name">nullable</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L422"></a><tt class="py-lineno"> 422</tt>  <tt class="py-line">        <tt class="py-name">dataType</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt> </tt>
<a name="L423"></a><tt class="py-lineno"> 423</tt>  <tt class="py-line">            <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">first_comma_index</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-name">last_comma_index</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L424"></a><tt class="py-lineno"> 424</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-29" class="py-name" targets="Class pyspark.sql.StructField=pyspark.sql.StructField-class.html"><a title="pyspark.sql.StructField" class="py-name" href="#" onclick="return doclink('link-29', 'StructField', 'link-29');">StructField</a></tt><tt class="py-op">(</tt><tt id="link-30" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-30', 'name', 'link-14');">name</a></tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt class="py-name">nullable</tt><tt class="py-op">)</tt> </tt>
<a name="L425"></a><tt class="py-lineno"> 425</tt>  <tt class="py-line"> </tt>
<a name="L426"></a><tt class="py-lineno"> 426</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">type_or_field</tt> <tt class="py-op">==</tt> <tt class="py-string">"StructType"</tt><tt class="py-op">:</tt> </tt>
<a name="L427"></a><tt class="py-lineno"> 427</tt>  <tt class="py-line">        <tt class="py-comment"># rest_part should be in the format like</tt> </tt>
<a name="L428"></a><tt class="py-lineno"> 428</tt>  <tt class="py-line">        <tt class="py-comment"># List(StructField(field1,IntegerType,false)).</tt> </tt>
<a name="L429"></a><tt class="py-lineno"> 429</tt>  <tt class="py-line">        <tt class="py-name">field_list_string</tt> <tt class="py-op">=</tt> <tt class="py-name">rest_part</tt><tt class="py-op">[</tt><tt class="py-name">rest_part</tt><tt class="py-op">.</tt><tt class="py-name">find</tt><tt class="py-op">(</tt><tt class="py-string">"("</tt><tt class="py-op">)</tt> <tt class="py-op">+</tt> <tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt> </tt>
<a name="L430"></a><tt class="py-lineno"> 430</tt>  <tt class="py-line">        <tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-name">_parse_datatype_list</tt><tt class="py-op">(</tt><tt class="py-name">field_list_string</tt><tt class="py-op">)</tt> </tt>
<a name="L431"></a><tt class="py-lineno"> 431</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-31" class="py-name" targets="Class pyspark.sql.StructType=pyspark.sql.StructType-class.html"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-31', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">(</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
</div><a name="L432"></a><tt class="py-lineno"> 432</tt>  <tt class="py-line"> </tt>
<a name="L433"></a><tt class="py-lineno"> 433</tt>  <tt class="py-line"> </tt>
<a name="L434"></a><tt class="py-lineno"> 434</tt>  <tt class="py-line"><tt class="py-comment"># Mapping Python types to Spark SQL DateType</tt> </tt>
<a name="L435"></a><tt class="py-lineno"> 435</tt>  <tt class="py-line"><tt id="link-32" class="py-name" targets="Variable pyspark.sql._type_mappings=pyspark.sql-module.html#_type_mappings"><a title="pyspark.sql._type_mappings" class="py-name" href="#" onclick="return doclink('link-32', '_type_mappings', 'link-32');">_type_mappings</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt> </tt>
<a name="L436"></a><tt class="py-lineno"> 436</tt>  <tt class="py-line">    <tt class="py-name">bool</tt><tt class="py-op">:</tt> <tt id="link-33" class="py-name" targets="Class pyspark.sql.BooleanType=pyspark.sql.BooleanType-class.html"><a title="pyspark.sql.BooleanType" class="py-name" href="#" onclick="return doclink('link-33', 'BooleanType', 'link-33');">BooleanType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L437"></a><tt class="py-lineno"> 437</tt>  <tt class="py-line">    <tt class="py-name">int</tt><tt class="py-op">:</tt> <tt id="link-34" class="py-name" targets="Class pyspark.sql.IntegerType=pyspark.sql.IntegerType-class.html"><a title="pyspark.sql.IntegerType" class="py-name" href="#" onclick="return doclink('link-34', 'IntegerType', 'link-34');">IntegerType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L438"></a><tt class="py-lineno"> 438</tt>  <tt class="py-line">    <tt class="py-name">long</tt><tt class="py-op">:</tt> <tt id="link-35" class="py-name" targets="Class pyspark.sql.LongType=pyspark.sql.LongType-class.html"><a title="pyspark.sql.LongType" class="py-name" href="#" onclick="return doclink('link-35', 'LongType', 'link-35');">LongType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L439"></a><tt class="py-lineno"> 439</tt>  <tt class="py-line">    <tt class="py-name">float</tt><tt class="py-op">:</tt> <tt id="link-36" class="py-name" targets="Class pyspark.sql.DoubleType=pyspark.sql.DoubleType-class.html"><a title="pyspark.sql.DoubleType" class="py-name" href="#" onclick="return doclink('link-36', 'DoubleType', 'link-36');">DoubleType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L440"></a><tt class="py-lineno"> 440</tt>  <tt class="py-line">    <tt class="py-name">str</tt><tt class="py-op">:</tt> <tt id="link-37" class="py-name" targets="Class pyspark.sql.StringType=pyspark.sql.StringType-class.html"><a title="pyspark.sql.StringType" class="py-name" href="#" onclick="return doclink('link-37', 'StringType', 'link-37');">StringType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L441"></a><tt class="py-lineno"> 441</tt>  <tt class="py-line">    <tt class="py-name">unicode</tt><tt class="py-op">:</tt> <tt id="link-38" class="py-name"><a title="pyspark.sql.StringType" class="py-name" href="#" onclick="return doclink('link-38', 'StringType', 'link-37');">StringType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L442"></a><tt class="py-lineno"> 442</tt>  <tt class="py-line">    <tt class="py-name">decimal</tt><tt class="py-op">.</tt><tt class="py-name">Decimal</tt><tt class="py-op">:</tt> <tt id="link-39" class="py-name" targets="Class pyspark.sql.DecimalType=pyspark.sql.DecimalType-class.html"><a title="pyspark.sql.DecimalType" class="py-name" href="#" onclick="return doclink('link-39', 'DecimalType', 'link-39');">DecimalType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L443"></a><tt class="py-lineno"> 443</tt>  <tt class="py-line">    <tt class="py-name">datetime</tt><tt class="py-op">.</tt><tt class="py-name">datetime</tt><tt class="py-op">:</tt> <tt id="link-40" class="py-name" targets="Class pyspark.sql.TimestampType=pyspark.sql.TimestampType-class.html"><a title="pyspark.sql.TimestampType" class="py-name" href="#" onclick="return doclink('link-40', 'TimestampType', 'link-40');">TimestampType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L444"></a><tt class="py-lineno"> 444</tt>  <tt class="py-line">    <tt class="py-name">datetime</tt><tt class="py-op">.</tt><tt class="py-name">date</tt><tt class="py-op">:</tt> <tt id="link-41" class="py-name"><a title="pyspark.sql.TimestampType" class="py-name" href="#" onclick="return doclink('link-41', 'TimestampType', 'link-40');">TimestampType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L445"></a><tt class="py-lineno"> 445</tt>  <tt class="py-line">    <tt class="py-name">datetime</tt><tt class="py-op">.</tt><tt class="py-name">time</tt><tt class="py-op">:</tt> <tt id="link-42" class="py-name"><a title="pyspark.sql.TimestampType" class="py-name" href="#" onclick="return doclink('link-42', 'TimestampType', 'link-40');">TimestampType</a></tt><tt class="py-op">,</tt> </tt>
<a name="L446"></a><tt class="py-lineno"> 446</tt>  <tt class="py-line"><tt class="py-op">}</tt> </tt>
<a name="_infer_type"></a><div id="_infer_type-def"><a name="L447"></a><tt class="py-lineno"> 447</tt>  <tt class="py-line"> </tt>
<a name="L448"></a><tt class="py-lineno"> 448</tt>  <tt class="py-line"> </tt>
<a name="L449"></a><tt class="py-lineno"> 449</tt> <a class="py-toggle" href="#" id="_infer_type-toggle" onclick="return toggle('_infer_type');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_infer_type">_infer_type</a><tt class="py-op">(</tt><tt class="py-param">obj</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_infer_type-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_infer_type-expanded"><a name="L450"></a><tt class="py-lineno"> 450</tt>  <tt class="py-line">    <tt class="py-docstring">"""Infer the DataType from obj"""</tt> </tt>
<a name="L451"></a><tt class="py-lineno"> 451</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">obj</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L452"></a><tt class="py-lineno"> 452</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can not infer type for None"</tt><tt class="py-op">)</tt> </tt>
<a name="L453"></a><tt class="py-lineno"> 453</tt>  <tt class="py-line"> </tt>
<a name="L454"></a><tt class="py-lineno"> 454</tt>  <tt class="py-line">    <tt class="py-name">dataType</tt> <tt class="py-op">=</tt> <tt id="link-43" class="py-name"><a title="pyspark.sql._type_mappings" class="py-name" href="#" onclick="return doclink('link-43', '_type_mappings', 'link-32');">_type_mappings</a></tt><tt class="py-op">.</tt><tt id="link-44" class="py-name" targets="Method pyspark.conf.SparkConf.get()=pyspark.conf.SparkConf-class.html#get,Class Method pyspark.files.SparkFiles.get()=pyspark.files.SparkFiles-class.html#get"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-44', 'get', 'link-44');">get</a></tt><tt class="py-op">(</tt><tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L455"></a><tt class="py-lineno"> 455</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">dataType</tt> <tt class="py-keyword">is</tt> <tt class="py-keyword">not</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L456"></a><tt class="py-lineno"> 456</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">dataType</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L457"></a><tt class="py-lineno"> 457</tt>  <tt class="py-line"> </tt>
<a name="L458"></a><tt class="py-lineno"> 458</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-name">dict</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L459"></a><tt class="py-lineno"> 459</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">obj</tt><tt class="py-op">:</tt> </tt>
<a name="L460"></a><tt class="py-lineno"> 460</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can not infer type for empty dict"</tt><tt class="py-op">)</tt> </tt>
<a name="L461"></a><tt class="py-lineno"> 461</tt>  <tt class="py-line">        <tt class="py-name">key</tt><tt class="py-op">,</tt> <tt id="link-45" class="py-name" targets="Method pyspark.accumulators.Accumulator.value()=pyspark.accumulators.Accumulator-class.html#value"><a title="pyspark.accumulators.Accumulator.value" class="py-name" href="#" onclick="return doclink('link-45', 'value', 'link-45');">value</a></tt> <tt class="py-op">=</tt> <tt class="py-name">obj</tt><tt class="py-op">.</tt><tt class="py-name">iteritems</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">next</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L462"></a><tt class="py-lineno"> 462</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-46" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-46', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">(</tt><tt class="py-name">_infer_type</tt><tt class="py-op">(</tt><tt class="py-name">key</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">_infer_type</tt><tt class="py-op">(</tt><tt id="link-47" class="py-name"><a title="pyspark.accumulators.Accumulator.value" class="py-name" href="#" onclick="return doclink('link-47', 'value', 'link-45');">value</a></tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L463"></a><tt class="py-lineno"> 463</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-name">list</tt><tt class="py-op">,</tt> <tt class="py-name">array</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L464"></a><tt class="py-lineno"> 464</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">obj</tt><tt class="py-op">:</tt> </tt>
<a name="L465"></a><tt class="py-lineno"> 465</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can not infer type for empty list/array"</tt><tt class="py-op">)</tt> </tt>
<a name="L466"></a><tt class="py-lineno"> 466</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-48" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-48', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">(</tt><tt class="py-name">_infer_type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L467"></a><tt class="py-lineno"> 467</tt>  <tt class="py-line">    <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L468"></a><tt class="py-lineno"> 468</tt>  <tt class="py-line">        <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L469"></a><tt class="py-lineno"> 469</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">_infer_schema</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt> </tt>
<a name="L470"></a><tt class="py-lineno"> 470</tt>  <tt class="py-line">        <tt class="py-keyword">except</tt> <tt class="py-name">ValueError</tt><tt class="py-op">:</tt> </tt>
<a name="L471"></a><tt class="py-lineno"> 471</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"not supported type: %s"</tt> <tt class="py-op">%</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L472"></a><tt class="py-lineno"> 472</tt>  <tt class="py-line"> </tt>
<a name="_infer_schema"></a><div id="_infer_schema-def"><a name="L473"></a><tt class="py-lineno"> 473</tt>  <tt class="py-line"> </tt>
<a name="L474"></a><tt class="py-lineno"> 474</tt> <a class="py-toggle" href="#" id="_infer_schema-toggle" onclick="return toggle('_infer_schema');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_infer_schema">_infer_schema</a><tt class="py-op">(</tt><tt class="py-param">row</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_infer_schema-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_infer_schema-expanded"><a name="L475"></a><tt class="py-lineno"> 475</tt>  <tt class="py-line">    <tt class="py-docstring">"""Infer the schema from dict/namedtuple/object"""</tt> </tt>
<a name="L476"></a><tt class="py-lineno"> 476</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt class="py-name">dict</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L477"></a><tt class="py-lineno"> 477</tt>  <tt class="py-line">        <tt class="py-name">items</tt> <tt class="py-op">=</tt> <tt class="py-name">sorted</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">items</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L478"></a><tt class="py-lineno"> 478</tt>  <tt class="py-line"> </tt>
<a name="L479"></a><tt class="py-lineno"> 479</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L480"></a><tt class="py-lineno"> 480</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt class="py-string">"_fields"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt>  <tt class="py-comment"># namedtuple</tt> </tt>
<a name="L481"></a><tt class="py-lineno"> 481</tt>  <tt class="py-line">            <tt class="py-name">items</tt> <tt class="py-op">=</tt> <tt id="link-49" class="py-name" targets="Method pyspark.rdd.RDD.zip()=pyspark.rdd.RDD-class.html#zip"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-49', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">_fields</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L482"></a><tt class="py-lineno"> 482</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt class="py-string">"__FIELDS__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt>  <tt class="py-comment"># Row</tt> </tt>
<a name="L483"></a><tt class="py-lineno"> 483</tt>  <tt class="py-line">            <tt class="py-name">items</tt> <tt class="py-op">=</tt> <tt id="link-50" class="py-name"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-50', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L484"></a><tt class="py-lineno"> 484</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">all</tt><tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-number">2</tt> <tt class="py-keyword">for</tt> <tt class="py-name">x</tt> <tt class="py-keyword">in</tt> <tt class="py-name">row</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L485"></a><tt class="py-lineno"> 485</tt>  <tt class="py-line">            <tt class="py-name">items</tt> <tt class="py-op">=</tt> <tt class="py-name">row</tt> </tt>
<a name="L486"></a><tt class="py-lineno"> 486</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L487"></a><tt class="py-lineno"> 487</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can't infer schema from tuple"</tt><tt class="py-op">)</tt> </tt>
<a name="L488"></a><tt class="py-lineno"> 488</tt>  <tt class="py-line"> </tt>
<a name="L489"></a><tt class="py-lineno"> 489</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt class="py-string">"__dict__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt>  <tt class="py-comment"># object</tt> </tt>
<a name="L490"></a><tt class="py-lineno"> 490</tt>  <tt class="py-line">        <tt class="py-name">items</tt> <tt class="py-op">=</tt> <tt class="py-name">sorted</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt><tt class="py-op">.</tt><tt class="py-name">items</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L491"></a><tt class="py-lineno"> 491</tt>  <tt class="py-line"> </tt>
<a name="L492"></a><tt class="py-lineno"> 492</tt>  <tt class="py-line">    <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L493"></a><tt class="py-lineno"> 493</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can not infer schema for type: %s"</tt> <tt class="py-op">%</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L494"></a><tt class="py-lineno"> 494</tt>  <tt class="py-line"> </tt>
<a name="L495"></a><tt class="py-lineno"> 495</tt>  <tt class="py-line">    <tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt id="link-51" class="py-name"><a title="pyspark.sql.StructField" class="py-name" href="#" onclick="return doclink('link-51', 'StructField', 'link-29');">StructField</a></tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">_infer_type</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt class="py-name">items</tt><tt class="py-op">]</tt> </tt>
<a name="L496"></a><tt class="py-lineno"> 496</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt id="link-52" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-52', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">(</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
</div><a name="L497"></a><tt class="py-lineno"> 497</tt>  <tt class="py-line"> </tt>
<a name="_create_converter"></a><div id="_create_converter-def"><a name="L498"></a><tt class="py-lineno"> 498</tt>  <tt class="py-line"> </tt>
<a name="L499"></a><tt class="py-lineno"> 499</tt> <a class="py-toggle" href="#" id="_create_converter-toggle" onclick="return toggle('_create_converter');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_create_converter">_create_converter</a><tt class="py-op">(</tt><tt class="py-param">obj</tt><tt class="py-op">,</tt> <tt class="py-param">dataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_create_converter-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_create_converter-expanded"><a name="L500"></a><tt class="py-lineno"> 500</tt>  <tt class="py-line">    <tt class="py-docstring">"""Create an converter to drop the names of fields in obj """</tt> </tt>
<a name="L501"></a><tt class="py-lineno"> 501</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-53" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-53', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L502"></a><tt class="py-lineno"> 502</tt>  <tt class="py-line">        <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_converter</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">)</tt> </tt>
<a name="L503"></a><tt class="py-lineno"> 503</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">row</tt><tt class="py-op">:</tt> <tt id="link-54" class="py-name" targets="Method pyspark.rdd.RDD.map()=pyspark.rdd.RDD-class.html#map"><a title="pyspark.rdd.RDD.map" class="py-name" href="#" onclick="return doclink('link-54', 'map', 'link-54');">map</a></tt><tt class="py-op">(</tt><tt class="py-name">conv</tt><tt class="py-op">,</tt> <tt class="py-name">row</tt><tt class="py-op">)</tt> </tt>
<a name="L504"></a><tt class="py-lineno"> 504</tt>  <tt class="py-line"> </tt>
<a name="L505"></a><tt class="py-lineno"> 505</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-55" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-55', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L506"></a><tt class="py-lineno"> 506</tt>  <tt class="py-line">        <tt id="link-56" class="py-name"><a title="pyspark.accumulators.Accumulator.value" class="py-name" href="#" onclick="return doclink('link-56', 'value', 'link-45');">value</a></tt> <tt class="py-op">=</tt> <tt class="py-name">obj</tt><tt class="py-op">.</tt><tt id="link-57" class="py-name" targets="Method pyspark.rdd.RDD.values()=pyspark.rdd.RDD-class.html#values"><a title="pyspark.rdd.RDD.values" class="py-name" href="#" onclick="return doclink('link-57', 'values', 'link-57');">values</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt> </tt>
<a name="L507"></a><tt class="py-lineno"> 507</tt>  <tt class="py-line">        <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_converter</tt><tt class="py-op">(</tt><tt id="link-58" class="py-name"><a title="pyspark.accumulators.Accumulator.value" class="py-name" href="#" onclick="return doclink('link-58', 'value', 'link-45');">value</a></tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">)</tt> </tt>
<a name="L508"></a><tt class="py-lineno"> 508</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">row</tt><tt class="py-op">:</tt> <tt class="py-name">dict</tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">conv</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">iteritems</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L509"></a><tt class="py-lineno"> 509</tt>  <tt class="py-line"> </tt>
<a name="L510"></a><tt class="py-lineno"> 510</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-59" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-59', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L511"></a><tt class="py-lineno"> 511</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">x</tt><tt class="py-op">:</tt> <tt class="py-name">x</tt> </tt>
<a name="L512"></a><tt class="py-lineno"> 512</tt>  <tt class="py-line"> </tt>
<a name="L513"></a><tt class="py-lineno"> 513</tt>  <tt class="py-line">    <tt class="py-comment"># dataType must be StructType</tt> </tt>
<a name="L514"></a><tt class="py-lineno"> 514</tt>  <tt class="py-line">    <tt class="py-name">names</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">f</tt><tt class="py-op">.</tt><tt id="link-60" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-60', 'name', 'link-14');">name</a></tt> <tt class="py-keyword">for</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">]</tt> </tt>
<a name="L515"></a><tt class="py-lineno"> 515</tt>  <tt class="py-line"> </tt>
<a name="L516"></a><tt class="py-lineno"> 516</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-name">dict</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L517"></a><tt class="py-lineno"> 517</tt>  <tt class="py-line">        <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">o</tt><tt class="py-op">:</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">o</tt><tt class="py-op">.</tt><tt id="link-61" class="py-name"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-61', 'get', 'link-44');">get</a></tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">n</tt> <tt class="py-keyword">in</tt> <tt class="py-name">names</tt><tt class="py-op">)</tt> </tt>
<a name="L518"></a><tt class="py-lineno"> 518</tt>  <tt class="py-line"> </tt>
<a name="L519"></a><tt class="py-lineno"> 519</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L520"></a><tt class="py-lineno"> 520</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-string">"_fields"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt>  <tt class="py-comment"># namedtuple</tt> </tt>
<a name="L521"></a><tt class="py-lineno"> 521</tt>  <tt class="py-line">            <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt> </tt>
<a name="L522"></a><tt class="py-lineno"> 522</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-string">"__FIELDS__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L523"></a><tt class="py-lineno"> 523</tt>  <tt class="py-line">            <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt> </tt>
<a name="L524"></a><tt class="py-lineno"> 524</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">all</tt><tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-number">2</tt> <tt class="py-keyword">for</tt> <tt class="py-name">x</tt> <tt class="py-keyword">in</tt> <tt class="py-name">obj</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L525"></a><tt class="py-lineno"> 525</tt>  <tt class="py-line">            <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">o</tt><tt class="py-op">:</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">v</tt> <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt class="py-name">o</tt><tt class="py-op">)</tt> </tt>
<a name="L526"></a><tt class="py-lineno"> 526</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L527"></a><tt class="py-lineno"> 527</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"unexpected tuple"</tt><tt class="py-op">)</tt> </tt>
<a name="L528"></a><tt class="py-lineno"> 528</tt>  <tt class="py-line"> </tt>
<a name="L529"></a><tt class="py-lineno"> 529</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-string">"__dict__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt>  <tt class="py-comment"># object</tt> </tt>
<a name="L530"></a><tt class="py-lineno"> 530</tt>  <tt class="py-line">        <tt class="py-name">conv</tt> <tt class="py-op">=</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">o</tt><tt class="py-op">:</tt> <tt class="py-op">[</tt><tt class="py-name">o</tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt><tt class="py-op">.</tt><tt id="link-62" class="py-name"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-62', 'get', 'link-44');">get</a></tt><tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">None</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">n</tt> <tt class="py-keyword">in</tt> <tt class="py-name">names</tt><tt class="py-op">]</tt> </tt>
<a name="L531"></a><tt class="py-lineno"> 531</tt>  <tt class="py-line"> </tt>
<a name="L532"></a><tt class="py-lineno"> 532</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">all</tt><tt class="py-op">(</tt><tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt class="py-name">PrimitiveType</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L533"></a><tt class="py-lineno"> 533</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">conv</tt> </tt>
<a name="L534"></a><tt class="py-lineno"> 534</tt>  <tt class="py-line"> </tt>
<a name="L535"></a><tt class="py-lineno"> 535</tt>  <tt class="py-line">    <tt class="py-name">row</tt> <tt class="py-op">=</tt> <tt class="py-name">conv</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt> </tt>
<a name="L536"></a><tt class="py-lineno"> 536</tt>  <tt class="py-line">    <tt class="py-name">convs</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">_create_converter</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
<a name="L537"></a><tt class="py-lineno"> 537</tt>  <tt class="py-line">             <tt class="py-keyword">for</tt> <tt class="py-name">v</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt id="link-63" class="py-name"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-63', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">]</tt> </tt>
<a name="L538"></a><tt class="py-lineno"> 538</tt>  <tt class="py-line"> </tt>
<a name="L539"></a><tt class="py-lineno"> 539</tt>  <tt class="py-line">    <tt class="py-keyword">def</tt> <tt class="py-def-name">nested_conv</tt><tt class="py-op">(</tt><tt class="py-param">row</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L540"></a><tt class="py-lineno"> 540</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">f</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt id="link-64" class="py-name"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-64', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">convs</tt><tt class="py-op">,</tt> <tt class="py-name">conv</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L541"></a><tt class="py-lineno"> 541</tt>  <tt class="py-line"> </tt>
<a name="L542"></a><tt class="py-lineno"> 542</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">nested_conv</tt> </tt>
</div><a name="L543"></a><tt class="py-lineno"> 543</tt>  <tt class="py-line"> </tt>
<a name="_drop_schema"></a><div id="_drop_schema-def"><a name="L544"></a><tt class="py-lineno"> 544</tt>  <tt class="py-line"> </tt>
<a name="L545"></a><tt class="py-lineno"> 545</tt> <a class="py-toggle" href="#" id="_drop_schema-toggle" onclick="return toggle('_drop_schema');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_drop_schema">_drop_schema</a><tt class="py-op">(</tt><tt class="py-param">rows</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_drop_schema-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_drop_schema-expanded"><a name="L546"></a><tt class="py-lineno"> 546</tt>  <tt class="py-line">    <tt class="py-docstring">""" all the names of fields, becoming tuples"""</tt> </tt>
<a name="L547"></a><tt class="py-lineno"> 547</tt>  <tt class="py-line">    <tt class="py-name">iterator</tt> <tt class="py-op">=</tt> <tt class="py-name">iter</tt><tt class="py-op">(</tt><tt class="py-name">rows</tt><tt class="py-op">)</tt> </tt>
<a name="L548"></a><tt class="py-lineno"> 548</tt>  <tt class="py-line">    <tt class="py-name">row</tt> <tt class="py-op">=</tt> <tt class="py-name">iterator</tt><tt class="py-op">.</tt><tt class="py-name">next</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L549"></a><tt class="py-lineno"> 549</tt>  <tt class="py-line">    <tt class="py-name">converter</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_converter</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt id="link-65" class="py-name" targets="Method pyspark.sql.SchemaRDD.schema()=pyspark.sql.SchemaRDD-class.html#schema"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-65', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt> </tt>
<a name="L550"></a><tt class="py-lineno"> 550</tt>  <tt class="py-line">    <tt class="py-keyword">yield</tt> <tt class="py-name">converter</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">)</tt> </tt>
<a name="L551"></a><tt class="py-lineno"> 551</tt>  <tt class="py-line">    <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">iterator</tt><tt class="py-op">:</tt> </tt>
<a name="L552"></a><tt class="py-lineno"> 552</tt>  <tt class="py-line">        <tt class="py-keyword">yield</tt> <tt class="py-name">converter</tt><tt class="py-op">(</tt><tt class="py-name">i</tt><tt class="py-op">)</tt> </tt>
</div><a name="L553"></a><tt class="py-lineno"> 553</tt>  <tt class="py-line"> </tt>
<a name="L554"></a><tt class="py-lineno"> 554</tt>  <tt class="py-line"> </tt>
<a name="L555"></a><tt class="py-lineno"> 555</tt>  <tt class="py-line"><tt id="link-66" class="py-name" targets="Variable pyspark.sql._BRACKETS=pyspark.sql-module.html#_BRACKETS"><a title="pyspark.sql._BRACKETS" class="py-name" href="#" onclick="return doclink('link-66', '_BRACKETS', 'link-66');">_BRACKETS</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-string">'('</tt><tt class="py-op">:</tt> <tt class="py-string">')'</tt><tt class="py-op">,</tt> <tt class="py-string">'['</tt><tt class="py-op">:</tt> <tt class="py-string">']'</tt><tt class="py-op">,</tt> <tt class="py-string">'{'</tt><tt class="py-op">:</tt> <tt class="py-string">'}'</tt><tt class="py-op">}</tt> </tt>
<a name="_split_schema_abstract"></a><div id="_split_schema_abstract-def"><a name="L556"></a><tt class="py-lineno"> 556</tt>  <tt class="py-line"> </tt>
<a name="L557"></a><tt class="py-lineno"> 557</tt>  <tt class="py-line"> </tt>
<a name="L558"></a><tt class="py-lineno"> 558</tt> <a class="py-toggle" href="#" id="_split_schema_abstract-toggle" onclick="return toggle('_split_schema_abstract');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_split_schema_abstract">_split_schema_abstract</a><tt class="py-op">(</tt><tt class="py-param">s</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_split_schema_abstract-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_split_schema_abstract-expanded"><a name="L559"></a><tt class="py-lineno"> 559</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L560"></a><tt class="py-lineno"> 560</tt>  <tt class="py-line"><tt class="py-docstring">    split the schema abstract into fields</tt> </tt>
<a name="L561"></a><tt class="py-lineno"> 561</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L562"></a><tt class="py-lineno"> 562</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _split_schema_abstract("a b  c")</tt> </tt>
<a name="L563"></a><tt class="py-lineno"> 563</tt>  <tt class="py-line"><tt class="py-docstring">    ['a', 'b', 'c']</tt> </tt>
<a name="L564"></a><tt class="py-lineno"> 564</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _split_schema_abstract("a(a b)")</tt> </tt>
<a name="L565"></a><tt class="py-lineno"> 565</tt>  <tt class="py-line"><tt class="py-docstring">    ['a(a b)']</tt> </tt>
<a name="L566"></a><tt class="py-lineno"> 566</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _split_schema_abstract("a b[] c{a b}")</tt> </tt>
<a name="L567"></a><tt class="py-lineno"> 567</tt>  <tt class="py-line"><tt class="py-docstring">    ['a', 'b[]', 'c{a b}']</tt> </tt>
<a name="L568"></a><tt class="py-lineno"> 568</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _split_schema_abstract(" ")</tt> </tt>
<a name="L569"></a><tt class="py-lineno"> 569</tt>  <tt class="py-line"><tt class="py-docstring">    []</tt> </tt>
<a name="L570"></a><tt class="py-lineno"> 570</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L571"></a><tt class="py-lineno"> 571</tt>  <tt class="py-line"> </tt>
<a name="L572"></a><tt class="py-lineno"> 572</tt>  <tt class="py-line">    <tt class="py-name">r</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L573"></a><tt class="py-lineno"> 573</tt>  <tt class="py-line">    <tt class="py-name">w</tt> <tt class="py-op">=</tt> <tt class="py-string">''</tt> </tt>
<a name="L574"></a><tt class="py-lineno"> 574</tt>  <tt class="py-line">    <tt class="py-name">brackets</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-op">]</tt> </tt>
<a name="L575"></a><tt class="py-lineno"> 575</tt>  <tt class="py-line">    <tt class="py-keyword">for</tt> <tt class="py-name">c</tt> <tt class="py-keyword">in</tt> <tt id="link-67" class="py-name" targets="Variable pyspark.s=pyspark-module.html#s"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-67', 's', 'link-67');">s</a></tt><tt class="py-op">:</tt> </tt>
<a name="L576"></a><tt class="py-lineno"> 576</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">c</tt> <tt class="py-op">==</tt> <tt class="py-string">' '</tt> <tt class="py-keyword">and</tt> <tt class="py-keyword">not</tt> <tt class="py-name">brackets</tt><tt class="py-op">:</tt> </tt>
<a name="L577"></a><tt class="py-lineno"> 577</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">w</tt><tt class="py-op">:</tt> </tt>
<a name="L578"></a><tt class="py-lineno"> 578</tt>  <tt class="py-line">                <tt class="py-name">r</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">w</tt><tt class="py-op">)</tt> </tt>
<a name="L579"></a><tt class="py-lineno"> 579</tt>  <tt class="py-line">            <tt class="py-name">w</tt> <tt class="py-op">=</tt> <tt class="py-string">''</tt> </tt>
<a name="L580"></a><tt class="py-lineno"> 580</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L581"></a><tt class="py-lineno"> 581</tt>  <tt class="py-line">            <tt class="py-name">w</tt> <tt class="py-op">+=</tt> <tt class="py-name">c</tt> </tt>
<a name="L582"></a><tt class="py-lineno"> 582</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">c</tt> <tt class="py-keyword">in</tt> <tt id="link-68" class="py-name"><a title="pyspark.sql._BRACKETS" class="py-name" href="#" onclick="return doclink('link-68', '_BRACKETS', 'link-66');">_BRACKETS</a></tt><tt class="py-op">:</tt> </tt>
<a name="L583"></a><tt class="py-lineno"> 583</tt>  <tt class="py-line">                <tt class="py-name">brackets</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">c</tt><tt class="py-op">)</tt> </tt>
<a name="L584"></a><tt class="py-lineno"> 584</tt>  <tt class="py-line">            <tt class="py-keyword">elif</tt> <tt class="py-name">c</tt> <tt class="py-keyword">in</tt> <tt id="link-69" class="py-name"><a title="pyspark.sql._BRACKETS" class="py-name" href="#" onclick="return doclink('link-69', '_BRACKETS', 'link-66');">_BRACKETS</a></tt><tt class="py-op">.</tt><tt id="link-70" class="py-name"><a title="pyspark.rdd.RDD.values" class="py-name" href="#" onclick="return doclink('link-70', 'values', 'link-57');">values</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L585"></a><tt class="py-lineno"> 585</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">brackets</tt> <tt class="py-keyword">or</tt> <tt class="py-name">c</tt> <tt class="py-op">!=</tt> <tt id="link-71" class="py-name"><a title="pyspark.sql._BRACKETS" class="py-name" href="#" onclick="return doclink('link-71', '_BRACKETS', 'link-66');">_BRACKETS</a></tt><tt class="py-op">[</tt><tt class="py-name">brackets</tt><tt class="py-op">.</tt><tt class="py-name">pop</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> </tt>
<a name="L586"></a><tt class="py-lineno"> 586</tt>  <tt class="py-line">                    <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"unexpected "</tt> <tt class="py-op">+</tt> <tt class="py-name">c</tt><tt class="py-op">)</tt> </tt>
<a name="L587"></a><tt class="py-lineno"> 587</tt>  <tt class="py-line"> </tt>
<a name="L588"></a><tt class="py-lineno"> 588</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">brackets</tt><tt class="py-op">:</tt> </tt>
<a name="L589"></a><tt class="py-lineno"> 589</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"brackets not closed: %s"</tt> <tt class="py-op">%</tt> <tt class="py-name">brackets</tt><tt class="py-op">)</tt> </tt>
<a name="L590"></a><tt class="py-lineno"> 590</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">w</tt><tt class="py-op">:</tt> </tt>
<a name="L591"></a><tt class="py-lineno"> 591</tt>  <tt class="py-line">        <tt class="py-name">r</tt><tt class="py-op">.</tt><tt class="py-name">append</tt><tt class="py-op">(</tt><tt class="py-name">w</tt><tt class="py-op">)</tt> </tt>
<a name="L592"></a><tt class="py-lineno"> 592</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">r</tt> </tt>
</div><a name="L593"></a><tt class="py-lineno"> 593</tt>  <tt class="py-line"> </tt>
<a name="_parse_field_abstract"></a><div id="_parse_field_abstract-def"><a name="L594"></a><tt class="py-lineno"> 594</tt>  <tt class="py-line"> </tt>
<a name="L595"></a><tt class="py-lineno"> 595</tt> <a class="py-toggle" href="#" id="_parse_field_abstract-toggle" onclick="return toggle('_parse_field_abstract');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_parse_field_abstract">_parse_field_abstract</a><tt class="py-op">(</tt><tt class="py-param">s</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_parse_field_abstract-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_parse_field_abstract-expanded"><a name="L596"></a><tt class="py-lineno"> 596</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L597"></a><tt class="py-lineno"> 597</tt>  <tt class="py-line"><tt class="py-docstring">    Parse a field in schema abstract</tt> </tt>
<a name="L598"></a><tt class="py-lineno"> 598</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L599"></a><tt class="py-lineno"> 599</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_field_abstract("a")</tt> </tt>
<a name="L600"></a><tt class="py-lineno"> 600</tt>  <tt class="py-line"><tt class="py-docstring">    StructField(a,None,true)</tt> </tt>
<a name="L601"></a><tt class="py-lineno"> 601</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_field_abstract("b(c d)")</tt> </tt>
<a name="L602"></a><tt class="py-lineno"> 602</tt>  <tt class="py-line"><tt class="py-docstring">    StructField(b,StructType(...c,None,true),StructField(d...</tt> </tt>
<a name="L603"></a><tt class="py-lineno"> 603</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_field_abstract("a[]")</tt> </tt>
<a name="L604"></a><tt class="py-lineno"> 604</tt>  <tt class="py-line"><tt class="py-docstring">    StructField(a,ArrayType(None,true),true)</tt> </tt>
<a name="L605"></a><tt class="py-lineno"> 605</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_field_abstract("a{[]}")</tt> </tt>
<a name="L606"></a><tt class="py-lineno"> 606</tt>  <tt class="py-line"><tt class="py-docstring">    StructField(a,MapType(None,ArrayType(None,true),true),true)</tt> </tt>
<a name="L607"></a><tt class="py-lineno"> 607</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L608"></a><tt class="py-lineno"> 608</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt id="link-72" class="py-name" targets="Method pyspark.conf.SparkConf.set()=pyspark.conf.SparkConf-class.html#set"><a title="pyspark.conf.SparkConf.set" class="py-name" href="#" onclick="return doclink('link-72', 'set', 'link-72');">set</a></tt><tt class="py-op">(</tt><tt id="link-73" class="py-name"><a title="pyspark.sql._BRACKETS" class="py-name" href="#" onclick="return doclink('link-73', '_BRACKETS', 'link-66');">_BRACKETS</a></tt><tt class="py-op">.</tt><tt id="link-74" class="py-name" targets="Method pyspark.rdd.RDD.keys()=pyspark.rdd.RDD-class.html#keys"><a title="pyspark.rdd.RDD.keys" class="py-name" href="#" onclick="return doclink('link-74', 'keys', 'link-74');">keys</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> <tt class="py-op">&amp;</tt> <tt id="link-75" class="py-name"><a title="pyspark.conf.SparkConf.set" class="py-name" href="#" onclick="return doclink('link-75', 'set', 'link-72');">set</a></tt><tt class="py-op">(</tt><tt id="link-76" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-76', 's', 'link-67');">s</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L609"></a><tt class="py-lineno"> 609</tt>  <tt class="py-line">        <tt class="py-name">idx</tt> <tt class="py-op">=</tt> <tt id="link-77" class="py-name" targets="Method pyspark.mllib.stat.MultivariateStatisticalSummary.min()=pyspark.mllib.stat.MultivariateStatisticalSummary-class.html#min,Method pyspark.rdd.RDD.min()=pyspark.rdd.RDD-class.html#min,Method pyspark.statcounter.StatCounter.min()=pyspark.statcounter.StatCounter-class.html#min"><a title="pyspark.mllib.stat.MultivariateStatisticalSummary.min
pyspark.rdd.RDD.min
pyspark.statcounter.StatCounter.min" class="py-name" href="#" onclick="return doclink('link-77', 'min', 'link-77');">min</a></tt><tt class="py-op">(</tt><tt class="py-op">(</tt><tt id="link-78" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-78', 's', 'link-67');">s</a></tt><tt class="py-op">.</tt><tt class="py-name">index</tt><tt class="py-op">(</tt><tt class="py-name">c</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">c</tt> <tt class="py-keyword">in</tt> <tt id="link-79" class="py-name"><a title="pyspark.sql._BRACKETS" class="py-name" href="#" onclick="return doclink('link-79', '_BRACKETS', 'link-66');">_BRACKETS</a></tt> <tt class="py-keyword">if</tt> <tt class="py-name">c</tt> <tt class="py-keyword">in</tt> <tt id="link-80" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-80', 's', 'link-67');">s</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L610"></a><tt class="py-lineno"> 610</tt>  <tt class="py-line">        <tt id="link-81" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-81', 'name', 'link-14');">name</a></tt> <tt class="py-op">=</tt> <tt id="link-82" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-82', 's', 'link-67');">s</a></tt><tt class="py-op">[</tt><tt class="py-op">:</tt><tt class="py-name">idx</tt><tt class="py-op">]</tt> </tt>
<a name="L611"></a><tt class="py-lineno"> 611</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-83" class="py-name"><a title="pyspark.sql.StructField" class="py-name" href="#" onclick="return doclink('link-83', 'StructField', 'link-29');">StructField</a></tt><tt class="py-op">(</tt><tt id="link-84" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-84', 'name', 'link-14');">name</a></tt><tt class="py-op">,</tt> <tt class="py-name">_parse_schema_abstract</tt><tt class="py-op">(</tt><tt id="link-85" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-85', 's', 'link-67');">s</a></tt><tt class="py-op">[</tt><tt class="py-name">idx</tt><tt class="py-op">:</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L612"></a><tt class="py-lineno"> 612</tt>  <tt class="py-line">    <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L613"></a><tt class="py-lineno"> 613</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-86" class="py-name"><a title="pyspark.sql.StructField" class="py-name" href="#" onclick="return doclink('link-86', 'StructField', 'link-29');">StructField</a></tt><tt class="py-op">(</tt><tt id="link-87" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-87', 's', 'link-67');">s</a></tt><tt class="py-op">,</tt> <tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
</div><a name="L614"></a><tt class="py-lineno"> 614</tt>  <tt class="py-line"> </tt>
<a name="_parse_schema_abstract"></a><div id="_parse_schema_abstract-def"><a name="L615"></a><tt class="py-lineno"> 615</tt>  <tt class="py-line"> </tt>
<a name="L616"></a><tt class="py-lineno"> 616</tt> <a class="py-toggle" href="#" id="_parse_schema_abstract-toggle" onclick="return toggle('_parse_schema_abstract');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_parse_schema_abstract">_parse_schema_abstract</a><tt class="py-op">(</tt><tt class="py-param">s</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_parse_schema_abstract-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_parse_schema_abstract-expanded"><a name="L617"></a><tt class="py-lineno"> 617</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L618"></a><tt class="py-lineno"> 618</tt>  <tt class="py-line"><tt class="py-docstring">    parse abstract into schema</tt> </tt>
<a name="L619"></a><tt class="py-lineno"> 619</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L620"></a><tt class="py-lineno"> 620</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_schema_abstract("a b  c")</tt> </tt>
<a name="L621"></a><tt class="py-lineno"> 621</tt>  <tt class="py-line"><tt class="py-docstring">    StructType...a...b...c...</tt> </tt>
<a name="L622"></a><tt class="py-lineno"> 622</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_schema_abstract("a[b c] b{}")</tt> </tt>
<a name="L623"></a><tt class="py-lineno"> 623</tt>  <tt class="py-line"><tt class="py-docstring">    StructType...a,ArrayType...b...c...b,MapType...</tt> </tt>
<a name="L624"></a><tt class="py-lineno"> 624</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_schema_abstract("c{} d{a b}")</tt> </tt>
<a name="L625"></a><tt class="py-lineno"> 625</tt>  <tt class="py-line"><tt class="py-docstring">    StructType...c,MapType...d,MapType...a...b...</tt> </tt>
<a name="L626"></a><tt class="py-lineno"> 626</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _parse_schema_abstract("a b(t)").fields[1]</tt> </tt>
<a name="L627"></a><tt class="py-lineno"> 627</tt>  <tt class="py-line"><tt class="py-docstring">    StructField(b,StructType(List(StructField(t,None,true))),true)</tt> </tt>
<a name="L628"></a><tt class="py-lineno"> 628</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L629"></a><tt class="py-lineno"> 629</tt>  <tt class="py-line">    <tt id="link-88" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-88', 's', 'link-67');">s</a></tt> <tt class="py-op">=</tt> <tt id="link-89" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-89', 's', 'link-67');">s</a></tt><tt class="py-op">.</tt><tt class="py-name">strip</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L630"></a><tt class="py-lineno"> 630</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt id="link-90" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-90', 's', 'link-67');">s</a></tt><tt class="py-op">:</tt> </tt>
<a name="L631"></a><tt class="py-lineno"> 631</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> </tt>
<a name="L632"></a><tt class="py-lineno"> 632</tt>  <tt class="py-line"> </tt>
<a name="L633"></a><tt class="py-lineno"> 633</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt id="link-91" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-91', 's', 'link-67');">s</a></tt><tt class="py-op">.</tt><tt class="py-name">startswith</tt><tt class="py-op">(</tt><tt class="py-string">'('</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L634"></a><tt class="py-lineno"> 634</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_parse_schema_abstract</tt><tt class="py-op">(</tt><tt id="link-92" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-92', 's', 'link-67');">s</a></tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L635"></a><tt class="py-lineno"> 635</tt>  <tt class="py-line"> </tt>
<a name="L636"></a><tt class="py-lineno"> 636</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt id="link-93" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-93', 's', 'link-67');">s</a></tt><tt class="py-op">.</tt><tt class="py-name">startswith</tt><tt class="py-op">(</tt><tt class="py-string">'['</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L637"></a><tt class="py-lineno"> 637</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-94" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-94', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">(</tt><tt class="py-name">_parse_schema_abstract</tt><tt class="py-op">(</tt><tt id="link-95" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-95', 's', 'link-67');">s</a></tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L638"></a><tt class="py-lineno"> 638</tt>  <tt class="py-line"> </tt>
<a name="L639"></a><tt class="py-lineno"> 639</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt id="link-96" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-96', 's', 'link-67');">s</a></tt><tt class="py-op">.</tt><tt class="py-name">startswith</tt><tt class="py-op">(</tt><tt class="py-string">'{'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L640"></a><tt class="py-lineno"> 640</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-97" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-97', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">(</tt><tt class="py-name">None</tt><tt class="py-op">,</tt> <tt class="py-name">_parse_schema_abstract</tt><tt class="py-op">(</tt><tt id="link-98" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-98', 's', 'link-67');">s</a></tt><tt class="py-op">[</tt><tt class="py-number">1</tt><tt class="py-op">:</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">]</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L641"></a><tt class="py-lineno"> 641</tt>  <tt class="py-line"> </tt>
<a name="L642"></a><tt class="py-lineno"> 642</tt>  <tt class="py-line">    <tt class="py-name">parts</tt> <tt class="py-op">=</tt> <tt class="py-name">_split_schema_abstract</tt><tt class="py-op">(</tt><tt id="link-99" class="py-name"><a title="pyspark.s" class="py-name" href="#" onclick="return doclink('link-99', 's', 'link-67');">s</a></tt><tt class="py-op">)</tt> </tt>
<a name="L643"></a><tt class="py-lineno"> 643</tt>  <tt class="py-line">    <tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt class="py-name">_parse_field_abstract</tt><tt class="py-op">(</tt><tt class="py-name">p</tt><tt class="py-op">)</tt> <tt class="py-keyword">for</tt> <tt class="py-name">p</tt> <tt class="py-keyword">in</tt> <tt class="py-name">parts</tt><tt class="py-op">]</tt> </tt>
<a name="L644"></a><tt class="py-lineno"> 644</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt id="link-100" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-100', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">(</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
</div><a name="L645"></a><tt class="py-lineno"> 645</tt>  <tt class="py-line"> </tt>
<a name="_infer_schema_type"></a><div id="_infer_schema_type-def"><a name="L646"></a><tt class="py-lineno"> 646</tt>  <tt class="py-line"> </tt>
<a name="L647"></a><tt class="py-lineno"> 647</tt> <a class="py-toggle" href="#" id="_infer_schema_type-toggle" onclick="return toggle('_infer_schema_type');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_infer_schema_type">_infer_schema_type</a><tt class="py-op">(</tt><tt class="py-param">obj</tt><tt class="py-op">,</tt> <tt class="py-param">dataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_infer_schema_type-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_infer_schema_type-expanded"><a name="L648"></a><tt class="py-lineno"> 648</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L649"></a><tt class="py-lineno"> 649</tt>  <tt class="py-line"><tt class="py-docstring">    Fill the dataType with types infered from obj</tt> </tt>
<a name="L650"></a><tt class="py-lineno"> 650</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L651"></a><tt class="py-lineno"> 651</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; schema = _parse_schema_abstract("a b c")</tt> </tt>
<a name="L652"></a><tt class="py-lineno"> 652</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row = (1, 1.0, "str")</tt> </tt>
<a name="L653"></a><tt class="py-lineno"> 653</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _infer_schema_type(row, schema)</tt> </tt>
<a name="L654"></a><tt class="py-lineno"> 654</tt>  <tt class="py-line"><tt class="py-docstring">    StructType...IntegerType...DoubleType...StringType...</tt> </tt>
<a name="L655"></a><tt class="py-lineno"> 655</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row = [[1], {"key": (1, 2.0)}]</tt> </tt>
<a name="L656"></a><tt class="py-lineno"> 656</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; schema = _parse_schema_abstract("a[] b{c d}")</tt> </tt>
<a name="L657"></a><tt class="py-lineno"> 657</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _infer_schema_type(row, schema)</tt> </tt>
<a name="L658"></a><tt class="py-lineno"> 658</tt>  <tt class="py-line"><tt class="py-docstring">    StructType...a,ArrayType...b,MapType(StringType,...c,IntegerType...</tt> </tt>
<a name="L659"></a><tt class="py-lineno"> 659</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L660"></a><tt class="py-lineno"> 660</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">dataType</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L661"></a><tt class="py-lineno"> 661</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_infer_type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt> </tt>
<a name="L662"></a><tt class="py-lineno"> 662</tt>  <tt class="py-line"> </tt>
<a name="L663"></a><tt class="py-lineno"> 663</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">obj</tt><tt class="py-op">:</tt> </tt>
<a name="L664"></a><tt class="py-lineno"> 664</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can not infer type from empty value"</tt><tt class="py-op">)</tt> </tt>
<a name="L665"></a><tt class="py-lineno"> 665</tt>  <tt class="py-line"> </tt>
<a name="L666"></a><tt class="py-lineno"> 666</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-101" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-101', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L667"></a><tt class="py-lineno"> 667</tt>  <tt class="py-line">        <tt class="py-name">eType</tt> <tt class="py-op">=</tt> <tt class="py-name">_infer_schema_type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">[</tt><tt class="py-number">0</tt><tt class="py-op">]</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">)</tt> </tt>
<a name="L668"></a><tt class="py-lineno"> 668</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-102" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-102', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">(</tt><tt class="py-name">eType</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L669"></a><tt class="py-lineno"> 669</tt>  <tt class="py-line"> </tt>
<a name="L670"></a><tt class="py-lineno"> 670</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-103" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-103', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L671"></a><tt class="py-lineno"> 671</tt>  <tt class="py-line">        <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-op">=</tt> <tt class="py-name">obj</tt><tt class="py-op">.</tt><tt class="py-name">iteritems</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">next</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L672"></a><tt class="py-lineno"> 672</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-104" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-104', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">(</tt><tt class="py-name">_infer_type</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L673"></a><tt class="py-lineno"> 673</tt>  <tt class="py-line">                       <tt class="py-name">_infer_schema_type</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L674"></a><tt class="py-lineno"> 674</tt>  <tt class="py-line"> </tt>
<a name="L675"></a><tt class="py-lineno"> 675</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-105" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-105', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L676"></a><tt class="py-lineno"> 676</tt>  <tt class="py-line">        <tt class="py-name">fs</tt> <tt class="py-op">=</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt> </tt>
<a name="L677"></a><tt class="py-lineno"> 677</tt>  <tt class="py-line">        <tt class="py-keyword">assert</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">fs</tt><tt class="py-op">)</tt> <tt class="py-op">==</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> \ </tt>
<a name="L678"></a><tt class="py-lineno"> 678</tt>  <tt class="py-line">            <tt class="py-string">"Obj(%s) have different length with fields(%s)"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-name">fs</tt><tt class="py-op">)</tt> </tt>
<a name="L679"></a><tt class="py-lineno"> 679</tt>  <tt class="py-line">        <tt class="py-name">fields</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt><tt id="link-106" class="py-name"><a title="pyspark.sql.StructField" class="py-name" href="#" onclick="return doclink('link-106', 'StructField', 'link-29');">StructField</a></tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">.</tt><tt id="link-107" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-107', 'name', 'link-14');">name</a></tt><tt class="py-op">,</tt> <tt class="py-name">_infer_schema_type</tt><tt class="py-op">(</tt><tt class="py-name">o</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">True</tt><tt class="py-op">)</tt> </tt>
<a name="L680"></a><tt class="py-lineno"> 680</tt>  <tt class="py-line">                  <tt class="py-keyword">for</tt> <tt class="py-name">o</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt id="link-108" class="py-name"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-108', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-name">fs</tt><tt class="py-op">)</tt><tt class="py-op">]</tt> </tt>
<a name="L681"></a><tt class="py-lineno"> 681</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-109" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-109', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">(</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
<a name="L682"></a><tt class="py-lineno"> 682</tt>  <tt class="py-line"> </tt>
<a name="L683"></a><tt class="py-lineno"> 683</tt>  <tt class="py-line">    <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L684"></a><tt class="py-lineno"> 684</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Unexpected dataType: %s"</tt> <tt class="py-op">%</tt> <tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
</div><a name="L685"></a><tt class="py-lineno"> 685</tt>  <tt class="py-line"> </tt>
<a name="L686"></a><tt class="py-lineno"> 686</tt>  <tt class="py-line"> </tt>
<a name="L687"></a><tt class="py-lineno"> 687</tt>  <tt class="py-line"><tt id="link-110" class="py-name" targets="Variable pyspark.sql._acceptable_types=pyspark.sql-module.html#_acceptable_types"><a title="pyspark.sql._acceptable_types" class="py-name" href="#" onclick="return doclink('link-110', '_acceptable_types', 'link-110');">_acceptable_types</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt> </tt>
<a name="L688"></a><tt class="py-lineno"> 688</tt>  <tt class="py-line">    <tt id="link-111" class="py-name"><a title="pyspark.sql.BooleanType" class="py-name" href="#" onclick="return doclink('link-111', 'BooleanType', 'link-33');">BooleanType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">bool</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L689"></a><tt class="py-lineno"> 689</tt>  <tt class="py-line">    <tt id="link-112" class="py-name" targets="Class pyspark.sql.ByteType=pyspark.sql.ByteType-class.html"><a title="pyspark.sql.ByteType" class="py-name" href="#" onclick="return doclink('link-112', 'ByteType', 'link-112');">ByteType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">int</tt><tt class="py-op">,</tt> <tt class="py-name">long</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L690"></a><tt class="py-lineno"> 690</tt>  <tt class="py-line">    <tt id="link-113" class="py-name" targets="Class pyspark.sql.ShortType=pyspark.sql.ShortType-class.html"><a title="pyspark.sql.ShortType" class="py-name" href="#" onclick="return doclink('link-113', 'ShortType', 'link-113');">ShortType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">int</tt><tt class="py-op">,</tt> <tt class="py-name">long</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L691"></a><tt class="py-lineno"> 691</tt>  <tt class="py-line">    <tt id="link-114" class="py-name"><a title="pyspark.sql.IntegerType" class="py-name" href="#" onclick="return doclink('link-114', 'IntegerType', 'link-34');">IntegerType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">int</tt><tt class="py-op">,</tt> <tt class="py-name">long</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L692"></a><tt class="py-lineno"> 692</tt>  <tt class="py-line">    <tt id="link-115" class="py-name"><a title="pyspark.sql.LongType" class="py-name" href="#" onclick="return doclink('link-115', 'LongType', 'link-35');">LongType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">long</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L693"></a><tt class="py-lineno"> 693</tt>  <tt class="py-line">    <tt id="link-116" class="py-name" targets="Class pyspark.sql.FloatType=pyspark.sql.FloatType-class.html"><a title="pyspark.sql.FloatType" class="py-name" href="#" onclick="return doclink('link-116', 'FloatType', 'link-116');">FloatType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">float</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L694"></a><tt class="py-lineno"> 694</tt>  <tt class="py-line">    <tt id="link-117" class="py-name"><a title="pyspark.sql.DoubleType" class="py-name" href="#" onclick="return doclink('link-117', 'DoubleType', 'link-36');">DoubleType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">float</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L695"></a><tt class="py-lineno"> 695</tt>  <tt class="py-line">    <tt id="link-118" class="py-name"><a title="pyspark.sql.DecimalType" class="py-name" href="#" onclick="return doclink('link-118', 'DecimalType', 'link-39');">DecimalType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">decimal</tt><tt class="py-op">.</tt><tt class="py-name">Decimal</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L696"></a><tt class="py-lineno"> 696</tt>  <tt class="py-line">    <tt id="link-119" class="py-name"><a title="pyspark.sql.StringType" class="py-name" href="#" onclick="return doclink('link-119', 'StringType', 'link-37');">StringType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">str</tt><tt class="py-op">,</tt> <tt class="py-name">unicode</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L697"></a><tt class="py-lineno"> 697</tt>  <tt class="py-line">    <tt id="link-120" class="py-name"><a title="pyspark.sql.TimestampType" class="py-name" href="#" onclick="return doclink('link-120', 'TimestampType', 'link-40');">TimestampType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">datetime</tt><tt class="py-op">.</tt><tt class="py-name">datetime</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L698"></a><tt class="py-lineno"> 698</tt>  <tt class="py-line">    <tt id="link-121" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-121', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">list</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">,</tt> <tt class="py-name">array</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L699"></a><tt class="py-lineno"> 699</tt>  <tt class="py-line">    <tt id="link-122" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-122', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">dict</tt><tt class="py-op">,</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L700"></a><tt class="py-lineno"> 700</tt>  <tt class="py-line">    <tt id="link-123" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-123', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">:</tt> <tt class="py-op">(</tt><tt class="py-name">tuple</tt><tt class="py-op">,</tt> <tt class="py-name">list</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L701"></a><tt class="py-lineno"> 701</tt>  <tt class="py-line"><tt class="py-op">}</tt> </tt>
<a name="_verify_type"></a><div id="_verify_type-def"><a name="L702"></a><tt class="py-lineno"> 702</tt>  <tt class="py-line"> </tt>
<a name="L703"></a><tt class="py-lineno"> 703</tt>  <tt class="py-line"> </tt>
<a name="L704"></a><tt class="py-lineno"> 704</tt> <a class="py-toggle" href="#" id="_verify_type-toggle" onclick="return toggle('_verify_type');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_verify_type">_verify_type</a><tt class="py-op">(</tt><tt class="py-param">obj</tt><tt class="py-op">,</tt> <tt class="py-param">dataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_verify_type-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_verify_type-expanded"><a name="L705"></a><tt class="py-lineno"> 705</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L706"></a><tt class="py-lineno"> 706</tt>  <tt class="py-line"><tt class="py-docstring">    Verify the type of obj against dataType, raise an exception if</tt> </tt>
<a name="L707"></a><tt class="py-lineno"> 707</tt>  <tt class="py-line"><tt class="py-docstring">    they do not match.</tt> </tt>
<a name="L708"></a><tt class="py-lineno"> 708</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L709"></a><tt class="py-lineno"> 709</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type(None, StructType([]))</tt> </tt>
<a name="L710"></a><tt class="py-lineno"> 710</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type("", StringType())</tt> </tt>
<a name="L711"></a><tt class="py-lineno"> 711</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type(0, IntegerType())</tt> </tt>
<a name="L712"></a><tt class="py-lineno"> 712</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type(range(3), ArrayType(ShortType()))</tt> </tt>
<a name="L713"></a><tt class="py-lineno"> 713</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type(set(), ArrayType(StringType())) # doctest: +IGNORE_EXCEPTION_DETAIL</tt> </tt>
<a name="L714"></a><tt class="py-lineno"> 714</tt>  <tt class="py-line"><tt class="py-docstring">    Traceback (most recent call last):</tt> </tt>
<a name="L715"></a><tt class="py-lineno"> 715</tt>  <tt class="py-line"><tt class="py-docstring">        ...</tt> </tt>
<a name="L716"></a><tt class="py-lineno"> 716</tt>  <tt class="py-line"><tt class="py-docstring">    TypeError:...</tt> </tt>
<a name="L717"></a><tt class="py-lineno"> 717</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type({}, MapType(StringType(), IntegerType()))</tt> </tt>
<a name="L718"></a><tt class="py-lineno"> 718</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type((), StructType([]))</tt> </tt>
<a name="L719"></a><tt class="py-lineno"> 719</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type([], StructType([]))</tt> </tt>
<a name="L720"></a><tt class="py-lineno"> 720</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; _verify_type([1], StructType([])) # doctest: +IGNORE_EXCEPTION_DETAIL</tt> </tt>
<a name="L721"></a><tt class="py-lineno"> 721</tt>  <tt class="py-line"><tt class="py-docstring">    Traceback (most recent call last):</tt> </tt>
<a name="L722"></a><tt class="py-lineno"> 722</tt>  <tt class="py-line"><tt class="py-docstring">        ...</tt> </tt>
<a name="L723"></a><tt class="py-lineno"> 723</tt>  <tt class="py-line"><tt class="py-docstring">    ValueError:...</tt> </tt>
<a name="L724"></a><tt class="py-lineno"> 724</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L725"></a><tt class="py-lineno"> 725</tt>  <tt class="py-line">    <tt class="py-comment"># all objects are nullable</tt> </tt>
<a name="L726"></a><tt class="py-lineno"> 726</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">obj</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L727"></a><tt class="py-lineno"> 727</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> </tt>
<a name="L728"></a><tt class="py-lineno"> 728</tt>  <tt class="py-line"> </tt>
<a name="L729"></a><tt class="py-lineno"> 729</tt>  <tt class="py-line">    <tt class="py-name">_type</tt> <tt class="py-op">=</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
<a name="L730"></a><tt class="py-lineno"> 730</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">_type</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt id="link-124" class="py-name"><a title="pyspark.sql._acceptable_types" class="py-name" href="#" onclick="return doclink('link-124', '_acceptable_types', 'link-110');">_acceptable_types</a></tt><tt class="py-op">:</tt> </tt>
<a name="L731"></a><tt class="py-lineno"> 731</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> </tt>
<a name="L732"></a><tt class="py-lineno"> 732</tt>  <tt class="py-line"> </tt>
<a name="L733"></a><tt class="py-lineno"> 733</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt> <tt class="py-keyword">not</tt> <tt class="py-keyword">in</tt> <tt id="link-125" class="py-name"><a title="pyspark.sql._acceptable_types" class="py-name" href="#" onclick="return doclink('link-125', '_acceptable_types', 'link-110');">_acceptable_types</a></tt><tt class="py-op">[</tt><tt class="py-name">_type</tt><tt class="py-op">]</tt><tt class="py-op">:</tt> </tt>
<a name="L734"></a><tt class="py-lineno"> 734</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">TypeError</tt><tt class="py-op">(</tt><tt class="py-string">"%s can not accept abject in type %s"</tt> </tt>
<a name="L735"></a><tt class="py-lineno"> 735</tt>  <tt class="py-line">                        <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L736"></a><tt class="py-lineno"> 736</tt>  <tt class="py-line"> </tt>
<a name="L737"></a><tt class="py-lineno"> 737</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-126" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-126', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L738"></a><tt class="py-lineno"> 738</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">obj</tt><tt class="py-op">:</tt> </tt>
<a name="L739"></a><tt class="py-lineno"> 739</tt>  <tt class="py-line">            <tt class="py-name">_verify_type</tt><tt class="py-op">(</tt><tt class="py-name">i</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">)</tt> </tt>
<a name="L740"></a><tt class="py-lineno"> 740</tt>  <tt class="py-line"> </tt>
<a name="L741"></a><tt class="py-lineno"> 741</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-127" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-127', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L742"></a><tt class="py-lineno"> 742</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt class="py-name">obj</tt><tt class="py-op">.</tt><tt class="py-name">iteritems</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L743"></a><tt class="py-lineno"> 743</tt>  <tt class="py-line">            <tt class="py-name">_verify_type</tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">keyType</tt><tt class="py-op">)</tt> </tt>
<a name="L744"></a><tt class="py-lineno"> 744</tt>  <tt class="py-line">            <tt class="py-name">_verify_type</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">)</tt> </tt>
<a name="L745"></a><tt class="py-lineno"> 745</tt>  <tt class="py-line"> </tt>
<a name="L746"></a><tt class="py-lineno"> 746</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-128" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-128', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L747"></a><tt class="py-lineno"> 747</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt> <tt class="py-op">!=</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L748"></a><tt class="py-lineno"> 748</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Length of object (%d) does not match with"</tt> </tt>
<a name="L749"></a><tt class="py-lineno"> 749</tt>  <tt class="py-line">                             <tt class="py-string">"length of fields (%d)"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L750"></a><tt class="py-lineno"> 750</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">v</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt id="link-129" class="py-name"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-129', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">,</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L751"></a><tt class="py-lineno"> 751</tt>  <tt class="py-line">            <tt class="py-name">_verify_type</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
</div><a name="L752"></a><tt class="py-lineno"> 752</tt>  <tt class="py-line"> </tt>
<a name="L753"></a><tt class="py-lineno"> 753</tt>  <tt class="py-line"> </tt>
<a name="L754"></a><tt class="py-lineno"> 754</tt>  <tt class="py-line"><tt id="link-130" class="py-name" targets="Variable pyspark.sql._cached_cls=pyspark.sql-module.html#_cached_cls"><a title="pyspark.sql._cached_cls" class="py-name" href="#" onclick="return doclink('link-130', '_cached_cls', 'link-130');">_cached_cls</a></tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-op">}</tt> </tt>
<a name="_restore_object"></a><div id="_restore_object-def"><a name="L755"></a><tt class="py-lineno"> 755</tt>  <tt class="py-line"> </tt>
<a name="L756"></a><tt class="py-lineno"> 756</tt>  <tt class="py-line"> </tt>
<a name="L757"></a><tt class="py-lineno"> 757</tt> <a class="py-toggle" href="#" id="_restore_object-toggle" onclick="return toggle('_restore_object');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_restore_object">_restore_object</a><tt class="py-op">(</tt><tt class="py-param">dataType</tt><tt class="py-op">,</tt> <tt class="py-param">obj</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_restore_object-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_restore_object-expanded"><a name="L758"></a><tt class="py-lineno"> 758</tt>  <tt class="py-line">    <tt class="py-docstring">""" Restore object during unpickling. """</tt> </tt>
<a name="L759"></a><tt class="py-lineno"> 759</tt>  <tt class="py-line">    <tt class="py-comment"># use id(dataType) as key to speed up lookup in dict</tt> </tt>
<a name="L760"></a><tt class="py-lineno"> 760</tt>  <tt class="py-line">    <tt class="py-comment"># Because of batched pickling, dataType will be the</tt> </tt>
<a name="L761"></a><tt class="py-lineno"> 761</tt>  <tt class="py-line">    <tt class="py-comment"># same object in mose cases.</tt> </tt>
<a name="L762"></a><tt class="py-lineno"> 762</tt>  <tt class="py-line">    <tt class="py-name">k</tt> <tt class="py-op">=</tt> <tt id="link-131" class="py-name" targets="Method pyspark.rdd.RDD.id()=pyspark.rdd.RDD-class.html#id"><a title="pyspark.rdd.RDD.id" class="py-name" href="#" onclick="return doclink('link-131', 'id', 'link-131');">id</a></tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
<a name="L763"></a><tt class="py-lineno"> 763</tt>  <tt class="py-line">    <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt id="link-132" class="py-name"><a title="pyspark.sql._cached_cls" class="py-name" href="#" onclick="return doclink('link-132', '_cached_cls', 'link-130');">_cached_cls</a></tt><tt class="py-op">.</tt><tt id="link-133" class="py-name"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-133', 'get', 'link-44');">get</a></tt><tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">)</tt> </tt>
<a name="L764"></a><tt class="py-lineno"> 764</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">cls</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L765"></a><tt class="py-lineno"> 765</tt>  <tt class="py-line">        <tt class="py-comment"># use dataType as key to avoid create multiple class</tt> </tt>
<a name="L766"></a><tt class="py-lineno"> 766</tt>  <tt class="py-line">        <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt id="link-134" class="py-name"><a title="pyspark.sql._cached_cls" class="py-name" href="#" onclick="return doclink('link-134', '_cached_cls', 'link-130');">_cached_cls</a></tt><tt class="py-op">.</tt><tt id="link-135" class="py-name"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-135', 'get', 'link-44');">get</a></tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
<a name="L767"></a><tt class="py-lineno"> 767</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">cls</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L768"></a><tt class="py-lineno"> 768</tt>  <tt class="py-line">            <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_cls</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
<a name="L769"></a><tt class="py-lineno"> 769</tt>  <tt class="py-line">            <tt id="link-136" class="py-name"><a title="pyspark.sql._cached_cls" class="py-name" href="#" onclick="return doclink('link-136', '_cached_cls', 'link-130');">_cached_cls</a></tt><tt class="py-op">[</tt><tt class="py-name">dataType</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">cls</tt> </tt>
<a name="L770"></a><tt class="py-lineno"> 770</tt>  <tt class="py-line">        <tt id="link-137" class="py-name"><a title="pyspark.sql._cached_cls" class="py-name" href="#" onclick="return doclink('link-137', '_cached_cls', 'link-130');">_cached_cls</a></tt><tt class="py-op">[</tt><tt class="py-name">k</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">cls</tt> </tt>
<a name="L771"></a><tt class="py-lineno"> 771</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">cls</tt><tt class="py-op">(</tt><tt class="py-name">obj</tt><tt class="py-op">)</tt> </tt>
</div><a name="L772"></a><tt class="py-lineno"> 772</tt>  <tt class="py-line"> </tt>
<a name="_create_object"></a><div id="_create_object-def"><a name="L773"></a><tt class="py-lineno"> 773</tt>  <tt class="py-line"> </tt>
<a name="L774"></a><tt class="py-lineno"> 774</tt> <a class="py-toggle" href="#" id="_create_object-toggle" onclick="return toggle('_create_object');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_create_object">_create_object</a><tt class="py-op">(</tt><tt class="py-param">cls</tt><tt class="py-op">,</tt> <tt class="py-param">v</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_create_object-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_create_object-expanded"><a name="L775"></a><tt class="py-lineno"> 775</tt>  <tt class="py-line">    <tt class="py-docstring">""" Create an customized object with class `cls`. """</tt> </tt>
<a name="L776"></a><tt class="py-lineno"> 776</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">cls</tt><tt class="py-op">(</tt><tt class="py-name">v</tt><tt class="py-op">)</tt> <tt class="py-keyword">if</tt> <tt class="py-name">v</tt> <tt class="py-keyword">is</tt> <tt class="py-keyword">not</tt> <tt class="py-name">None</tt> <tt class="py-keyword">else</tt> <tt class="py-name">v</tt> </tt>
</div><a name="L777"></a><tt class="py-lineno"> 777</tt>  <tt class="py-line"> </tt>
<a name="_create_getter"></a><div id="_create_getter-def"><a name="L778"></a><tt class="py-lineno"> 778</tt>  <tt class="py-line"> </tt>
<a name="L779"></a><tt class="py-lineno"> 779</tt> <a class="py-toggle" href="#" id="_create_getter-toggle" onclick="return toggle('_create_getter');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_create_getter">_create_getter</a><tt class="py-op">(</tt><tt class="py-param">dt</tt><tt class="py-op">,</tt> <tt class="py-param">i</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_create_getter-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_create_getter-expanded"><a name="L780"></a><tt class="py-lineno"> 780</tt>  <tt class="py-line">    <tt class="py-docstring">""" Create a getter for item `i` with schema """</tt> </tt>
<a name="L781"></a><tt class="py-lineno"> 781</tt>  <tt class="py-line">    <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_cls</tt><tt class="py-op">(</tt><tt class="py-name">dt</tt><tt class="py-op">)</tt> </tt>
<a name="L782"></a><tt class="py-lineno"> 782</tt>  <tt class="py-line"> </tt>
<a name="L783"></a><tt class="py-lineno"> 783</tt>  <tt class="py-line">    <tt class="py-keyword">def</tt> <tt class="py-def-name">getter</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L784"></a><tt class="py-lineno"> 784</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_create_object</tt><tt class="py-op">(</tt><tt class="py-name">cls</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
</div><a name="L785"></a><tt class="py-lineno"> 785</tt>  <tt class="py-line"> </tt>
<a name="L786"></a><tt class="py-lineno"> 786</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">getter</tt> </tt>
</div><a name="L787"></a><tt class="py-lineno"> 787</tt>  <tt class="py-line"> </tt>
<a name="_has_struct"></a><div id="_has_struct-def"><a name="L788"></a><tt class="py-lineno"> 788</tt>  <tt class="py-line"> </tt>
<a name="L789"></a><tt class="py-lineno"> 789</tt> <a class="py-toggle" href="#" id="_has_struct-toggle" onclick="return toggle('_has_struct');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_has_struct">_has_struct</a><tt class="py-op">(</tt><tt class="py-param">dt</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_has_struct-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_has_struct-expanded"><a name="L790"></a><tt class="py-lineno"> 790</tt>  <tt class="py-line">    <tt class="py-docstring">"""Return whether `dt` is or has StructType in it"""</tt> </tt>
<a name="L791"></a><tt class="py-lineno"> 791</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dt</tt><tt class="py-op">,</tt> <tt id="link-138" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-138', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L792"></a><tt class="py-lineno"> 792</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">True</tt> </tt>
<a name="L793"></a><tt class="py-lineno"> 793</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dt</tt><tt class="py-op">,</tt> <tt id="link-139" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-139', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L794"></a><tt class="py-lineno"> 794</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_has_struct</tt><tt class="py-op">(</tt><tt class="py-name">dt</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">)</tt> </tt>
<a name="L795"></a><tt class="py-lineno"> 795</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dt</tt><tt class="py-op">,</tt> <tt id="link-140" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-140', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L796"></a><tt class="py-lineno"> 796</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_has_struct</tt><tt class="py-op">(</tt><tt class="py-name">dt</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">)</tt> </tt>
<a name="L797"></a><tt class="py-lineno"> 797</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">False</tt> </tt>
</div><a name="L798"></a><tt class="py-lineno"> 798</tt>  <tt class="py-line"> </tt>
<a name="_create_properties"></a><div id="_create_properties-def"><a name="L799"></a><tt class="py-lineno"> 799</tt>  <tt class="py-line"> </tt>
<a name="L800"></a><tt class="py-lineno"> 800</tt> <a class="py-toggle" href="#" id="_create_properties-toggle" onclick="return toggle('_create_properties');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_create_properties">_create_properties</a><tt class="py-op">(</tt><tt class="py-param">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_create_properties-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_create_properties-expanded"><a name="L801"></a><tt class="py-lineno"> 801</tt>  <tt class="py-line">    <tt class="py-docstring">"""Create properties according to fields"""</tt> </tt>
<a name="L802"></a><tt class="py-lineno"> 802</tt>  <tt class="py-line">    <tt class="py-name">ps</tt> <tt class="py-op">=</tt> <tt class="py-op">{</tt><tt class="py-op">}</tt> </tt>
<a name="L803"></a><tt class="py-lineno"> 803</tt>  <tt class="py-line">    <tt class="py-keyword">for</tt> <tt class="py-name">i</tt><tt class="py-op">,</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt class="py-name">enumerate</tt><tt class="py-op">(</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L804"></a><tt class="py-lineno"> 804</tt>  <tt class="py-line">        <tt id="link-141" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-141', 'name', 'link-14');">name</a></tt> <tt class="py-op">=</tt> <tt class="py-name">f</tt><tt class="py-op">.</tt><tt id="link-142" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-142', 'name', 'link-14');">name</a></tt> </tt>
<a name="L805"></a><tt class="py-lineno"> 805</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt id="link-143" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-143', 'name', 'link-14');">name</a></tt><tt class="py-op">.</tt><tt class="py-name">startswith</tt><tt class="py-op">(</tt><tt class="py-string">"__"</tt><tt class="py-op">)</tt> <tt class="py-keyword">and</tt> <tt id="link-144" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-144', 'name', 'link-14');">name</a></tt><tt class="py-op">.</tt><tt class="py-name">endswith</tt><tt class="py-op">(</tt><tt class="py-string">"__"</tt><tt class="py-op">)</tt> </tt>
<a name="L806"></a><tt class="py-lineno"> 806</tt>  <tt class="py-line">                <tt class="py-keyword">or</tt> <tt class="py-name">keyword</tt><tt class="py-op">.</tt><tt class="py-name">iskeyword</tt><tt class="py-op">(</tt><tt id="link-145" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-145', 'name', 'link-14');">name</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L807"></a><tt class="py-lineno"> 807</tt>  <tt class="py-line">            <tt class="py-name">warnings</tt><tt class="py-op">.</tt><tt class="py-name">warn</tt><tt class="py-op">(</tt><tt class="py-string">"field name %s can not be accessed in Python,"</tt> </tt>
<a name="L808"></a><tt class="py-lineno"> 808</tt>  <tt class="py-line">                          <tt class="py-string">"use position to access it instead"</tt> <tt class="py-op">%</tt> <tt id="link-146" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-146', 'name', 'link-14');">name</a></tt><tt class="py-op">)</tt> </tt>
<a name="L809"></a><tt class="py-lineno"> 809</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">_has_struct</tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L810"></a><tt class="py-lineno"> 810</tt>  <tt class="py-line">            <tt class="py-comment"># delay creating object until accessing it</tt> </tt>
<a name="L811"></a><tt class="py-lineno"> 811</tt>  <tt class="py-line">            <tt class="py-name">getter</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_getter</tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">.</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt class="py-name">i</tt><tt class="py-op">)</tt> </tt>
<a name="L812"></a><tt class="py-lineno"> 812</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L813"></a><tt class="py-lineno"> 813</tt>  <tt class="py-line">            <tt class="py-name">getter</tt> <tt class="py-op">=</tt> <tt class="py-name">itemgetter</tt><tt class="py-op">(</tt><tt class="py-name">i</tt><tt class="py-op">)</tt> </tt>
<a name="L814"></a><tt class="py-lineno"> 814</tt>  <tt class="py-line">        <tt class="py-name">ps</tt><tt class="py-op">[</tt><tt id="link-147" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-147', 'name', 'link-14');">name</a></tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">property</tt><tt class="py-op">(</tt><tt class="py-name">getter</tt><tt class="py-op">)</tt> </tt>
<a name="L815"></a><tt class="py-lineno"> 815</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">ps</tt> </tt>
</div><a name="L816"></a><tt class="py-lineno"> 816</tt>  <tt class="py-line"> </tt>
<a name="_create_cls"></a><div id="_create_cls-def"><a name="L817"></a><tt class="py-lineno"> 817</tt>  <tt class="py-line"> </tt>
<a name="L818"></a><tt class="py-lineno"> 818</tt> <a class="py-toggle" href="#" id="_create_cls-toggle" onclick="return toggle('_create_cls');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_create_cls">_create_cls</a><tt class="py-op">(</tt><tt class="py-param">dataType</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_create_cls-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_create_cls-expanded"><a name="L819"></a><tt class="py-lineno"> 819</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L820"></a><tt class="py-lineno"> 820</tt>  <tt class="py-line"><tt class="py-docstring">    Create an class by dataType</tt> </tt>
<a name="L821"></a><tt class="py-lineno"> 821</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L822"></a><tt class="py-lineno"> 822</tt>  <tt class="py-line"><tt class="py-docstring">    The created class is similar to namedtuple, but can have nested schema.</tt> </tt>
<a name="L823"></a><tt class="py-lineno"> 823</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L824"></a><tt class="py-lineno"> 824</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; schema = _parse_schema_abstract("a b c")</tt> </tt>
<a name="L825"></a><tt class="py-lineno"> 825</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row = (1, 1.0, "str")</tt> </tt>
<a name="L826"></a><tt class="py-lineno"> 826</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; schema = _infer_schema_type(row, schema)</tt> </tt>
<a name="L827"></a><tt class="py-lineno"> 827</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; obj = _create_cls(schema)(row)</tt> </tt>
<a name="L828"></a><tt class="py-lineno"> 828</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; import pickle</tt> </tt>
<a name="L829"></a><tt class="py-lineno"> 829</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; pickle.loads(pickle.dumps(obj))</tt> </tt>
<a name="L830"></a><tt class="py-lineno"> 830</tt>  <tt class="py-line"><tt class="py-docstring">    Row(a=1, b=1.0, c='str')</tt> </tt>
<a name="L831"></a><tt class="py-lineno"> 831</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L832"></a><tt class="py-lineno"> 832</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row = [[1], {"key": (1, 2.0)}]</tt> </tt>
<a name="L833"></a><tt class="py-lineno"> 833</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; schema = _parse_schema_abstract("a[] b{c d}")</tt> </tt>
<a name="L834"></a><tt class="py-lineno"> 834</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; schema = _infer_schema_type(row, schema)</tt> </tt>
<a name="L835"></a><tt class="py-lineno"> 835</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; obj = _create_cls(schema)(row)</tt> </tt>
<a name="L836"></a><tt class="py-lineno"> 836</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; pickle.loads(pickle.dumps(obj))</tt> </tt>
<a name="L837"></a><tt class="py-lineno"> 837</tt>  <tt class="py-line"><tt class="py-docstring">    Row(a=[1], b={'key': Row(c=1, d=2.0)})</tt> </tt>
<a name="L838"></a><tt class="py-lineno"> 838</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L839"></a><tt class="py-lineno"> 839</tt>  <tt class="py-line"> </tt>
<a name="L840"></a><tt class="py-lineno"> 840</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-148" class="py-name"><a title="pyspark.sql.ArrayType" class="py-name" href="#" onclick="return doclink('link-148', 'ArrayType', 'link-26');">ArrayType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L841"></a><tt class="py-lineno"> 841</tt>  <tt class="py-line">        <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_cls</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">elementType</tt><tt class="py-op">)</tt> </tt>
<a name="L842"></a><tt class="py-lineno"> 842</tt>  <tt class="py-line"> </tt>
<a name="L843"></a><tt class="py-lineno"> 843</tt>  <tt class="py-line">        <tt class="py-keyword">class</tt> <tt class="py-def-name">List</tt><tt class="py-op">(</tt><tt class="py-base-class">list</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L844"></a><tt class="py-lineno"> 844</tt>  <tt class="py-line"> </tt>
<a name="L845"></a><tt class="py-lineno"> 845</tt>  <tt class="py-line">            <tt class="py-keyword">def</tt> <tt class="py-def-name">__getitem__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">i</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L846"></a><tt class="py-lineno"> 846</tt>  <tt class="py-line">                <tt class="py-comment"># create object with datetype</tt> </tt>
<a name="L847"></a><tt class="py-lineno"> 847</tt>  <tt class="py-line">                <tt class="py-keyword">return</tt> <tt class="py-name">_create_object</tt><tt class="py-op">(</tt><tt class="py-name">cls</tt><tt class="py-op">,</tt> <tt class="py-name">list</tt><tt class="py-op">.</tt><tt class="py-name">__getitem__</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">i</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L848"></a><tt class="py-lineno"> 848</tt>  <tt class="py-line"> </tt>
<a name="L849"></a><tt class="py-lineno"> 849</tt>  <tt class="py-line">            <tt class="py-keyword">def</tt> <tt class="py-def-name">__repr__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L850"></a><tt class="py-lineno"> 850</tt>  <tt class="py-line">                <tt class="py-comment"># call collect __repr__ for nested objects</tt> </tt>
<a name="L851"></a><tt class="py-lineno"> 851</tt>  <tt class="py-line">                <tt class="py-keyword">return</tt> <tt class="py-string">"[%s]"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-string">", "</tt><tt class="py-op">.</tt><tt id="link-149" class="py-name"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-149', 'join', 'link-17');">join</a></tt><tt class="py-op">(</tt><tt class="py-name">repr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">[</tt><tt class="py-name">i</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L852"></a><tt class="py-lineno"> 852</tt>  <tt class="py-line">                                           <tt class="py-keyword">for</tt> <tt class="py-name">i</tt> <tt class="py-keyword">in</tt> <tt class="py-name">range</tt><tt class="py-op">(</tt><tt class="py-name">len</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L853"></a><tt class="py-lineno"> 853</tt>  <tt class="py-line"> </tt>
<a name="L854"></a><tt class="py-lineno"> 854</tt>  <tt class="py-line">            <tt class="py-keyword">def</tt> <tt class="py-def-name">__reduce__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L855"></a><tt class="py-lineno"> 855</tt>  <tt class="py-line">                <tt class="py-keyword">return</tt> <tt class="py-name">list</tt><tt class="py-op">.</tt><tt id="link-150" class="py-name" targets="Method pyspark.accumulators.Accumulator.__reduce__()=pyspark.accumulators.Accumulator-class.html#__reduce__,Method pyspark.broadcast.Broadcast.__reduce__()=pyspark.broadcast.Broadcast-class.html#__reduce__,Method pyspark.sql.Row.__reduce__()=pyspark.sql.Row-class.html#__reduce__"><a title="pyspark.accumulators.Accumulator.__reduce__
pyspark.broadcast.Broadcast.__reduce__
pyspark.sql.Row.__reduce__" class="py-name" href="#" onclick="return doclink('link-150', '__reduce__', 'link-150');">__reduce__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L856"></a><tt class="py-lineno"> 856</tt>  <tt class="py-line"> </tt>
<a name="L857"></a><tt class="py-lineno"> 857</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">List</tt> </tt>
<a name="L858"></a><tt class="py-lineno"> 858</tt>  <tt class="py-line"> </tt>
<a name="L859"></a><tt class="py-lineno"> 859</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-151" class="py-name"><a title="pyspark.sql.MapType" class="py-name" href="#" onclick="return doclink('link-151', 'MapType', 'link-27');">MapType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L860"></a><tt class="py-lineno"> 860</tt>  <tt class="py-line">        <tt class="py-name">vcls</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_cls</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">valueType</tt><tt class="py-op">)</tt> </tt>
<a name="L861"></a><tt class="py-lineno"> 861</tt>  <tt class="py-line"> </tt>
<a name="L862"></a><tt class="py-lineno"> 862</tt>  <tt class="py-line">        <tt class="py-keyword">class</tt> <tt class="py-def-name">Dict</tt><tt class="py-op">(</tt><tt class="py-base-class">dict</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L863"></a><tt class="py-lineno"> 863</tt>  <tt class="py-line"> </tt>
<a name="L864"></a><tt class="py-lineno"> 864</tt>  <tt class="py-line">            <tt class="py-keyword">def</tt> <tt class="py-def-name">__getitem__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">k</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L865"></a><tt class="py-lineno"> 865</tt>  <tt class="py-line">                <tt class="py-comment"># create object with datetype</tt> </tt>
<a name="L866"></a><tt class="py-lineno"> 866</tt>  <tt class="py-line">                <tt class="py-keyword">return</tt> <tt class="py-name">_create_object</tt><tt class="py-op">(</tt><tt class="py-name">vcls</tt><tt class="py-op">,</tt> <tt class="py-name">dict</tt><tt class="py-op">.</tt><tt class="py-name">__getitem__</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">k</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L867"></a><tt class="py-lineno"> 867</tt>  <tt class="py-line"> </tt>
<a name="L868"></a><tt class="py-lineno"> 868</tt>  <tt class="py-line">            <tt class="py-keyword">def</tt> <tt class="py-def-name">__repr__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L869"></a><tt class="py-lineno"> 869</tt>  <tt class="py-line">                <tt class="py-comment"># call collect __repr__ for nested objects</tt> </tt>
<a name="L870"></a><tt class="py-lineno"> 870</tt>  <tt class="py-line">                <tt class="py-keyword">return</tt> <tt class="py-string">"{%s}"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-string">", "</tt><tt class="py-op">.</tt><tt id="link-152" class="py-name"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-152', 'join', 'link-17');">join</a></tt><tt class="py-op">(</tt><tt class="py-string">"%r: %r"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">[</tt><tt class="py-name">k</tt><tt class="py-op">]</tt><tt class="py-op">)</tt> </tt>
<a name="L871"></a><tt class="py-lineno"> 871</tt>  <tt class="py-line">                                           <tt class="py-keyword">for</tt> <tt class="py-name">k</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L872"></a><tt class="py-lineno"> 872</tt>  <tt class="py-line"> </tt>
<a name="L873"></a><tt class="py-lineno"> 873</tt>  <tt class="py-line">            <tt class="py-keyword">def</tt> <tt class="py-def-name">__reduce__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L874"></a><tt class="py-lineno"> 874</tt>  <tt class="py-line">                <tt class="py-keyword">return</tt> <tt class="py-name">dict</tt><tt class="py-op">.</tt><tt id="link-153" class="py-name"><a title="pyspark.accumulators.Accumulator.__reduce__
pyspark.broadcast.Broadcast.__reduce__
pyspark.sql.Row.__reduce__" class="py-name" href="#" onclick="return doclink('link-153', '__reduce__', 'link-150');">__reduce__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L875"></a><tt class="py-lineno"> 875</tt>  <tt class="py-line"> </tt>
<a name="L876"></a><tt class="py-lineno"> 876</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">Dict</tt> </tt>
<a name="L877"></a><tt class="py-lineno"> 877</tt>  <tt class="py-line"> </tt>
<a name="L878"></a><tt class="py-lineno"> 878</tt>  <tt class="py-line">    <tt class="py-keyword">elif</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">,</tt> <tt id="link-154" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-154', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L879"></a><tt class="py-lineno"> 879</tt>  <tt class="py-line">        <tt class="py-keyword">raise</tt> <tt class="py-name">Exception</tt><tt class="py-op">(</tt><tt class="py-string">"unexpected data type: %s"</tt> <tt class="py-op">%</tt> <tt class="py-name">dataType</tt><tt class="py-op">)</tt> </tt>
<a name="L880"></a><tt class="py-lineno"> 880</tt>  <tt class="py-line"> </tt>
<a name="L881"></a><tt class="py-lineno"> 881</tt>  <tt class="py-line">    <tt class="py-keyword">class</tt> <tt class="py-def-name">Row</tt><tt class="py-op">(</tt><tt class="py-base-class">tuple</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L882"></a><tt class="py-lineno"> 882</tt>  <tt class="py-line"> </tt>
<a name="L883"></a><tt class="py-lineno"> 883</tt>  <tt class="py-line">        <tt class="py-docstring">""" Row in SchemaRDD """</tt> </tt>
<a name="L884"></a><tt class="py-lineno"> 884</tt>  <tt class="py-line">        <tt class="py-name">__DATATYPE__</tt> <tt class="py-op">=</tt> <tt class="py-name">dataType</tt> </tt>
<a name="L885"></a><tt class="py-lineno"> 885</tt>  <tt class="py-line">        <tt class="py-name">__FIELDS__</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">.</tt><tt id="link-155" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-155', 'name', 'link-14');">name</a></tt> <tt class="py-keyword">for</tt> <tt class="py-name">f</tt> <tt class="py-keyword">in</tt> <tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt> </tt>
<a name="L886"></a><tt class="py-lineno"> 886</tt>  <tt class="py-line">        <tt class="py-name">__slots__</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L887"></a><tt class="py-lineno"> 887</tt>  <tt class="py-line"> </tt>
<a name="L888"></a><tt class="py-lineno"> 888</tt>  <tt class="py-line">        <tt class="py-comment"># create property for fast access</tt> </tt>
<a name="L889"></a><tt class="py-lineno"> 889</tt>  <tt class="py-line">        <tt class="py-name">locals</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">update</tt><tt class="py-op">(</tt><tt class="py-name">_create_properties</tt><tt class="py-op">(</tt><tt class="py-name">dataType</tt><tt class="py-op">.</tt><tt class="py-name">fields</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L890"></a><tt class="py-lineno"> 890</tt>  <tt class="py-line"> </tt>
<a name="L891"></a><tt class="py-lineno"> 891</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">__repr__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L892"></a><tt class="py-lineno"> 892</tt>  <tt class="py-line">            <tt class="py-comment"># call collect __repr__ for nested objects</tt> </tt>
<a name="L893"></a><tt class="py-lineno"> 893</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-string">"Row(%s)"</tt> <tt class="py-op">%</tt> <tt class="py-string">", "</tt><tt class="py-op">.</tt><tt id="link-156" class="py-name"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-156', 'join', 'link-17');">join</a></tt><tt class="py-op">(</tt><tt class="py-string">"%s=%r"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">n</tt><tt class="py-op">,</tt> <tt class="py-name">getattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">n</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L894"></a><tt class="py-lineno"> 894</tt>  <tt class="py-line">                                          <tt class="py-keyword">for</tt> <tt class="py-name">n</tt> <tt class="py-keyword">in</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L895"></a><tt class="py-lineno"> 895</tt>  <tt class="py-line"> </tt>
<a name="L896"></a><tt class="py-lineno"> 896</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">__reduce__</tt><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L897"></a><tt class="py-lineno"> 897</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">_restore_object</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__DATATYPE__</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L898"></a><tt class="py-lineno"> 898</tt>  <tt class="py-line"> </tt>
<a name="L899"></a><tt class="py-lineno"> 899</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt id="link-157" class="py-name" targets="Class pyspark.sql.Row=pyspark.sql.Row-class.html"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-157', 'Row', 'link-157');">Row</a></tt> </tt>
</div><a name="L900"></a><tt class="py-lineno"> 900</tt>  <tt class="py-line"> </tt>
<a name="SQLContext"></a><div id="SQLContext-def"><a name="L901"></a><tt class="py-lineno"> 901</tt>  <tt class="py-line"> </tt>
<a name="L902"></a><tt class="py-lineno"> 902</tt> <a class="py-toggle" href="#" id="SQLContext-toggle" onclick="return toggle('SQLContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html">SQLContext</a><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="SQLContext-expanded"><a name="L903"></a><tt class="py-lineno"> 903</tt>  <tt class="py-line"> </tt>
<a name="L904"></a><tt class="py-lineno"> 904</tt>  <tt class="py-line">    <tt class="py-docstring">"""Main entry point for SparkSQL functionality.</tt> </tt>
<a name="L905"></a><tt class="py-lineno"> 905</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L906"></a><tt class="py-lineno"> 906</tt>  <tt class="py-line"><tt class="py-docstring">    A SQLContext can be used create L{SchemaRDD}s, register L{SchemaRDD}s as</tt> </tt>
<a name="L907"></a><tt class="py-lineno"> 907</tt>  <tt class="py-line"><tt class="py-docstring">    tables, execute SQL over tables, cache tables, and read parquet files.</tt> </tt>
<a name="L908"></a><tt class="py-lineno"> 908</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L909"></a><tt class="py-lineno"> 909</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.__init__"></a><div id="SQLContext.__init__-def"><a name="L910"></a><tt class="py-lineno"> 910</tt> <a class="py-toggle" href="#" id="SQLContext.__init__-toggle" onclick="return toggle('SQLContext.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sparkContext</tt><tt class="py-op">,</tt> <tt class="py-param">sqlContext</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.__init__-expanded"><a name="L911"></a><tt class="py-lineno"> 911</tt>  <tt class="py-line">        <tt class="py-docstring">"""Create a new SQLContext.</tt> </tt>
<a name="L912"></a><tt class="py-lineno"> 912</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L913"></a><tt class="py-lineno"> 913</tt>  <tt class="py-line"><tt class="py-docstring">        @param sparkContext: The SparkContext to wrap.</tt> </tt>
<a name="L914"></a><tt class="py-lineno"> 914</tt>  <tt class="py-line"><tt class="py-docstring">        @param sqlContext: An optional JVM Scala SQLContext. If set, we do not instatiate a new</tt> </tt>
<a name="L915"></a><tt class="py-lineno"> 915</tt>  <tt class="py-line"><tt class="py-docstring">        SQLContext in the JVM, instead we make all calls to this object.</tt> </tt>
<a name="L916"></a><tt class="py-lineno"> 916</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L917"></a><tt class="py-lineno"> 917</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L918"></a><tt class="py-lineno"> 918</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.inferSchema(srdd) # doctest: +IGNORE_EXCEPTION_DETAIL</tt> </tt>
<a name="L919"></a><tt class="py-lineno"> 919</tt>  <tt class="py-line"><tt class="py-docstring">        Traceback (most recent call last):</tt> </tt>
<a name="L920"></a><tt class="py-lineno"> 920</tt>  <tt class="py-line"><tt class="py-docstring">            ...</tt> </tt>
<a name="L921"></a><tt class="py-lineno"> 921</tt>  <tt class="py-line"><tt class="py-docstring">        TypeError:...</tt> </tt>
<a name="L922"></a><tt class="py-lineno"> 922</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L923"></a><tt class="py-lineno"> 923</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; bad_rdd = sc.parallelize([1,2,3])</tt> </tt>
<a name="L924"></a><tt class="py-lineno"> 924</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.inferSchema(bad_rdd) # doctest: +IGNORE_EXCEPTION_DETAIL</tt> </tt>
<a name="L925"></a><tt class="py-lineno"> 925</tt>  <tt class="py-line"><tt class="py-docstring">        Traceback (most recent call last):</tt> </tt>
<a name="L926"></a><tt class="py-lineno"> 926</tt>  <tt class="py-line"><tt class="py-docstring">            ...</tt> </tt>
<a name="L927"></a><tt class="py-lineno"> 927</tt>  <tt class="py-line"><tt class="py-docstring">        ValueError:...</tt> </tt>
<a name="L928"></a><tt class="py-lineno"> 928</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L929"></a><tt class="py-lineno"> 929</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from datetime import datetime</tt> </tt>
<a name="L930"></a><tt class="py-lineno"> 930</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; allTypes = sc.parallelize([Row(i=1, s="string", d=1.0, l=1L,</tt> </tt>
<a name="L931"></a><tt class="py-lineno"> 931</tt>  <tt class="py-line"><tt class="py-docstring">        ...     b=True, list=[1, 2, 3], dict={"s": 0}, row=Row(a=1),</tt> </tt>
<a name="L932"></a><tt class="py-lineno"> 932</tt>  <tt class="py-line"><tt class="py-docstring">        ...     time=datetime(2014, 8, 1, 14, 1, 5))])</tt> </tt>
<a name="L933"></a><tt class="py-lineno"> 933</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(allTypes)</tt> </tt>
<a name="L934"></a><tt class="py-lineno"> 934</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.registerTempTable("allTypes")</tt> </tt>
<a name="L935"></a><tt class="py-lineno"> 935</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.sql('select i+1, d+1, not b, list[1], dict["s"], time, row.a '</tt> </tt>
<a name="L936"></a><tt class="py-lineno"> 936</tt>  <tt class="py-line"><tt class="py-docstring">        ...            'from allTypes where b and i &gt; 0').collect()</tt> </tt>
<a name="L937"></a><tt class="py-lineno"> 937</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(c0=2, c1=2.0, c2=False, c3=2, c4=0...8, 1, 14, 1, 5), a=1)]</tt> </tt>
<a name="L938"></a><tt class="py-lineno"> 938</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.map(lambda x: (x.i, x.s, x.d, x.l, x.b, x.time,</tt> </tt>
<a name="L939"></a><tt class="py-lineno"> 939</tt>  <tt class="py-line"><tt class="py-docstring">        ...                     x.row.a, x.list)).collect()</tt> </tt>
<a name="L940"></a><tt class="py-lineno"> 940</tt>  <tt class="py-line"><tt class="py-docstring">        [(1, u'string', 1.0, 1, True, ...(2014, 8, 1, 14, 1, 5), 1, [1, 2, 3])]</tt> </tt>
<a name="L941"></a><tt class="py-lineno"> 941</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L942"></a><tt class="py-lineno"> 942</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-158" class="py-name" targets="Variable pyspark.files.SparkFiles._sc=pyspark.files.SparkFiles-class.html#_sc"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-158', '_sc', 'link-158');">_sc</a></tt> <tt class="py-op">=</tt> <tt class="py-name">sparkContext</tt> </tt>
<a name="L943"></a><tt class="py-lineno"> 943</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-159" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-159', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt> </tt>
<a name="L944"></a><tt class="py-lineno"> 944</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-160" class="py-name" targets="Variable pyspark.context.SparkContext._jvm=pyspark.context.SparkContext-class.html#_jvm"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-160', '_jvm', 'link-160');">_jvm</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-161" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-161', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt id="link-162" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-162', '_jvm', 'link-160');">_jvm</a></tt> </tt>
<a name="L945"></a><tt class="py-lineno"> 945</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_pythonToJava</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-163" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-163', '_jvm', 'link-160');">_jvm</a></tt><tt class="py-op">.</tt><tt class="py-name">PythonRDD</tt><tt class="py-op">.</tt><tt class="py-name">pythonToJavaArray</tt> </tt>
<a name="L946"></a><tt class="py-lineno"> 946</tt>  <tt class="py-line"> </tt>
<a name="L947"></a><tt class="py-lineno"> 947</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">sqlContext</tt><tt class="py-op">:</tt> </tt>
<a name="L948"></a><tt class="py-lineno"> 948</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_SQLContext</tt> <tt class="py-op">=</tt> <tt class="py-name">sqlContext</tt> </tt>
</div><a name="L949"></a><tt class="py-lineno"> 949</tt>  <tt class="py-line"> </tt>
<a name="L950"></a><tt class="py-lineno"> 950</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="SQLContext._ssql_ctx"></a><div id="SQLContext._ssql_ctx-def"><a name="L951"></a><tt class="py-lineno"> 951</tt> <a class="py-toggle" href="#" id="SQLContext._ssql_ctx-toggle" onclick="return toggle('SQLContext._ssql_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#_ssql_ctx">_ssql_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext._ssql_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext._ssql_ctx-expanded"><a name="L952"></a><tt class="py-lineno"> 952</tt>  <tt class="py-line">        <tt class="py-docstring">"""Accessor for the JVM SparkSQL context.</tt> </tt>
<a name="L953"></a><tt class="py-lineno"> 953</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L954"></a><tt class="py-lineno"> 954</tt>  <tt class="py-line"><tt class="py-docstring">        Subclasses can override this property to provide their own</tt> </tt>
<a name="L955"></a><tt class="py-lineno"> 955</tt>  <tt class="py-line"><tt class="py-docstring">        JVM Contexts.</tt> </tt>
<a name="L956"></a><tt class="py-lineno"> 956</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L957"></a><tt class="py-lineno"> 957</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">'_scala_SQLContext'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L958"></a><tt class="py-lineno"> 958</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_SQLContext</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-164" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-164', '_jvm', 'link-160');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-165" class="py-name" targets="Class pyspark.sql.SQLContext=pyspark.sql.SQLContext-class.html"><a title="pyspark.sql.SQLContext" class="py-name" href="#" onclick="return doclink('link-165', 'SQLContext', 'link-165');">SQLContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L959"></a><tt class="py-lineno"> 959</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_SQLContext</tt> </tt>
</div><a name="L960"></a><tt class="py-lineno"> 960</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.registerFunction"></a><div id="SQLContext.registerFunction-def"><a name="L961"></a><tt class="py-lineno"> 961</tt> <a class="py-toggle" href="#" id="SQLContext.registerFunction-toggle" onclick="return toggle('SQLContext.registerFunction');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#registerFunction">registerFunction</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">name</tt><tt class="py-op">,</tt> <tt class="py-param">f</tt><tt class="py-op">,</tt> <tt class="py-param">returnType</tt><tt class="py-op">=</tt><tt id="link-166" class="py-name"><a title="pyspark.sql.StringType" class="py-name" href="#" onclick="return doclink('link-166', 'StringType', 'link-37');">StringType</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.registerFunction-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.registerFunction-expanded"><a name="L962"></a><tt class="py-lineno"> 962</tt>  <tt class="py-line">        <tt class="py-docstring">"""Registers a lambda function as a UDF so it can be used in SQL statements.</tt> </tt>
<a name="L963"></a><tt class="py-lineno"> 963</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L964"></a><tt class="py-lineno"> 964</tt>  <tt class="py-line"><tt class="py-docstring">        In addition to a name and the function itself, the return type can be optionally specified.</tt> </tt>
<a name="L965"></a><tt class="py-lineno"> 965</tt>  <tt class="py-line"><tt class="py-docstring">        When the return type is not given it default to a string and conversion will automatically</tt> </tt>
<a name="L966"></a><tt class="py-lineno"> 966</tt>  <tt class="py-line"><tt class="py-docstring">        be done.  For any other return type, the produced object must match the specified type.</tt> </tt>
<a name="L967"></a><tt class="py-lineno"> 967</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L968"></a><tt class="py-lineno"> 968</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerFunction("stringLengthString", lambda x: len(x))</tt> </tt>
<a name="L969"></a><tt class="py-lineno"> 969</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.sql("SELECT stringLengthString('test')").collect()</tt> </tt>
<a name="L970"></a><tt class="py-lineno"> 970</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(c0=u'4')]</tt> </tt>
<a name="L971"></a><tt class="py-lineno"> 971</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerFunction("stringLengthInt", lambda x: len(x), IntegerType())</tt> </tt>
<a name="L972"></a><tt class="py-lineno"> 972</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.sql("SELECT stringLengthInt('test')").collect()</tt> </tt>
<a name="L973"></a><tt class="py-lineno"> 973</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(c0=4)]</tt> </tt>
<a name="L974"></a><tt class="py-lineno"> 974</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerFunction("twoArgs", lambda x, y: len(x) + y, IntegerType())</tt> </tt>
<a name="L975"></a><tt class="py-lineno"> 975</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.sql("SELECT twoArgs('test', 1)").collect()</tt> </tt>
<a name="L976"></a><tt class="py-lineno"> 976</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(c0=5)]</tt> </tt>
<a name="L977"></a><tt class="py-lineno"> 977</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L978"></a><tt class="py-lineno"> 978</tt>  <tt class="py-line">        <tt class="py-name">func</tt> <tt class="py-op">=</tt> <tt class="py-keyword">lambda</tt> <tt class="py-name">_</tt><tt class="py-op">,</tt> <tt class="py-name">it</tt><tt class="py-op">:</tt> <tt class="py-name">imap</tt><tt class="py-op">(</tt><tt class="py-keyword">lambda</tt> <tt class="py-name">x</tt><tt class="py-op">:</tt> <tt class="py-name">f</tt><tt class="py-op">(</tt><tt class="py-op">*</tt><tt class="py-name">x</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">it</tt><tt class="py-op">)</tt> </tt>
<a name="L979"></a><tt class="py-lineno"> 979</tt>  <tt class="py-line">        <tt class="py-name">command</tt> <tt class="py-op">=</tt> <tt class="py-op">(</tt><tt class="py-name">func</tt><tt class="py-op">,</tt> </tt>
<a name="L980"></a><tt class="py-lineno"> 980</tt>  <tt class="py-line">                   <tt class="py-name">BatchedSerializer</tt><tt class="py-op">(</tt><tt id="link-167" class="py-name"><a title="pyspark.serializers.PickleSerializer" class="py-name" href="#" onclick="return doclink('link-167', 'PickleSerializer', 'link-5');">PickleSerializer</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-number">1024</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L981"></a><tt class="py-lineno"> 981</tt>  <tt class="py-line">                   <tt class="py-name">BatchedSerializer</tt><tt class="py-op">(</tt><tt id="link-168" class="py-name"><a title="pyspark.serializers.PickleSerializer" class="py-name" href="#" onclick="return doclink('link-168', 'PickleSerializer', 'link-5');">PickleSerializer</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-number">1024</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L982"></a><tt class="py-lineno"> 982</tt>  <tt class="py-line">        <tt class="py-name">env</tt> <tt class="py-op">=</tt> <tt class="py-name">MapConverter</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">convert</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-169" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-169', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt class="py-name">environment</tt><tt class="py-op">,</tt> </tt>
<a name="L983"></a><tt class="py-lineno"> 983</tt>  <tt class="py-line">                                     <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-170" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-170', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt id="link-171" class="py-name" targets="Variable pyspark.context.SparkContext._gateway=pyspark.context.SparkContext-class.html#_gateway"><a title="pyspark.context.SparkContext._gateway" class="py-name" href="#" onclick="return doclink('link-171', '_gateway', 'link-171');">_gateway</a></tt><tt class="py-op">.</tt><tt class="py-name">_gateway_client</tt><tt class="py-op">)</tt> </tt>
<a name="L984"></a><tt class="py-lineno"> 984</tt>  <tt class="py-line">        <tt class="py-name">includes</tt> <tt class="py-op">=</tt> <tt class="py-name">ListConverter</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">convert</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-172" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-172', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt id="link-173" class="py-name" targets="Variable pyspark.context.SparkContext._python_includes=pyspark.context.SparkContext-class.html#_python_includes"><a title="pyspark.context.SparkContext._python_includes" class="py-name" href="#" onclick="return doclink('link-173', '_python_includes', 'link-173');">_python_includes</a></tt><tt class="py-op">,</tt> </tt>
<a name="L985"></a><tt class="py-lineno"> 985</tt>  <tt class="py-line">                                           <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-174" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-174', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt id="link-175" class="py-name"><a title="pyspark.context.SparkContext._gateway" class="py-name" href="#" onclick="return doclink('link-175', '_gateway', 'link-171');">_gateway</a></tt><tt class="py-op">.</tt><tt class="py-name">_gateway_client</tt><tt class="py-op">)</tt> </tt>
<a name="L986"></a><tt class="py-lineno"> 986</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt class="py-name">registerPython</tt><tt class="py-op">(</tt><tt id="link-176" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-176', 'name', 'link-14');">name</a></tt><tt class="py-op">,</tt> </tt>
<a name="L987"></a><tt class="py-lineno"> 987</tt>  <tt class="py-line">                                      <tt class="py-name">bytearray</tt><tt class="py-op">(</tt><tt class="py-name">CloudPickleSerializer</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt id="link-177" class="py-name" targets="Variable pyspark.serializers.MarshalSerializer.dumps=pyspark.serializers.MarshalSerializer-class.html#dumps,Method pyspark.serializers.PickleSerializer.dumps()=pyspark.serializers.PickleSerializer-class.html#dumps"><a title="pyspark.serializers.MarshalSerializer.dumps
pyspark.serializers.PickleSerializer.dumps" class="py-name" href="#" onclick="return doclink('link-177', 'dumps', 'link-177');">dumps</a></tt><tt class="py-op">(</tt><tt class="py-name">command</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L988"></a><tt class="py-lineno"> 988</tt>  <tt class="py-line">                                      <tt class="py-name">env</tt><tt class="py-op">,</tt> </tt>
<a name="L989"></a><tt class="py-lineno"> 989</tt>  <tt class="py-line">                                      <tt class="py-name">includes</tt><tt class="py-op">,</tt> </tt>
<a name="L990"></a><tt class="py-lineno"> 990</tt>  <tt class="py-line">                                      <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-178" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-178', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt class="py-name">pythonExec</tt><tt class="py-op">,</tt> </tt>
<a name="L991"></a><tt class="py-lineno"> 991</tt>  <tt class="py-line">                                      <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-179" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-179', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">.</tt><tt class="py-name">_javaAccumulator</tt><tt class="py-op">,</tt> </tt>
<a name="L992"></a><tt class="py-lineno"> 992</tt>  <tt class="py-line">                                      <tt class="py-name">str</tt><tt class="py-op">(</tt><tt class="py-name">returnType</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L993"></a><tt class="py-lineno"> 993</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.inferSchema"></a><div id="SQLContext.inferSchema-def"><a name="L994"></a><tt class="py-lineno"> 994</tt> <a class="py-toggle" href="#" id="SQLContext.inferSchema-toggle" onclick="return toggle('SQLContext.inferSchema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#inferSchema">inferSchema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.inferSchema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.inferSchema-expanded"><a name="L995"></a><tt class="py-lineno"> 995</tt>  <tt class="py-line">        <tt class="py-docstring">"""Infer and apply a schema to an RDD of L{Row}s.</tt> </tt>
<a name="L996"></a><tt class="py-lineno"> 996</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L997"></a><tt class="py-lineno"> 997</tt>  <tt class="py-line"><tt class="py-docstring">        We peek at the first row of the RDD to determine the fields' names</tt> </tt>
<a name="L998"></a><tt class="py-lineno"> 998</tt>  <tt class="py-line"><tt class="py-docstring">        and types. Nested collections are supported, which include array,</tt> </tt>
<a name="L999"></a><tt class="py-lineno"> 999</tt>  <tt class="py-line"><tt class="py-docstring">        dict, list, Row, tuple, namedtuple, or object.</tt> </tt>
<a name="L1000"></a><tt class="py-lineno">1000</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1001"></a><tt class="py-lineno">1001</tt>  <tt class="py-line"><tt class="py-docstring">        All the rows in `rdd` should have the same type with the first one,</tt> </tt>
<a name="L1002"></a><tt class="py-lineno">1002</tt>  <tt class="py-line"><tt class="py-docstring">        or it will cause runtime exceptions.</tt> </tt>
<a name="L1003"></a><tt class="py-lineno">1003</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1004"></a><tt class="py-lineno">1004</tt>  <tt class="py-line"><tt class="py-docstring">        Each row could be L{pyspark.sql.Row} object or namedtuple or objects,</tt> </tt>
<a name="L1005"></a><tt class="py-lineno">1005</tt>  <tt class="py-line"><tt class="py-docstring">        using dict is deprecated.</tt> </tt>
<a name="L1006"></a><tt class="py-lineno">1006</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1007"></a><tt class="py-lineno">1007</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rdd = sc.parallelize(</tt> </tt>
<a name="L1008"></a><tt class="py-lineno">1008</tt>  <tt class="py-line"><tt class="py-docstring">        ...     [Row(field1=1, field2="row1"),</tt> </tt>
<a name="L1009"></a><tt class="py-lineno">1009</tt>  <tt class="py-line"><tt class="py-docstring">        ...      Row(field1=2, field2="row2"),</tt> </tt>
<a name="L1010"></a><tt class="py-lineno">1010</tt>  <tt class="py-line"><tt class="py-docstring">        ...      Row(field1=3, field2="row3")])</tt> </tt>
<a name="L1011"></a><tt class="py-lineno">1011</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1012"></a><tt class="py-lineno">1012</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect()[0]</tt> </tt>
<a name="L1013"></a><tt class="py-lineno">1013</tt>  <tt class="py-line"><tt class="py-docstring">        Row(field1=1, field2=u'row1')</tt> </tt>
<a name="L1014"></a><tt class="py-lineno">1014</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1015"></a><tt class="py-lineno">1015</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; NestedRow = Row("f1", "f2")</tt> </tt>
<a name="L1016"></a><tt class="py-lineno">1016</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; nestedRdd1 = sc.parallelize([</tt> </tt>
<a name="L1017"></a><tt class="py-lineno">1017</tt>  <tt class="py-line"><tt class="py-docstring">        ...     NestedRow(array('i', [1, 2]), {"row1": 1.0}),</tt> </tt>
<a name="L1018"></a><tt class="py-lineno">1018</tt>  <tt class="py-line"><tt class="py-docstring">        ...     NestedRow(array('i', [2, 3]), {"row2": 2.0})])</tt> </tt>
<a name="L1019"></a><tt class="py-lineno">1019</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(nestedRdd1)</tt> </tt>
<a name="L1020"></a><tt class="py-lineno">1020</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect()</tt> </tt>
<a name="L1021"></a><tt class="py-lineno">1021</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(f1=[1, 2], f2={u'row1': 1.0}), ..., f2={u'row2': 2.0})]</tt> </tt>
<a name="L1022"></a><tt class="py-lineno">1022</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1023"></a><tt class="py-lineno">1023</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; nestedRdd2 = sc.parallelize([</tt> </tt>
<a name="L1024"></a><tt class="py-lineno">1024</tt>  <tt class="py-line"><tt class="py-docstring">        ...     NestedRow([[1, 2], [2, 3]], [1, 2]),</tt> </tt>
<a name="L1025"></a><tt class="py-lineno">1025</tt>  <tt class="py-line"><tt class="py-docstring">        ...     NestedRow([[2, 3], [3, 4]], [2, 3])])</tt> </tt>
<a name="L1026"></a><tt class="py-lineno">1026</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(nestedRdd2)</tt> </tt>
<a name="L1027"></a><tt class="py-lineno">1027</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect()</tt> </tt>
<a name="L1028"></a><tt class="py-lineno">1028</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(f1=[[1, 2], [2, 3]], f2=[1, 2]), ..., f2=[2, 3])]</tt> </tt>
<a name="L1029"></a><tt class="py-lineno">1029</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1030"></a><tt class="py-lineno">1030</tt>  <tt class="py-line"> </tt>
<a name="L1031"></a><tt class="py-lineno">1031</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt id="link-180" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-180', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt id="link-181" class="py-name" targets="Class pyspark.sql.SchemaRDD=pyspark.sql.SchemaRDD-class.html"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-181', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1032"></a><tt class="py-lineno">1032</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">TypeError</tt><tt class="py-op">(</tt><tt class="py-string">"Cannot apply schema to SchemaRDD"</tt><tt class="py-op">)</tt> </tt>
<a name="L1033"></a><tt class="py-lineno">1033</tt>  <tt class="py-line"> </tt>
<a name="L1034"></a><tt class="py-lineno">1034</tt>  <tt class="py-line">        <tt id="link-182" class="py-name" targets="Method pyspark.rdd.RDD.first()=pyspark.rdd.RDD-class.html#first"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-182', 'first', 'link-182');">first</a></tt> <tt class="py-op">=</tt> <tt id="link-183" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-183', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-184" class="py-name"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-184', 'first', 'link-182');">first</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1035"></a><tt class="py-lineno">1035</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt id="link-185" class="py-name"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-185', 'first', 'link-182');">first</a></tt><tt class="py-op">:</tt> </tt>
<a name="L1036"></a><tt class="py-lineno">1036</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"The first row in RDD is empty, "</tt> </tt>
<a name="L1037"></a><tt class="py-lineno">1037</tt>  <tt class="py-line">                             <tt class="py-string">"can not infer schema"</tt><tt class="py-op">)</tt> </tt>
<a name="L1038"></a><tt class="py-lineno">1038</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">type</tt><tt class="py-op">(</tt><tt id="link-186" class="py-name"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-186', 'first', 'link-182');">first</a></tt><tt class="py-op">)</tt> <tt class="py-keyword">is</tt> <tt class="py-name">dict</tt><tt class="py-op">:</tt> </tt>
<a name="L1039"></a><tt class="py-lineno">1039</tt>  <tt class="py-line">            <tt class="py-name">warnings</tt><tt class="py-op">.</tt><tt class="py-name">warn</tt><tt class="py-op">(</tt><tt class="py-string">"Using RDD of dict to inferSchema is deprecated,"</tt> </tt>
<a name="L1040"></a><tt class="py-lineno">1040</tt>  <tt class="py-line">                          <tt class="py-string">"please use pyspark.Row instead"</tt><tt class="py-op">)</tt> </tt>
<a name="L1041"></a><tt class="py-lineno">1041</tt>  <tt class="py-line"> </tt>
<a name="L1042"></a><tt class="py-lineno">1042</tt>  <tt class="py-line">        <tt id="link-187" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-187', 'schema', 'link-65');">schema</a></tt> <tt class="py-op">=</tt> <tt class="py-name">_infer_schema</tt><tt class="py-op">(</tt><tt id="link-188" class="py-name"><a title="pyspark.rdd.RDD.first" class="py-name" href="#" onclick="return doclink('link-188', 'first', 'link-182');">first</a></tt><tt class="py-op">)</tt> </tt>
<a name="L1043"></a><tt class="py-lineno">1043</tt>  <tt class="py-line">        <tt id="link-189" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-189', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt id="link-190" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-190', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-191" class="py-name" targets="Method pyspark.rdd.RDD.mapPartitions()=pyspark.rdd.RDD-class.html#mapPartitions"><a title="pyspark.rdd.RDD.mapPartitions" class="py-name" href="#" onclick="return doclink('link-191', 'mapPartitions', 'link-191');">mapPartitions</a></tt><tt class="py-op">(</tt><tt class="py-keyword">lambda</tt> <tt class="py-name">rows</tt><tt class="py-op">:</tt> <tt class="py-name">_drop_schema</tt><tt class="py-op">(</tt><tt class="py-name">rows</tt><tt class="py-op">,</tt> <tt id="link-192" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-192', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1044"></a><tt class="py-lineno">1044</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-193" class="py-name" targets="Method pyspark.sql.SQLContext.applySchema()=pyspark.sql.SQLContext-class.html#applySchema"><a title="pyspark.sql.SQLContext.applySchema" class="py-name" href="#" onclick="return doclink('link-193', 'applySchema', 'link-193');">applySchema</a></tt><tt class="py-op">(</tt><tt id="link-194" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-194', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt id="link-195" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-195', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt> </tt>
</div><a name="L1045"></a><tt class="py-lineno">1045</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.applySchema"></a><div id="SQLContext.applySchema-def"><a name="L1046"></a><tt class="py-lineno">1046</tt> <a class="py-toggle" href="#" id="SQLContext.applySchema-toggle" onclick="return toggle('SQLContext.applySchema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#applySchema">applySchema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.applySchema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.applySchema-expanded"><a name="L1047"></a><tt class="py-lineno">1047</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L1048"></a><tt class="py-lineno">1048</tt>  <tt class="py-line"><tt class="py-docstring">        Applies the given schema to the given RDD of L{tuple} or L{list}s.</tt> </tt>
<a name="L1049"></a><tt class="py-lineno">1049</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1050"></a><tt class="py-lineno">1050</tt>  <tt class="py-line"><tt class="py-docstring">        These tuples or lists can contain complex nested structures like</tt> </tt>
<a name="L1051"></a><tt class="py-lineno">1051</tt>  <tt class="py-line"><tt class="py-docstring">        lists, maps or nested rows.</tt> </tt>
<a name="L1052"></a><tt class="py-lineno">1052</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1053"></a><tt class="py-lineno">1053</tt>  <tt class="py-line"><tt class="py-docstring">        The schema should be a StructType.</tt> </tt>
<a name="L1054"></a><tt class="py-lineno">1054</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1055"></a><tt class="py-lineno">1055</tt>  <tt class="py-line"><tt class="py-docstring">        It is important that the schema matches the types of the objects</tt> </tt>
<a name="L1056"></a><tt class="py-lineno">1056</tt>  <tt class="py-line"><tt class="py-docstring">        in each row or exceptions could be thrown at runtime.</tt> </tt>
<a name="L1057"></a><tt class="py-lineno">1057</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1058"></a><tt class="py-lineno">1058</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rdd2 = sc.parallelize([(1, "row1"), (2, "row2"), (3, "row3")])</tt> </tt>
<a name="L1059"></a><tt class="py-lineno">1059</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([StructField("field1", IntegerType(), False),</tt> </tt>
<a name="L1060"></a><tt class="py-lineno">1060</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field2", StringType(), False)])</tt> </tt>
<a name="L1061"></a><tt class="py-lineno">1061</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.applySchema(rdd2, schema)</tt> </tt>
<a name="L1062"></a><tt class="py-lineno">1062</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L1063"></a><tt class="py-lineno">1063</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql("SELECT * from table1")</tt> </tt>
<a name="L1064"></a><tt class="py-lineno">1064</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2.collect()</tt> </tt>
<a name="L1065"></a><tt class="py-lineno">1065</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(field1=1, field2=u'row1'),..., Row(field1=3, field2=u'row3')]</tt> </tt>
<a name="L1066"></a><tt class="py-lineno">1066</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1067"></a><tt class="py-lineno">1067</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; from datetime import datetime</tt> </tt>
<a name="L1068"></a><tt class="py-lineno">1068</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rdd = sc.parallelize([(127, -128L, -32768, 32767, 2147483647L, 1.0,</tt> </tt>
<a name="L1069"></a><tt class="py-lineno">1069</tt>  <tt class="py-line"><tt class="py-docstring">        ...     datetime(2010, 1, 1, 1, 1, 1),</tt> </tt>
<a name="L1070"></a><tt class="py-lineno">1070</tt>  <tt class="py-line"><tt class="py-docstring">        ...     {"a": 1}, (2,), [1, 2, 3], None)])</tt> </tt>
<a name="L1071"></a><tt class="py-lineno">1071</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([</tt> </tt>
<a name="L1072"></a><tt class="py-lineno">1072</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("byte1", ByteType(), False),</tt> </tt>
<a name="L1073"></a><tt class="py-lineno">1073</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("byte2", ByteType(), False),</tt> </tt>
<a name="L1074"></a><tt class="py-lineno">1074</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("short1", ShortType(), False),</tt> </tt>
<a name="L1075"></a><tt class="py-lineno">1075</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("short2", ShortType(), False),</tt> </tt>
<a name="L1076"></a><tt class="py-lineno">1076</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("int", IntegerType(), False),</tt> </tt>
<a name="L1077"></a><tt class="py-lineno">1077</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("float", FloatType(), False),</tt> </tt>
<a name="L1078"></a><tt class="py-lineno">1078</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("time", TimestampType(), False),</tt> </tt>
<a name="L1079"></a><tt class="py-lineno">1079</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("map",</tt> </tt>
<a name="L1080"></a><tt class="py-lineno">1080</tt>  <tt class="py-line"><tt class="py-docstring">        ...         MapType(StringType(), IntegerType(), False), False),</tt> </tt>
<a name="L1081"></a><tt class="py-lineno">1081</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("struct",</tt> </tt>
<a name="L1082"></a><tt class="py-lineno">1082</tt>  <tt class="py-line"><tt class="py-docstring">        ...         StructType([StructField("b", ShortType(), False)]), False),</tt> </tt>
<a name="L1083"></a><tt class="py-lineno">1083</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("list", ArrayType(ByteType(), False), False),</tt> </tt>
<a name="L1084"></a><tt class="py-lineno">1084</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("null", DoubleType(), True)])</tt> </tt>
<a name="L1085"></a><tt class="py-lineno">1085</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.applySchema(rdd, schema)</tt> </tt>
<a name="L1086"></a><tt class="py-lineno">1086</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; results = srdd.map(</tt> </tt>
<a name="L1087"></a><tt class="py-lineno">1087</tt>  <tt class="py-line"><tt class="py-docstring">        ...     lambda x: (x.byte1, x.byte2, x.short1, x.short2, x.int, x.float, x.time,</tt> </tt>
<a name="L1088"></a><tt class="py-lineno">1088</tt>  <tt class="py-line"><tt class="py-docstring">        ...         x.map["a"], x.struct.b, x.list, x.null))</tt> </tt>
<a name="L1089"></a><tt class="py-lineno">1089</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; results.collect()[0]</tt> </tt>
<a name="L1090"></a><tt class="py-lineno">1090</tt>  <tt class="py-line"><tt class="py-docstring">        (127, -128, -32768, 32767, 2147483647, 1.0, ...(2010, 1, 1, 1, 1, 1), 1, 2, [1, 2, 3], None)</tt> </tt>
<a name="L1091"></a><tt class="py-lineno">1091</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1092"></a><tt class="py-lineno">1092</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.registerTempTable("table2")</tt> </tt>
<a name="L1093"></a><tt class="py-lineno">1093</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.sql(</tt> </tt>
<a name="L1094"></a><tt class="py-lineno">1094</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT byte1 - 1 AS byte1, byte2 + 1 AS byte2, " +</tt> </tt>
<a name="L1095"></a><tt class="py-lineno">1095</tt>  <tt class="py-line"><tt class="py-docstring">        ...     "short1 + 1 AS short1, short2 - 1 AS short2, int - 1 AS int, " +</tt> </tt>
<a name="L1096"></a><tt class="py-lineno">1096</tt>  <tt class="py-line"><tt class="py-docstring">        ...     "float + 1.5 as float FROM table2").collect()</tt> </tt>
<a name="L1097"></a><tt class="py-lineno">1097</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(byte1=126, byte2=-127, short1=-32767, short2=32766, int=2147483646, float=2.5)]</tt> </tt>
<a name="L1098"></a><tt class="py-lineno">1098</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1099"></a><tt class="py-lineno">1099</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rdd = sc.parallelize([(127, -32768, 1.0,</tt> </tt>
<a name="L1100"></a><tt class="py-lineno">1100</tt>  <tt class="py-line"><tt class="py-docstring">        ...     datetime(2010, 1, 1, 1, 1, 1),</tt> </tt>
<a name="L1101"></a><tt class="py-lineno">1101</tt>  <tt class="py-line"><tt class="py-docstring">        ...     {"a": 1}, (2,), [1, 2, 3])])</tt> </tt>
<a name="L1102"></a><tt class="py-lineno">1102</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; abstract = "byte short float time map{} struct(b) list[]"</tt> </tt>
<a name="L1103"></a><tt class="py-lineno">1103</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = _parse_schema_abstract(abstract)</tt> </tt>
<a name="L1104"></a><tt class="py-lineno">1104</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; typedSchema = _infer_schema_type(rdd.first(), schema)</tt> </tt>
<a name="L1105"></a><tt class="py-lineno">1105</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.applySchema(rdd, typedSchema)</tt> </tt>
<a name="L1106"></a><tt class="py-lineno">1106</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.collect()</tt> </tt>
<a name="L1107"></a><tt class="py-lineno">1107</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(byte=127, short=-32768, float=1.0, time=..., list=[1, 2, 3])]</tt> </tt>
<a name="L1108"></a><tt class="py-lineno">1108</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1109"></a><tt class="py-lineno">1109</tt>  <tt class="py-line"> </tt>
<a name="L1110"></a><tt class="py-lineno">1110</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt id="link-196" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-196', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt id="link-197" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-197', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1111"></a><tt class="py-lineno">1111</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">TypeError</tt><tt class="py-op">(</tt><tt class="py-string">"Cannot apply schema to SchemaRDD"</tt><tt class="py-op">)</tt> </tt>
<a name="L1112"></a><tt class="py-lineno">1112</tt>  <tt class="py-line"> </tt>
<a name="L1113"></a><tt class="py-lineno">1113</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt id="link-198" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-198', 'schema', 'link-65');">schema</a></tt><tt class="py-op">,</tt> <tt id="link-199" class="py-name"><a title="pyspark.sql.StructType" class="py-name" href="#" onclick="return doclink('link-199', 'StructType', 'link-31');">StructType</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1114"></a><tt class="py-lineno">1114</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">TypeError</tt><tt class="py-op">(</tt><tt class="py-string">"schema should be StructType"</tt><tt class="py-op">)</tt> </tt>
<a name="L1115"></a><tt class="py-lineno">1115</tt>  <tt class="py-line"> </tt>
<a name="L1116"></a><tt class="py-lineno">1116</tt>  <tt class="py-line">        <tt class="py-comment"># take the first few rows to verify schema</tt> </tt>
<a name="L1117"></a><tt class="py-lineno">1117</tt>  <tt class="py-line">        <tt class="py-name">rows</tt> <tt class="py-op">=</tt> <tt id="link-200" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-200', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-201" class="py-name" targets="Method pyspark.rdd.RDD.take()=pyspark.rdd.RDD-class.html#take"><a title="pyspark.rdd.RDD.take" class="py-name" href="#" onclick="return doclink('link-201', 'take', 'link-201');">take</a></tt><tt class="py-op">(</tt><tt class="py-number">10</tt><tt class="py-op">)</tt> </tt>
<a name="L1118"></a><tt class="py-lineno">1118</tt>  <tt class="py-line">        <tt class="py-keyword">for</tt> <tt class="py-name">row</tt> <tt class="py-keyword">in</tt> <tt class="py-name">rows</tt><tt class="py-op">:</tt> </tt>
<a name="L1119"></a><tt class="py-lineno">1119</tt>  <tt class="py-line">            <tt class="py-name">_verify_type</tt><tt class="py-op">(</tt><tt class="py-name">row</tt><tt class="py-op">,</tt> <tt id="link-202" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-202', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt> </tt>
<a name="L1120"></a><tt class="py-lineno">1120</tt>  <tt class="py-line"> </tt>
<a name="L1121"></a><tt class="py-lineno">1121</tt>  <tt class="py-line">        <tt class="py-name">batched</tt> <tt class="py-op">=</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt id="link-203" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-203', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">_jrdd_deserializer</tt><tt class="py-op">,</tt> <tt class="py-name">BatchedSerializer</tt><tt class="py-op">)</tt> </tt>
<a name="L1122"></a><tt class="py-lineno">1122</tt>  <tt class="py-line">        <tt class="py-name">jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_pythonToJava</tt><tt class="py-op">(</tt><tt id="link-204" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-204', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">,</tt> <tt class="py-name">batched</tt><tt class="py-op">)</tt> </tt>
<a name="L1123"></a><tt class="py-lineno">1123</tt>  <tt class="py-line">        <tt class="py-name">srdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt class="py-name">applySchemaToPythonRDD</tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-205" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-205', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">str</tt><tt class="py-op">(</tt><tt id="link-206" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-206', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1124"></a><tt class="py-lineno">1124</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-207" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-207', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">srdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1125"></a><tt class="py-lineno">1125</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.registerRDDAsTable"></a><div id="SQLContext.registerRDDAsTable-def"><a name="L1126"></a><tt class="py-lineno">1126</tt> <a class="py-toggle" href="#" id="SQLContext.registerRDDAsTable-toggle" onclick="return toggle('SQLContext.registerRDDAsTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#registerRDDAsTable">registerRDDAsTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.registerRDDAsTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.registerRDDAsTable-expanded"><a name="L1127"></a><tt class="py-lineno">1127</tt>  <tt class="py-line">        <tt class="py-docstring">"""Registers the given RDD as a temporary table in the catalog.</tt> </tt>
<a name="L1128"></a><tt class="py-lineno">1128</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1129"></a><tt class="py-lineno">1129</tt>  <tt class="py-line"><tt class="py-docstring">        Temporary tables exist only during the lifetime of this instance of</tt> </tt>
<a name="L1130"></a><tt class="py-lineno">1130</tt>  <tt class="py-line"><tt class="py-docstring">        SQLContext.</tt> </tt>
<a name="L1131"></a><tt class="py-lineno">1131</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1132"></a><tt class="py-lineno">1132</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1133"></a><tt class="py-lineno">1133</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L1134"></a><tt class="py-lineno">1134</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1135"></a><tt class="py-lineno">1135</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt id="link-208" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-208', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-209" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-209', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1136"></a><tt class="py-lineno">1136</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt id="link-210" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-210', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt> </tt>
<a name="L1137"></a><tt class="py-lineno">1137</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-211" class="py-name" targets="Method pyspark.sql.SQLContext.registerRDDAsTable()=pyspark.sql.SQLContext-class.html#registerRDDAsTable"><a title="pyspark.sql.SQLContext.registerRDDAsTable" class="py-name" href="#" onclick="return doclink('link-211', 'registerRDDAsTable', 'link-211');">registerRDDAsTable</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
<a name="L1138"></a><tt class="py-lineno">1138</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1139"></a><tt class="py-lineno">1139</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can only register SchemaRDD as table"</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1140"></a><tt class="py-lineno">1140</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.parquetFile"></a><div id="SQLContext.parquetFile-def"><a name="L1141"></a><tt class="py-lineno">1141</tt> <a class="py-toggle" href="#" id="SQLContext.parquetFile-toggle" onclick="return toggle('SQLContext.parquetFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#parquetFile">parquetFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">path</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.parquetFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.parquetFile-expanded"><a name="L1142"></a><tt class="py-lineno">1142</tt>  <tt class="py-line">        <tt class="py-docstring">"""Loads a Parquet file, returning the result as a L{SchemaRDD}.</tt> </tt>
<a name="L1143"></a><tt class="py-lineno">1143</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1144"></a><tt class="py-lineno">1144</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import tempfile, shutil</tt> </tt>
<a name="L1145"></a><tt class="py-lineno">1145</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; parquetFile = tempfile.mkdtemp()</tt> </tt>
<a name="L1146"></a><tt class="py-lineno">1146</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; shutil.rmtree(parquetFile)</tt> </tt>
<a name="L1147"></a><tt class="py-lineno">1147</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1148"></a><tt class="py-lineno">1148</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.saveAsParquetFile(parquetFile)</tt> </tt>
<a name="L1149"></a><tt class="py-lineno">1149</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.parquetFile(parquetFile)</tt> </tt>
<a name="L1150"></a><tt class="py-lineno">1150</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd.collect()) == sorted(srdd2.collect())</tt> </tt>
<a name="L1151"></a><tt class="py-lineno">1151</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L1152"></a><tt class="py-lineno">1152</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1153"></a><tt class="py-lineno">1153</tt>  <tt class="py-line">        <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-212" class="py-name" targets="Method pyspark.sql.SQLContext.parquetFile()=pyspark.sql.SQLContext-class.html#parquetFile"><a title="pyspark.sql.SQLContext.parquetFile" class="py-name" href="#" onclick="return doclink('link-212', 'parquetFile', 'link-212');">parquetFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">)</tt> </tt>
<a name="L1154"></a><tt class="py-lineno">1154</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-213" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-213', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1155"></a><tt class="py-lineno">1155</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.jsonFile"></a><div id="SQLContext.jsonFile-def"><a name="L1156"></a><tt class="py-lineno">1156</tt> <a class="py-toggle" href="#" id="SQLContext.jsonFile-toggle" onclick="return toggle('SQLContext.jsonFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#jsonFile">jsonFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">path</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.jsonFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.jsonFile-expanded"><a name="L1157"></a><tt class="py-lineno">1157</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L1158"></a><tt class="py-lineno">1158</tt>  <tt class="py-line"><tt class="py-docstring">        Loads a text file storing one JSON object per line as a</tt> </tt>
<a name="L1159"></a><tt class="py-lineno">1159</tt>  <tt class="py-line"><tt class="py-docstring">        L{SchemaRDD}.</tt> </tt>
<a name="L1160"></a><tt class="py-lineno">1160</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1161"></a><tt class="py-lineno">1161</tt>  <tt class="py-line"><tt class="py-docstring">        If the schema is provided, applies the given schema to this</tt> </tt>
<a name="L1162"></a><tt class="py-lineno">1162</tt>  <tt class="py-line"><tt class="py-docstring">        JSON dataset.</tt> </tt>
<a name="L1163"></a><tt class="py-lineno">1163</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1164"></a><tt class="py-lineno">1164</tt>  <tt class="py-line"><tt class="py-docstring">        Otherwise, it goes through the entire dataset once to determine</tt> </tt>
<a name="L1165"></a><tt class="py-lineno">1165</tt>  <tt class="py-line"><tt class="py-docstring">        the schema.</tt> </tt>
<a name="L1166"></a><tt class="py-lineno">1166</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1167"></a><tt class="py-lineno">1167</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import tempfile, shutil</tt> </tt>
<a name="L1168"></a><tt class="py-lineno">1168</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; jsonFile = tempfile.mkdtemp()</tt> </tt>
<a name="L1169"></a><tt class="py-lineno">1169</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; shutil.rmtree(jsonFile)</tt> </tt>
<a name="L1170"></a><tt class="py-lineno">1170</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ofn = open(jsonFile, 'w')</tt> </tt>
<a name="L1171"></a><tt class="py-lineno">1171</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; for json in jsonStrings:</tt> </tt>
<a name="L1172"></a><tt class="py-lineno">1172</tt>  <tt class="py-line"><tt class="py-docstring">        ...   print&gt;&gt;ofn, json</tt> </tt>
<a name="L1173"></a><tt class="py-lineno">1173</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; ofn.close()</tt> </tt>
<a name="L1174"></a><tt class="py-lineno">1174</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd1 = sqlCtx.jsonFile(jsonFile)</tt> </tt>
<a name="L1175"></a><tt class="py-lineno">1175</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd1, "table1")</tt> </tt>
<a name="L1176"></a><tt class="py-lineno">1176</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql(</tt> </tt>
<a name="L1177"></a><tt class="py-lineno">1177</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, "</tt> </tt>
<a name="L1178"></a><tt class="py-lineno">1178</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "field6 as f4 from table1")</tt> </tt>
<a name="L1179"></a><tt class="py-lineno">1179</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; for r in srdd2.collect():</tt> </tt>
<a name="L1180"></a><tt class="py-lineno">1180</tt>  <tt class="py-line"><tt class="py-docstring">        ...     print r</tt> </tt>
<a name="L1181"></a><tt class="py-lineno">1181</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=1, f2=u'row1', f3=Row(field4=11, field5=None), f4=None)</tt> </tt>
<a name="L1182"></a><tt class="py-lineno">1182</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=2, f2=None, f3=Row(field4=22,..., f4=[Row(field7=u'row2')])</tt> </tt>
<a name="L1183"></a><tt class="py-lineno">1183</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=None, f2=u'row3', f3=Row(field4=33, field5=[]), f4=None)</tt> </tt>
<a name="L1184"></a><tt class="py-lineno">1184</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd3 = sqlCtx.jsonFile(jsonFile, srdd1.schema())</tt> </tt>
<a name="L1185"></a><tt class="py-lineno">1185</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd3, "table2")</tt> </tt>
<a name="L1186"></a><tt class="py-lineno">1186</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd4 = sqlCtx.sql(</tt> </tt>
<a name="L1187"></a><tt class="py-lineno">1187</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, "</tt> </tt>
<a name="L1188"></a><tt class="py-lineno">1188</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "field6 as f4 from table2")</tt> </tt>
<a name="L1189"></a><tt class="py-lineno">1189</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; for r in srdd4.collect():</tt> </tt>
<a name="L1190"></a><tt class="py-lineno">1190</tt>  <tt class="py-line"><tt class="py-docstring">        ...    print r</tt> </tt>
<a name="L1191"></a><tt class="py-lineno">1191</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=1, f2=u'row1', f3=Row(field4=11, field5=None), f4=None)</tt> </tt>
<a name="L1192"></a><tt class="py-lineno">1192</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=2, f2=None, f3=Row(field4=22,..., f4=[Row(field7=u'row2')])</tt> </tt>
<a name="L1193"></a><tt class="py-lineno">1193</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=None, f2=u'row3', f3=Row(field4=33, field5=[]), f4=None)</tt> </tt>
<a name="L1194"></a><tt class="py-lineno">1194</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([</tt> </tt>
<a name="L1195"></a><tt class="py-lineno">1195</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field2", StringType(), True),</tt> </tt>
<a name="L1196"></a><tt class="py-lineno">1196</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field3",</tt> </tt>
<a name="L1197"></a><tt class="py-lineno">1197</tt>  <tt class="py-line"><tt class="py-docstring">        ...         StructType([</tt> </tt>
<a name="L1198"></a><tt class="py-lineno">1198</tt>  <tt class="py-line"><tt class="py-docstring">        ...             StructField("field5",</tt> </tt>
<a name="L1199"></a><tt class="py-lineno">1199</tt>  <tt class="py-line"><tt class="py-docstring">        ...                 ArrayType(IntegerType(), False), True)]), False)])</tt> </tt>
<a name="L1200"></a><tt class="py-lineno">1200</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd5 = sqlCtx.jsonFile(jsonFile, schema)</tt> </tt>
<a name="L1201"></a><tt class="py-lineno">1201</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd5, "table3")</tt> </tt>
<a name="L1202"></a><tt class="py-lineno">1202</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6 = sqlCtx.sql(</tt> </tt>
<a name="L1203"></a><tt class="py-lineno">1203</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field2 AS f1, field3.field5 as f2, "</tt> </tt>
<a name="L1204"></a><tt class="py-lineno">1204</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "field3.field5[0] as f3 from table3")</tt> </tt>
<a name="L1205"></a><tt class="py-lineno">1205</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6.collect()</tt> </tt>
<a name="L1206"></a><tt class="py-lineno">1206</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(f1=u'row1', f2=None, f3=None)...Row(f1=u'row3', f2=[], f3=None)]</tt> </tt>
<a name="L1207"></a><tt class="py-lineno">1207</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1208"></a><tt class="py-lineno">1208</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-214" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-214', 'schema', 'link-65');">schema</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L1209"></a><tt class="py-lineno">1209</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-215" class="py-name" targets="Method pyspark.sql.SQLContext.jsonFile()=pyspark.sql.SQLContext-class.html#jsonFile"><a title="pyspark.sql.SQLContext.jsonFile" class="py-name" href="#" onclick="return doclink('link-215', 'jsonFile', 'link-215');">jsonFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">)</tt> </tt>
<a name="L1210"></a><tt class="py-lineno">1210</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1211"></a><tt class="py-lineno">1211</tt>  <tt class="py-line">            <tt class="py-name">scala_datatype</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt class="py-name">parseDataType</tt><tt class="py-op">(</tt><tt class="py-name">str</tt><tt class="py-op">(</tt><tt id="link-216" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-216', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1212"></a><tt class="py-lineno">1212</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-217" class="py-name"><a title="pyspark.sql.SQLContext.jsonFile" class="py-name" href="#" onclick="return doclink('link-217', 'jsonFile', 'link-215');">jsonFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">,</tt> <tt class="py-name">scala_datatype</tt><tt class="py-op">)</tt> </tt>
<a name="L1213"></a><tt class="py-lineno">1213</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-218" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-218', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1214"></a><tt class="py-lineno">1214</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.jsonRDD"></a><div id="SQLContext.jsonRDD-def"><a name="L1215"></a><tt class="py-lineno">1215</tt> <a class="py-toggle" href="#" id="SQLContext.jsonRDD-toggle" onclick="return toggle('SQLContext.jsonRDD');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#jsonRDD">jsonRDD</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">rdd</tt><tt class="py-op">,</tt> <tt class="py-param">schema</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.jsonRDD-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.jsonRDD-expanded"><a name="L1216"></a><tt class="py-lineno">1216</tt>  <tt class="py-line">        <tt class="py-docstring">"""Loads an RDD storing one JSON object per string as a L{SchemaRDD}.</tt> </tt>
<a name="L1217"></a><tt class="py-lineno">1217</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1218"></a><tt class="py-lineno">1218</tt>  <tt class="py-line"><tt class="py-docstring">        If the schema is provided, applies the given schema to this</tt> </tt>
<a name="L1219"></a><tt class="py-lineno">1219</tt>  <tt class="py-line"><tt class="py-docstring">        JSON dataset.</tt> </tt>
<a name="L1220"></a><tt class="py-lineno">1220</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1221"></a><tt class="py-lineno">1221</tt>  <tt class="py-line"><tt class="py-docstring">        Otherwise, it goes through the entire dataset once to determine</tt> </tt>
<a name="L1222"></a><tt class="py-lineno">1222</tt>  <tt class="py-line"><tt class="py-docstring">        the schema.</tt> </tt>
<a name="L1223"></a><tt class="py-lineno">1223</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1224"></a><tt class="py-lineno">1224</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd1 = sqlCtx.jsonRDD(json)</tt> </tt>
<a name="L1225"></a><tt class="py-lineno">1225</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd1, "table1")</tt> </tt>
<a name="L1226"></a><tt class="py-lineno">1226</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql(</tt> </tt>
<a name="L1227"></a><tt class="py-lineno">1227</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, "</tt> </tt>
<a name="L1228"></a><tt class="py-lineno">1228</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "field6 as f4 from table1")</tt> </tt>
<a name="L1229"></a><tt class="py-lineno">1229</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; for r in srdd2.collect():</tt> </tt>
<a name="L1230"></a><tt class="py-lineno">1230</tt>  <tt class="py-line"><tt class="py-docstring">        ...     print r</tt> </tt>
<a name="L1231"></a><tt class="py-lineno">1231</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=1, f2=u'row1', f3=Row(field4=11, field5=None), f4=None)</tt> </tt>
<a name="L1232"></a><tt class="py-lineno">1232</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=2, f2=None, f3=Row(field4=22..., f4=[Row(field7=u'row2')])</tt> </tt>
<a name="L1233"></a><tt class="py-lineno">1233</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=None, f2=u'row3', f3=Row(field4=33, field5=[]), f4=None)</tt> </tt>
<a name="L1234"></a><tt class="py-lineno">1234</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd3 = sqlCtx.jsonRDD(json, srdd1.schema())</tt> </tt>
<a name="L1235"></a><tt class="py-lineno">1235</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd3, "table2")</tt> </tt>
<a name="L1236"></a><tt class="py-lineno">1236</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd4 = sqlCtx.sql(</tt> </tt>
<a name="L1237"></a><tt class="py-lineno">1237</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field1 AS f1, field2 as f2, field3 as f3, "</tt> </tt>
<a name="L1238"></a><tt class="py-lineno">1238</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "field6 as f4 from table2")</tt> </tt>
<a name="L1239"></a><tt class="py-lineno">1239</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; for r in srdd4.collect():</tt> </tt>
<a name="L1240"></a><tt class="py-lineno">1240</tt>  <tt class="py-line"><tt class="py-docstring">        ...     print r</tt> </tt>
<a name="L1241"></a><tt class="py-lineno">1241</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=1, f2=u'row1', f3=Row(field4=11, field5=None), f4=None)</tt> </tt>
<a name="L1242"></a><tt class="py-lineno">1242</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=2, f2=None, f3=Row(field4=22..., f4=[Row(field7=u'row2')])</tt> </tt>
<a name="L1243"></a><tt class="py-lineno">1243</tt>  <tt class="py-line"><tt class="py-docstring">        Row(f1=None, f2=u'row3', f3=Row(field4=33, field5=[]), f4=None)</tt> </tt>
<a name="L1244"></a><tt class="py-lineno">1244</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; schema = StructType([</tt> </tt>
<a name="L1245"></a><tt class="py-lineno">1245</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field2", StringType(), True),</tt> </tt>
<a name="L1246"></a><tt class="py-lineno">1246</tt>  <tt class="py-line"><tt class="py-docstring">        ...     StructField("field3",</tt> </tt>
<a name="L1247"></a><tt class="py-lineno">1247</tt>  <tt class="py-line"><tt class="py-docstring">        ...         StructType([</tt> </tt>
<a name="L1248"></a><tt class="py-lineno">1248</tt>  <tt class="py-line"><tt class="py-docstring">        ...             StructField("field5",</tt> </tt>
<a name="L1249"></a><tt class="py-lineno">1249</tt>  <tt class="py-line"><tt class="py-docstring">        ...                 ArrayType(IntegerType(), False), True)]), False)])</tt> </tt>
<a name="L1250"></a><tt class="py-lineno">1250</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd5 = sqlCtx.jsonRDD(json, schema)</tt> </tt>
<a name="L1251"></a><tt class="py-lineno">1251</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd5, "table3")</tt> </tt>
<a name="L1252"></a><tt class="py-lineno">1252</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6 = sqlCtx.sql(</tt> </tt>
<a name="L1253"></a><tt class="py-lineno">1253</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "SELECT field2 AS f1, field3.field5 as f2, "</tt> </tt>
<a name="L1254"></a><tt class="py-lineno">1254</tt>  <tt class="py-line"><tt class="py-docstring">        ...   "field3.field5[0] as f3 from table3")</tt> </tt>
<a name="L1255"></a><tt class="py-lineno">1255</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd6.collect()</tt> </tt>
<a name="L1256"></a><tt class="py-lineno">1256</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(f1=u'row1', f2=None,...Row(f1=u'row3', f2=[], f3=None)]</tt> </tt>
<a name="L1257"></a><tt class="py-lineno">1257</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1258"></a><tt class="py-lineno">1258</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.jsonRDD(sc.parallelize(['{}',</tt> </tt>
<a name="L1259"></a><tt class="py-lineno">1259</tt>  <tt class="py-line"><tt class="py-docstring">        ...         '{"key0": {"key1": "value1"}}'])).collect()</tt> </tt>
<a name="L1260"></a><tt class="py-lineno">1260</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(key0=None), Row(key0=Row(key1=u'value1'))]</tt> </tt>
<a name="L1261"></a><tt class="py-lineno">1261</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.jsonRDD(sc.parallelize(['{"key0": null}',</tt> </tt>
<a name="L1262"></a><tt class="py-lineno">1262</tt>  <tt class="py-line"><tt class="py-docstring">        ...         '{"key0": {"key1": "value1"}}'])).collect()</tt> </tt>
<a name="L1263"></a><tt class="py-lineno">1263</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(key0=None), Row(key0=Row(key1=u'value1'))]</tt> </tt>
<a name="L1264"></a><tt class="py-lineno">1264</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1265"></a><tt class="py-lineno">1265</tt>  <tt class="py-line"> </tt>
<a name="L1266"></a><tt class="py-lineno">1266</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">func</tt><tt class="py-op">(</tt><tt class="py-param">iterator</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1267"></a><tt class="py-lineno">1267</tt>  <tt class="py-line">            <tt class="py-keyword">for</tt> <tt class="py-name">x</tt> <tt class="py-keyword">in</tt> <tt class="py-name">iterator</tt><tt class="py-op">:</tt> </tt>
<a name="L1268"></a><tt class="py-lineno">1268</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">basestring</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1269"></a><tt class="py-lineno">1269</tt>  <tt class="py-line">                    <tt class="py-name">x</tt> <tt class="py-op">=</tt> <tt class="py-name">unicode</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">)</tt> </tt>
<a name="L1270"></a><tt class="py-lineno">1270</tt>  <tt class="py-line">                <tt class="py-keyword">if</tt> <tt class="py-name">isinstance</tt><tt class="py-op">(</tt><tt class="py-name">x</tt><tt class="py-op">,</tt> <tt class="py-name">unicode</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1271"></a><tt class="py-lineno">1271</tt>  <tt class="py-line">                    <tt class="py-name">x</tt> <tt class="py-op">=</tt> <tt class="py-name">x</tt><tt class="py-op">.</tt><tt class="py-name">encode</tt><tt class="py-op">(</tt><tt class="py-string">"utf-8"</tt><tt class="py-op">)</tt> </tt>
<a name="L1272"></a><tt class="py-lineno">1272</tt>  <tt class="py-line">                <tt class="py-keyword">yield</tt> <tt class="py-name">x</tt> </tt>
</div><a name="L1273"></a><tt class="py-lineno">1273</tt>  <tt class="py-line">        <tt class="py-name">keyed</tt> <tt class="py-op">=</tt> <tt id="link-219" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-219', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-220" class="py-name"><a title="pyspark.rdd.RDD.mapPartitions" class="py-name" href="#" onclick="return doclink('link-220', 'mapPartitions', 'link-191');">mapPartitions</a></tt><tt class="py-op">(</tt><tt class="py-name">func</tt><tt class="py-op">)</tt> </tt>
<a name="L1274"></a><tt class="py-lineno">1274</tt>  <tt class="py-line">        <tt class="py-name">keyed</tt><tt class="py-op">.</tt><tt class="py-name">_bypass_serializer</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L1275"></a><tt class="py-lineno">1275</tt>  <tt class="py-line">        <tt class="py-name">jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">keyed</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">.</tt><tt id="link-221" class="py-name"><a title="pyspark.rdd.RDD.map" class="py-name" href="#" onclick="return doclink('link-221', 'map', 'link-54');">map</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-222" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-222', '_jvm', 'link-160');">_jvm</a></tt><tt class="py-op">.</tt><tt class="py-name">BytesToString</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1276"></a><tt class="py-lineno">1276</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt id="link-223" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-223', 'schema', 'link-65');">schema</a></tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L1277"></a><tt class="py-lineno">1277</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-224" class="py-name" targets="Method pyspark.sql.SQLContext.jsonRDD()=pyspark.sql.SQLContext-class.html#jsonRDD"><a title="pyspark.sql.SQLContext.jsonRDD" class="py-name" href="#" onclick="return doclink('link-224', 'jsonRDD', 'link-224');">jsonRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-225" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-225', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1278"></a><tt class="py-lineno">1278</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1279"></a><tt class="py-lineno">1279</tt>  <tt class="py-line">            <tt class="py-name">scala_datatype</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt class="py-name">parseDataType</tt><tt class="py-op">(</tt><tt class="py-name">str</tt><tt class="py-op">(</tt><tt id="link-226" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-226', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1280"></a><tt class="py-lineno">1280</tt>  <tt class="py-line">            <tt class="py-name">jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-227" class="py-name"><a title="pyspark.sql.SQLContext.jsonRDD" class="py-name" href="#" onclick="return doclink('link-227', 'jsonRDD', 'link-224');">jsonRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jrdd</tt><tt class="py-op">.</tt><tt id="link-228" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-228', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">scala_datatype</tt><tt class="py-op">)</tt> </tt>
<a name="L1281"></a><tt class="py-lineno">1281</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-229" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-229', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1282"></a><tt class="py-lineno">1282</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.sql"></a><div id="SQLContext.sql-def"><a name="L1283"></a><tt class="py-lineno">1283</tt> <a class="py-toggle" href="#" id="SQLContext.sql-toggle" onclick="return toggle('SQLContext.sql');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#sql">sql</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.sql-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.sql-expanded"><a name="L1284"></a><tt class="py-lineno">1284</tt>  <tt class="py-line">        <tt class="py-docstring">"""Return a L{SchemaRDD} representing the result of the given query.</tt> </tt>
<a name="L1285"></a><tt class="py-lineno">1285</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1286"></a><tt class="py-lineno">1286</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1287"></a><tt class="py-lineno">1287</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L1288"></a><tt class="py-lineno">1288</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql("SELECT field1 AS f1, field2 as f2 from table1")</tt> </tt>
<a name="L1289"></a><tt class="py-lineno">1289</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2.collect()</tt> </tt>
<a name="L1290"></a><tt class="py-lineno">1290</tt>  <tt class="py-line"><tt class="py-docstring">        [Row(f1=1, f2=u'row1'), Row(f1=2, f2=u'row2'), Row(f1=3, f2=u'row3')]</tt> </tt>
<a name="L1291"></a><tt class="py-lineno">1291</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1292"></a><tt class="py-lineno">1292</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-230" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-230', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-231" class="py-name" targets="Module pyspark.sql=pyspark.sql-module.html,Method pyspark.sql.SQLContext.sql()=pyspark.sql.SQLContext-class.html#sql"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-231', 'sql', 'link-231');">sql</a></tt><tt class="py-op">(</tt><tt class="py-name">sqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1293"></a><tt class="py-lineno">1293</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.table"></a><div id="SQLContext.table-def"><a name="L1294"></a><tt class="py-lineno">1294</tt> <a class="py-toggle" href="#" id="SQLContext.table-toggle" onclick="return toggle('SQLContext.table');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#table">table</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.table-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.table-expanded"><a name="L1295"></a><tt class="py-lineno">1295</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the specified table as a L{SchemaRDD}.</tt> </tt>
<a name="L1296"></a><tt class="py-lineno">1296</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1297"></a><tt class="py-lineno">1297</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1298"></a><tt class="py-lineno">1298</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sqlCtx.registerRDDAsTable(srdd, "table1")</tt> </tt>
<a name="L1299"></a><tt class="py-lineno">1299</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.table("table1")</tt> </tt>
<a name="L1300"></a><tt class="py-lineno">1300</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd.collect()) == sorted(srdd2.collect())</tt> </tt>
<a name="L1301"></a><tt class="py-lineno">1301</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L1302"></a><tt class="py-lineno">1302</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1303"></a><tt class="py-lineno">1303</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-232" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-232', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-233" class="py-name" targets="Method pyspark.sql.SQLContext.table()=pyspark.sql.SQLContext-class.html#table"><a title="pyspark.sql.SQLContext.table" class="py-name" href="#" onclick="return doclink('link-233', 'table', 'link-233');">table</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1304"></a><tt class="py-lineno">1304</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.cacheTable"></a><div id="SQLContext.cacheTable-def"><a name="L1305"></a><tt class="py-lineno">1305</tt> <a class="py-toggle" href="#" id="SQLContext.cacheTable-toggle" onclick="return toggle('SQLContext.cacheTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#cacheTable">cacheTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.cacheTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.cacheTable-expanded"><a name="L1306"></a><tt class="py-lineno">1306</tt>  <tt class="py-line">        <tt class="py-docstring">"""Caches the specified table in-memory."""</tt> </tt>
<a name="L1307"></a><tt class="py-lineno">1307</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-234" class="py-name" targets="Method pyspark.sql.SQLContext.cacheTable()=pyspark.sql.SQLContext-class.html#cacheTable"><a title="pyspark.sql.SQLContext.cacheTable" class="py-name" href="#" onclick="return doclink('link-234', 'cacheTable', 'link-234');">cacheTable</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1308"></a><tt class="py-lineno">1308</tt>  <tt class="py-line"> </tt>
<a name="SQLContext.uncacheTable"></a><div id="SQLContext.uncacheTable-def"><a name="L1309"></a><tt class="py-lineno">1309</tt> <a class="py-toggle" href="#" id="SQLContext.uncacheTable-toggle" onclick="return toggle('SQLContext.uncacheTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SQLContext-class.html#uncacheTable">uncacheTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SQLContext.uncacheTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SQLContext.uncacheTable-expanded"><a name="L1310"></a><tt class="py-lineno">1310</tt>  <tt class="py-line">        <tt class="py-docstring">"""Removes the specified table from the in-memory cache."""</tt> </tt>
<a name="L1311"></a><tt class="py-lineno">1311</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-235" class="py-name" targets="Method pyspark.sql.SQLContext.uncacheTable()=pyspark.sql.SQLContext-class.html#uncacheTable"><a title="pyspark.sql.SQLContext.uncacheTable" class="py-name" href="#" onclick="return doclink('link-235', 'uncacheTable', 'link-235');">uncacheTable</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L1312"></a><tt class="py-lineno">1312</tt>  <tt class="py-line"> </tt>
<a name="HiveContext"></a><div id="HiveContext-def"><a name="L1313"></a><tt class="py-lineno">1313</tt>  <tt class="py-line"> </tt>
<a name="L1314"></a><tt class="py-lineno">1314</tt> <a class="py-toggle" href="#" id="HiveContext-toggle" onclick="return toggle('HiveContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html">HiveContext</a><tt class="py-op">(</tt><tt class="py-base-class">SQLContext</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="HiveContext-expanded"><a name="L1315"></a><tt class="py-lineno">1315</tt>  <tt class="py-line"> </tt>
<a name="L1316"></a><tt class="py-lineno">1316</tt>  <tt class="py-line">    <tt class="py-docstring">"""A variant of Spark SQL that integrates with data stored in Hive.</tt> </tt>
<a name="L1317"></a><tt class="py-lineno">1317</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1318"></a><tt class="py-lineno">1318</tt>  <tt class="py-line"><tt class="py-docstring">    Configuration for Hive is read from hive-site.xml on the classpath.</tt> </tt>
<a name="L1319"></a><tt class="py-lineno">1319</tt>  <tt class="py-line"><tt class="py-docstring">    It supports running both SQL and HiveQL commands.</tt> </tt>
<a name="L1320"></a><tt class="py-lineno">1320</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L1321"></a><tt class="py-lineno">1321</tt>  <tt class="py-line"> </tt>
<a name="HiveContext.__init__"></a><div id="HiveContext.__init__-def"><a name="L1322"></a><tt class="py-lineno">1322</tt> <a class="py-toggle" href="#" id="HiveContext.__init__-toggle" onclick="return toggle('HiveContext.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sparkContext</tt><tt class="py-op">,</tt> <tt class="py-param">hiveContext</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext.__init__-expanded"><a name="L1323"></a><tt class="py-lineno">1323</tt>  <tt class="py-line">        <tt class="py-docstring">"""Create a new HiveContext.</tt> </tt>
<a name="L1324"></a><tt class="py-lineno">1324</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1325"></a><tt class="py-lineno">1325</tt>  <tt class="py-line"><tt class="py-docstring">        @param sparkContext: The SparkContext to wrap.</tt> </tt>
<a name="L1326"></a><tt class="py-lineno">1326</tt>  <tt class="py-line"><tt class="py-docstring">        @param hiveContext: An optional JVM Scala HiveContext. If set, we do not instatiate a new</tt> </tt>
<a name="L1327"></a><tt class="py-lineno">1327</tt>  <tt class="py-line"><tt class="py-docstring">        HiveContext in the JVM, instead we make all calls to this object.</tt> </tt>
<a name="L1328"></a><tt class="py-lineno">1328</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1329"></a><tt class="py-lineno">1329</tt>  <tt class="py-line">        <tt id="link-236" class="py-name"><a title="pyspark.sql.SQLContext" class="py-name" href="#" onclick="return doclink('link-236', 'SQLContext', 'link-165');">SQLContext</a></tt><tt class="py-op">.</tt><tt id="link-237" class="py-name" targets="Method pyspark.accumulators.Accumulator.__init__()=pyspark.accumulators.Accumulator-class.html#__init__,Method pyspark.accumulators.AddingAccumulatorParam.__init__()=pyspark.accumulators.AddingAccumulatorParam-class.html#__init__,Method pyspark.broadcast.Broadcast.__init__()=pyspark.broadcast.Broadcast-class.html#__init__,Method pyspark.conf.SparkConf.__init__()=pyspark.conf.SparkConf-class.html#__init__,Method pyspark.context.SparkContext.__init__()=pyspark.context.SparkContext-class.html#__init__,Method pyspark.files.SparkFiles.__init__()=pyspark.files.SparkFiles-class.html#__init__,Method pyspark.mllib.classification.NaiveBayesModel.__init__()=pyspark.mllib.classification.NaiveBayesModel-class.html#__init__,Method pyspark.mllib.clustering.KMeansModel.__init__()=pyspark.mllib.clustering.KMeansModel-class.html#__init__,Method pyspark.mllib.linalg.SparseVector.__init__()=pyspark.mllib.linalg.SparseVector-class.html#__init__,Method pyspark.mllib.recommendation.MatrixFactorizationModel.__init__()=pyspark.mllib.recommendation.MatrixFactorizationModel-class.html#__init__,Method pyspark.mllib.regression.LabeledPoint.__init__()=pyspark.mllib.regression.LabeledPoint-class.html#__init__,Method pyspark.mllib.regression.LinearModel.__init__()=pyspark.mllib.regression.LinearModel-class.html#__init__,Method pyspark.mllib.stat.MultivariateStatisticalSummary.__init__()=pyspark.mllib.stat.MultivariateStatisticalSummary-class.html#__init__,Method pyspark.mllib.tree.DecisionTreeModel.__init__()=pyspark.mllib.tree.DecisionTreeModel-class.html#__init__,Method pyspark.rdd.RDD.__init__()=pyspark.rdd.RDD-class.html#__init__,Method pyspark.resultiterable.ResultIterable.__init__()=pyspark.resultiterable.ResultIterable-class.html#__init__,Method pyspark.sql.ArrayType.__init__()=pyspark.sql.ArrayType-class.html#__init__,Method pyspark.sql.HiveContext.__init__()=pyspark.sql.HiveContext-class.html#__init__,Method pyspark.sql.LocalHiveContext.__init__()=pyspark.sql.LocalHiveContext-class.html#__init__,Method pyspark.sql.MapType.__init__()=pyspark.sql.MapType-class.html#__init__,Method pyspark.sql.SQLContext.__init__()=pyspark.sql.SQLContext-class.html#__init__,Method pyspark.sql.SchemaRDD.__init__()=pyspark.sql.SchemaRDD-class.html#__init__,Method pyspark.sql.StructField.__init__()=pyspark.sql.StructField-class.html#__init__,Method pyspark.sql.StructType.__init__()=pyspark.sql.StructType-class.html#__init__,Method pyspark.statcounter.StatCounter.__init__()=pyspark.statcounter.StatCounter-class.html#__init__,Method pyspark.storagelevel.StorageLevel.__init__()=pyspark.storagelevel.StorageLevel-class.html#__init__"><a title="pyspark.accumulators.Accumulator.__init__
pyspark.accumulators.AddingAccumulatorParam.__init__
pyspark.broadcast.Broadcast.__init__
pyspark.conf.SparkConf.__init__
pyspark.context.SparkContext.__init__
pyspark.files.SparkFiles.__init__
pyspark.mllib.classification.NaiveBayesModel.__init__
pyspark.mllib.clustering.KMeansModel.__init__
pyspark.mllib.linalg.SparseVector.__init__
pyspark.mllib.recommendation.MatrixFactorizationModel.__init__
pyspark.mllib.regression.LabeledPoint.__init__
pyspark.mllib.regression.LinearModel.__init__
pyspark.mllib.stat.MultivariateStatisticalSummary.__init__
pyspark.mllib.tree.DecisionTreeModel.__init__
pyspark.rdd.RDD.__init__
pyspark.resultiterable.ResultIterable.__init__
pyspark.sql.ArrayType.__init__
pyspark.sql.HiveContext.__init__
pyspark.sql.LocalHiveContext.__init__
pyspark.sql.MapType.__init__
pyspark.sql.SQLContext.__init__
pyspark.sql.SchemaRDD.__init__
pyspark.sql.StructField.__init__
pyspark.sql.StructType.__init__
pyspark.statcounter.StatCounter.__init__
pyspark.storagelevel.StorageLevel.__init__" class="py-name" href="#" onclick="return doclink('link-237', '__init__', 'link-237');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">sparkContext</tt><tt class="py-op">)</tt> </tt>
<a name="L1330"></a><tt class="py-lineno">1330</tt>  <tt class="py-line"> </tt>
<a name="L1331"></a><tt class="py-lineno">1331</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">hiveContext</tt><tt class="py-op">:</tt> </tt>
<a name="L1332"></a><tt class="py-lineno">1332</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_HiveContext</tt> <tt class="py-op">=</tt> <tt class="py-name">hiveContext</tt> </tt>
</div><a name="L1333"></a><tt class="py-lineno">1333</tt>  <tt class="py-line"> </tt>
<a name="L1334"></a><tt class="py-lineno">1334</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="HiveContext._ssql_ctx"></a><div id="HiveContext._ssql_ctx-def"><a name="L1335"></a><tt class="py-lineno">1335</tt> <a class="py-toggle" href="#" id="HiveContext._ssql_ctx-toggle" onclick="return toggle('HiveContext._ssql_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#_ssql_ctx">_ssql_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext._ssql_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext._ssql_ctx-expanded"><a name="L1336"></a><tt class="py-lineno">1336</tt>  <tt class="py-line">        <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L1337"></a><tt class="py-lineno">1337</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">'_scala_HiveContext'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1338"></a><tt class="py-lineno">1338</tt>  <tt class="py-line">                <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_HiveContext</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_get_hive_ctx</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1339"></a><tt class="py-lineno">1339</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_scala_HiveContext</tt> </tt>
<a name="L1340"></a><tt class="py-lineno">1340</tt>  <tt class="py-line">        <tt class="py-keyword">except</tt> <tt class="py-name">Py4JError</tt> <tt class="py-keyword">as</tt> <tt class="py-name">e</tt><tt class="py-op">:</tt> </tt>
<a name="L1341"></a><tt class="py-lineno">1341</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">Exception</tt><tt class="py-op">(</tt><tt class="py-string">"You must build Spark with Hive. "</tt> </tt>
<a name="L1342"></a><tt class="py-lineno">1342</tt>  <tt class="py-line">                            <tt class="py-string">"Export 'SPARK_HIVE=true' and run "</tt> </tt>
<a name="L1343"></a><tt class="py-lineno">1343</tt>  <tt class="py-line">                            <tt class="py-string">"sbt/sbt assembly"</tt><tt class="py-op">,</tt> <tt class="py-name">e</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1344"></a><tt class="py-lineno">1344</tt>  <tt class="py-line"> </tt>
<a name="HiveContext._get_hive_ctx"></a><div id="HiveContext._get_hive_ctx-def"><a name="L1345"></a><tt class="py-lineno">1345</tt> <a class="py-toggle" href="#" id="HiveContext._get_hive_ctx-toggle" onclick="return toggle('HiveContext._get_hive_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#_get_hive_ctx">_get_hive_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext._get_hive_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext._get_hive_ctx-expanded"><a name="L1346"></a><tt class="py-lineno">1346</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-238" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-238', '_jvm', 'link-160');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-239" class="py-name" targets="Class pyspark.sql.HiveContext=pyspark.sql.HiveContext-class.html"><a title="pyspark.sql.HiveContext" class="py-name" href="#" onclick="return doclink('link-239', 'HiveContext', 'link-239');">HiveContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1347"></a><tt class="py-lineno">1347</tt>  <tt class="py-line"> </tt>
<a name="HiveContext.hiveql"></a><div id="HiveContext.hiveql-def"><a name="L1348"></a><tt class="py-lineno">1348</tt> <a class="py-toggle" href="#" id="HiveContext.hiveql-toggle" onclick="return toggle('HiveContext.hiveql');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#hiveql">hiveql</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">hqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext.hiveql-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext.hiveql-expanded"><a name="L1349"></a><tt class="py-lineno">1349</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L1350"></a><tt class="py-lineno">1350</tt>  <tt class="py-line"><tt class="py-docstring">        DEPRECATED: Use sql()</tt> </tt>
<a name="L1351"></a><tt class="py-lineno">1351</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1352"></a><tt class="py-lineno">1352</tt>  <tt class="py-line">        <tt class="py-name">warnings</tt><tt class="py-op">.</tt><tt class="py-name">warn</tt><tt class="py-op">(</tt><tt class="py-string">"hiveql() is deprecated as the sql function now parses using HiveQL by"</tt> <tt class="py-op">+</tt> </tt>
<a name="L1353"></a><tt class="py-lineno">1353</tt>  <tt class="py-line">                      <tt class="py-string">"default. The SQL dialect for parsing can be set using 'spark.sql.dialect'"</tt><tt class="py-op">,</tt> </tt>
<a name="L1354"></a><tt class="py-lineno">1354</tt>  <tt class="py-line">                      <tt class="py-name">DeprecationWarning</tt><tt class="py-op">)</tt> </tt>
<a name="L1355"></a><tt class="py-lineno">1355</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-240" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-240', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_ssql_ctx</tt><tt class="py-op">.</tt><tt id="link-241" class="py-name" targets="Method pyspark.sql.HiveContext.hiveql()=pyspark.sql.HiveContext-class.html#hiveql"><a title="pyspark.sql.HiveContext.hiveql" class="py-name" href="#" onclick="return doclink('link-241', 'hiveql', 'link-241');">hiveql</a></tt><tt class="py-op">(</tt><tt class="py-name">hqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1356"></a><tt class="py-lineno">1356</tt>  <tt class="py-line"> </tt>
<a name="HiveContext.hql"></a><div id="HiveContext.hql-def"><a name="L1357"></a><tt class="py-lineno">1357</tt> <a class="py-toggle" href="#" id="HiveContext.hql-toggle" onclick="return toggle('HiveContext.hql');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.HiveContext-class.html#hql">hql</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">hqlQuery</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="HiveContext.hql-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="HiveContext.hql-expanded"><a name="L1358"></a><tt class="py-lineno">1358</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L1359"></a><tt class="py-lineno">1359</tt>  <tt class="py-line"><tt class="py-docstring">        DEPRECATED: Use sql()</tt> </tt>
<a name="L1360"></a><tt class="py-lineno">1360</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1361"></a><tt class="py-lineno">1361</tt>  <tt class="py-line">        <tt class="py-name">warnings</tt><tt class="py-op">.</tt><tt class="py-name">warn</tt><tt class="py-op">(</tt><tt class="py-string">"hql() is deprecated as the sql function now parses using HiveQL by"</tt> <tt class="py-op">+</tt> </tt>
<a name="L1362"></a><tt class="py-lineno">1362</tt>  <tt class="py-line">                      <tt class="py-string">"default. The SQL dialect for parsing can be set using 'spark.sql.dialect'"</tt><tt class="py-op">,</tt> </tt>
<a name="L1363"></a><tt class="py-lineno">1363</tt>  <tt class="py-line">                      <tt class="py-name">DeprecationWarning</tt><tt class="py-op">)</tt> </tt>
<a name="L1364"></a><tt class="py-lineno">1364</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-242" class="py-name"><a title="pyspark.sql.HiveContext.hiveql" class="py-name" href="#" onclick="return doclink('link-242', 'hiveql', 'link-241');">hiveql</a></tt><tt class="py-op">(</tt><tt class="py-name">hqlQuery</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L1365"></a><tt class="py-lineno">1365</tt>  <tt class="py-line"> </tt>
<a name="LocalHiveContext"></a><div id="LocalHiveContext-def"><a name="L1366"></a><tt class="py-lineno">1366</tt>  <tt class="py-line"> </tt>
<a name="L1367"></a><tt class="py-lineno">1367</tt> <a class="py-toggle" href="#" id="LocalHiveContext-toggle" onclick="return toggle('LocalHiveContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.LocalHiveContext-class.html">LocalHiveContext</a><tt class="py-op">(</tt><tt class="py-base-class">HiveContext</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LocalHiveContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="LocalHiveContext-expanded"><a name="L1368"></a><tt class="py-lineno">1368</tt>  <tt class="py-line"> </tt>
<a name="L1369"></a><tt class="py-lineno">1369</tt>  <tt class="py-line">    <tt class="py-docstring">"""Starts up an instance of hive where metadata is stored locally.</tt> </tt>
<a name="L1370"></a><tt class="py-lineno">1370</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1371"></a><tt class="py-lineno">1371</tt>  <tt class="py-line"><tt class="py-docstring">    An in-process metadata data is created with data stored in ./metadata.</tt> </tt>
<a name="L1372"></a><tt class="py-lineno">1372</tt>  <tt class="py-line"><tt class="py-docstring">    Warehouse data is stored in in ./warehouse.</tt> </tt>
<a name="L1373"></a><tt class="py-lineno">1373</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1374"></a><tt class="py-lineno">1374</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; import os</tt> </tt>
<a name="L1375"></a><tt class="py-lineno">1375</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; hiveCtx = LocalHiveContext(sc)</tt> </tt>
<a name="L1376"></a><tt class="py-lineno">1376</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; try:</tt> </tt>
<a name="L1377"></a><tt class="py-lineno">1377</tt>  <tt class="py-line"><tt class="py-docstring">    ...     supress = hiveCtx.sql("DROP TABLE src")</tt> </tt>
<a name="L1378"></a><tt class="py-lineno">1378</tt>  <tt class="py-line"><tt class="py-docstring">    ... except Exception:</tt> </tt>
<a name="L1379"></a><tt class="py-lineno">1379</tt>  <tt class="py-line"><tt class="py-docstring">    ...     pass</tt> </tt>
<a name="L1380"></a><tt class="py-lineno">1380</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; kv1 = os.path.join(os.environ["SPARK_HOME"],</tt> </tt>
<a name="L1381"></a><tt class="py-lineno">1381</tt>  <tt class="py-line"><tt class="py-docstring">    ...        'examples/src/main/resources/kv1.txt')</tt> </tt>
<a name="L1382"></a><tt class="py-lineno">1382</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; supress = hiveCtx.sql(</tt> </tt>
<a name="L1383"></a><tt class="py-lineno">1383</tt>  <tt class="py-line"><tt class="py-docstring">    ...     "CREATE TABLE IF NOT EXISTS src (key INT, value STRING)")</tt> </tt>
<a name="L1384"></a><tt class="py-lineno">1384</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; supress = hiveCtx.sql("LOAD DATA LOCAL INPATH '%s' INTO TABLE src"</tt> </tt>
<a name="L1385"></a><tt class="py-lineno">1385</tt>  <tt class="py-line"><tt class="py-docstring">    ...        % kv1)</tt> </tt>
<a name="L1386"></a><tt class="py-lineno">1386</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; results = hiveCtx.sql("FROM src SELECT value"</tt> </tt>
<a name="L1387"></a><tt class="py-lineno">1387</tt>  <tt class="py-line"><tt class="py-docstring">    ...      ).map(lambda r: int(r.value.split('_')[1]))</tt> </tt>
<a name="L1388"></a><tt class="py-lineno">1388</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; num = results.count()</tt> </tt>
<a name="L1389"></a><tt class="py-lineno">1389</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; reduce_sum = results.reduce(lambda x, y: x + y)</tt> </tt>
<a name="L1390"></a><tt class="py-lineno">1390</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; num</tt> </tt>
<a name="L1391"></a><tt class="py-lineno">1391</tt>  <tt class="py-line"><tt class="py-docstring">    500</tt> </tt>
<a name="L1392"></a><tt class="py-lineno">1392</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; reduce_sum</tt> </tt>
<a name="L1393"></a><tt class="py-lineno">1393</tt>  <tt class="py-line"><tt class="py-docstring">    130091</tt> </tt>
<a name="L1394"></a><tt class="py-lineno">1394</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L1395"></a><tt class="py-lineno">1395</tt>  <tt class="py-line"> </tt>
<a name="LocalHiveContext.__init__"></a><div id="LocalHiveContext.__init__-def"><a name="L1396"></a><tt class="py-lineno">1396</tt> <a class="py-toggle" href="#" id="LocalHiveContext.__init__-toggle" onclick="return toggle('LocalHiveContext.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.LocalHiveContext-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">sparkContext</tt><tt class="py-op">,</tt> <tt class="py-param">sqlContext</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LocalHiveContext.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="LocalHiveContext.__init__-expanded"><a name="L1397"></a><tt class="py-lineno">1397</tt>  <tt class="py-line">        <tt id="link-243" class="py-name"><a title="pyspark.sql.HiveContext" class="py-name" href="#" onclick="return doclink('link-243', 'HiveContext', 'link-239');">HiveContext</a></tt><tt class="py-op">.</tt><tt id="link-244" class="py-name"><a title="pyspark.accumulators.Accumulator.__init__
pyspark.accumulators.AddingAccumulatorParam.__init__
pyspark.broadcast.Broadcast.__init__
pyspark.conf.SparkConf.__init__
pyspark.context.SparkContext.__init__
pyspark.files.SparkFiles.__init__
pyspark.mllib.classification.NaiveBayesModel.__init__
pyspark.mllib.clustering.KMeansModel.__init__
pyspark.mllib.linalg.SparseVector.__init__
pyspark.mllib.recommendation.MatrixFactorizationModel.__init__
pyspark.mllib.regression.LabeledPoint.__init__
pyspark.mllib.regression.LinearModel.__init__
pyspark.mllib.stat.MultivariateStatisticalSummary.__init__
pyspark.mllib.tree.DecisionTreeModel.__init__
pyspark.rdd.RDD.__init__
pyspark.resultiterable.ResultIterable.__init__
pyspark.sql.ArrayType.__init__
pyspark.sql.HiveContext.__init__
pyspark.sql.LocalHiveContext.__init__
pyspark.sql.MapType.__init__
pyspark.sql.SQLContext.__init__
pyspark.sql.SchemaRDD.__init__
pyspark.sql.StructField.__init__
pyspark.sql.StructType.__init__
pyspark.statcounter.StatCounter.__init__
pyspark.storagelevel.StorageLevel.__init__" class="py-name" href="#" onclick="return doclink('link-244', '__init__', 'link-237');">__init__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">sparkContext</tt><tt class="py-op">,</tt> <tt class="py-name">sqlContext</tt><tt class="py-op">)</tt> </tt>
<a name="L1398"></a><tt class="py-lineno">1398</tt>  <tt class="py-line">        <tt class="py-name">warnings</tt><tt class="py-op">.</tt><tt class="py-name">warn</tt><tt class="py-op">(</tt><tt class="py-string">"LocalHiveContext is deprecated. "</tt> </tt>
<a name="L1399"></a><tt class="py-lineno">1399</tt>  <tt class="py-line">                      <tt class="py-string">"Use HiveContext instead."</tt><tt class="py-op">,</tt> <tt class="py-name">DeprecationWarning</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1400"></a><tt class="py-lineno">1400</tt>  <tt class="py-line"> </tt>
<a name="LocalHiveContext._get_hive_ctx"></a><div id="LocalHiveContext._get_hive_ctx-def"><a name="L1401"></a><tt class="py-lineno">1401</tt> <a class="py-toggle" href="#" id="LocalHiveContext._get_hive_ctx-toggle" onclick="return toggle('LocalHiveContext._get_hive_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.LocalHiveContext-class.html#_get_hive_ctx">_get_hive_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="LocalHiveContext._get_hive_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="LocalHiveContext._get_hive_ctx-expanded"><a name="L1402"></a><tt class="py-lineno">1402</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-245" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-245', '_jvm', 'link-160');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-246" class="py-name" targets="Class pyspark.sql.LocalHiveContext=pyspark.sql.LocalHiveContext-class.html"><a title="pyspark.sql.LocalHiveContext" class="py-name" href="#" onclick="return doclink('link-246', 'LocalHiveContext', 'link-246');">LocalHiveContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L1403"></a><tt class="py-lineno">1403</tt>  <tt class="py-line"> </tt>
<a name="TestHiveContext"></a><div id="TestHiveContext-def"><a name="L1404"></a><tt class="py-lineno">1404</tt>  <tt class="py-line"> </tt>
<a name="L1405"></a><tt class="py-lineno">1405</tt> <a class="py-toggle" href="#" id="TestHiveContext-toggle" onclick="return toggle('TestHiveContext');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.TestHiveContext-class.html">TestHiveContext</a><tt class="py-op">(</tt><tt class="py-base-class">HiveContext</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TestHiveContext-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="TestHiveContext-expanded"><a name="L1406"></a><tt class="py-lineno">1406</tt>  <tt class="py-line"> </tt>
<a name="TestHiveContext._get_hive_ctx"></a><div id="TestHiveContext._get_hive_ctx-def"><a name="L1407"></a><tt class="py-lineno">1407</tt> <a class="py-toggle" href="#" id="TestHiveContext._get_hive_ctx-toggle" onclick="return toggle('TestHiveContext._get_hive_ctx');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.TestHiveContext-class.html#_get_hive_ctx">_get_hive_ctx</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="TestHiveContext._get_hive_ctx-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="TestHiveContext._get_hive_ctx-expanded"><a name="L1408"></a><tt class="py-lineno">1408</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-247" class="py-name"><a title="pyspark.context.SparkContext._jvm" class="py-name" href="#" onclick="return doclink('link-247', '_jvm', 'link-160');">_jvm</a></tt><tt class="py-op">.</tt><tt id="link-248" class="py-name" targets="Class pyspark.sql.TestHiveContext=pyspark.sql.TestHiveContext-class.html"><a title="pyspark.sql.TestHiveContext" class="py-name" href="#" onclick="return doclink('link-248', 'TestHiveContext', 'link-248');">TestHiveContext</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jsc</tt><tt class="py-op">.</tt><tt class="py-name">sc</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L1409"></a><tt class="py-lineno">1409</tt>  <tt class="py-line"> </tt>
<a name="_create_row"></a><div id="_create_row-def"><a name="L1410"></a><tt class="py-lineno">1410</tt>  <tt class="py-line"> </tt>
<a name="L1411"></a><tt class="py-lineno">1411</tt> <a class="py-toggle" href="#" id="_create_row-toggle" onclick="return toggle('_create_row');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_create_row">_create_row</a><tt class="py-op">(</tt><tt class="py-param">fields</tt><tt class="py-op">,</tt> <tt class="py-param">values</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_create_row-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_create_row-expanded"><a name="L1412"></a><tt class="py-lineno">1412</tt>  <tt class="py-line">    <tt class="py-name">row</tt> <tt class="py-op">=</tt> <tt id="link-249" class="py-name"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-249', 'Row', 'link-157');">Row</a></tt><tt class="py-op">(</tt><tt class="py-op">*</tt><tt id="link-250" class="py-name"><a title="pyspark.rdd.RDD.values" class="py-name" href="#" onclick="return doclink('link-250', 'values', 'link-57');">values</a></tt><tt class="py-op">)</tt> </tt>
<a name="L1413"></a><tt class="py-lineno">1413</tt>  <tt class="py-line">    <tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt> <tt class="py-op">=</tt> <tt class="py-name">fields</tt> </tt>
<a name="L1414"></a><tt class="py-lineno">1414</tt>  <tt class="py-line">    <tt class="py-keyword">return</tt> <tt class="py-name">row</tt> </tt>
</div><a name="L1415"></a><tt class="py-lineno">1415</tt>  <tt class="py-line"> </tt>
<a name="Row"></a><div id="Row-def"><a name="L1416"></a><tt class="py-lineno">1416</tt>  <tt class="py-line"> </tt>
<a name="L1417"></a><tt class="py-lineno">1417</tt> <a class="py-toggle" href="#" id="Row-toggle" onclick="return toggle('Row');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html">Row</a><tt class="py-op">(</tt><tt class="py-base-class">tuple</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="Row-expanded"><a name="L1418"></a><tt class="py-lineno">1418</tt>  <tt class="py-line"> </tt>
<a name="L1419"></a><tt class="py-lineno">1419</tt>  <tt class="py-line">    <tt class="py-docstring">"""</tt> </tt>
<a name="L1420"></a><tt class="py-lineno">1420</tt>  <tt class="py-line"><tt class="py-docstring">    A row in L{SchemaRDD}. The fields in it can be accessed like attributes.</tt> </tt>
<a name="L1421"></a><tt class="py-lineno">1421</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1422"></a><tt class="py-lineno">1422</tt>  <tt class="py-line"><tt class="py-docstring">    Row can be used to create a row object by using named arguments,</tt> </tt>
<a name="L1423"></a><tt class="py-lineno">1423</tt>  <tt class="py-line"><tt class="py-docstring">    the fields will be sorted by names.</tt> </tt>
<a name="L1424"></a><tt class="py-lineno">1424</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1425"></a><tt class="py-lineno">1425</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row = Row(name="Alice", age=11)</tt> </tt>
<a name="L1426"></a><tt class="py-lineno">1426</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row</tt> </tt>
<a name="L1427"></a><tt class="py-lineno">1427</tt>  <tt class="py-line"><tt class="py-docstring">    Row(age=11, name='Alice')</tt> </tt>
<a name="L1428"></a><tt class="py-lineno">1428</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; row.name, row.age</tt> </tt>
<a name="L1429"></a><tt class="py-lineno">1429</tt>  <tt class="py-line"><tt class="py-docstring">    ('Alice', 11)</tt> </tt>
<a name="L1430"></a><tt class="py-lineno">1430</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1431"></a><tt class="py-lineno">1431</tt>  <tt class="py-line"><tt class="py-docstring">    Row also can be used to create another Row like class, then it</tt> </tt>
<a name="L1432"></a><tt class="py-lineno">1432</tt>  <tt class="py-line"><tt class="py-docstring">    could be used to create Row objects, such as</tt> </tt>
<a name="L1433"></a><tt class="py-lineno">1433</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1434"></a><tt class="py-lineno">1434</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; Person = Row("name", "age")</tt> </tt>
<a name="L1435"></a><tt class="py-lineno">1435</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; Person</tt> </tt>
<a name="L1436"></a><tt class="py-lineno">1436</tt>  <tt class="py-line"><tt class="py-docstring">    &lt;Row(name, age)&gt;</tt> </tt>
<a name="L1437"></a><tt class="py-lineno">1437</tt>  <tt class="py-line"><tt class="py-docstring">    &gt;&gt;&gt; Person("Alice", 11)</tt> </tt>
<a name="L1438"></a><tt class="py-lineno">1438</tt>  <tt class="py-line"><tt class="py-docstring">    Row(name='Alice', age=11)</tt> </tt>
<a name="L1439"></a><tt class="py-lineno">1439</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L1440"></a><tt class="py-lineno">1440</tt>  <tt class="py-line"> </tt>
<a name="Row.__new__"></a><div id="Row.__new__-def"><a name="L1441"></a><tt class="py-lineno">1441</tt> <a class="py-toggle" href="#" id="Row.__new__-toggle" onclick="return toggle('Row.__new__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html#__new__">__new__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-op">*</tt><tt class="py-param">args</tt><tt class="py-op">,</tt> <tt class="py-op">**</tt><tt class="py-param">kwargs</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row.__new__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="Row.__new__-expanded"><a name="L1442"></a><tt class="py-lineno">1442</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">args</tt> <tt class="py-keyword">and</tt> <tt class="py-name">kwargs</tt><tt class="py-op">:</tt> </tt>
<a name="L1443"></a><tt class="py-lineno">1443</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can not use both args "</tt> </tt>
<a name="L1444"></a><tt class="py-lineno">1444</tt>  <tt class="py-line">                             <tt class="py-string">"and kwargs to create Row"</tt><tt class="py-op">)</tt> </tt>
<a name="L1445"></a><tt class="py-lineno">1445</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">args</tt><tt class="py-op">:</tt> </tt>
<a name="L1446"></a><tt class="py-lineno">1446</tt>  <tt class="py-line">            <tt class="py-comment"># create row class or objects</tt> </tt>
<a name="L1447"></a><tt class="py-lineno">1447</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">tuple</tt><tt class="py-op">.</tt><tt id="link-251" class="py-name" targets="Method pyspark.sql.Row.__new__()=pyspark.sql.Row-class.html#__new__"><a title="pyspark.sql.Row.__new__" class="py-name" href="#" onclick="return doclink('link-251', '__new__', 'link-251');">__new__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">args</tt><tt class="py-op">)</tt> </tt>
<a name="L1448"></a><tt class="py-lineno">1448</tt>  <tt class="py-line"> </tt>
<a name="L1449"></a><tt class="py-lineno">1449</tt>  <tt class="py-line">        <tt class="py-keyword">elif</tt> <tt class="py-name">kwargs</tt><tt class="py-op">:</tt> </tt>
<a name="L1450"></a><tt class="py-lineno">1450</tt>  <tt class="py-line">            <tt class="py-comment"># create row objects</tt> </tt>
<a name="L1451"></a><tt class="py-lineno">1451</tt>  <tt class="py-line">            <tt class="py-name">names</tt> <tt class="py-op">=</tt> <tt class="py-name">sorted</tt><tt class="py-op">(</tt><tt class="py-name">kwargs</tt><tt class="py-op">.</tt><tt id="link-252" class="py-name"><a title="pyspark.rdd.RDD.keys" class="py-name" href="#" onclick="return doclink('link-252', 'keys', 'link-74');">keys</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1452"></a><tt class="py-lineno">1452</tt>  <tt class="py-line">            <tt id="link-253" class="py-name"><a title="pyspark.rdd.RDD.values" class="py-name" href="#" onclick="return doclink('link-253', 'values', 'link-57');">values</a></tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">kwargs</tt><tt class="py-op">[</tt><tt class="py-name">n</tt><tt class="py-op">]</tt> <tt class="py-keyword">for</tt> <tt class="py-name">n</tt> <tt class="py-keyword">in</tt> <tt class="py-name">names</tt><tt class="py-op">)</tt> </tt>
<a name="L1453"></a><tt class="py-lineno">1453</tt>  <tt class="py-line">            <tt class="py-name">row</tt> <tt class="py-op">=</tt> <tt class="py-name">tuple</tt><tt class="py-op">.</tt><tt id="link-254" class="py-name"><a title="pyspark.sql.Row.__new__" class="py-name" href="#" onclick="return doclink('link-254', '__new__', 'link-251');">__new__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt id="link-255" class="py-name"><a title="pyspark.rdd.RDD.values" class="py-name" href="#" onclick="return doclink('link-255', 'values', 'link-57');">values</a></tt><tt class="py-op">)</tt> </tt>
<a name="L1454"></a><tt class="py-lineno">1454</tt>  <tt class="py-line">            <tt class="py-name">row</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt> <tt class="py-op">=</tt> <tt class="py-name">names</tt> </tt>
<a name="L1455"></a><tt class="py-lineno">1455</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">row</tt> </tt>
<a name="L1456"></a><tt class="py-lineno">1456</tt>  <tt class="py-line"> </tt>
<a name="L1457"></a><tt class="py-lineno">1457</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1458"></a><tt class="py-lineno">1458</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"No args or kwargs"</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1459"></a><tt class="py-lineno">1459</tt>  <tt class="py-line"> </tt>
<a name="L1460"></a><tt class="py-lineno">1460</tt>  <tt class="py-line">    <tt class="py-comment"># let obect acs like class</tt> </tt>
<a name="Row.__call__"></a><div id="Row.__call__-def"><a name="L1461"></a><tt class="py-lineno">1461</tt> <a class="py-toggle" href="#" id="Row.__call__-toggle" onclick="return toggle('Row.__call__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html#__call__">__call__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-op">*</tt><tt class="py-param">args</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row.__call__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="Row.__call__-expanded"><a name="L1462"></a><tt class="py-lineno">1462</tt>  <tt class="py-line">        <tt class="py-docstring">"""create new Row object"""</tt> </tt>
<a name="L1463"></a><tt class="py-lineno">1463</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_create_row</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-name">args</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1464"></a><tt class="py-lineno">1464</tt>  <tt class="py-line"> </tt>
<a name="Row.__getattr__"></a><div id="Row.__getattr__-def"><a name="L1465"></a><tt class="py-lineno">1465</tt> <a class="py-toggle" href="#" id="Row.__getattr__-toggle" onclick="return toggle('Row.__getattr__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html#__getattr__">__getattr__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">item</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row.__getattr__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="Row.__getattr__-expanded"><a name="L1466"></a><tt class="py-lineno">1466</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">item</tt><tt class="py-op">.</tt><tt class="py-name">startswith</tt><tt class="py-op">(</tt><tt class="py-string">"__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1467"></a><tt class="py-lineno">1467</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">AttributeError</tt><tt class="py-op">(</tt><tt class="py-name">item</tt><tt class="py-op">)</tt> </tt>
<a name="L1468"></a><tt class="py-lineno">1468</tt>  <tt class="py-line">        <tt class="py-keyword">try</tt><tt class="py-op">:</tt> </tt>
<a name="L1469"></a><tt class="py-lineno">1469</tt>  <tt class="py-line">            <tt class="py-comment"># it will be slow when it has many fields,</tt> </tt>
<a name="L1470"></a><tt class="py-lineno">1470</tt>  <tt class="py-line">            <tt class="py-comment"># but this will not be used in normal cases</tt> </tt>
<a name="L1471"></a><tt class="py-lineno">1471</tt>  <tt class="py-line">            <tt class="py-name">idx</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt><tt class="py-op">.</tt><tt class="py-name">index</tt><tt class="py-op">(</tt><tt class="py-name">item</tt><tt class="py-op">)</tt> </tt>
<a name="L1472"></a><tt class="py-lineno">1472</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">[</tt><tt class="py-name">idx</tt><tt class="py-op">]</tt> </tt>
<a name="L1473"></a><tt class="py-lineno">1473</tt>  <tt class="py-line">        <tt class="py-keyword">except</tt> <tt class="py-name">IndexError</tt><tt class="py-op">:</tt> </tt>
<a name="L1474"></a><tt class="py-lineno">1474</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">AttributeError</tt><tt class="py-op">(</tt><tt class="py-name">item</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1475"></a><tt class="py-lineno">1475</tt>  <tt class="py-line"> </tt>
<a name="Row.__reduce__"></a><div id="Row.__reduce__-def"><a name="L1476"></a><tt class="py-lineno">1476</tt> <a class="py-toggle" href="#" id="Row.__reduce__-toggle" onclick="return toggle('Row.__reduce__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html#__reduce__">__reduce__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row.__reduce__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="Row.__reduce__-expanded"><a name="L1477"></a><tt class="py-lineno">1477</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">"__FIELDS__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1478"></a><tt class="py-lineno">1478</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-op">(</tt><tt class="py-name">_create_row</tt><tt class="py-op">,</tt> <tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt><tt class="py-op">,</tt> <tt class="py-name">tuple</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1479"></a><tt class="py-lineno">1479</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1480"></a><tt class="py-lineno">1480</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">tuple</tt><tt class="py-op">.</tt><tt id="link-256" class="py-name"><a title="pyspark.accumulators.Accumulator.__reduce__
pyspark.broadcast.Broadcast.__reduce__
pyspark.sql.Row.__reduce__" class="py-name" href="#" onclick="return doclink('link-256', '__reduce__', 'link-150');">__reduce__</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1481"></a><tt class="py-lineno">1481</tt>  <tt class="py-line"> </tt>
<a name="Row.__repr__"></a><div id="Row.__repr__-def"><a name="L1482"></a><tt class="py-lineno">1482</tt> <a class="py-toggle" href="#" id="Row.__repr__-toggle" onclick="return toggle('Row.__repr__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.Row-class.html#__repr__">__repr__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="Row.__repr__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="Row.__repr__-expanded"><a name="L1483"></a><tt class="py-lineno">1483</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">"__FIELDS__"</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1484"></a><tt class="py-lineno">1484</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-string">"Row(%s)"</tt> <tt class="py-op">%</tt> <tt class="py-string">", "</tt><tt class="py-op">.</tt><tt id="link-257" class="py-name"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-257', 'join', 'link-17');">join</a></tt><tt class="py-op">(</tt><tt class="py-string">"%s=%r"</tt> <tt class="py-op">%</tt> <tt class="py-op">(</tt><tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt><tt class="py-op">)</tt> </tt>
<a name="L1485"></a><tt class="py-lineno">1485</tt>  <tt class="py-line">                                         <tt class="py-keyword">for</tt> <tt class="py-name">k</tt><tt class="py-op">,</tt> <tt class="py-name">v</tt> <tt class="py-keyword">in</tt> <tt id="link-258" class="py-name"><a title="pyspark.rdd.RDD.zip" class="py-name" href="#" onclick="return doclink('link-258', 'zip', 'link-49');">zip</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">__FIELDS__</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1486"></a><tt class="py-lineno">1486</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1487"></a><tt class="py-lineno">1487</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-string">"&lt;Row(%s)&gt;"</tt> <tt class="py-op">%</tt> <tt class="py-string">", "</tt><tt class="py-op">.</tt><tt id="link-259" class="py-name"><a title="pyspark.rdd.RDD.join" class="py-name" href="#" onclick="return doclink('link-259', 'join', 'link-17');">join</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L1488"></a><tt class="py-lineno">1488</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD"></a><div id="SchemaRDD-def"><a name="L1489"></a><tt class="py-lineno">1489</tt>  <tt class="py-line"> </tt>
<a name="L1490"></a><tt class="py-lineno">1490</tt> <a class="py-toggle" href="#" id="SchemaRDD-toggle" onclick="return toggle('SchemaRDD');">-</a><tt class="py-line"><tt class="py-keyword">class</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html">SchemaRDD</a><tt class="py-op">(</tt><tt class="py-base-class">RDD</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="SchemaRDD-expanded"><a name="L1491"></a><tt class="py-lineno">1491</tt>  <tt class="py-line"> </tt>
<a name="L1492"></a><tt class="py-lineno">1492</tt>  <tt class="py-line">    <tt class="py-docstring">"""An RDD of L{Row} objects that has an associated schema.</tt> </tt>
<a name="L1493"></a><tt class="py-lineno">1493</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1494"></a><tt class="py-lineno">1494</tt>  <tt class="py-line"><tt class="py-docstring">    The underlying JVM object is a SchemaRDD, not a PythonRDD, so we can</tt> </tt>
<a name="L1495"></a><tt class="py-lineno">1495</tt>  <tt class="py-line"><tt class="py-docstring">    utilize the relational query api exposed by SparkSQL.</tt> </tt>
<a name="L1496"></a><tt class="py-lineno">1496</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1497"></a><tt class="py-lineno">1497</tt>  <tt class="py-line"><tt class="py-docstring">    For normal L{pyspark.rdd.RDD} operations (map, count, etc.) the</tt> </tt>
<a name="L1498"></a><tt class="py-lineno">1498</tt>  <tt class="py-line"><tt class="py-docstring">    L{SchemaRDD} is not operated on directly, as it's underlying</tt> </tt>
<a name="L1499"></a><tt class="py-lineno">1499</tt>  <tt class="py-line"><tt class="py-docstring">    implementation is an RDD composed of Java objects. Instead it is</tt> </tt>
<a name="L1500"></a><tt class="py-lineno">1500</tt>  <tt class="py-line"><tt class="py-docstring">    converted to a PythonRDD in the JVM, on which Python operations can</tt> </tt>
<a name="L1501"></a><tt class="py-lineno">1501</tt>  <tt class="py-line"><tt class="py-docstring">    be done.</tt> </tt>
<a name="L1502"></a><tt class="py-lineno">1502</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1503"></a><tt class="py-lineno">1503</tt>  <tt class="py-line"><tt class="py-docstring">    This class receives raw tuples from Java but assigns a class to it in</tt> </tt>
<a name="L1504"></a><tt class="py-lineno">1504</tt>  <tt class="py-line"><tt class="py-docstring">    all its data-collection methods (mapPartitionsWithIndex, collect, take,</tt> </tt>
<a name="L1505"></a><tt class="py-lineno">1505</tt>  <tt class="py-line"><tt class="py-docstring">    etc) so that PySpark sees them as Row objects with named fields.</tt> </tt>
<a name="L1506"></a><tt class="py-lineno">1506</tt>  <tt class="py-line"><tt class="py-docstring">    """</tt> </tt>
<a name="L1507"></a><tt class="py-lineno">1507</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.__init__"></a><div id="SchemaRDD.__init__-def"><a name="L1508"></a><tt class="py-lineno">1508</tt> <a class="py-toggle" href="#" id="SchemaRDD.__init__-toggle" onclick="return toggle('SchemaRDD.__init__');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#__init__">__init__</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">jschema_rdd</tt><tt class="py-op">,</tt> <tt class="py-param">sql_ctx</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.__init__-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.__init__-expanded"><a name="L1509"></a><tt class="py-lineno">1509</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt> <tt class="py-op">=</tt> <tt class="py-name">sql_ctx</tt> </tt>
<a name="L1510"></a><tt class="py-lineno">1510</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-260" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-260', '_sc', 'link-158');">_sc</a></tt> <tt class="py-op">=</tt> <tt class="py-name">sql_ctx</tt><tt class="py-op">.</tt><tt id="link-261" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-261', '_sc', 'link-158');">_sc</a></tt> </tt>
<a name="L1511"></a><tt class="py-lineno">1511</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt> <tt class="py-op">=</tt> <tt class="py-name">jschema_rdd</tt> </tt>
<a name="L1512"></a><tt class="py-lineno">1512</tt>  <tt class="py-line"> </tt>
<a name="L1513"></a><tt class="py-lineno">1513</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L1514"></a><tt class="py-lineno">1514</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_checkpointed</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L1515"></a><tt class="py-lineno">1515</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ctx</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">.</tt><tt id="link-262" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-262', '_sc', 'link-158');">_sc</a></tt> </tt>
<a name="L1516"></a><tt class="py-lineno">1516</tt>  <tt class="py-line">        <tt class="py-comment"># the _jrdd is created by javaToPython(), serialized by pickle</tt> </tt>
<a name="L1517"></a><tt class="py-lineno">1517</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd_deserializer</tt> <tt class="py-op">=</tt> <tt class="py-name">BatchedSerializer</tt><tt class="py-op">(</tt><tt id="link-263" class="py-name"><a title="pyspark.serializers.PickleSerializer" class="py-name" href="#" onclick="return doclink('link-263', 'PickleSerializer', 'link-5');">PickleSerializer</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1518"></a><tt class="py-lineno">1518</tt>  <tt class="py-line"> </tt>
<a name="L1519"></a><tt class="py-lineno">1519</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="SchemaRDD._jrdd"></a><div id="SchemaRDD._jrdd-def"><a name="L1520"></a><tt class="py-lineno">1520</tt> <a class="py-toggle" href="#" id="SchemaRDD._jrdd-toggle" onclick="return toggle('SchemaRDD._jrdd');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#_jrdd">_jrdd</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD._jrdd-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD._jrdd-expanded"><a name="L1521"></a><tt class="py-lineno">1521</tt>  <tt class="py-line">        <tt class="py-docstring">"""Lazy evaluation of PythonRDD object.</tt> </tt>
<a name="L1522"></a><tt class="py-lineno">1522</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1523"></a><tt class="py-lineno">1523</tt>  <tt class="py-line"><tt class="py-docstring">        Only done when a user calls methods defined by the</tt> </tt>
<a name="L1524"></a><tt class="py-lineno">1524</tt>  <tt class="py-line"><tt class="py-docstring">        L{pyspark.rdd.RDD} super class (map, filter, etc.).</tt> </tt>
<a name="L1525"></a><tt class="py-lineno">1525</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1526"></a><tt class="py-lineno">1526</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-keyword">not</tt> <tt class="py-name">hasattr</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">,</tt> <tt class="py-string">'_lazy_jrdd'</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1527"></a><tt class="py-lineno">1527</tt>  <tt class="py-line">            <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lazy_jrdd</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt class="py-name">javaToPython</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1528"></a><tt class="py-lineno">1528</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_lazy_jrdd</tt> </tt>
</div><a name="L1529"></a><tt class="py-lineno">1529</tt>  <tt class="py-line"> </tt>
<a name="L1530"></a><tt class="py-lineno">1530</tt>  <tt class="py-line">    <tt class="py-decorator">@</tt><tt class="py-decorator">property</tt> </tt>
<a name="SchemaRDD._id"></a><div id="SchemaRDD._id-def"><a name="L1531"></a><tt class="py-lineno">1531</tt> <a class="py-toggle" href="#" id="SchemaRDD._id-toggle" onclick="return toggle('SchemaRDD._id');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#_id">_id</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD._id-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD._id-expanded"><a name="L1532"></a><tt class="py-lineno">1532</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">.</tt><tt id="link-264" class="py-name"><a title="pyspark.rdd.RDD.id" class="py-name" href="#" onclick="return doclink('link-264', 'id', 'link-131');">id</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1533"></a><tt class="py-lineno">1533</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.saveAsParquetFile"></a><div id="SchemaRDD.saveAsParquetFile-def"><a name="L1534"></a><tt class="py-lineno">1534</tt> <a class="py-toggle" href="#" id="SchemaRDD.saveAsParquetFile-toggle" onclick="return toggle('SchemaRDD.saveAsParquetFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#saveAsParquetFile">saveAsParquetFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">path</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.saveAsParquetFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.saveAsParquetFile-expanded"><a name="L1535"></a><tt class="py-lineno">1535</tt>  <tt class="py-line">        <tt class="py-docstring">"""Save the contents as a Parquet file, preserving the schema.</tt> </tt>
<a name="L1536"></a><tt class="py-lineno">1536</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1537"></a><tt class="py-lineno">1537</tt>  <tt class="py-line"><tt class="py-docstring">        Files that are written out using this method can be read back in as</tt> </tt>
<a name="L1538"></a><tt class="py-lineno">1538</tt>  <tt class="py-line"><tt class="py-docstring">        a SchemaRDD using the L{SQLContext.parquetFile} method.</tt> </tt>
<a name="L1539"></a><tt class="py-lineno">1539</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1540"></a><tt class="py-lineno">1540</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; import tempfile, shutil</tt> </tt>
<a name="L1541"></a><tt class="py-lineno">1541</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; parquetFile = tempfile.mkdtemp()</tt> </tt>
<a name="L1542"></a><tt class="py-lineno">1542</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; shutil.rmtree(parquetFile)</tt> </tt>
<a name="L1543"></a><tt class="py-lineno">1543</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1544"></a><tt class="py-lineno">1544</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.saveAsParquetFile(parquetFile)</tt> </tt>
<a name="L1545"></a><tt class="py-lineno">1545</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.parquetFile(parquetFile)</tt> </tt>
<a name="L1546"></a><tt class="py-lineno">1546</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd2.collect()) == sorted(srdd.collect())</tt> </tt>
<a name="L1547"></a><tt class="py-lineno">1547</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L1548"></a><tt class="py-lineno">1548</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1549"></a><tt class="py-lineno">1549</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-265" class="py-name" targets="Method pyspark.sql.SchemaRDD.saveAsParquetFile()=pyspark.sql.SchemaRDD-class.html#saveAsParquetFile"><a title="pyspark.sql.SchemaRDD.saveAsParquetFile" class="py-name" href="#" onclick="return doclink('link-265', 'saveAsParquetFile', 'link-265');">saveAsParquetFile</a></tt><tt class="py-op">(</tt><tt class="py-name">path</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1550"></a><tt class="py-lineno">1550</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.registerTempTable"></a><div id="SchemaRDD.registerTempTable-def"><a name="L1551"></a><tt class="py-lineno">1551</tt> <a class="py-toggle" href="#" id="SchemaRDD.registerTempTable-toggle" onclick="return toggle('SchemaRDD.registerTempTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#registerTempTable">registerTempTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">name</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.registerTempTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.registerTempTable-expanded"><a name="L1552"></a><tt class="py-lineno">1552</tt>  <tt class="py-line">        <tt class="py-docstring">"""Registers this RDD as a temporary table using the given name.</tt> </tt>
<a name="L1553"></a><tt class="py-lineno">1553</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1554"></a><tt class="py-lineno">1554</tt>  <tt class="py-line"><tt class="py-docstring">        The lifetime of this temporary table is tied to the L{SQLContext}</tt> </tt>
<a name="L1555"></a><tt class="py-lineno">1555</tt>  <tt class="py-line"><tt class="py-docstring">        that was used to create this SchemaRDD.</tt> </tt>
<a name="L1556"></a><tt class="py-lineno">1556</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1557"></a><tt class="py-lineno">1557</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1558"></a><tt class="py-lineno">1558</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.registerTempTable("test")</tt> </tt>
<a name="L1559"></a><tt class="py-lineno">1559</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd2 = sqlCtx.sql("select * from test")</tt> </tt>
<a name="L1560"></a><tt class="py-lineno">1560</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; sorted(srdd.collect()) == sorted(srdd2.collect())</tt> </tt>
<a name="L1561"></a><tt class="py-lineno">1561</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L1562"></a><tt class="py-lineno">1562</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1563"></a><tt class="py-lineno">1563</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-266" class="py-name" targets="Method pyspark.sql.SchemaRDD.registerTempTable()=pyspark.sql.SchemaRDD-class.html#registerTempTable"><a title="pyspark.sql.SchemaRDD.registerTempTable" class="py-name" href="#" onclick="return doclink('link-266', 'registerTempTable', 'link-266');">registerTempTable</a></tt><tt class="py-op">(</tt><tt id="link-267" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-267', 'name', 'link-14');">name</a></tt><tt class="py-op">)</tt> </tt>
</div><a name="L1564"></a><tt class="py-lineno">1564</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.registerAsTable"></a><div id="SchemaRDD.registerAsTable-def"><a name="L1565"></a><tt class="py-lineno">1565</tt> <a class="py-toggle" href="#" id="SchemaRDD.registerAsTable-toggle" onclick="return toggle('SchemaRDD.registerAsTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#registerAsTable">registerAsTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">name</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.registerAsTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.registerAsTable-expanded"><a name="L1566"></a><tt class="py-lineno">1566</tt>  <tt class="py-line">        <tt class="py-name">warnings</tt><tt class="py-op">.</tt><tt class="py-name">warn</tt><tt class="py-op">(</tt><tt class="py-string">"Use registerTempTable instead of registerAsTable."</tt><tt class="py-op">,</tt> <tt class="py-name">DeprecationWarning</tt><tt class="py-op">)</tt> </tt>
<a name="L1567"></a><tt class="py-lineno">1567</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-268" class="py-name"><a title="pyspark.sql.SchemaRDD.registerTempTable" class="py-name" href="#" onclick="return doclink('link-268', 'registerTempTable', 'link-266');">registerTempTable</a></tt><tt class="py-op">(</tt><tt id="link-269" class="py-name"><a title="pyspark.rdd.RDD.name" class="py-name" href="#" onclick="return doclink('link-269', 'name', 'link-14');">name</a></tt><tt class="py-op">)</tt> </tt>
</div><a name="L1568"></a><tt class="py-lineno">1568</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.insertInto"></a><div id="SchemaRDD.insertInto-def"><a name="L1569"></a><tt class="py-lineno">1569</tt> <a class="py-toggle" href="#" id="SchemaRDD.insertInto-toggle" onclick="return toggle('SchemaRDD.insertInto');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#insertInto">insertInto</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">,</tt> <tt class="py-param">overwrite</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.insertInto-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.insertInto-expanded"><a name="L1570"></a><tt class="py-lineno">1570</tt>  <tt class="py-line">        <tt class="py-docstring">"""Inserts the contents of this SchemaRDD into the specified table.</tt> </tt>
<a name="L1571"></a><tt class="py-lineno">1571</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1572"></a><tt class="py-lineno">1572</tt>  <tt class="py-line"><tt class="py-docstring">        Optionally overwriting any existing data.</tt> </tt>
<a name="L1573"></a><tt class="py-lineno">1573</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1574"></a><tt class="py-lineno">1574</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-270" class="py-name" targets="Method pyspark.sql.SchemaRDD.insertInto()=pyspark.sql.SchemaRDD-class.html#insertInto"><a title="pyspark.sql.SchemaRDD.insertInto" class="py-name" href="#" onclick="return doclink('link-270', 'insertInto', 'link-270');">insertInto</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">,</tt> <tt class="py-name">overwrite</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1575"></a><tt class="py-lineno">1575</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.saveAsTable"></a><div id="SchemaRDD.saveAsTable-def"><a name="L1576"></a><tt class="py-lineno">1576</tt> <a class="py-toggle" href="#" id="SchemaRDD.saveAsTable-toggle" onclick="return toggle('SchemaRDD.saveAsTable');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#saveAsTable">saveAsTable</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">tableName</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.saveAsTable-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.saveAsTable-expanded"><a name="L1577"></a><tt class="py-lineno">1577</tt>  <tt class="py-line">        <tt class="py-docstring">"""Creates a new table with the contents of this SchemaRDD."""</tt> </tt>
<a name="L1578"></a><tt class="py-lineno">1578</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-271" class="py-name" targets="Method pyspark.sql.SchemaRDD.saveAsTable()=pyspark.sql.SchemaRDD-class.html#saveAsTable"><a title="pyspark.sql.SchemaRDD.saveAsTable" class="py-name" href="#" onclick="return doclink('link-271', 'saveAsTable', 'link-271');">saveAsTable</a></tt><tt class="py-op">(</tt><tt class="py-name">tableName</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1579"></a><tt class="py-lineno">1579</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.schema"></a><div id="SchemaRDD.schema-def"><a name="L1580"></a><tt class="py-lineno">1580</tt> <a class="py-toggle" href="#" id="SchemaRDD.schema-toggle" onclick="return toggle('SchemaRDD.schema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#schema">schema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.schema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.schema-expanded"><a name="L1581"></a><tt class="py-lineno">1581</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the schema of this SchemaRDD (represented by</tt> </tt>
<a name="L1582"></a><tt class="py-lineno">1582</tt>  <tt class="py-line"><tt class="py-docstring">        a L{StructType})."""</tt> </tt>
<a name="L1583"></a><tt class="py-lineno">1583</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">_parse_datatype_string</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-272" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-272', 'schema', 'link-65');">schema</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">.</tt><tt class="py-name">toString</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1584"></a><tt class="py-lineno">1584</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.schemaString"></a><div id="SchemaRDD.schemaString-def"><a name="L1585"></a><tt class="py-lineno">1585</tt> <a class="py-toggle" href="#" id="SchemaRDD.schemaString-toggle" onclick="return toggle('SchemaRDD.schemaString');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#schemaString">schemaString</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.schemaString-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.schemaString-expanded"><a name="L1586"></a><tt class="py-lineno">1586</tt>  <tt class="py-line">        <tt class="py-docstring">"""Returns the output schema in the tree format."""</tt> </tt>
<a name="L1587"></a><tt class="py-lineno">1587</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-273" class="py-name" targets="Method pyspark.sql.SchemaRDD.schemaString()=pyspark.sql.SchemaRDD-class.html#schemaString"><a title="pyspark.sql.SchemaRDD.schemaString" class="py-name" href="#" onclick="return doclink('link-273', 'schemaString', 'link-273');">schemaString</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1588"></a><tt class="py-lineno">1588</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.printSchema"></a><div id="SchemaRDD.printSchema-def"><a name="L1589"></a><tt class="py-lineno">1589</tt> <a class="py-toggle" href="#" id="SchemaRDD.printSchema-toggle" onclick="return toggle('SchemaRDD.printSchema');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#printSchema">printSchema</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.printSchema-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.printSchema-expanded"><a name="L1590"></a><tt class="py-lineno">1590</tt>  <tt class="py-line">        <tt class="py-docstring">"""Prints out the schema in the tree format."""</tt> </tt>
<a name="L1591"></a><tt class="py-lineno">1591</tt>  <tt class="py-line">        <tt class="py-keyword">print</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-274" class="py-name"><a title="pyspark.sql.SchemaRDD.schemaString" class="py-name" href="#" onclick="return doclink('link-274', 'schemaString', 'link-273');">schemaString</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1592"></a><tt class="py-lineno">1592</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.count"></a><div id="SchemaRDD.count-def"><a name="L1593"></a><tt class="py-lineno">1593</tt> <a class="py-toggle" href="#" id="SchemaRDD.count-toggle" onclick="return toggle('SchemaRDD.count');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#count">count</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.count-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.count-expanded"><a name="L1594"></a><tt class="py-lineno">1594</tt>  <tt class="py-line">        <tt class="py-docstring">"""Return the number of elements in this RDD.</tt> </tt>
<a name="L1595"></a><tt class="py-lineno">1595</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1596"></a><tt class="py-lineno">1596</tt>  <tt class="py-line"><tt class="py-docstring">        Unlike the base RDD implementation of count, this implementation</tt> </tt>
<a name="L1597"></a><tt class="py-lineno">1597</tt>  <tt class="py-line"><tt class="py-docstring">        leverages the query optimizer to compute the count on the SchemaRDD,</tt> </tt>
<a name="L1598"></a><tt class="py-lineno">1598</tt>  <tt class="py-line"><tt class="py-docstring">        which supports features such as filter pushdown.</tt> </tt>
<a name="L1599"></a><tt class="py-lineno">1599</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1600"></a><tt class="py-lineno">1600</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd = sqlCtx.inferSchema(rdd)</tt> </tt>
<a name="L1601"></a><tt class="py-lineno">1601</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.count()</tt> </tt>
<a name="L1602"></a><tt class="py-lineno">1602</tt>  <tt class="py-line"><tt class="py-docstring">        3L</tt> </tt>
<a name="L1603"></a><tt class="py-lineno">1603</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; srdd.count() == srdd.map(lambda x: x).count()</tt> </tt>
<a name="L1604"></a><tt class="py-lineno">1604</tt>  <tt class="py-line"><tt class="py-docstring">        True</tt> </tt>
<a name="L1605"></a><tt class="py-lineno">1605</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1606"></a><tt class="py-lineno">1606</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-275" class="py-name" targets="Method pyspark.mllib.stat.MultivariateStatisticalSummary.count()=pyspark.mllib.stat.MultivariateStatisticalSummary-class.html#count,Method pyspark.rdd.RDD.count()=pyspark.rdd.RDD-class.html#count,Method pyspark.sql.SchemaRDD.count()=pyspark.sql.SchemaRDD-class.html#count,Method pyspark.statcounter.StatCounter.count()=pyspark.statcounter.StatCounter-class.html#count"><a title="pyspark.mllib.stat.MultivariateStatisticalSummary.count
pyspark.rdd.RDD.count
pyspark.sql.SchemaRDD.count
pyspark.statcounter.StatCounter.count" class="py-name" href="#" onclick="return doclink('link-275', 'count', 'link-275');">count</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1607"></a><tt class="py-lineno">1607</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.collect"></a><div id="SchemaRDD.collect-def"><a name="L1608"></a><tt class="py-lineno">1608</tt> <a class="py-toggle" href="#" id="SchemaRDD.collect-toggle" onclick="return toggle('SchemaRDD.collect');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#collect">collect</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.collect-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.collect-expanded"><a name="L1609"></a><tt class="py-lineno">1609</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L1610"></a><tt class="py-lineno">1610</tt>  <tt class="py-line"><tt class="py-docstring">        Return a list that contains all of the rows in this RDD.</tt> </tt>
<a name="L1611"></a><tt class="py-lineno">1611</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1612"></a><tt class="py-lineno">1612</tt>  <tt class="py-line"><tt class="py-docstring">        Each object in the list is on Row, the fields can be accessed as</tt> </tt>
<a name="L1613"></a><tt class="py-lineno">1613</tt>  <tt class="py-line"><tt class="py-docstring">        attributes.</tt> </tt>
<a name="L1614"></a><tt class="py-lineno">1614</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1615"></a><tt class="py-lineno">1615</tt>  <tt class="py-line">        <tt class="py-name">rows</tt> <tt class="py-op">=</tt> <tt id="link-276" class="py-name"><a title="pyspark.rdd.RDD" class="py-name" href="#" onclick="return doclink('link-276', 'RDD', 'link-2');">RDD</a></tt><tt class="py-op">.</tt><tt id="link-277" class="py-name" targets="Method pyspark.rdd.RDD.collect()=pyspark.rdd.RDD-class.html#collect,Method pyspark.sql.SchemaRDD.collect()=pyspark.sql.SchemaRDD-class.html#collect"><a title="pyspark.rdd.RDD.collect
pyspark.sql.SchemaRDD.collect" class="py-name" href="#" onclick="return doclink('link-277', 'collect', 'link-277');">collect</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">)</tt> </tt>
<a name="L1616"></a><tt class="py-lineno">1616</tt>  <tt class="py-line">        <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_cls</tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-278" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-278', 'schema', 'link-65');">schema</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1617"></a><tt class="py-lineno">1617</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-279" class="py-name"><a title="pyspark.rdd.RDD.map" class="py-name" href="#" onclick="return doclink('link-279', 'map', 'link-54');">map</a></tt><tt class="py-op">(</tt><tt class="py-name">cls</tt><tt class="py-op">,</tt> <tt class="py-name">rows</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1618"></a><tt class="py-lineno">1618</tt>  <tt class="py-line"> </tt>
<a name="L1619"></a><tt class="py-lineno">1619</tt>  <tt class="py-line">    <tt class="py-comment"># Convert each object in the RDD to a Row with the right class</tt> </tt>
<a name="L1620"></a><tt class="py-lineno">1620</tt>  <tt class="py-line">    <tt class="py-comment"># for this SchemaRDD, so that fields can be accessed as attributes.</tt> </tt>
<a name="SchemaRDD.mapPartitionsWithIndex"></a><div id="SchemaRDD.mapPartitionsWithIndex-def"><a name="L1621"></a><tt class="py-lineno">1621</tt> <a class="py-toggle" href="#" id="SchemaRDD.mapPartitionsWithIndex-toggle" onclick="return toggle('SchemaRDD.mapPartitionsWithIndex');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#mapPartitionsWithIndex">mapPartitionsWithIndex</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">f</tt><tt class="py-op">,</tt> <tt class="py-param">preservesPartitioning</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.mapPartitionsWithIndex-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.mapPartitionsWithIndex-expanded"><a name="L1622"></a><tt class="py-lineno">1622</tt>  <tt class="py-line">        <tt class="py-docstring">"""</tt> </tt>
<a name="L1623"></a><tt class="py-lineno">1623</tt>  <tt class="py-line"><tt class="py-docstring">        Return a new RDD by applying a function to each partition of this RDD,</tt> </tt>
<a name="L1624"></a><tt class="py-lineno">1624</tt>  <tt class="py-line"><tt class="py-docstring">        while tracking the index of the original partition.</tt> </tt>
<a name="L1625"></a><tt class="py-lineno">1625</tt>  <tt class="py-line"><tt class="py-docstring"></tt> </tt>
<a name="L1626"></a><tt class="py-lineno">1626</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4], 4)</tt> </tt>
<a name="L1627"></a><tt class="py-lineno">1627</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; def f(splitIndex, iterator): yield splitIndex</tt> </tt>
<a name="L1628"></a><tt class="py-lineno">1628</tt>  <tt class="py-line"><tt class="py-docstring">        &gt;&gt;&gt; rdd.mapPartitionsWithIndex(f).sum()</tt> </tt>
<a name="L1629"></a><tt class="py-lineno">1629</tt>  <tt class="py-line"><tt class="py-docstring">        6</tt> </tt>
<a name="L1630"></a><tt class="py-lineno">1630</tt>  <tt class="py-line"><tt class="py-docstring">        """</tt> </tt>
<a name="L1631"></a><tt class="py-lineno">1631</tt>  <tt class="py-line">        <tt id="link-280" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-280', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt id="link-281" class="py-name"><a title="pyspark.rdd.RDD" class="py-name" href="#" onclick="return doclink('link-281', 'RDD', 'link-2');">RDD</a></tt><tt class="py-op">(</tt><tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd</tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-282" class="py-name"><a title="pyspark.files.SparkFiles._sc" class="py-name" href="#" onclick="return doclink('link-282', '_sc', 'link-158');">_sc</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jrdd_deserializer</tt><tt class="py-op">)</tt> </tt>
<a name="L1632"></a><tt class="py-lineno">1632</tt>  <tt class="py-line"> </tt>
<a name="L1633"></a><tt class="py-lineno">1633</tt>  <tt class="py-line">        <tt id="link-283" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-283', 'schema', 'link-65');">schema</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt id="link-284" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-284', 'schema', 'link-65');">schema</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1634"></a><tt class="py-lineno">1634</tt>  <tt class="py-line">        <tt class="py-keyword">import</tt> <tt class="py-name">pickle</tt> </tt>
<a name="L1635"></a><tt class="py-lineno">1635</tt>  <tt class="py-line">        <tt class="py-name">pickle</tt><tt class="py-op">.</tt><tt id="link-285" class="py-name" targets="Variable pyspark.serializers.MarshalSerializer.loads=pyspark.serializers.MarshalSerializer-class.html#loads,Variable pyspark.serializers.PickleSerializer.loads=pyspark.serializers.PickleSerializer-class.html#loads"><a title="pyspark.serializers.MarshalSerializer.loads
pyspark.serializers.PickleSerializer.loads" class="py-name" href="#" onclick="return doclink('link-285', 'loads', 'link-285');">loads</a></tt><tt class="py-op">(</tt><tt class="py-name">pickle</tt><tt class="py-op">.</tt><tt id="link-286" class="py-name"><a title="pyspark.serializers.MarshalSerializer.dumps
pyspark.serializers.PickleSerializer.dumps" class="py-name" href="#" onclick="return doclink('link-286', 'dumps', 'link-177');">dumps</a></tt><tt class="py-op">(</tt><tt id="link-287" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-287', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt><tt class="py-op">)</tt> </tt>
<a name="L1636"></a><tt class="py-lineno">1636</tt>  <tt class="py-line"> </tt>
<a name="L1637"></a><tt class="py-lineno">1637</tt>  <tt class="py-line">        <tt class="py-keyword">def</tt> <tt class="py-def-name">applySchema</tt><tt class="py-op">(</tt><tt class="py-param">_</tt><tt class="py-op">,</tt> <tt class="py-param">it</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1638"></a><tt class="py-lineno">1638</tt>  <tt class="py-line">            <tt class="py-name">cls</tt> <tt class="py-op">=</tt> <tt class="py-name">_create_cls</tt><tt class="py-op">(</tt><tt id="link-288" class="py-name"><a title="pyspark.sql.SchemaRDD.schema" class="py-name" href="#" onclick="return doclink('link-288', 'schema', 'link-65');">schema</a></tt><tt class="py-op">)</tt> </tt>
<a name="L1639"></a><tt class="py-lineno">1639</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">itertools</tt><tt class="py-op">.</tt><tt class="py-name">imap</tt><tt class="py-op">(</tt><tt class="py-name">cls</tt><tt class="py-op">,</tt> <tt class="py-name">it</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1640"></a><tt class="py-lineno">1640</tt>  <tt class="py-line"> </tt>
<a name="L1641"></a><tt class="py-lineno">1641</tt>  <tt class="py-line">        <tt class="py-name">objrdd</tt> <tt class="py-op">=</tt> <tt id="link-289" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-289', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">.</tt><tt id="link-290" class="py-name" targets="Method pyspark.rdd.RDD.mapPartitionsWithIndex()=pyspark.rdd.RDD-class.html#mapPartitionsWithIndex,Method pyspark.sql.SchemaRDD.mapPartitionsWithIndex()=pyspark.sql.SchemaRDD-class.html#mapPartitionsWithIndex"><a title="pyspark.rdd.RDD.mapPartitionsWithIndex
pyspark.sql.SchemaRDD.mapPartitionsWithIndex" class="py-name" href="#" onclick="return doclink('link-290', 'mapPartitionsWithIndex', 'link-290');">mapPartitionsWithIndex</a></tt><tt class="py-op">(</tt><tt id="link-291" class="py-name"><a title="pyspark.sql.SQLContext.applySchema" class="py-name" href="#" onclick="return doclink('link-291', 'applySchema', 'link-193');">applySchema</a></tt><tt class="py-op">,</tt> <tt class="py-name">preservesPartitioning</tt><tt class="py-op">)</tt> </tt>
<a name="L1642"></a><tt class="py-lineno">1642</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">objrdd</tt><tt class="py-op">.</tt><tt id="link-292" class="py-name"><a title="pyspark.rdd.RDD.mapPartitionsWithIndex
pyspark.sql.SchemaRDD.mapPartitionsWithIndex" class="py-name" href="#" onclick="return doclink('link-292', 'mapPartitionsWithIndex', 'link-290');">mapPartitionsWithIndex</a></tt><tt class="py-op">(</tt><tt class="py-name">f</tt><tt class="py-op">,</tt> <tt class="py-name">preservesPartitioning</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1643"></a><tt class="py-lineno">1643</tt>  <tt class="py-line"> </tt>
<a name="L1644"></a><tt class="py-lineno">1644</tt>  <tt class="py-line">    <tt class="py-comment"># We override the default cache/persist/checkpoint behavior</tt> </tt>
<a name="L1645"></a><tt class="py-lineno">1645</tt>  <tt class="py-line">    <tt class="py-comment"># as we want to cache the underlying SchemaRDD object in the JVM,</tt> </tt>
<a name="L1646"></a><tt class="py-lineno">1646</tt>  <tt class="py-line">    <tt class="py-comment"># not the PythonRDD checkpointed by the super class</tt> </tt>
<a name="SchemaRDD.cache"></a><div id="SchemaRDD.cache-def"><a name="L1647"></a><tt class="py-lineno">1647</tt> <a class="py-toggle" href="#" id="SchemaRDD.cache-toggle" onclick="return toggle('SchemaRDD.cache');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#cache">cache</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.cache-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.cache-expanded"><a name="L1648"></a><tt class="py-lineno">1648</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L1649"></a><tt class="py-lineno">1649</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-293" class="py-name" targets="Method pyspark.rdd.RDD.cache()=pyspark.rdd.RDD-class.html#cache,Method pyspark.sql.SchemaRDD.cache()=pyspark.sql.SchemaRDD-class.html#cache"><a title="pyspark.rdd.RDD.cache
pyspark.sql.SchemaRDD.cache" class="py-name" href="#" onclick="return doclink('link-293', 'cache', 'link-293');">cache</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1650"></a><tt class="py-lineno">1650</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> </tt>
</div><a name="L1651"></a><tt class="py-lineno">1651</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.persist"></a><div id="SchemaRDD.persist-def"><a name="L1652"></a><tt class="py-lineno">1652</tt> <a class="py-toggle" href="#" id="SchemaRDD.persist-toggle" onclick="return toggle('SchemaRDD.persist');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#persist">persist</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">storageLevel</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.persist-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.persist-expanded"><a name="L1653"></a><tt class="py-lineno">1653</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L1654"></a><tt class="py-lineno">1654</tt>  <tt class="py-line">        <tt class="py-name">javaStorageLevel</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">ctx</tt><tt class="py-op">.</tt><tt class="py-name">_getJavaStorageLevel</tt><tt class="py-op">(</tt><tt class="py-name">storageLevel</tt><tt class="py-op">)</tt> </tt>
<a name="L1655"></a><tt class="py-lineno">1655</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-294" class="py-name" targets="Method pyspark.rdd.RDD.persist()=pyspark.rdd.RDD-class.html#persist,Method pyspark.sql.SchemaRDD.persist()=pyspark.sql.SchemaRDD-class.html#persist"><a title="pyspark.rdd.RDD.persist
pyspark.sql.SchemaRDD.persist" class="py-name" href="#" onclick="return doclink('link-294', 'persist', 'link-294');">persist</a></tt><tt class="py-op">(</tt><tt class="py-name">javaStorageLevel</tt><tt class="py-op">)</tt> </tt>
<a name="L1656"></a><tt class="py-lineno">1656</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> </tt>
</div><a name="L1657"></a><tt class="py-lineno">1657</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.unpersist"></a><div id="SchemaRDD.unpersist-def"><a name="L1658"></a><tt class="py-lineno">1658</tt> <a class="py-toggle" href="#" id="SchemaRDD.unpersist-toggle" onclick="return toggle('SchemaRDD.unpersist');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#unpersist">unpersist</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">blocking</tt><tt class="py-op">=</tt><tt class="py-name">True</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.unpersist-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.unpersist-expanded"><a name="L1659"></a><tt class="py-lineno">1659</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_cached</tt> <tt class="py-op">=</tt> <tt class="py-name">False</tt> </tt>
<a name="L1660"></a><tt class="py-lineno">1660</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-295" class="py-name" targets="Method pyspark.broadcast.Broadcast.unpersist()=pyspark.broadcast.Broadcast-class.html#unpersist,Method pyspark.rdd.RDD.unpersist()=pyspark.rdd.RDD-class.html#unpersist,Method pyspark.sql.SchemaRDD.unpersist()=pyspark.sql.SchemaRDD-class.html#unpersist"><a title="pyspark.broadcast.Broadcast.unpersist
pyspark.rdd.RDD.unpersist
pyspark.sql.SchemaRDD.unpersist" class="py-name" href="#" onclick="return doclink('link-295', 'unpersist', 'link-295');">unpersist</a></tt><tt class="py-op">(</tt><tt class="py-name">blocking</tt><tt class="py-op">)</tt> </tt>
<a name="L1661"></a><tt class="py-lineno">1661</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt> </tt>
</div><a name="L1662"></a><tt class="py-lineno">1662</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.checkpoint"></a><div id="SchemaRDD.checkpoint-def"><a name="L1663"></a><tt class="py-lineno">1663</tt> <a class="py-toggle" href="#" id="SchemaRDD.checkpoint-toggle" onclick="return toggle('SchemaRDD.checkpoint');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#checkpoint">checkpoint</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.checkpoint-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.checkpoint-expanded"><a name="L1664"></a><tt class="py-lineno">1664</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">is_checkpointed</tt> <tt class="py-op">=</tt> <tt class="py-name">True</tt> </tt>
<a name="L1665"></a><tt class="py-lineno">1665</tt>  <tt class="py-line">        <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-296" class="py-name" targets="Method pyspark.rdd.RDD.checkpoint()=pyspark.rdd.RDD-class.html#checkpoint,Method pyspark.sql.SchemaRDD.checkpoint()=pyspark.sql.SchemaRDD-class.html#checkpoint"><a title="pyspark.rdd.RDD.checkpoint
pyspark.sql.SchemaRDD.checkpoint" class="py-name" href="#" onclick="return doclink('link-296', 'checkpoint', 'link-296');">checkpoint</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1666"></a><tt class="py-lineno">1666</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.isCheckpointed"></a><div id="SchemaRDD.isCheckpointed-def"><a name="L1667"></a><tt class="py-lineno">1667</tt> <a class="py-toggle" href="#" id="SchemaRDD.isCheckpointed-toggle" onclick="return toggle('SchemaRDD.isCheckpointed');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#isCheckpointed">isCheckpointed</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.isCheckpointed-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.isCheckpointed-expanded"><a name="L1668"></a><tt class="py-lineno">1668</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-297" class="py-name" targets="Method pyspark.rdd.RDD.isCheckpointed()=pyspark.rdd.RDD-class.html#isCheckpointed,Method pyspark.sql.SchemaRDD.isCheckpointed()=pyspark.sql.SchemaRDD-class.html#isCheckpointed"><a title="pyspark.rdd.RDD.isCheckpointed
pyspark.sql.SchemaRDD.isCheckpointed" class="py-name" href="#" onclick="return doclink('link-297', 'isCheckpointed', 'link-297');">isCheckpointed</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1669"></a><tt class="py-lineno">1669</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.getCheckpointFile"></a><div id="SchemaRDD.getCheckpointFile-def"><a name="L1670"></a><tt class="py-lineno">1670</tt> <a class="py-toggle" href="#" id="SchemaRDD.getCheckpointFile-toggle" onclick="return toggle('SchemaRDD.getCheckpointFile');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#getCheckpointFile">getCheckpointFile</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.getCheckpointFile-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.getCheckpointFile-expanded"><a name="L1671"></a><tt class="py-lineno">1671</tt>  <tt class="py-line">        <tt class="py-name">checkpointFile</tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-298" class="py-name" targets="Method pyspark.rdd.RDD.getCheckpointFile()=pyspark.rdd.RDD-class.html#getCheckpointFile,Method pyspark.sql.SchemaRDD.getCheckpointFile()=pyspark.sql.SchemaRDD-class.html#getCheckpointFile"><a title="pyspark.rdd.RDD.getCheckpointFile
pyspark.sql.SchemaRDD.getCheckpointFile" class="py-name" href="#" onclick="return doclink('link-298', 'getCheckpointFile', 'link-298');">getCheckpointFile</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1672"></a><tt class="py-lineno">1672</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-name">checkpointFile</tt><tt class="py-op">.</tt><tt class="py-name">isDefined</tt><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1673"></a><tt class="py-lineno">1673</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">checkpointFile</tt><tt class="py-op">.</tt><tt id="link-299" class="py-name"><a title="pyspark.conf.SparkConf.get
pyspark.files.SparkFiles.get" class="py-name" href="#" onclick="return doclink('link-299', 'get', 'link-44');">get</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1674"></a><tt class="py-lineno">1674</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1675"></a><tt class="py-lineno">1675</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt class="py-name">None</tt> </tt>
</div><a name="L1676"></a><tt class="py-lineno">1676</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.coalesce"></a><div id="SchemaRDD.coalesce-def"><a name="L1677"></a><tt class="py-lineno">1677</tt> <a class="py-toggle" href="#" id="SchemaRDD.coalesce-toggle" onclick="return toggle('SchemaRDD.coalesce');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#coalesce">coalesce</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">numPartitions</tt><tt class="py-op">,</tt> <tt class="py-param">shuffle</tt><tt class="py-op">=</tt><tt class="py-name">False</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.coalesce-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.coalesce-expanded"><a name="L1678"></a><tt class="py-lineno">1678</tt>  <tt class="py-line">        <tt id="link-300" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-300', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-301" class="py-name" targets="Method pyspark.rdd.RDD.coalesce()=pyspark.rdd.RDD-class.html#coalesce,Method pyspark.sql.SchemaRDD.coalesce()=pyspark.sql.SchemaRDD-class.html#coalesce"><a title="pyspark.rdd.RDD.coalesce
pyspark.sql.SchemaRDD.coalesce" class="py-name" href="#" onclick="return doclink('link-301', 'coalesce', 'link-301');">coalesce</a></tt><tt class="py-op">(</tt><tt class="py-name">numPartitions</tt><tt class="py-op">,</tt> <tt class="py-name">shuffle</tt><tt class="py-op">)</tt> </tt>
<a name="L1679"></a><tt class="py-lineno">1679</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-302" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-302', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-303" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-303', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1680"></a><tt class="py-lineno">1680</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.distinct"></a><div id="SchemaRDD.distinct-def"><a name="L1681"></a><tt class="py-lineno">1681</tt> <a class="py-toggle" href="#" id="SchemaRDD.distinct-toggle" onclick="return toggle('SchemaRDD.distinct');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#distinct">distinct</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.distinct-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.distinct-expanded"><a name="L1682"></a><tt class="py-lineno">1682</tt>  <tt class="py-line">        <tt id="link-304" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-304', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-305" class="py-name" targets="Method pyspark.rdd.RDD.distinct()=pyspark.rdd.RDD-class.html#distinct,Method pyspark.sql.SchemaRDD.distinct()=pyspark.sql.SchemaRDD-class.html#distinct"><a title="pyspark.rdd.RDD.distinct
pyspark.sql.SchemaRDD.distinct" class="py-name" href="#" onclick="return doclink('link-305', 'distinct', 'link-305');">distinct</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1683"></a><tt class="py-lineno">1683</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-306" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-306', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-307" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-307', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1684"></a><tt class="py-lineno">1684</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.intersection"></a><div id="SchemaRDD.intersection-def"><a name="L1685"></a><tt class="py-lineno">1685</tt> <a class="py-toggle" href="#" id="SchemaRDD.intersection-toggle" onclick="return toggle('SchemaRDD.intersection');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#intersection">intersection</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.intersection-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.intersection-expanded"><a name="L1686"></a><tt class="py-lineno">1686</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-308" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-308', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1687"></a><tt class="py-lineno">1687</tt>  <tt class="py-line">            <tt id="link-309" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-309', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-310" class="py-name" targets="Method pyspark.rdd.RDD.intersection()=pyspark.rdd.RDD-class.html#intersection,Method pyspark.sql.SchemaRDD.intersection()=pyspark.sql.SchemaRDD-class.html#intersection"><a title="pyspark.rdd.RDD.intersection
pyspark.sql.SchemaRDD.intersection" class="py-name" href="#" onclick="return doclink('link-310', 'intersection', 'link-310');">intersection</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">)</tt> </tt>
<a name="L1688"></a><tt class="py-lineno">1688</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt id="link-311" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-311', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-312" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-312', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
<a name="L1689"></a><tt class="py-lineno">1689</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1690"></a><tt class="py-lineno">1690</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can only intersect with another SchemaRDD"</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1691"></a><tt class="py-lineno">1691</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.repartition"></a><div id="SchemaRDD.repartition-def"><a name="L1692"></a><tt class="py-lineno">1692</tt> <a class="py-toggle" href="#" id="SchemaRDD.repartition-toggle" onclick="return toggle('SchemaRDD.repartition');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#repartition">repartition</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">numPartitions</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.repartition-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.repartition-expanded"><a name="L1693"></a><tt class="py-lineno">1693</tt>  <tt class="py-line">        <tt id="link-313" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-313', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-314" class="py-name" targets="Method pyspark.rdd.RDD.repartition()=pyspark.rdd.RDD-class.html#repartition,Method pyspark.sql.SchemaRDD.repartition()=pyspark.sql.SchemaRDD-class.html#repartition"><a title="pyspark.rdd.RDD.repartition
pyspark.sql.SchemaRDD.repartition" class="py-name" href="#" onclick="return doclink('link-314', 'repartition', 'link-314');">repartition</a></tt><tt class="py-op">(</tt><tt class="py-name">numPartitions</tt><tt class="py-op">)</tt> </tt>
<a name="L1694"></a><tt class="py-lineno">1694</tt>  <tt class="py-line">        <tt class="py-keyword">return</tt> <tt id="link-315" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-315', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-316" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-316', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1695"></a><tt class="py-lineno">1695</tt>  <tt class="py-line"> </tt>
<a name="SchemaRDD.subtract"></a><div id="SchemaRDD.subtract-def"><a name="L1696"></a><tt class="py-lineno">1696</tt> <a class="py-toggle" href="#" id="SchemaRDD.subtract-toggle" onclick="return toggle('SchemaRDD.subtract');">-</a><tt class="py-line">    <tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql.SchemaRDD-class.html#subtract">subtract</a><tt class="py-op">(</tt><tt class="py-param">self</tt><tt class="py-op">,</tt> <tt class="py-param">other</tt><tt class="py-op">,</tt> <tt class="py-param">numPartitions</tt><tt class="py-op">=</tt><tt class="py-name">None</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="SchemaRDD.subtract-collapsed" style="display:none;" pad="++++" indent="++++++++"></div><div id="SchemaRDD.subtract-expanded"><a name="L1697"></a><tt class="py-lineno">1697</tt>  <tt class="py-line">        <tt class="py-keyword">if</tt> <tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">__class__</tt> <tt class="py-keyword">is</tt> <tt id="link-317" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-317', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
<a name="L1698"></a><tt class="py-lineno">1698</tt>  <tt class="py-line">            <tt class="py-keyword">if</tt> <tt class="py-name">numPartitions</tt> <tt class="py-keyword">is</tt> <tt class="py-name">None</tt><tt class="py-op">:</tt> </tt>
<a name="L1699"></a><tt class="py-lineno">1699</tt>  <tt class="py-line">                <tt id="link-318" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-318', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-319" class="py-name" targets="Method pyspark.rdd.RDD.subtract()=pyspark.rdd.RDD-class.html#subtract,Method pyspark.sql.SchemaRDD.subtract()=pyspark.sql.SchemaRDD-class.html#subtract"><a title="pyspark.rdd.RDD.subtract
pyspark.sql.SchemaRDD.subtract" class="py-name" href="#" onclick="return doclink('link-319', 'subtract', 'link-319');">subtract</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">)</tt> </tt>
<a name="L1700"></a><tt class="py-lineno">1700</tt>  <tt class="py-line">            <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1701"></a><tt class="py-lineno">1701</tt>  <tt class="py-line">                <tt id="link-320" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-320', 'rdd', 'link-1');">rdd</a></tt> <tt class="py-op">=</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">.</tt><tt id="link-321" class="py-name"><a title="pyspark.rdd.RDD.subtract
pyspark.sql.SchemaRDD.subtract" class="py-name" href="#" onclick="return doclink('link-321', 'subtract', 'link-319');">subtract</a></tt><tt class="py-op">(</tt><tt class="py-name">other</tt><tt class="py-op">.</tt><tt class="py-name">_jschema_rdd</tt><tt class="py-op">,</tt> </tt>
<a name="L1702"></a><tt class="py-lineno">1702</tt>  <tt class="py-line">                                                 <tt class="py-name">numPartitions</tt><tt class="py-op">)</tt> </tt>
<a name="L1703"></a><tt class="py-lineno">1703</tt>  <tt class="py-line">            <tt class="py-keyword">return</tt> <tt id="link-322" class="py-name"><a title="pyspark.sql.SchemaRDD" class="py-name" href="#" onclick="return doclink('link-322', 'SchemaRDD', 'link-181');">SchemaRDD</a></tt><tt class="py-op">(</tt><tt id="link-323" class="py-name"><a title="pyspark.rdd" class="py-name" href="#" onclick="return doclink('link-323', 'rdd', 'link-1');">rdd</a></tt><tt class="py-op">,</tt> <tt class="py-name">self</tt><tt class="py-op">.</tt><tt class="py-name">sql_ctx</tt><tt class="py-op">)</tt> </tt>
<a name="L1704"></a><tt class="py-lineno">1704</tt>  <tt class="py-line">        <tt class="py-keyword">else</tt><tt class="py-op">:</tt> </tt>
<a name="L1705"></a><tt class="py-lineno">1705</tt>  <tt class="py-line">            <tt class="py-keyword">raise</tt> <tt class="py-name">ValueError</tt><tt class="py-op">(</tt><tt class="py-string">"Can only subtract another SchemaRDD"</tt><tt class="py-op">)</tt> </tt>
</div></div><a name="L1706"></a><tt class="py-lineno">1706</tt>  <tt class="py-line"> </tt>
<a name="_test"></a><div id="_test-def"><a name="L1707"></a><tt class="py-lineno">1707</tt>  <tt class="py-line"> </tt>
<a name="L1708"></a><tt class="py-lineno">1708</tt> <a class="py-toggle" href="#" id="_test-toggle" onclick="return toggle('_test');">-</a><tt class="py-line"><tt class="py-keyword">def</tt> <a class="py-def-name" href="pyspark.sql-module.html#_test">_test</a><tt class="py-op">(</tt><tt class="py-op">)</tt><tt class="py-op">:</tt> </tt>
</div><div id="_test-collapsed" style="display:none;" pad="++++" indent="++++"></div><div id="_test-expanded"><a name="L1709"></a><tt class="py-lineno">1709</tt>  <tt class="py-line">    <tt class="py-keyword">import</tt> <tt class="py-name">doctest</tt> </tt>
<a name="L1710"></a><tt class="py-lineno">1710</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt class="py-name">array</tt> <tt class="py-keyword">import</tt> <tt class="py-name">array</tt> </tt>
<a name="L1711"></a><tt class="py-lineno">1711</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt id="link-324" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-324', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-325" class="py-name" targets="Module pyspark.context=pyspark.context-module.html,Method pyspark.rdd.RDD.context()=pyspark.rdd.RDD-class.html#context"><a title="pyspark.context
pyspark.rdd.RDD.context" class="py-name" href="#" onclick="return doclink('link-325', 'context', 'link-325');">context</a></tt> <tt class="py-keyword">import</tt> <tt id="link-326" class="py-name" targets="Class pyspark.context.SparkContext=pyspark.context.SparkContext-class.html"><a title="pyspark.context.SparkContext" class="py-name" href="#" onclick="return doclink('link-326', 'SparkContext', 'link-326');">SparkContext</a></tt> </tt>
<a name="L1712"></a><tt class="py-lineno">1712</tt>  <tt class="py-line">    <tt class="py-comment"># let doctest run in pyspark.sql, so DataTypes can be picklable</tt> </tt>
<a name="L1713"></a><tt class="py-lineno">1713</tt>  <tt class="py-line">    <tt class="py-keyword">import</tt> <tt id="link-327" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-327', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-328" class="py-name"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-328', 'sql', 'link-231');">sql</a></tt> </tt>
<a name="L1714"></a><tt class="py-lineno">1714</tt>  <tt class="py-line">    <tt class="py-keyword">from</tt> <tt id="link-329" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-329', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-330" class="py-name"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-330', 'sql', 'link-231');">sql</a></tt> <tt class="py-keyword">import</tt> <tt id="link-331" class="py-name"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-331', 'Row', 'link-157');">Row</a></tt><tt class="py-op">,</tt> <tt id="link-332" class="py-name"><a title="pyspark.sql.SQLContext" class="py-name" href="#" onclick="return doclink('link-332', 'SQLContext', 'link-165');">SQLContext</a></tt> </tt>
<a name="L1715"></a><tt class="py-lineno">1715</tt>  <tt class="py-line">    <tt class="py-name">globs</tt> <tt class="py-op">=</tt> <tt id="link-333" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-333', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-334" class="py-name"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-334', 'sql', 'link-231');">sql</a></tt><tt class="py-op">.</tt><tt class="py-name">__dict__</tt><tt class="py-op">.</tt><tt id="link-335" class="py-name" targets="Method pyspark.statcounter.StatCounter.copy()=pyspark.statcounter.StatCounter-class.html#copy"><a title="pyspark.statcounter.StatCounter.copy" class="py-name" href="#" onclick="return doclink('link-335', 'copy', 'link-335');">copy</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1716"></a><tt class="py-lineno">1716</tt>  <tt class="py-line">    <tt class="py-comment"># The small batch size here ensures that we see multiple batches,</tt> </tt>
<a name="L1717"></a><tt class="py-lineno">1717</tt>  <tt class="py-line">    <tt class="py-comment"># even in these small test examples:</tt> </tt>
<a name="L1718"></a><tt class="py-lineno">1718</tt>  <tt class="py-line">    <tt class="py-name">sc</tt> <tt class="py-op">=</tt> <tt id="link-336" class="py-name"><a title="pyspark.context.SparkContext" class="py-name" href="#" onclick="return doclink('link-336', 'SparkContext', 'link-326');">SparkContext</a></tt><tt class="py-op">(</tt><tt class="py-string">'local[4]'</tt><tt class="py-op">,</tt> <tt class="py-string">'PythonTest'</tt><tt class="py-op">,</tt> <tt class="py-name">batchSize</tt><tt class="py-op">=</tt><tt class="py-number">2</tt><tt class="py-op">)</tt> </tt>
<a name="L1719"></a><tt class="py-lineno">1719</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'sc'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt> </tt>
<a name="L1720"></a><tt class="py-lineno">1720</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'sqlCtx'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt id="link-337" class="py-name"><a title="pyspark.sql.SQLContext" class="py-name" href="#" onclick="return doclink('link-337', 'SQLContext', 'link-165');">SQLContext</a></tt><tt class="py-op">(</tt><tt class="py-name">sc</tt><tt class="py-op">)</tt> </tt>
<a name="L1721"></a><tt class="py-lineno">1721</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'rdd'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt><tt class="py-op">.</tt><tt id="link-338" class="py-name" targets="Method pyspark.context.SparkContext.parallelize()=pyspark.context.SparkContext-class.html#parallelize"><a title="pyspark.context.SparkContext.parallelize" class="py-name" href="#" onclick="return doclink('link-338', 'parallelize', 'link-338');">parallelize</a></tt><tt class="py-op">(</tt> </tt>
<a name="L1722"></a><tt class="py-lineno">1722</tt>  <tt class="py-line">        <tt class="py-op">[</tt><tt id="link-339" class="py-name"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-339', 'Row', 'link-157');">Row</a></tt><tt class="py-op">(</tt><tt class="py-name">field1</tt><tt class="py-op">=</tt><tt class="py-number">1</tt><tt class="py-op">,</tt> <tt class="py-name">field2</tt><tt class="py-op">=</tt><tt class="py-string">"row1"</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L1723"></a><tt class="py-lineno">1723</tt>  <tt class="py-line">         <tt id="link-340" class="py-name"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-340', 'Row', 'link-157');">Row</a></tt><tt class="py-op">(</tt><tt class="py-name">field1</tt><tt class="py-op">=</tt><tt class="py-number">2</tt><tt class="py-op">,</tt> <tt class="py-name">field2</tt><tt class="py-op">=</tt><tt class="py-string">"row2"</tt><tt class="py-op">)</tt><tt class="py-op">,</tt> </tt>
<a name="L1724"></a><tt class="py-lineno">1724</tt>  <tt class="py-line">         <tt id="link-341" class="py-name"><a title="pyspark.sql.Row" class="py-name" href="#" onclick="return doclink('link-341', 'Row', 'link-157');">Row</a></tt><tt class="py-op">(</tt><tt class="py-name">field1</tt><tt class="py-op">=</tt><tt class="py-number">3</tt><tt class="py-op">,</tt> <tt class="py-name">field2</tt><tt class="py-op">=</tt><tt class="py-string">"row3"</tt><tt class="py-op">)</tt><tt class="py-op">]</tt> </tt>
<a name="L1725"></a><tt class="py-lineno">1725</tt>  <tt class="py-line">    <tt class="py-op">)</tt> </tt>
<a name="L1726"></a><tt class="py-lineno">1726</tt>  <tt class="py-line">    <tt class="py-name">jsonStrings</tt> <tt class="py-op">=</tt> <tt class="py-op">[</tt> </tt>
<a name="L1727"></a><tt class="py-lineno">1727</tt>  <tt class="py-line">        <tt class="py-string">'{"field1": 1, "field2": "row1", "field3":{"field4":11}}'</tt><tt class="py-op">,</tt> </tt>
<a name="L1728"></a><tt class="py-lineno">1728</tt>  <tt class="py-line">        <tt class="py-string">'{"field1" : 2, "field3":{"field4":22, "field5": [10, 11]},'</tt> </tt>
<a name="L1729"></a><tt class="py-lineno">1729</tt>  <tt class="py-line">        <tt class="py-string">'"field6":[{"field7": "row2"}]}'</tt><tt class="py-op">,</tt> </tt>
<a name="L1730"></a><tt class="py-lineno">1730</tt>  <tt class="py-line">        <tt class="py-string">'{"field1" : null, "field2": "row3", '</tt> </tt>
<a name="L1731"></a><tt class="py-lineno">1731</tt>  <tt class="py-line">        <tt class="py-string">'"field3":{"field4":33, "field5": []}}'</tt> </tt>
<a name="L1732"></a><tt class="py-lineno">1732</tt>  <tt class="py-line">    <tt class="py-op">]</tt> </tt>
<a name="L1733"></a><tt class="py-lineno">1733</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'jsonStrings'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">jsonStrings</tt> </tt>
<a name="L1734"></a><tt class="py-lineno">1734</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'json'</tt><tt class="py-op">]</tt> <tt class="py-op">=</tt> <tt class="py-name">sc</tt><tt class="py-op">.</tt><tt id="link-342" class="py-name"><a title="pyspark.context.SparkContext.parallelize" class="py-name" href="#" onclick="return doclink('link-342', 'parallelize', 'link-338');">parallelize</a></tt><tt class="py-op">(</tt><tt class="py-name">jsonStrings</tt><tt class="py-op">)</tt> </tt>
<a name="L1735"></a><tt class="py-lineno">1735</tt>  <tt class="py-line">    <tt class="py-op">(</tt><tt class="py-name">failure_count</tt><tt class="py-op">,</tt> <tt class="py-name">test_count</tt><tt class="py-op">)</tt> <tt class="py-op">=</tt> <tt class="py-name">doctest</tt><tt class="py-op">.</tt><tt class="py-name">testmod</tt><tt class="py-op">(</tt> </tt>
<a name="L1736"></a><tt class="py-lineno">1736</tt>  <tt class="py-line">        <tt id="link-343" class="py-name"><a title="pyspark" class="py-name" href="#" onclick="return doclink('link-343', 'pyspark', 'link-0');">pyspark</a></tt><tt class="py-op">.</tt><tt id="link-344" class="py-name"><a title="pyspark.sql
pyspark.sql.SQLContext.sql" class="py-name" href="#" onclick="return doclink('link-344', 'sql', 'link-231');">sql</a></tt><tt class="py-op">,</tt> <tt class="py-name">globs</tt><tt class="py-op">=</tt><tt class="py-name">globs</tt><tt class="py-op">,</tt> <tt class="py-name">optionflags</tt><tt class="py-op">=</tt><tt class="py-name">doctest</tt><tt class="py-op">.</tt><tt class="py-name">ELLIPSIS</tt><tt class="py-op">)</tt> </tt>
<a name="L1737"></a><tt class="py-lineno">1737</tt>  <tt class="py-line">    <tt class="py-name">globs</tt><tt class="py-op">[</tt><tt class="py-string">'sc'</tt><tt class="py-op">]</tt><tt class="py-op">.</tt><tt id="link-345" class="py-name" targets="Method pyspark.context.SparkContext.stop()=pyspark.context.SparkContext-class.html#stop"><a title="pyspark.context.SparkContext.stop" class="py-name" href="#" onclick="return doclink('link-345', 'stop', 'link-345');">stop</a></tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1738"></a><tt class="py-lineno">1738</tt>  <tt class="py-line">    <tt class="py-keyword">if</tt> <tt class="py-name">failure_count</tt><tt class="py-op">:</tt> </tt>
<a name="L1739"></a><tt class="py-lineno">1739</tt>  <tt class="py-line">        <tt class="py-name">exit</tt><tt class="py-op">(</tt><tt class="py-op">-</tt><tt class="py-number">1</tt><tt class="py-op">)</tt> </tt>
</div><a name="L1740"></a><tt class="py-lineno">1740</tt>  <tt class="py-line"> </tt>
<a name="L1741"></a><tt class="py-lineno">1741</tt>  <tt class="py-line"> </tt>
<a name="L1742"></a><tt class="py-lineno">1742</tt>  <tt class="py-line"><tt class="py-keyword">if</tt> <tt class="py-name">__name__</tt> <tt class="py-op">==</tt> <tt class="py-string">"__main__"</tt><tt class="py-op">:</tt> </tt>
<a name="L1743"></a><tt class="py-lineno">1743</tt>  <tt class="py-line">    <tt class="py-name">_test</tt><tt class="py-op">(</tt><tt class="py-op">)</tt> </tt>
<a name="L1744"></a><tt class="py-lineno">1744</tt>  <tt class="py-line"> </tt><script type="text/javascript">
<!--
expandto(location.href);
// -->
</script>
</pre>
<br />
<!-- ==================== NAVIGATION BAR ==================== -->
<table class="navbar" border="0" width="100%" cellpadding="0"
       bgcolor="#a0c0ff" cellspacing="0">
  <tr valign="middle">
  <!-- Home link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="pyspark-module.html">Home</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Tree link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="module-tree.html">Trees</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Index link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="identifier-index.html">Indices</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Help link -->
      <th>&nbsp;&nbsp;&nbsp;<a
        href="help.html">Help</a>&nbsp;&nbsp;&nbsp;</th>

  <!-- Project homepage -->
      <th class="navbar" align="right" width="100%">
        <table border="0" cellpadding="0" cellspacing="0">
          <tr><th class="navbar" align="center"
            ><a class="navbar" target="_top" href="http://spark.apache.org">Spark 1.1.0 Python API Docs</a></th>
          </tr></table></th>
  </tr>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="100%%">
  <tr>
    <td align="left" class="footer">
    Generated by Epydoc 3.0.1 on Thu Sep 11 01:19:41 2014
    </td>
    <td align="right" class="footer">
      <a target="mainFrame" href="http://epydoc.sourceforge.net"
        >http://epydoc.sourceforge.net</a>
    </td>
  </tr>
</table>

<script type="text/javascript">
  <!--
  // Private objects are initially displayed (because if
  // javascript is turned off then we want them to be
  // visible); but by default, we want to hide them.  So hide
  // them unless we have a cookie that says to show them.
  checkCookie();
  // -->
</script>
</body>
</html>
