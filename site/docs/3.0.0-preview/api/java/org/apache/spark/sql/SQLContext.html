<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_131) on Wed Nov 06 15:46:05 PST 2019 -->
<title>SQLContext (Spark 3.0.0-preview JavaDoc)</title>
<meta name="date" content="2019-11-06">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="SQLContext (Spark 3.0.0-preview JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10,"i32":10,"i33":10,"i34":10,"i35":10,"i36":10,"i37":10,"i38":10,"i39":10,"i40":10,"i41":10,"i42":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SparkSessionExtensions.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql</div>
<h2 title="Class SQLContext" class="title">Class SQLContext</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.sql.SQLContext</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">SQLContext</span>
extends Object
implements <a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a>, scala.Serializable</pre>
<div class="block">The entry point for working with structured data (rows and columns) in Spark 1.x.
 <p>
 As of Spark 2.0, this is replaced by <a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql"><code>SparkSession</code></a>. However, we are keeping the class
 here for backward compatibility.
 <p></div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.0.0</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../serialized-form.html#org.apache.spark.sql.SQLContext">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a></span></code>
<div class="block">(Scala-specific) Implicit methods available in Scala for converting
 common Scala objects into <code>DataFrame</code>s.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#baseRelationToDataFrame-org.apache.spark.sql.sources.BaseRelation-">baseRelationToDataFrame</a></span>(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</code>
<div class="block">Convert a <code>BaseRelation</code> created for external data sources into a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#cacheTable-java.lang.String-">cacheTable</a></span>(String&nbsp;tableName)</code>
<div class="block">Caches the specified table in-memory.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#clearCache--">clearCache</a></span>()</code>
<div class="block">Removes all cached tables from the in-memory cache.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-org.apache.spark.api.java.JavaRDD-java.lang.Class-">createDataFrame</a></span>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
               Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-org.apache.spark.api.java.JavaRDD-org.apache.spark.sql.types.StructType-">createDataFrame</a></span>(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from a <code>JavaRDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-java.util.List-java.lang.Class-">createDataFrame</a></span>(java.util.List&lt;?&gt;&nbsp;data,
               Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to a List of Java Beans.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-java.util.List-org.apache.spark.sql.types.StructType-">createDataFrame</a></span>(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from a <code>java.util.List</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-org.apache.spark.rdd.RDD-java.lang.Class-">createDataFrame</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
               Class&lt;?&gt;&nbsp;beanClass)</code>
<div class="block">Applies a schema to an RDD of Java Beans.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-org.apache.spark.rdd.RDD-scala.reflect.api.TypeTags.TypeTag-">createDataFrame</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</code>
<div class="block">Creates a DataFrame from an RDD of Product (e.g.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-org.apache.spark.rdd.RDD-org.apache.spark.sql.types.StructType-">createDataFrame</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
               <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</code>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>RDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>&lt;A extends scala.Product&gt;<br><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataFrame-scala.collection.Seq-scala.reflect.api.TypeTags.TypeTag-">createDataFrame</a></span>(scala.collection.Seq&lt;A&gt;&nbsp;data,
               scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</code>
<div class="block">Creates a DataFrame from a local Seq of Product.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset-java.util.List-org.apache.spark.sql.Encoder-">createDataset</a></span>(java.util.List&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</code>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from a <code>java.util.List</code> of a given type.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset-org.apache.spark.rdd.RDD-org.apache.spark.sql.Encoder-">createDataset</a></span>(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</code>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from an RDD of a given type.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#createDataset-scala.collection.Seq-org.apache.spark.sql.Encoder-">createDataset</a></span>(scala.collection.Seq&lt;T&gt;&nbsp;data,
             <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</code>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from a local Seq of data of a given type.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#dropTempTable-java.lang.String-">dropTempTable</a></span>(String&nbsp;tableName)</code>
<div class="block">Drops the temporary table with the given table name in the catalog.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#emptyDataFrame--">emptyDataFrame</a></span>()</code>
<div class="block">Returns a <code>DataFrame</code> with no rows or columns.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#experimental--">experimental</a></span>()</code>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>scala.collection.immutable.Map&lt;String,String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#getAllConfs--">getAllConfs</a></span>()</code>
<div class="block">Return all the configuration properties that have been set (i.e.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf-java.lang.String-">getConf</a></span>(String&nbsp;key)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#getConf-java.lang.String-java.lang.String-">getConf</a></span>(String&nbsp;key,
       String&nbsp;defaultValue)</code>
<div class="block">Return the value of Spark SQL configuration property for the given key.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#implicits--">implicits</a></span>()</code>
<div class="block">Accessor for nested Scala object</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#isCached-java.lang.String-">isCached</a></span>(String&nbsp;tableName)</code>
<div class="block">Returns true if the table is currently cached in-memory.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#listenerManager--">listenerManager</a></span>()</code>
<div class="block">An interface to register custom <a href="../../../../org/apache/spark/sql/util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a>s
 that listen for execution metrics.</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#newSession--">newSession</a></span>()</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a> as new session, with separated SQL configurations, temporary
 tables, registered functions, but sharing the same <code>SparkContext</code>, cached data and
 other things.</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#range-long-">range</a></span>(long&nbsp;end)</code>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in a range from 0 to <code>end</code> (exclusive) with step value 1.</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#range-long-long-">range</a></span>(long&nbsp;start,
     long&nbsp;end)</code>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in a range from <code>start</code> to <code>end</code> (exclusive) with step value 1.</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#range-long-long-long-">range</a></span>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step)</code>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in a range from <code>start</code> to <code>end</code> (exclusive) with a step value.</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#range-long-long-long-int-">range</a></span>(long&nbsp;start,
     long&nbsp;end,
     long&nbsp;step,
     int&nbsp;numPartitions)</code>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
 specified.</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#read--">read</a></span>()</code>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><code>DataFrameReader</code></a> that can be used to read non-streaming data in as a
 <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/streaming/DataStreamReader.html" title="class in org.apache.spark.sql.streaming">DataStreamReader</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#readStream--">readStream</a></span>()</code>
<div class="block">Returns a <code>DataStreamReader</code> that can be used to read streaming data in as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf-java.util.Properties-">setConf</a></span>(java.util.Properties&nbsp;props)</code>
<div class="block">Set Spark SQL configuration properties.</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#setConf-java.lang.String-java.lang.String-">setConf</a></span>(String&nbsp;key,
       String&nbsp;value)</code>
<div class="block">Set the given Spark SQL configuration property.</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkContext--">sparkContext</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#sparkSession--">sparkSession</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#sql-java.lang.String-">sql</a></span>(String&nbsp;sqlText)</code>
<div class="block">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/streaming/StreamingQueryManager.html" title="class in org.apache.spark.sql.streaming">StreamingQueryManager</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#streams--">streams</a></span>()</code>
<div class="block">Returns a <code>StreamingQueryManager</code> that allows managing all the
 <a href="../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQueries</code></a> active on <code>this</code> context.</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#table-java.lang.String-">table</a></span>(String&nbsp;tableName)</code>
<div class="block">Returns the specified table as a <code>DataFrame</code>.</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code>String[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#tableNames--">tableNames</a></span>()</code>
<div class="block">Returns the names of tables in the current database as an array.</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>String[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#tableNames-java.lang.String-">tableNames</a></span>(String&nbsp;databaseName)</code>
<div class="block">Returns the names of tables in the given database as an array.</div>
</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#tables--">tables</a></span>()</code>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the current database.</div>
</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#tables-java.lang.String-">tables</a></span>(String&nbsp;databaseName)</code>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the given database.</div>
</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#udf--">udf</a></span>()</code>
<div class="block">A collection of methods for registering user-defined functions (UDF).</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/apache/spark/sql/SQLContext.html#uncacheTable-java.lang.String-">uncacheTable</a></span>(String&nbsp;tableName)</code>
<div class="block">Removes the specified table from the in-memory cache.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.internal.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.internal.<a href="../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></h3>
<code><a href="../../../../org/apache/spark/internal/Logging.html#initializeLogging-boolean-boolean-">initializeLogging</a>, <a href="../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-">initializeLogIfNecessary</a>, <a href="../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-boolean-">initializeLogIfNecessary</a>, <a href="../../../../org/apache/spark/internal/Logging.html#isTraceEnabled--">isTraceEnabled</a>, <a href="../../../../org/apache/spark/internal/Logging.html#log--">log</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-">logDebug</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-java.lang.Throwable-">logDebug</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-">logError</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-java.lang.Throwable-">logError</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-">logInfo</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-java.lang.Throwable-">logInfo</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logName--">logName</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-">logTrace</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-java.lang.Throwable-">logTrace</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-">logWarning</a>, <a href="../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-java.lang.Throwable-">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="implicits--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>implicits</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql">SQLContext.implicits$</a>&nbsp;implicits()</pre>
<div class="block">Accessor for nested Scala object</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="sparkSession--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkSession</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SparkSession.html" title="class in org.apache.spark.sql">SparkSession</a>&nbsp;sparkSession()</pre>
</li>
</ul>
<a name="sparkContext--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sparkContext</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/SparkContext.html" title="class in org.apache.spark">SparkContext</a>&nbsp;sparkContext()</pre>
</li>
</ul>
<a name="newSession--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newSession</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql">SQLContext</a>&nbsp;newSession()</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/SQLContext.html" title="class in org.apache.spark.sql"><code>SQLContext</code></a> as new session, with separated SQL configurations, temporary
 tables, registered functions, but sharing the same <code>SparkContext</code>, cached data and
 other things.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="listenerManager--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>listenerManager</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/util/ExecutionListenerManager.html" title="class in org.apache.spark.sql.util">ExecutionListenerManager</a>&nbsp;listenerManager()</pre>
<div class="block">An interface to register custom <a href="../../../../org/apache/spark/sql/util/QueryExecutionListener.html" title="interface in org.apache.spark.sql.util"><code>QueryExecutionListener</code></a>s
 that listen for execution metrics.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="setConf-java.util.Properties-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(java.util.Properties&nbsp;props)</pre>
<div class="block">Set Spark SQL configuration properties.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>props</code> - (undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.0.0</dd>
</dl>
</li>
</ul>
<a name="setConf-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(String&nbsp;key,
                    String&nbsp;value)</pre>
<div class="block">Set the given Spark SQL configuration property.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>value</code> - (undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.0.0</dd>
</dl>
</li>
</ul>
<a name="getConf-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;String&nbsp;getConf(String&nbsp;key)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.0.0</dd>
</dl>
</li>
</ul>
<a name="getConf-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConf</h4>
<pre>public&nbsp;String&nbsp;getConf(String&nbsp;key,
                      String&nbsp;defaultValue)</pre>
<div class="block">Return the value of Spark SQL configuration property for the given key. If the key is not set
 yet, return <code>defaultValue</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - (undocumented)</dd>
<dd><code>defaultValue</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.0.0</dd>
</dl>
</li>
</ul>
<a name="getAllConfs--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllConfs</h4>
<pre>public&nbsp;scala.collection.immutable.Map&lt;String,String&gt;&nbsp;getAllConfs()</pre>
<div class="block">Return all the configuration properties that have been set (i.e. not the default).
 This creates a new copy of the config properties in the form of a Map.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.0.0</dd>
</dl>
</li>
</ul>
<a name="experimental--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>experimental</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/ExperimentalMethods.html" title="class in org.apache.spark.sql">ExperimentalMethods</a>&nbsp;experimental()</pre>
<div class="block">:: Experimental ::
 A collection of methods that are considered experimental, but can be used to hook into
 the query planner for advanced functionality.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="emptyDataFrame--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>emptyDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;emptyDataFrame()</pre>
<div class="block">Returns a <code>DataFrame</code> with no rows or columns.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="udf--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>udf</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/UDFRegistration.html" title="class in org.apache.spark.sql">UDFRegistration</a>&nbsp;udf()</pre>
<div class="block">A collection of methods for registering user-defined functions (UDF).
 <p>
 The following example registers a Scala closure as UDF:
 <pre><code>
   sqlContext.udf.register("myUDF", (arg1: Int, arg2: String) =&gt; arg2 + arg1)
 </code></pre>
 <p>
 The following example registers a UDF in Java:
 <pre><code>
   sqlContext.udf().register("myUDF",
       (Integer arg1, String arg2) -&gt; arg2 + arg1,
       DataTypes.StringType);
 </code></pre>
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
<dt><span class="simpleTagLabel">Note:</span></dt>
<dd>The user-defined functions must be deterministic. Due to optimization,
 duplicate invocations may be eliminated or the function may even be invoked more times than
 it is present in the query.
 <p></dd>
</dl>
</li>
</ul>
<a name="isCached-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isCached</h4>
<pre>public&nbsp;boolean&nbsp;isCached(String&nbsp;tableName)</pre>
<div class="block">Returns true if the table is currently cached in-memory.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="cacheTable-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cacheTable</h4>
<pre>public&nbsp;void&nbsp;cacheTable(String&nbsp;tableName)</pre>
<div class="block">Caches the specified table in-memory.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="uncacheTable-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>uncacheTable</h4>
<pre>public&nbsp;void&nbsp;uncacheTable(String&nbsp;tableName)</pre>
<div class="block">Removes the specified table from the in-memory cache.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="clearCache--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearCache</h4>
<pre>public&nbsp;void&nbsp;clearCache()</pre>
<div class="block">Removes all cached tables from the in-memory cache.</div>
<dl>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-org.apache.spark.rdd.RDD-scala.reflect.api.TypeTags.TypeTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;A&gt;&nbsp;rdd,
                                                              scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$1)</pre>
<div class="block">Creates a DataFrame from an RDD of Product (e.g. case classes, tuples).
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rdd</code> - (undocumented)</dd>
<dd><code>evidence$1</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-scala.collection.Seq-scala.reflect.api.TypeTags.TypeTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;&lt;A extends scala.Product&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(scala.collection.Seq&lt;A&gt;&nbsp;data,
                                                              scala.reflect.api.TypeTags.TypeTag&lt;A&gt;&nbsp;evidence$2)</pre>
<div class="block">Creates a DataFrame from a local Seq of Product.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - (undocumented)</dd>
<dd><code>evidence$2</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="baseRelationToDataFrame-org.apache.spark.sql.sources.BaseRelation-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>baseRelationToDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;baseRelationToDataFrame(<a href="../../../../org/apache/spark/sql/sources/BaseRelation.html" title="class in org.apache.spark.sql.sources">BaseRelation</a>&nbsp;baseRelation)</pre>
<div class="block">Convert a <code>BaseRelation</code> created for external data sources into a <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>baseRelation</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-org.apache.spark.rdd.RDD-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                                    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from an <code>RDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 Example:
 <pre><code>
  import org.apache.spark.sql._
  import org.apache.spark.sql.types._
  val sqlContext = new org.apache.spark.sql.SQLContext(sc)

  val schema =
    StructType(
      StructField("name", StringType, false) ::
      StructField("age", IntegerType, true) :: Nil)

  val people =
    sc.textFile("examples/src/main/resources/people.txt").map(
      _.split(",")).map(p =&gt; Row(p(0), p(1).trim.toInt))
  val dataFrame = sqlContext.createDataFrame(people, schema)
  dataFrame.printSchema
  // root
  // |-- name: string (nullable = false)
  // |-- age: integer (nullable = true)

  dataFrame.createOrReplaceTempView("people")
  sqlContext.sql("select name from people").collect.foreach(println)
 </code></pre>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rowRDD</code> - (undocumented)</dd>
<dd><code>schema</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataset-scala.collection.Seq-org.apache.spark.sql.Encoder-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(scala.collection.Seq&lt;T&gt;&nbsp;data,
                                    <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$3)</pre>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from a local Seq of data of a given type. This method requires an
 encoder (to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation)
 that is generally created automatically through implicits from a <code>SparkSession</code>, or can be
 created explicitly by calling static methods on <a href="../../../../org/apache/spark/sql/Encoders.html" title="class in org.apache.spark.sql"><code>Encoders</code></a>.
 <p>
 == Example ==
 <p>
 <pre><code>

   import spark.implicits._
   case class Person(name: String, age: Long)
   val data = Seq(Person("Michael", 29), Person("Andy", 30), Person("Justin", 19))
   val ds = spark.createDataset(data)

   ds.show()
   // +-------+---+
   // |   name|age|
   // +-------+---+
   // |Michael| 29|
   // |   Andy| 30|
   // | Justin| 19|
   // +-------+---+
 </code></pre>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - (undocumented)</dd>
<dd><code>evidence$3</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="createDataset-org.apache.spark.rdd.RDD-org.apache.spark.sql.Encoder-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;T&gt;&nbsp;data,
                                    <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$4)</pre>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from an RDD of a given type. This method requires an
 encoder (to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation)
 that is generally created automatically through implicits from a <code>SparkSession</code>, or can be
 created explicitly by calling static methods on <a href="../../../../org/apache/spark/sql/Encoders.html" title="class in org.apache.spark.sql"><code>Encoders</code></a>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - (undocumented)</dd>
<dd><code>evidence$4</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="createDataset-java.util.List-org.apache.spark.sql.Encoder-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataset</h4>
<pre>public&nbsp;&lt;T&gt;&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;T&gt;&nbsp;createDataset(java.util.List&lt;T&gt;&nbsp;data,
                                    <a href="../../../../org/apache/spark/sql/Encoder.html" title="interface in org.apache.spark.sql">Encoder</a>&lt;T&gt;&nbsp;evidence$5)</pre>
<div class="block">Creates a <a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql"><code>Dataset</code></a> from a <code>java.util.List</code> of a given type. This method requires an
 encoder (to convert a JVM object of type <code>T</code> to and from the internal Spark SQL representation)
 that is generally created automatically through implicits from a <code>SparkSession</code>, or can be
 created explicitly by calling static methods on <a href="../../../../org/apache/spark/sql/Encoders.html" title="class in org.apache.spark.sql"><code>Encoders</code></a>.
 <p>
 == Java Example ==
 <p>
 <pre><code>
     List&lt;String&gt; data = Arrays.asList("hello", "world");
     Dataset&lt;String&gt; ds = spark.createDataset(data, Encoders.STRING());
 </code></pre>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - (undocumented)</dd>
<dd><code>evidence$5</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-org.apache.spark.api.java.JavaRDD-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rowRDD,
                                    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from a <code>JavaRDD</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided RDD matches
 the provided schema. Otherwise, there will be runtime exception.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rowRDD</code> - (undocumented)</dd>
<dd><code>schema</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-java.util.List-org.apache.spark.sql.types.StructType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(java.util.List&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;rows,
                                    <a href="../../../../org/apache/spark/sql/types/StructType.html" title="class in org.apache.spark.sql.types">StructType</a>&nbsp;schema)</pre>
<div class="block">:: DeveloperApi ::
 Creates a <code>DataFrame</code> from a <code>java.util.List</code> containing <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a>s using the given schema.
 It is important to make sure that the structure of every <a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql"><code>Row</code></a> of the provided List matches
 the provided schema. Otherwise, there will be runtime exception.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rows</code> - (undocumented)</dd>
<dd><code>schema</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-org.apache.spark.rdd.RDD-java.lang.Class-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;?&gt;&nbsp;rdd,
                                    Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an RDD of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rdd</code> - (undocumented)</dd>
<dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-org.apache.spark.api.java.JavaRDD-java.lang.Class-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(<a href="../../../../org/apache/spark/api/java/JavaRDD.html" title="class in org.apache.spark.api.java">JavaRDD</a>&lt;?&gt;&nbsp;rdd,
                                    Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to an RDD of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>rdd</code> - (undocumented)</dd>
<dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="createDataFrame-java.util.List-java.lang.Class-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createDataFrame</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;createDataFrame(java.util.List&lt;?&gt;&nbsp;data,
                                    Class&lt;?&gt;&nbsp;beanClass)</pre>
<div class="block">Applies a schema to a List of Java Beans.
 <p>
 WARNING: Since there is no guaranteed ordering for fields in a Java Bean,
          SELECT * queries will return the columns in an undefined order.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - (undocumented)</dd>
<dd><code>beanClass</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.6.0</dd>
</dl>
</li>
</ul>
<a name="read--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>read</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql">DataFrameReader</a>&nbsp;read()</pre>
<div class="block">Returns a <a href="../../../../org/apache/spark/sql/DataFrameReader.html" title="class in org.apache.spark.sql"><code>DataFrameReader</code></a> that can be used to read non-streaming data in as a
 <code>DataFrame</code>.
 <pre><code>
   sqlContext.read.parquet("/path/to/file.parquet")
   sqlContext.read.schema(schema).json("/path/to/file.json")
 </code></pre>
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="readStream--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>readStream</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/streaming/DataStreamReader.html" title="class in org.apache.spark.sql.streaming">DataStreamReader</a>&nbsp;readStream()</pre>
<div class="block">Returns a <code>DataStreamReader</code> that can be used to read streaming data in as a <code>DataFrame</code>.
 <pre><code>
   sparkSession.readStream.parquet("/path/to/directory/of/parquet/files")
   sparkSession.readStream.schema(schema).json("/path/to/directory/of/json/files")
 </code></pre>
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="dropTempTable-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dropTempTable</h4>
<pre>public&nbsp;void&nbsp;dropTempTable(String&nbsp;tableName)</pre>
<div class="block">Drops the temporary table with the given table name in the catalog. If the table has been
 cached/persisted before, it's also unpersisted.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>tableName</code> - the name of the table to be unregistered.</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="range-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;range(long&nbsp;end)</pre>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in a range from 0 to <code>end</code> (exclusive) with step value 1.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>end</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.1</dd>
</dl>
</li>
</ul>
<a name="range-long-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;range(long&nbsp;start,
                          long&nbsp;end)</pre>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in a range from <code>start</code> to <code>end</code> (exclusive) with step value 1.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>start</code> - (undocumented)</dd>
<dd><code>end</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="range-long-long-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;range(long&nbsp;start,
                          long&nbsp;end,
                          long&nbsp;step)</pre>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in a range from <code>start</code> to <code>end</code> (exclusive) with a step value.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>start</code> - (undocumented)</dd>
<dd><code>end</code> - (undocumented)</dd>
<dd><code>step</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="range-long-long-long-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>range</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;range(long&nbsp;start,
                          long&nbsp;end,
                          long&nbsp;step,
                          int&nbsp;numPartitions)</pre>
<div class="block">Creates a <code>DataFrame</code> with a single <code>LongType</code> column named <code>id</code>, containing elements
 in an range from <code>start</code> to <code>end</code> (exclusive) with an step value, with partition number
 specified.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>start</code> - (undocumented)</dd>
<dd><code>end</code> - (undocumented)</dd>
<dd><code>step</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.4.0</dd>
</dl>
</li>
</ul>
<a name="sql-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>sql</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;sql(String&nbsp;sqlText)</pre>
<div class="block">Executes a SQL query using Spark, returning the result as a <code>DataFrame</code>. The dialect that is
 used for SQL parsing can be configured with 'spark.sql.dialect'.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>sqlText</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="table-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>table</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;table(String&nbsp;tableName)</pre>
<div class="block">Returns the specified table as a <code>DataFrame</code>.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>tableName</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="tables--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tables</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;tables()</pre>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the current database.
 The returned DataFrame has two columns, tableName and isTemporary (a Boolean
 indicating if a table is a temporary one or not).
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="tables-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tables</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/Dataset.html" title="class in org.apache.spark.sql">Dataset</a>&lt;<a href="../../../../org/apache/spark/sql/Row.html" title="interface in org.apache.spark.sql">Row</a>&gt;&nbsp;tables(String&nbsp;databaseName)</pre>
<div class="block">Returns a <code>DataFrame</code> containing names of existing tables in the given database.
 The returned DataFrame has two columns, tableName and isTemporary (a Boolean
 indicating if a table is a temporary one or not).
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>databaseName</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="streams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>streams</h4>
<pre>public&nbsp;<a href="../../../../org/apache/spark/sql/streaming/StreamingQueryManager.html" title="class in org.apache.spark.sql.streaming">StreamingQueryManager</a>&nbsp;streams()</pre>
<div class="block">Returns a <code>StreamingQueryManager</code> that allows managing all the
 <a href="../../../../org/apache/spark/sql/streaming/StreamingQuery.html" title="interface in org.apache.spark.sql.streaming"><code>StreamingQueries</code></a> active on <code>this</code> context.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>2.0.0</dd>
</dl>
</li>
</ul>
<a name="tableNames--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>tableNames</h4>
<pre>public&nbsp;String[]&nbsp;tableNames()</pre>
<div class="block">Returns the names of tables in the current database as an array.
 <p></div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
<a name="tableNames-java.lang.String-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>tableNames</h4>
<pre>public&nbsp;String[]&nbsp;tableNames(String&nbsp;databaseName)</pre>
<div class="block">Returns the names of tables in the given database as an array.
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>databaseName</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
<dt><span class="simpleTagLabel">Since:</span></dt>
<dd>1.3.0</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/apache/spark/sql/SparkSessionExtensions.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/apache/spark/sql/SQLContext.implicits$.html" title="class in org.apache.spark.sql"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/apache/spark/sql/SQLContext.html" target="_top">Frames</a></li>
<li><a href="SQLContext.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.class.summary">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../lib/api-javadocs.js"></script></body>
</html>
