
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Frequent Pattern Mining - Spark 2.4.1 Documentation</title>
        

        

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 60px;
                padding-bottom: 40px;
            }
        </style>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="css/bootstrap-responsive.min.css">
        <link rel="stylesheet" href="css/main.css">

        <script src="js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="css/pygments-default.css">

        
        <!-- Google analytics script -->
        <script type="text/javascript">
          var _gaq = _gaq || [];
          _gaq.push(['_setAccount', 'UA-32518208-2']);
          _gaq.push(['_trackPageview']);

          (function() {
            var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
          })();
        </script>
        

    </head>
    <body>
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an outdated browser. <a href="https://browsehappy.com/">Upgrade your browser today</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
        <![endif]-->

        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->

        <div class="navbar navbar-fixed-top" id="topbar">
            <div class="navbar-inner">
                <div class="container">
                    <div class="brand"><a href="index.html">
                      <img src="img/spark-logo-hd.png" style="height:50px;"/></a><span class="version">2.4.1</span>
                    </div>
                    <ul class="nav">
                        <!--TODO(andyk): Add class="active" attribute to li some how.-->
                        <li><a href="index.html">Overview</a></li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Programming Guides<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="quick-start.html">Quick Start</a></li>
                                <li><a href="rdd-programming-guide.html">RDDs, Accumulators, Broadcasts Vars</a></li>
                                <li><a href="sql-programming-guide.html">SQL, DataFrames, and Datasets</a></li>
                                <li><a href="structured-streaming-programming-guide.html">Structured Streaming</a></li>
                                <li><a href="streaming-programming-guide.html">Spark Streaming (DStreams)</a></li>
                                <li><a href="ml-guide.html">MLlib (Machine Learning)</a></li>
                                <li><a href="graphx-programming-guide.html">GraphX (Graph Processing)</a></li>
                                <li><a href="sparkr.html">SparkR (R on Spark)</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Docs<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="api/scala/index.html#org.apache.spark.package">Scala</a></li>
                                <li><a href="api/java/index.html">Java</a></li>
                                <li><a href="api/python/index.html">Python</a></li>
                                <li><a href="api/R/index.html">R</a></li>
                                <li><a href="api/sql/index.html">SQL, Built-in Functions</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Deploying<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="cluster-overview.html">Overview</a></li>
                                <li><a href="submitting-applications.html">Submitting Applications</a></li>
                                <li class="divider"></li>
                                <li><a href="spark-standalone.html">Spark Standalone</a></li>
                                <li><a href="running-on-mesos.html">Mesos</a></li>
                                <li><a href="running-on-yarn.html">YARN</a></li>
                                <li><a href="running-on-kubernetes.html">Kubernetes</a></li>
                            </ul>
                        </li>

                        <li class="dropdown">
                            <a href="api.html" class="dropdown-toggle" data-toggle="dropdown">More<b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="configuration.html">Configuration</a></li>
                                <li><a href="monitoring.html">Monitoring</a></li>
                                <li><a href="tuning.html">Tuning Guide</a></li>
                                <li><a href="job-scheduling.html">Job Scheduling</a></li>
                                <li><a href="security.html">Security</a></li>
                                <li><a href="hardware-provisioning.html">Hardware Provisioning</a></li>
                                <li class="divider"></li>
                                <li><a href="building-spark.html">Building Spark</a></li>
                                <li><a href="https://spark.apache.org/contributing.html">Contributing to Spark</a></li>
                                <li><a href="https://spark.apache.org/third-party-projects.html">Third Party Projects</a></li>
                            </ul>
                        </li>
                    </ul>
                    <!--<p class="navbar-text pull-right"><span class="version-text">v2.4.1</span></p>-->
                </div>
            </div>
        </div>

        <div class="container-wrapper">

            
                
                    <div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="ml-guide.html">MLlib: Main Guide</a></h3>
        
<ul>

    <li>
        <a href="ml-statistics.html">
            
                Basic statistics
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-datasource">
            
                Data sources
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-pipeline.html">
            
                Pipelines
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-features.html">
            
                Extracting, transforming and selecting features
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-classification-regression.html">
            
                Classification and Regression
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-clustering.html">
            
                Clustering
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-collaborative-filtering.html">
            
                Collaborative filtering
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-frequent-pattern-mining.html">
            
                <b>Frequent Pattern Mining</b>
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-tuning.html">
            
                Model selection and tuning
            
        </a>
    </li>
    
    

    <li>
        <a href="ml-advanced.html">
            
                Advanced topics
            
        </a>
    </li>
    
    

</ul>

        <h3><a href="mllib-guide.html">MLlib: RDD-based API Guide</a></h3>
        
<ul>

    <li>
        <a href="mllib-data-types.html">
            
                Data types
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-statistics.html">
            
                Basic statistics
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-classification-regression.html">
            
                Classification and regression
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-collaborative-filtering.html">
            
                Collaborative filtering
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-clustering.html">
            
                Clustering
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-dimensionality-reduction.html">
            
                Dimensionality reduction
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-feature-extraction.html">
            
                Feature extraction and transformation
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-frequent-pattern-mining.html">
            
                Frequent pattern mining
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-evaluation-metrics.html">
            
                Evaluation metrics
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-pmml-model-export.html">
            
                PMML model export
            
        </a>
    </li>
    
    

    <li>
        <a href="mllib-optimization.html">
            
                Optimization (developer)
            
        </a>
    </li>
    
    

</ul>

    </div>
</div>
                
                <input id="nav-trigger" class="nav-trigger" checked type="checkbox">
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar" id="content">
                    
                        <h1 class="title">Frequent Pattern Mining</h1>
                    

                    <p>Mining frequent items, itemsets, subsequences, or other substructures is usually among the
first steps to analyze a large-scale dataset, which has been an active research topic in
data mining for years.
We refer users to Wikipedia&#8217;s <a href="http://en.wikipedia.org/wiki/Association_rule_learning">association rule learning</a>
for more information.</p>

<p><strong>Table of Contents</strong></p>

<ul id="markdown-toc">
  <li><a href="#fp-growth" id="markdown-toc-fp-growth">FP-Growth</a></li>
  <li><a href="#prefixspan" id="markdown-toc-prefixspan">PrefixSpan</a></li>
</ul>

<h2 id="fp-growth">FP-Growth</h2>

<p>The FP-growth algorithm is described in the paper
<a href="http://dx.doi.org/10.1145/335191.335372">Han et al., Mining frequent patterns without candidate generation</a>,
where &#8220;FP&#8221; stands for frequent pattern.
Given a dataset of transactions, the first step of FP-growth is to calculate item frequencies and identify frequent items.
Different from <a href="http://en.wikipedia.org/wiki/Apriori_algorithm">Apriori-like</a> algorithms designed for the same purpose,
the second step of FP-growth uses a suffix tree (FP-tree) structure to encode transactions without generating candidate sets
explicitly, which are usually expensive to generate.
After the second step, the frequent itemsets can be extracted from the FP-tree.
In <code>spark.mllib</code>, we implemented a parallel version of FP-growth called PFP,
as described in <a href="http://dx.doi.org/10.1145/1454008.1454027">Li et al., PFP: Parallel FP-growth for query recommendation</a>.
PFP distributes the work of growing FP-trees based on the suffixes of transactions,
and hence is more scalable than a single-machine implementation.
We refer users to the papers for more details.</p>

<p><code>spark.ml</code>&#8217;s FP-growth implementation takes the following (hyper-)parameters:</p>

<ul>
  <li><code>minSupport</code>: the minimum support for an itemset to be identified as frequent.
For example, if an item appears 3 out of 5 transactions, it has a support of 3/5=0.6.</li>
  <li><code>minConfidence</code>: minimum confidence for generating Association Rule. Confidence is an indication of how often an
association rule has been found to be true. For example, if in the transactions itemset <code>X</code> appears 4 times, <code>X</code>
and <code>Y</code> co-occur only 2 times, the confidence for the rule <code>X =&gt; Y</code> is then 2/4 = 0.5. The parameter will not
affect the mining for frequent itemsets, but specify the minimum confidence for generating association rules
from frequent itemsets.</li>
  <li><code>numPartitions</code>: the number of partitions used to distribute the work. By default the param is not set, and
number of partitions of the input dataset is used.</li>
</ul>

<p>The <code>FPGrowthModel</code> provides:</p>

<ul>
  <li><code>freqItemsets</code>: frequent itemsets in the format of DataFrame(&#8220;items&#8221;[Array], &#8220;freq&#8221;[Long])</li>
  <li><code>associationRules</code>: association rules generated with confidence above <code>minConfidence</code>, in the format of 
DataFrame(&#8220;antecedent&#8221;[Array], &#8220;consequent&#8221;[Array], &#8220;confidence&#8221;[Double]).</li>
  <li><code>transform</code>: For each transaction in <code>itemsCol</code>, the <code>transform</code> method will compare its items against the antecedents
of each association rule. If the record contains all the antecedents of a specific association rule, the rule
will be considered as applicable and its consequents will be added to the prediction result. The transform
method will summarize the consequents from all the applicable rules as prediction. The prediction column has
the same data type as <code>itemsCol</code> and does not contain existing items in the <code>itemsCol</code>.</li>
</ul>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">
    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.fpm.FPGrowth">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.fpm.FPGrowth</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataset</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="s">&quot;1 2 5&quot;</span><span class="o">,</span>
  <span class="s">&quot;1 2 3 5&quot;</span><span class="o">,</span>
  <span class="s">&quot;1 2&quot;</span><span class="o">)</span>
<span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">t</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;items&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">fpgrowth</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FPGrowth</span><span class="o">().</span><span class="n">setItemsCol</span><span class="o">(</span><span class="s">&quot;items&quot;</span><span class="o">).</span><span class="n">setMinSupport</span><span class="o">(</span><span class="mf">0.5</span><span class="o">).</span><span class="n">setMinConfidence</span><span class="o">(</span><span class="mf">0.6</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">fpgrowth</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="c1">// Display frequent itemsets.</span>
<span class="n">model</span><span class="o">.</span><span class="n">freqItemsets</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// Display generated association rules.</span>
<span class="n">model</span><span class="o">.</span><span class="n">associationRules</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

<span class="c1">// transform examines the input items against all the association rules and summarize the</span>
<span class="c1">// consequents as prediction</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">
    <p>Refer to the <a href="api/java/org/apache/spark/ml/fpm/FPGrowth.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.fpm.FPGrowth</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.fpm.FPGrowthModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;1 2 5&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;1 2 3 5&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="s">&quot;1 2&quot;</span><span class="o">.</span><span class="na">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span> <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span>
  <span class="s">&quot;items&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">StringType</span><span class="o">,</span> <span class="kc">true</span><span class="o">),</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">itemsDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">FPGrowthModel</span> <span class="n">model</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FPGrowth</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setItemsCol</span><span class="o">(</span><span class="s">&quot;items&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMinSupport</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMinConfidence</span><span class="o">(</span><span class="mf">0.6</span><span class="o">)</span>
  <span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">itemsDF</span><span class="o">);</span>

<span class="c1">// Display frequent itemsets.</span>
<span class="n">model</span><span class="o">.</span><span class="na">freqItemsets</span><span class="o">().</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// Display generated association rules.</span>
<span class="n">model</span><span class="o">.</span><span class="na">associationRules</span><span class="o">().</span><span class="na">show</span><span class="o">();</span>

<span class="c1">// transform examines the input items against all the association rules and summarize the</span>
<span class="c1">// consequents as prediction</span>
<span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">itemsDF</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">
    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.fpm.FPGrowth">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.fpm</span> <span class="kn">import</span> <span class="n">FPGrowth</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;items&quot;</span><span class="p">])</span>

<span class="n">fpGrowth</span> <span class="o">=</span> <span class="n">FPGrowth</span><span class="p">(</span><span class="n">itemsCol</span><span class="o">=</span><span class="s2">&quot;items&quot;</span><span class="p">,</span> <span class="n">minSupport</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">minConfidence</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">fpGrowth</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Display frequent itemsets.</span>
<span class="n">model</span><span class="o">.</span><span class="n">freqItemsets</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Display generated association rules.</span>
<span class="n">model</span><span class="o">.</span><span class="n">associationRules</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># transform examines the input items against all the association rules and summarize the</span>
<span class="c1"># consequents as prediction</span>
<span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/fpgrowth_example.py" in the Spark repo.</small></div>
  </div>

<div data-lang="r">

    <p>Refer to the <a href="api/R/spark.fpGrowth.html">R API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="c1"># Load training data</span>

df <span class="o">&lt;-</span> selectExpr<span class="p">(</span>createDataFrame<span class="p">(</span><span class="kt">data.frame</span><span class="p">(</span>rawItems <span class="o">=</span> <span class="kt">c</span><span class="p">(</span>
  <span class="s">&quot;1,2,5&quot;</span><span class="p">,</span> <span class="s">&quot;1,2,3,5&quot;</span><span class="p">,</span> <span class="s">&quot;1,2&quot;</span>
<span class="p">))),</span> <span class="s">&quot;split(rawItems, &#39;,&#39;) AS items&quot;</span><span class="p">)</span>

fpm <span class="o">&lt;-</span> spark.fpGrowth<span class="p">(</span>df<span class="p">,</span> itemsCol<span class="o">=</span><span class="s">&quot;items&quot;</span><span class="p">,</span> minSupport<span class="o">=</span><span class="m">0.5</span><span class="p">,</span> minConfidence<span class="o">=</span><span class="m">0.6</span><span class="p">)</span>

<span class="c1"># Extracting frequent itemsets</span>

spark.freqItemsets<span class="p">(</span>fpm<span class="p">)</span>

<span class="c1"># Extracting association rules</span>

spark.associationRules<span class="p">(</span>fpm<span class="p">)</span>

<span class="c1"># Predict uses association rules to and combines possible consequents</span>

predict<span class="p">(</span>fpm<span class="p">,</span> df<span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/r/ml/fpm.R" in the Spark repo.</small></div>
  </div>

</div>

<h2 id="prefixspan">PrefixSpan</h2>

<p>PrefixSpan is a sequential pattern mining algorithm described in
<a href="http://dx.doi.org/10.1109%2FTKDE.2004.77">Pei et al., Mining Sequential Patterns by Pattern-Growth: The
PrefixSpan Approach</a>. We refer
the reader to the referenced paper for formalizing the sequential
pattern mining problem.</p>

<p><code>spark.ml</code>&#8217;s PrefixSpan implementation takes the following parameters:</p>

<ul>
  <li><code>minSupport</code>: the minimum support required to be considered a frequent
sequential pattern.</li>
  <li><code>maxPatternLength</code>: the maximum length of a frequent sequential
pattern. Any frequent pattern exceeding this length will not be
included in the results.</li>
  <li><code>maxLocalProjDBSize</code>: the maximum number of items allowed in a
prefix-projected database before local iterative processing of the
projected database begins. This parameter should be tuned with respect
to the size of your executors.</li>
  <li><code>sequenceCol</code>: the name of the sequence column in dataset (default &#8220;sequence&#8221;), rows with
nulls in this column are ignored.</li>
</ul>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">
    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.fpm.PrefixSpan">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.fpm.PrefixSpan</span>

<span class="k">val</span> <span class="n">smallTestData</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="nc">Seq</span><span class="o">(</span><span class="mi">3</span><span class="o">)),</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span> <span class="nc">Seq</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">)),</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="nc">Seq</span><span class="o">(</span><span class="mi">5</span><span class="o">)),</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mi">6</span><span class="o">)))</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">smallTestData</span><span class="o">.</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;sequence&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PrefixSpan</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setMinSupport</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMaxPatternLength</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="o">.</span><span class="n">setMaxLocalProjDBSize</span><span class="o">(</span><span class="mi">32000000</span><span class="o">)</span>
  <span class="o">.</span><span class="n">findFrequentSequentialPatterns</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
  <span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">
    <p>Refer to the <a href="api/java/org/apache/spark/ml/fpm/PrefixSpan.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.fpm.PrefixSpan</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.*</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">3</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">1</span><span class="o">),</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">),</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">5</span><span class="o">))),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">6</span><span class="o">)))</span>
<span class="o">);</span>
<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span> <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span>
  <span class="s">&quot;sequence&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="k">new</span> <span class="n">ArrayType</span><span class="o">(</span><span class="n">DataTypes</span><span class="o">.</span><span class="na">IntegerType</span><span class="o">,</span> <span class="kc">true</span><span class="o">),</span> <span class="kc">true</span><span class="o">),</span>
  <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">sequenceDF</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">PrefixSpan</span> <span class="n">prefixSpan</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PrefixSpan</span><span class="o">().</span><span class="na">setMinSupport</span><span class="o">(</span><span class="mf">0.5</span><span class="o">).</span><span class="na">setMaxPatternLength</span><span class="o">(</span><span class="mi">5</span><span class="o">);</span>

<span class="c1">// Finding frequent sequential patterns</span>
<span class="n">prefixSpan</span><span class="o">.</span><span class="na">findFrequentSequentialPatterns</span><span class="o">(</span><span class="n">sequenceDF</span><span class="o">).</span><span class="na">show</span><span class="o">();</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">
    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.fpm.PrefixSpan">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.fpm</span> <span class="kn">import</span> <span class="n">PrefixSpan</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="n">Row</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]]),</span>
                     <span class="n">Row</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span>
                     <span class="n">Row</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">]]),</span>
                     <span class="n">Row</span><span class="p">(</span><span class="n">sequence</span><span class="o">=</span><span class="p">[[</span><span class="mi">6</span><span class="p">]])])</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>

<span class="n">prefixSpan</span> <span class="o">=</span> <span class="n">PrefixSpan</span><span class="p">(</span><span class="n">minSupport</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">maxPatternLength</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">maxLocalProjDBSize</span><span class="o">=</span><span class="mi">32000000</span><span class="p">)</span>

<span class="c1"># Find frequent sequential patterns.</span>
<span class="n">prefixSpan</span><span class="o">.</span><span class="n">findFrequentSequentialPatterns</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/prefixspan_example.py" in the Spark repo.</small></div>
  </div>

</div>


                </div>
            
             <!-- /container -->
        </div>

        <script src="js/vendor/jquery-1.8.0.min.js"></script>
        <script src="js/vendor/bootstrap.min.js"></script>
        <script src="js/vendor/anchor.min.js"></script>
        <script src="js/main.js"></script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    </body>
</html>
