<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Alternating Least Squares (ALS) for Collaborative Filtering</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for spark.als {SparkR}"><tr><td>spark.als {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Alternating Least Squares (ALS) for Collaborative Filtering</h2>

<h3>Description</h3>

<p><code>spark.als</code> learns latent factors in collaborative filtering via alternating least
squares. Users can call <code>summary</code> to obtain fitted latent factors, <code>predict</code>
to make predictions on new data, and <code>write.ml</code>/<code>read.ml</code> to save/load fitted models.
</p>


<h3>Usage</h3>

<pre>
spark.als(data, ...)

## S4 method for signature 'SparkDataFrame'
spark.als(data, ratingCol = "rating",
  userCol = "user", itemCol = "item", rank = 10, regParam = 0.1,
  maxIter = 10, nonnegative = FALSE, implicitPrefs = FALSE,
  alpha = 1, numUserBlocks = 10, numItemBlocks = 10,
  checkpointInterval = 10, seed = 0)

## S4 method for signature 'ALSModel'
summary(object)

## S4 method for signature 'ALSModel'
predict(object, newData)

## S4 method for signature 'ALSModel,character'
write.ml(object, path, overwrite = FALSE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>data</code></td>
<td>
<p>a SparkDataFrame for training.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>additional argument(s) passed to the method.</p>
</td></tr>
<tr valign="top"><td><code>ratingCol</code></td>
<td>
<p>column name for ratings.</p>
</td></tr>
<tr valign="top"><td><code>userCol</code></td>
<td>
<p>column name for user ids. Ids must be (or can be coerced into) integers.</p>
</td></tr>
<tr valign="top"><td><code>itemCol</code></td>
<td>
<p>column name for item ids. Ids must be (or can be coerced into) integers.</p>
</td></tr>
<tr valign="top"><td><code>rank</code></td>
<td>
<p>rank of the matrix factorization (&gt; 0).</p>
</td></tr>
<tr valign="top"><td><code>regParam</code></td>
<td>
<p>regularization parameter (&gt;= 0).</p>
</td></tr>
<tr valign="top"><td><code>maxIter</code></td>
<td>
<p>maximum number of iterations (&gt;= 0).</p>
</td></tr>
<tr valign="top"><td><code>nonnegative</code></td>
<td>
<p>logical value indicating whether to apply nonnegativity constraints.</p>
</td></tr>
<tr valign="top"><td><code>implicitPrefs</code></td>
<td>
<p>logical value indicating whether to use implicit preference.</p>
</td></tr>
<tr valign="top"><td><code>alpha</code></td>
<td>
<p>alpha parameter in the implicit preference formulation (&gt;= 0).</p>
</td></tr>
<tr valign="top"><td><code>numUserBlocks</code></td>
<td>
<p>number of user blocks used to parallelize computation (&gt; 0).</p>
</td></tr>
<tr valign="top"><td><code>numItemBlocks</code></td>
<td>
<p>number of item blocks used to parallelize computation (&gt; 0).</p>
</td></tr>
<tr valign="top"><td><code>checkpointInterval</code></td>
<td>
<p>number of checkpoint intervals (&gt;= 1) or disable checkpoint (-1).
Note: this setting will be ignored if the checkpoint directory is not
set.</p>
</td></tr>
<tr valign="top"><td><code>seed</code></td>
<td>
<p>integer seed for random number generation.</p>
</td></tr>
<tr valign="top"><td><code>object</code></td>
<td>
<p>a fitted ALS model.</p>
</td></tr>
<tr valign="top"><td><code>newData</code></td>
<td>
<p>a SparkDataFrame for testing.</p>
</td></tr>
<tr valign="top"><td><code>path</code></td>
<td>
<p>the directory where the model is saved.</p>
</td></tr>
<tr valign="top"><td><code>overwrite</code></td>
<td>
<p>logical value indicating whether to overwrite if the output path
already exists. Default is FALSE which means throw exception
if the output path exists.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details, see
<a href="http://spark.apache.org/docs/latest/ml-collaborative-filtering.html">MLlib:
Collaborative Filtering</a>.
</p>


<h3>Value</h3>

<p><code>spark.als</code> returns a fitted ALS model.
</p>
<p><code>summary</code> returns summary information of the fitted model, which is a list.
The list includes <code>user</code> (the names of the user column),
<code>item</code> (the item column), <code>rating</code> (the rating column), <code>userFactors</code>
(the estimated user factors), <code>itemFactors</code> (the estimated item factors),
and <code>rank</code> (rank of the matrix factorization model).
</p>
<p><code>predict</code> returns a SparkDataFrame containing predicted values.
</p>


<h3>Note</h3>

<p>spark.als since 2.1.0
</p>
<p>summary(ALSModel) since 2.1.0
</p>
<p>predict(ALSModel) since 2.1.0
</p>
<p>write.ml(ALSModel, character) since 2.1.0
</p>


<h3>See Also</h3>

<p><a href="read.ml.html">read.ml</a>
</p>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D ratings &lt;- list(list(0, 0, 4.0), list(0, 1, 2.0), list(1, 1, 3.0), list(1, 2, 4.0),
##D                 list(2, 1, 1.0), list(2, 2, 5.0))
##D df &lt;- createDataFrame(ratings, c(&quot;user&quot;, &quot;item&quot;, &quot;rating&quot;))
##D model &lt;- spark.als(df, &quot;rating&quot;, &quot;user&quot;, &quot;item&quot;)
##D 
##D # extract latent factors
##D stats &lt;- summary(model)
##D userFactors &lt;- stats$userFactors
##D itemFactors &lt;- stats$itemFactors
##D 
##D # make predictions
##D predicted &lt;- predict(model, df)
##D showDF(predicted)
##D 
##D # save and load the model
##D path &lt;- &quot;path/to/model&quot;
##D write.ml(model, path)
##D savedModel &lt;- read.ml(path)
##D summary(savedModel)
##D 
##D # set other arguments
##D modelS &lt;- spark.als(df, &quot;rating&quot;, &quot;user&quot;, &quot;item&quot;, rank = 20,
##D                     regParam = 0.1, nonnegative = TRUE)
##D statsS &lt;- summary(modelS)
## End(Not run)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 2.4.1 <a href="00Index.html">Index</a>]</div>
</body></html>
