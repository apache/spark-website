<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_191) on Wed Mar 27 05:01:11 UTC 2019 -->
<title>PairDStreamFunctions (Spark 2.4.1 JavaDoc)</title>
<meta name="date" content="2019-03-27">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="PairDStreamFunctions (Spark 2.4.1 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10,"i32":10,"i33":10,"i34":10,"i35":10,"i36":10,"i37":10,"i38":10,"i39":10,"i40":10,"i41":10,"i42":10,"i43":10,"i44":10,"i45":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/streaming/dstream/MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../../org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/streaming/dstream/PairDStreamFunctions.html" target="_top">Frames</a></li>
<li><a href="PairDStreamFunctions.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.streaming.dstream</div>
<h2 title="Class PairDStreamFunctions" class="title">Class PairDStreamFunctions&lt;K,V&gt;</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li>org.apache.spark.streaming.dstream.PairDStreamFunctions&lt;K,V&gt;</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable</dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">PairDStreamFunctions&lt;K,V&gt;</span>
extends Object
implements scala.Serializable</pre>
<div class="block">Extra functions available on DStream of (key, value) pairs through an implicit conversion.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../../serialized-form.html#org.apache.spark.streaming.dstream.PairDStreamFunctions">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#PairDStreamFunctions-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.math.Ordering-">PairDStreamFunctions</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;self,
                    scala.reflect.ClassTag&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;kt,
                    scala.reflect.ClassTag&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;vt,
                    scala.math.Ordering&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;ord)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">cogroup</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
       scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$13)</code>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">cogroup</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
       int&nbsp;numPartitions,
       scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$14)</code>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">cogroup</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
       scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$15)</code>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>&lt;C&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,C&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#combineByKey-scala.Function1-scala.Function2-scala.Function2-org.apache.spark.Partitioner-boolean-scala.reflect.ClassTag-">combineByKey</a></span>(scala.Function1&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,C&gt;&nbsp;createCombiner,
            scala.Function2&lt;C,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,C&gt;&nbsp;mergeValue,
            scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiner,
            <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
            boolean&nbsp;mapSideCombine,
            scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$1)</code>
<div class="block">Combine elements of each key in DStream's RDDs using custom functions.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#flatMapValues-scala.Function1-scala.reflect.ClassTag-">flatMapValues</a></span>(scala.Function1&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;flatMapValuesFunc,
             scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$12)</code>
<div class="block">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">fullOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$25)</code>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">fullOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
             int&nbsp;numPartitions,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$26)</code>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">fullOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
             <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$27)</code>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey--">groupByKey</a></span>()</code>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey-int-">groupByKey</a></span>(int&nbsp;numPartitions)</code>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey-org.apache.spark.Partitioner-">groupByKey</a></span>(<a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Return a new DStream by applying <code>groupByKey</code> on each RDD.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow-org.apache.spark.streaming.Duration-">groupByKeyAndWindow</a></span>(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</code>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-">groupByKeyAndWindow</a></span>(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                   <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</code>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-int-">groupByKeyAndWindow</a></span>(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                   <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                   int&nbsp;numPartitions)</code>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-org.apache.spark.Partitioner-">groupByKeyAndWindow</a></span>(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                   <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                   <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">join</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$16)</code>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">join</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
    int&nbsp;numPartitions,
    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$17)</code>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">join</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
    <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$18)</code>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">leftOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$19)</code>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">leftOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
             int&nbsp;numPartitions,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$20)</code>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">leftOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
             <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
             scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$21)</code>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>&lt;U&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,U&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapValues-scala.Function1-scala.reflect.ClassTag-">mapValues</a></span>(scala.Function1&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,U&gt;&nbsp;mapValuesFunc,
         scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$11)</code>
<div class="block">Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>&lt;StateType,MappedType&gt;<br><a href="../../../../../org/apache/spark/streaming/dstream/MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream">MapWithStateDStream</a>&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,StateType,MappedType&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapWithState-org.apache.spark.streaming.StateSpec-scala.reflect.ClassTag-scala.reflect.ClassTag-">mapWithState</a></span>(<a href="../../../../../org/apache/spark/streaming/StateSpec.html" title="class in org.apache.spark.streaming">StateSpec</a>&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,StateType,MappedType&gt;&nbsp;spec,
            scala.reflect.ClassTag&lt;StateType&gt;&nbsp;evidence$2,
            scala.reflect.ClassTag&lt;MappedType&gt;&nbsp;evidence$3)</code>
<div class="block">:: Experimental ::
 Return a <a href="../../../../../org/apache/spark/streaming/dstream/MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream"><code>MapWithStateDStream</code></a> by applying a function to every key-value element of
 <code>this</code> stream, while maintaining some state data for each unique key.</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey-scala.Function2-">reduceByKey</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey-scala.Function2-int-">reduceByKey</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
           int&nbsp;numPartitions)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey-scala.Function2-org.apache.spark.Partitioner-">reduceByKey</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
           <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-">reduceByKeyAndWindow</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-">reduceByKeyAndWindow</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-int-">reduceByKeyAndWindow</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                    int&nbsp;numPartitions)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-org.apache.spark.Partitioner-">reduceByKeyAndWindow</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                    <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</code>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow-scala.Function2-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-int-scala.Function1-">reduceByKeyAndWindow</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                    scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                    int&nbsp;numPartitions,
                    scala.Function1&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,Object&gt;&nbsp;filterFunc)</code>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow-scala.Function2-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-org.apache.spark.Partitioner-scala.Function1-">reduceByKeyAndWindow</a></span>(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                    scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                    <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                    <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                    scala.Function1&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,Object&gt;&nbsp;filterFunc)</code>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">rightOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$22)</code>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">rightOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
              int&nbsp;numPartitions,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$23)</code>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code>&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,W&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">rightOuterJoin</a></span>(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
              <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
              scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$24)</code>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream.</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles-java.lang.String-java.lang.String-java.lang.Class-java.lang.Class-java.lang.Class-org.apache.hadoop.mapred.JobConf-">saveAsHadoopFiles</a></span>(String&nbsp;prefix,
                 String&nbsp;suffix,
                 Class&lt;?&gt;&nbsp;keyClass,
                 Class&lt;?&gt;&nbsp;valueClass,
                 Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                 org.apache.hadoop.mapred.JobConf&nbsp;conf)</code>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code>&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;<br>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles-java.lang.String-java.lang.String-scala.reflect.ClassTag-">saveAsHadoopFiles</a></span>(String&nbsp;prefix,
                 String&nbsp;suffix,
                 scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles-java.lang.String-java.lang.String-java.lang.Class-java.lang.Class-java.lang.Class-org.apache.hadoop.conf.Configuration-">saveAsNewAPIHadoopFiles</a></span>(String&nbsp;prefix,
                       String&nbsp;suffix,
                       Class&lt;?&gt;&nbsp;keyClass,
                       Class&lt;?&gt;&nbsp;valueClass,
                       Class&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                       org.apache.hadoop.conf.Configuration&nbsp;conf)</code>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;<br>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles-java.lang.String-java.lang.String-scala.reflect.ClassTag-">saveAsNewAPIHadoopFiles</a></span>(String&nbsp;prefix,
                       String&nbsp;suffix,
                       scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</code>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file.</div>
</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function1-org.apache.spark.Partitioner-boolean-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&gt;&nbsp;updateFunc,
                <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                boolean&nbsp;rememberPartitioner,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$7)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function1-org.apache.spark.Partitioner-boolean-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&gt;&nbsp;updateFunc,
                <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                boolean&nbsp;rememberPartitioner,
                <a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;initialRDD,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$9)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function2-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$4)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function2-int-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                int&nbsp;numPartitions,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$5)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.</div>
</td>
</tr>
<tr id="i43" class="rowColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function2-org.apache.spark.Partitioner-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$6)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</td>
</tr>
<tr id="i44" class="altColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function2-org.apache.spark.Partitioner-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                <a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;initialRDD,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$8)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</td>
</tr>
<tr id="i45" class="rowColor">
<td class="colFirst"><code>&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey-scala.Function4-org.apache.spark.Partitioner-boolean-scala.Option-scala.reflect.ClassTag-">updateStateByKey</a></span>(scala.Function4&lt;<a href="../../../../../org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                boolean&nbsp;rememberPartitioner,
                scala.Option&lt;<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&gt;&nbsp;initialRDD,
                scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$10)</code>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="PairDStreamFunctions-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-scala.reflect.ClassTag-scala.math.Ordering-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>PairDStreamFunctions</h4>
<pre>public&nbsp;PairDStreamFunctions(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;self,
                            scala.reflect.ClassTag&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;kt,
                            scala.reflect.ClassTag&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;vt,
                            scala.math.Ordering&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>&gt;&nbsp;ord)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="cogroup-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                                    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$13)</pre>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with Spark's default number
 of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$13</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="cogroup-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                                    int&nbsp;numPartitions,
                                                                                                                    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$14)</pre>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$14</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="cogroup-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>cogroup</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.collection.Iterable&lt;W&gt;&gt;&gt;&gt;&nbsp;cogroup(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                                    <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                                                                                    scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$15)</pre>
<div class="block">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 The supplied org.apache.spark.Partitioner is used to partition the generated RDDs.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$15</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="combineByKey-scala.Function1-scala.Function2-scala.Function2-org.apache.spark.Partitioner-boolean-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>combineByKey</h4>
<pre>public&nbsp;&lt;C&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,C&gt;&gt;&nbsp;combineByKey(scala.Function1&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,C&gt;&nbsp;createCombiner,
                                                   scala.Function2&lt;C,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,C&gt;&nbsp;mergeValue,
                                                   scala.Function2&lt;C,C,C&gt;&nbsp;mergeCombiner,
                                                   <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                   boolean&nbsp;mapSideCombine,
                                                   scala.reflect.ClassTag&lt;C&gt;&nbsp;evidence$1)</pre>
<div class="block">Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
 combineByKey for RDDs. Please refer to combineByKey in
 org.apache.spark.rdd.PairRDDFunctions in the Spark core documentation for more information.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>createCombiner</code> - (undocumented)</dd>
<dd><code>mergeValue</code> - (undocumented)</dd>
<dd><code>mergeCombiner</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>mapSideCombine</code> - (undocumented)</dd>
<dd><code>evidence$1</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="flatMapValues-scala.Function1-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flatMapValues</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,U&gt;&gt;&nbsp;flatMapValues(scala.Function1&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.collection.TraversableOnce&lt;U&gt;&gt;&nbsp;flatMapValuesFunc,
                                                    scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$12)</pre>
<div class="block">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>flatMapValuesFunc</code> - (undocumented)</dd>
<dd><code>evidence$12</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="fullOuterJoin-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fullOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;fullOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$25)</pre>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$25</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="fullOuterJoin-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fullOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;fullOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                int&nbsp;numPartitions,
                                                                                                scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$26)</pre>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$26</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="fullOuterJoin-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fullOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;fullOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                                <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                                                                scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$27)</pre>
<div class="block">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$27</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKey--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKey</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKey()</pre>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKey-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKey</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKey(int&nbsp;numPartitions)</pre>
<div class="block">Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
 generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKey-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKey</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKey(<a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Return a new DStream by applying <code>groupByKey</code> on each RDD. The supplied
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>partitioner</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKeyAndWindow-org.apache.spark.streaming.Duration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKeyAndWindow(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</pre>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
 <code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
 with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
 Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKeyAndWindow-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKeyAndWindow(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                                                 <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</pre>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
 <code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKeyAndWindow-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKeyAndWindow(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                                                 <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                                                                                 int&nbsp;numPartitions)</pre>
<div class="block">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>numPartitions</code> - number of partitions of each RDD in the new DStream; if not specified
                       then Spark's default number of partitions will be used</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="groupByKeyAndWindow-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>groupByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Iterable&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&gt;&nbsp;groupByKeyAndWindow(<a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                                                 <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                                                                                 <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>partitioner</code> - partitioner for controlling the partitioning of each RDD in the new
                       DStream.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="join-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,W&gt;&gt;&gt;&nbsp;join(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                           scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$16)</pre>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$16</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="join-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,W&gt;&gt;&gt;&nbsp;join(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                           int&nbsp;numPartitions,
                                                           scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$17)</pre>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$17</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="join-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>join</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,W&gt;&gt;&gt;&nbsp;join(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                           <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                           scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$18)</pre>
<div class="block">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
 The supplied org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$18</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="leftOuterJoin-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;leftOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                  scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$19)</pre>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$19</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="leftOuterJoin-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;leftOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                  int&nbsp;numPartitions,
                                                                                  scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$20)</pre>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$20</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="leftOuterJoin-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>leftOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,scala.Option&lt;W&gt;&gt;&gt;&gt;&nbsp;leftOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                  <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                                                  scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$21)</pre>
<div class="block">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$21</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="mapValues-scala.Function1-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapValues</h4>
<pre>public&nbsp;&lt;U&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,U&gt;&gt;&nbsp;mapValues(scala.Function1&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,U&gt;&nbsp;mapValuesFunc,
                                                scala.reflect.ClassTag&lt;U&gt;&nbsp;evidence$11)</pre>
<div class="block">Return a new DStream by applying a map function to the value of each key-value pairs in
 'this' DStream without changing the key.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>mapValuesFunc</code> - (undocumented)</dd>
<dd><code>evidence$11</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="mapWithState-org.apache.spark.streaming.StateSpec-scala.reflect.ClassTag-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mapWithState</h4>
<pre>public&nbsp;&lt;StateType,MappedType&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream">MapWithStateDStream</a>&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,StateType,MappedType&gt;&nbsp;mapWithState(<a href="../../../../../org/apache/spark/streaming/StateSpec.html" title="class in org.apache.spark.streaming">StateSpec</a>&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,StateType,MappedType&gt;&nbsp;spec,
                                                                                         scala.reflect.ClassTag&lt;StateType&gt;&nbsp;evidence$2,
                                                                                         scala.reflect.ClassTag&lt;MappedType&gt;&nbsp;evidence$3)</pre>
<div class="block">:: Experimental ::
 Return a <a href="../../../../../org/apache/spark/streaming/dstream/MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream"><code>MapWithStateDStream</code></a> by applying a function to every key-value element of
 <code>this</code> stream, while maintaining some state data for each unique key. The mapping function
 and other specification (e.g. partitioners, timeouts, initial state data, etc.) of this
 transformation can be specified using <code>StateSpec</code> class. The state data is accessible in
 as a parameter of type <code>State</code> in the mapping function.
 <p>
 Example of using <code>mapWithState</code>:
 <pre><code>
    // A mapping function that maintains an integer state and return a String
    def mappingFunction(key: String, value: Option[Int], state: State[Int]): Option[String] = {
      // Use state.exists(), state.get(), state.update() and state.remove()
      // to manage state, and return the necessary string
    }

    val spec = StateSpec.function(mappingFunction).numPartitions(10)

    val mapWithStateDStream = keyValueDStream.mapWithState[StateType, MappedType](spec)
 </code></pre>
 <p></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>spec</code> - Specification of this transformation</dd>
<dd><code>evidence$2</code> - (undocumented)</dd>
<dd><code>evidence$3</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKey-scala.Function2-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKey</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKey(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the associative and commutative reduce function. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKey-scala.Function2-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKey</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKey(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                              int&nbsp;numPartitions)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
 with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKey-scala.Function2-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKey</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKey(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                              <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
 merged using the supplied reduce function. org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKeyAndWindow(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
 Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
 generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
 the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKeyAndWindow(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
 <code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKeyAndWindow(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                                                       int&nbsp;numPartitions)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
 <code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
 generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>numPartitions</code> - number of partitions of each RDD in the new DStream.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKeyAndWindow-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-org.apache.spark.Partitioner-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKeyAndWindow(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner)</pre>
<div class="block">Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
 <code>DStream.reduceByKey()</code>, but applies it over a sliding window.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>partitioner</code> - partitioner for controlling the partitioning of each RDD
                       in the new DStream.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKeyAndWindow-scala.Function2-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-int-scala.Function1-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKeyAndWindow(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                                       scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                                                       int&nbsp;numPartitions,
                                                       scala.Function1&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,Object&gt;&nbsp;filterFunc)</pre>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
 The reduced value of over a new window is calculated using the old window's reduced value :
  1. reduce the new values that entered the window (e.g., adding new counts)
 <p>
  2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
 <p>
 This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
 However, it is applicable to only "invertible reduce functions".
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>invReduceFunc</code> - inverse reduce function; such that for all y, invertible x:
                      <code>invReduceFunc(reduceFunc(x, y), x) = y</code></dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>filterFunc</code> - Optional function to filter expired key-value pairs;
                       only pairs that satisfy the function are retained</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="reduceByKeyAndWindow-scala.Function2-scala.Function2-org.apache.spark.streaming.Duration-org.apache.spark.streaming.Duration-org.apache.spark.Partitioner-scala.Function1-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reduceByKeyAndWindow</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;reduceByKeyAndWindow(scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;reduceFunc,
                                                       scala.Function2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&nbsp;invReduceFunc,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;windowDuration,
                                                       <a href="../../../../../org/apache/spark/streaming/Duration.html" title="class in org.apache.spark.streaming">Duration</a>&nbsp;slideDuration,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                       scala.Function1&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,Object&gt;&nbsp;filterFunc)</pre>
<div class="block">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
 The reduced value of over a new window is calculated using the old window's reduced value :
  1. reduce the new values that entered the window (e.g., adding new counts)
  2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
 This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
 However, it is applicable to only "invertible reduce functions".</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>reduceFunc</code> - associative and commutative reduce function</dd>
<dd><code>invReduceFunc</code> - inverse reduce function</dd>
<dd><code>windowDuration</code> - width of the window; must be a multiple of this DStream's
                       batching interval</dd>
<dd><code>slideDuration</code> - sliding interval of the window (i.e., the interval after which
                       the new DStream will generate RDDs); must be a multiple of this
                       DStream's batching interval</dd>
<dd><code>partitioner</code> - partitioner for controlling the partitioning of each RDD in the new
                       DStream.</dd>
<dd><code>filterFunc</code> - Optional function to filter expired key-value pairs;
                       only pairs that satisfy the function are retained</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="rightOuterJoin-org.apache.spark.streaming.dstream.DStream-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,W&gt;&gt;&gt;&nbsp;rightOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                   scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$22)</pre>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
 number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>evidence$22</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="rightOuterJoin-org.apache.spark.streaming.dstream.DStream-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,W&gt;&gt;&gt;&nbsp;rightOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                   int&nbsp;numPartitions,
                                                                                   scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$23)</pre>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
 partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>numPartitions</code> - (undocumented)</dd>
<dd><code>evidence$23</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="rightOuterJoin-org.apache.spark.streaming.dstream.DStream-org.apache.spark.Partitioner-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rightOuterJoin</h4>
<pre>public&nbsp;&lt;W&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.Tuple2&lt;scala.Option&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,W&gt;&gt;&gt;&nbsp;rightOuterJoin(<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,W&gt;&gt;&nbsp;other,
                                                                                   <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                                                   scala.reflect.ClassTag&lt;W&gt;&nbsp;evidence$24)</pre>
<div class="block">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
 <code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
 the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>other</code> - (undocumented)</dd>
<dd><code>partitioner</code> - (undocumented)</dd>
<dd><code>evidence$24</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="saveAsHadoopFiles-java.lang.String-java.lang.String-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopFiles</h4>
<pre>public&nbsp;&lt;F extends org.apache.hadoop.mapred.OutputFormat&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;void&nbsp;saveAsHadoopFiles(String&nbsp;prefix,
                                                                                     String&nbsp;suffix,
                                                                                     scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</pre>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
 is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>fm</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="saveAsHadoopFiles-java.lang.String-java.lang.String-java.lang.Class-java.lang.Class-java.lang.Class-org.apache.hadoop.mapred.JobConf-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsHadoopFiles</h4>
<pre>public&nbsp;void&nbsp;saveAsHadoopFiles(String&nbsp;prefix,
                              String&nbsp;suffix,
                              Class&lt;?&gt;&nbsp;keyClass,
                              Class&lt;?&gt;&nbsp;valueClass,
                              Class&lt;? extends org.apache.hadoop.mapred.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                              org.apache.hadoop.mapred.JobConf&nbsp;conf)</pre>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
 is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>keyClass</code> - (undocumented)</dd>
<dd><code>valueClass</code> - (undocumented)</dd>
<dd><code>outputFormatClass</code> - (undocumented)</dd>
<dd><code>conf</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="saveAsNewAPIHadoopFiles-java.lang.String-java.lang.String-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsNewAPIHadoopFiles</h4>
<pre>public&nbsp;&lt;F extends org.apache.hadoop.mapreduce.OutputFormat&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;&gt;&nbsp;void&nbsp;saveAsNewAPIHadoopFiles(String&nbsp;prefix,
                                                                                              String&nbsp;suffix,
                                                                                              scala.reflect.ClassTag&lt;F&gt;&nbsp;fm)</pre>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
 generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>fm</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="saveAsNewAPIHadoopFiles-java.lang.String-java.lang.String-java.lang.Class-java.lang.Class-java.lang.Class-org.apache.hadoop.conf.Configuration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveAsNewAPIHadoopFiles</h4>
<pre>public&nbsp;void&nbsp;saveAsNewAPIHadoopFiles(String&nbsp;prefix,
                                    String&nbsp;suffix,
                                    Class&lt;?&gt;&nbsp;keyClass,
                                    Class&lt;?&gt;&nbsp;valueClass,
                                    Class&lt;? extends org.apache.hadoop.mapreduce.OutputFormat&lt;?,?&gt;&gt;&nbsp;outputFormatClass,
                                    org.apache.hadoop.conf.Configuration&nbsp;conf)</pre>
<div class="block">Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
 generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>prefix</code> - (undocumented)</dd>
<dd><code>suffix</code> - (undocumented)</dd>
<dd><code>keyClass</code> - (undocumented)</dd>
<dd><code>valueClass</code> - (undocumented)</dd>
<dd><code>outputFormatClass</code> - (undocumented)</dd>
<dd><code>conf</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function2-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$4)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>evidence$4</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function2-int-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       int&nbsp;numPartitions,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$5)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>numPartitions</code> - Number of partitions of each RDD in the new DStream.</dd>
<dd><code>evidence$5</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function2-org.apache.spark.Partitioner-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$6)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark"><code>Partitioner</code></a> is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.</dd>
<dd><code>evidence$6</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function1-org.apache.spark.Partitioner-boolean-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&gt;&nbsp;updateFunc,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                       boolean&nbsp;rememberPartitioner,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$7)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark"><code>Partitioner</code></a> is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. Note, that this function may generate a different
                   tuple with a different key than the input key. Therefore keys may be removed
                   or added in this way. It is up to the developer to decide whether to
                   remember the partitioner despite the key being changed.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream</dd>
<dd><code>rememberPartitioner</code> - Whether to remember the partitioner object in the generated RDDs.</dd>
<dd><code>evidence$7</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function2-org.apache.spark.Partitioner-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function2&lt;scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                       <a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;initialRDD,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$8)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.</dd>
<dd><code>initialRDD</code> - initial state value of each key.</dd>
<dd><code>evidence$8</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function1-org.apache.spark.Partitioner-boolean-org.apache.spark.rdd.RDD-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function1&lt;scala.collection.Iterator&lt;scala.Tuple3&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;&gt;&gt;,scala.collection.Iterator&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&gt;&nbsp;updateFunc,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                       boolean&nbsp;rememberPartitioner,
                                                       <a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;initialRDD,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$9)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of each key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. Note, that this function may generate a different
                   tuple with a different key than the input key. Therefore keys may be removed
                   or added in this way. It is up to the developer to decide whether to
                   remember the  partitioner despite the key being changed.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream</dd>
<dd><code>rememberPartitioner</code> - Whether to remember the partitioner object in the generated RDDs.</dd>
<dd><code>initialRDD</code> - initial state value of each key.</dd>
<dd><code>evidence$9</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="updateStateByKey-scala.Function4-org.apache.spark.Partitioner-boolean-scala.Option-scala.reflect.ClassTag-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>updateStateByKey</h4>
<pre>public&nbsp;&lt;S&gt;&nbsp;<a href="../../../../../org/apache/spark/streaming/dstream/DStream.html" title="class in org.apache.spark.streaming.dstream">DStream</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&nbsp;updateStateByKey(scala.Function4&lt;<a href="../../../../../org/apache/spark/streaming/Time.html" title="class in org.apache.spark.streaming">Time</a>,<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">V</a>&gt;,scala.Option&lt;S&gt;,scala.Option&lt;S&gt;&gt;&nbsp;updateFunc,
                                                       <a href="../../../../../org/apache/spark/Partitioner.html" title="class in org.apache.spark">Partitioner</a>&nbsp;partitioner,
                                                       boolean&nbsp;rememberPartitioner,
                                                       scala.Option&lt;<a href="../../../../../org/apache/spark/rdd/RDD.html" title="class in org.apache.spark.rdd">RDD</a>&lt;scala.Tuple2&lt;<a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="type parameter in PairDStreamFunctions">K</a>,S&gt;&gt;&gt;&nbsp;initialRDD,
                                                       scala.reflect.ClassTag&lt;S&gt;&nbsp;evidence$10)</pre>
<div class="block">Return a new "state" DStream where the state for each key is updated by applying
 the given function on the previous state of the key and the new values of the key.
 In every batch the updateFunc will be called for each state even if there are no new values.
 org.apache.spark.Partitioner is used to control the partitioning of each RDD.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>updateFunc</code> - State update function. If <code>this</code> function returns None, then
                   corresponding state key-value pair will be eliminated.</dd>
<dd><code>partitioner</code> - Partitioner for controlling the partitioning of each RDD in the new
                    DStream.</dd>
<dd><code>rememberPartitioner</code> - (undocumented)</dd>
<dd><code>initialRDD</code> - (undocumented)</dd>
<dd><code>evidence$10</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/streaming/dstream/MapWithStateDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../../org/apache/spark/streaming/dstream/ReceiverInputDStream.html" title="class in org.apache.spark.streaming.dstream"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/streaming/dstream/PairDStreamFunctions.html" target="_top">Frames</a></li>
<li><a href="PairDStreamFunctions.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
