<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_191) on Wed Mar 27 05:00:43 UTC 2019 -->
<title>HadoopMapReduceCommitProtocol (Spark 2.4.1 JavaDoc)</title>
<meta name="date" content="2019-03-27">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="HadoopMapReduceCommitProtocol (Spark 2.4.1 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":9,"i5":10,"i6":10,"i7":9,"i8":10,"i9":10};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/internal/io/HadoopMapRedCommitProtocol.html" title="class in org.apache.spark.internal.io"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="class in org.apache.spark.internal.io"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" target="_top">Frames</a></li>
<li><a href="HadoopMapReduceCommitProtocol.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.classes.inherited.from.class.org.apache.spark.internal.io.FileCommitProtocol">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.internal.io</div>
<h2 title="Class HadoopMapReduceCommitProtocol" class="title">Class HadoopMapReduceCommitProtocol</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>Object</li>
<li>
<ul class="inheritance">
<li><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">org.apache.spark.internal.io.FileCommitProtocol</a></li>
<li>
<ul class="inheritance">
<li>org.apache.spark.internal.io.HadoopMapReduceCommitProtocol</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../../../org/apache/spark/internal/io/HadoopMapRedCommitProtocol.html" title="class in org.apache.spark.internal.io">HadoopMapRedCommitProtocol</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">HadoopMapReduceCommitProtocol</span>
extends <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a>
implements scala.Serializable, <a href="../../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></pre>
<div class="block">An <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io"><code>FileCommitProtocol</code></a> implementation backed by an underlying Hadoop OutputCommitter
 (from the newer mapreduce API, not the old mapred API).
 <p>
 Unlike Hadoop's OutputCommitter, this implementation is serializable.
 <p>
 param:  jobId the job's or stage's id
 param:  path the job's output path, or null if committer acts as a noop
 param:  dynamicPartitionOverwrite If true, Spark will overwrite partition directories at runtime
                                  dynamically, i.e., we first write files under a staging
                                  directory with partition path, e.g.
                                  /path/to/staging/a=1/b=1/xxx.parquet. When committing the job,
                                  we first clean up the corresponding partition directories at
                                  destination path, e.g. /path/to/destination/a=1/b=1, and move
                                  files from staging directory to the corresponding partition
                                  directories under destination path.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../../serialized-form.html#org.apache.spark.internal.io.HadoopMapReduceCommitProtocol">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.org.apache.spark.internal.io.FileCommitProtocol">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from class&nbsp;org.apache.spark.internal.io.<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></h3>
<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.EmptyTaskCommitMessage$.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.EmptyTaskCommitMessage$</a>, <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#HadoopMapReduceCommitProtocol-java.lang.String-java.lang.String-boolean-">HadoopMapReduceCommitProtocol</a></span>(String&nbsp;jobId,
                             String&nbsp;path,
                             boolean&nbsp;dynamicPartitionOverwrite)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#abortJob-org.apache.hadoop.mapreduce.JobContext-">abortJob</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</code>
<div class="block">Aborts a job after the writes fail.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#abortTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">abortTask</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>
<div class="block">Aborts a task after the writes have failed.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#commitJob-org.apache.hadoop.mapreduce.JobContext-scala.collection.Seq-">commitJob</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext,
         scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a>&gt;&nbsp;taskCommits)</code>
<div class="block">Commits a job after the writes succeed.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#commitTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">commitTask</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>
<div class="block">Commits a task after the writes succeed.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#deleteWithJob-org.apache.hadoop.fs.FileSystem-org.apache.hadoop.fs.Path-boolean-">deleteWithJob</a></span>(org.apache.hadoop.fs.FileSystem&nbsp;fs,
             org.apache.hadoop.fs.Path&nbsp;path,
             boolean&nbsp;recursive)</code>&nbsp;</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#newTaskTempFile-org.apache.hadoop.mapreduce.TaskAttemptContext-scala.Option-java.lang.String-">newTaskTempFile</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
               scala.Option&lt;String&gt;&nbsp;dir,
               String&nbsp;ext)</code>
<div class="block">Notifies the commit protocol to add a new file, and gets back the full path that should be
 used.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#newTaskTempFileAbsPath-org.apache.hadoop.mapreduce.TaskAttemptContext-java.lang.String-java.lang.String-">newTaskTempFileAbsPath</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                      String&nbsp;absoluteDir,
                      String&nbsp;ext)</code>
<div class="block">Similar to newTaskTempFile(), but allows files to committed to an absolute output location.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#onTaskCommit-org.apache.spark.internal.io.FileCommitProtocol.TaskCommitMessage-">onTaskCommit</a></span>(<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a>&nbsp;taskCommit)</code>&nbsp;</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#setupJob-org.apache.hadoop.mapreduce.JobContext-">setupJob</a></span>(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</code>
<div class="block">Setups up a job.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html#setupTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">setupTask</a></span>(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</code>
<div class="block">Sets up a task within a job.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.internal.io.FileCommitProtocol">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;org.apache.spark.internal.io.<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></h3>
<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#deleteWithJob-org.apache.hadoop.fs.FileSystem-org.apache.hadoop.fs.Path-boolean-">deleteWithJob</a>, <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#instantiate-java.lang.String-java.lang.String-java.lang.String-boolean-">instantiate</a>, <a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#onTaskCommit-org.apache.spark.internal.io.FileCommitProtocol.TaskCommitMessage-">onTaskCommit</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;Object</h3>
<code>equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.internal.Logging">
<!--   -->
</a>
<h3>Methods inherited from interface&nbsp;org.apache.spark.internal.<a href="../../../../../org/apache/spark/internal/Logging.html" title="interface in org.apache.spark.internal">Logging</a></h3>
<code><a href="../../../../../org/apache/spark/internal/Logging.html#initializeLogging-boolean-boolean-">initializeLogging</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-">initializeLogIfNecessary</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#initializeLogIfNecessary-boolean-boolean-">initializeLogIfNecessary</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#isTraceEnabled--">isTraceEnabled</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#log_--">log_</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#log--">log</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-">logDebug</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logDebug-scala.Function0-java.lang.Throwable-">logDebug</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-">logError</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logError-scala.Function0-java.lang.Throwable-">logError</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-">logInfo</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logInfo-scala.Function0-java.lang.Throwable-">logInfo</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logName--">logName</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-">logTrace</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logTrace-scala.Function0-java.lang.Throwable-">logTrace</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-">logWarning</a>, <a href="../../../../../org/apache/spark/internal/Logging.html#logWarning-scala.Function0-java.lang.Throwable-">logWarning</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="HadoopMapReduceCommitProtocol-java.lang.String-java.lang.String-boolean-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>HadoopMapReduceCommitProtocol</h4>
<pre>public&nbsp;HadoopMapReduceCommitProtocol(String&nbsp;jobId,
                                     String&nbsp;path,
                                     boolean&nbsp;dynamicPartitionOverwrite)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="deleteWithJob-org.apache.hadoop.fs.FileSystem-org.apache.hadoop.fs.Path-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deleteWithJob</h4>
<pre>public static&nbsp;boolean&nbsp;deleteWithJob(org.apache.hadoop.fs.FileSystem&nbsp;fs,
                                    org.apache.hadoop.fs.Path&nbsp;path,
                                    boolean&nbsp;recursive)</pre>
</li>
</ul>
<a name="onTaskCommit-org.apache.spark.internal.io.FileCommitProtocol.TaskCommitMessage-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>onTaskCommit</h4>
<pre>public static&nbsp;void&nbsp;onTaskCommit(<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a>&nbsp;taskCommit)</pre>
</li>
</ul>
<a name="newTaskTempFile-org.apache.hadoop.mapreduce.TaskAttemptContext-scala.Option-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newTaskTempFile</h4>
<pre>public&nbsp;String&nbsp;newTaskTempFile(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                              scala.Option&lt;String&gt;&nbsp;dir,
                              String&nbsp;ext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#newTaskTempFile-org.apache.hadoop.mapreduce.TaskAttemptContext-scala.Option-java.lang.String-">FileCommitProtocol</a></code></span></div>
<div class="block">Notifies the commit protocol to add a new file, and gets back the full path that should be
 used. Must be called on the executors when running tasks.
 <p>
 Note that the returned temp file may have an arbitrary path. The commit protocol only
 promises that the file will be at the location specified by the arguments after job commit.
 <p>
 A full file path consists of the following parts:
  1. the base path
  2. some sub-directory within the base path, used to specify partitioning
  3. file prefix, usually some unique job id with the task id
  4. bucket id
  5. source specific file extension, e.g. ".snappy.parquet"
 <p>
 The "dir" parameter specifies 2, and "ext" parameter specifies both 4 and 5, and the rest
 are left to the commit protocol implementation to decide.
 <p>
 Important: it is the caller's responsibility to add uniquely identifying content to "ext"
 if a task is going to write out multiple files to the same dir. The file commit protocol only
 guarantees that files written by different tasks will not conflict.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#newTaskTempFile-org.apache.hadoop.mapreduce.TaskAttemptContext-scala.Option-java.lang.String-">newTaskTempFile</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
<dd><code>dir</code> - (undocumented)</dd>
<dd><code>ext</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="newTaskTempFileAbsPath-org.apache.hadoop.mapreduce.TaskAttemptContext-java.lang.String-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newTaskTempFileAbsPath</h4>
<pre>public&nbsp;String&nbsp;newTaskTempFileAbsPath(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext,
                                     String&nbsp;absoluteDir,
                                     String&nbsp;ext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#newTaskTempFileAbsPath-org.apache.hadoop.mapreduce.TaskAttemptContext-java.lang.String-java.lang.String-">FileCommitProtocol</a></code></span></div>
<div class="block">Similar to newTaskTempFile(), but allows files to committed to an absolute output location.
 Depending on the implementation, there may be weaker guarantees around adding files this way.
 <p>
 Important: it is the caller's responsibility to add uniquely identifying content to "ext"
 if a task is going to write out multiple files to the same dir. The file commit protocol only
 guarantees that files written by different tasks will not conflict.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#newTaskTempFileAbsPath-org.apache.hadoop.mapreduce.TaskAttemptContext-java.lang.String-java.lang.String-">newTaskTempFileAbsPath</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
<dd><code>absoluteDir</code> - (undocumented)</dd>
<dd><code>ext</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="setupJob-org.apache.hadoop.mapreduce.JobContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setupJob</h4>
<pre>public&nbsp;void&nbsp;setupJob(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#setupJob-org.apache.hadoop.mapreduce.JobContext-">FileCommitProtocol</a></code></span></div>
<div class="block">Setups up a job. Must be called on the driver before any other methods can be invoked.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#setupJob-org.apache.hadoop.mapreduce.JobContext-">setupJob</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>jobContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="commitJob-org.apache.hadoop.mapreduce.JobContext-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitJob</h4>
<pre>public&nbsp;void&nbsp;commitJob(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext,
                      scala.collection.Seq&lt;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a>&gt;&nbsp;taskCommits)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#commitJob-org.apache.hadoop.mapreduce.JobContext-scala.collection.Seq-">FileCommitProtocol</a></code></span></div>
<div class="block">Commits a job after the writes succeed. Must be called on the driver.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#commitJob-org.apache.hadoop.mapreduce.JobContext-scala.collection.Seq-">commitJob</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>jobContext</code> - (undocumented)</dd>
<dd><code>taskCommits</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="abortJob-org.apache.hadoop.mapreduce.JobContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>abortJob</h4>
<pre>public&nbsp;void&nbsp;abortJob(org.apache.hadoop.mapreduce.JobContext&nbsp;jobContext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#abortJob-org.apache.hadoop.mapreduce.JobContext-">FileCommitProtocol</a></code></span></div>
<div class="block">Aborts a job after the writes fail. Must be called on the driver.
 <p>
 Calling this function is a best-effort attempt, because it is possible that the driver
 just crashes (or killed) before it can call abort.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#abortJob-org.apache.hadoop.mapreduce.JobContext-">abortJob</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>jobContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="setupTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setupTask</h4>
<pre>public&nbsp;void&nbsp;setupTask(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#setupTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">FileCommitProtocol</a></code></span></div>
<div class="block">Sets up a task within a job.
 Must be called before any other task related methods can be invoked.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#setupTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">setupTask</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
<a name="commitTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commitTask</h4>
<pre>public&nbsp;<a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.TaskCommitMessage.html" title="class in org.apache.spark.internal.io">FileCommitProtocol.TaskCommitMessage</a>&nbsp;commitTask(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#commitTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">FileCommitProtocol</a></code></span></div>
<div class="block">Commits a task after the writes succeed. Must be called on the executors when running tasks.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#commitTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">commitTask</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>(undocumented)</dd>
</dl>
</li>
</ul>
<a name="abortTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>abortTask</h4>
<pre>public&nbsp;void&nbsp;abortTask(org.apache.hadoop.mapreduce.TaskAttemptContext&nbsp;taskContext)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from class:&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#abortTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">FileCommitProtocol</a></code></span></div>
<div class="block">Aborts a task after the writes have failed. Must be called on the executors when running tasks.
 <p>
 Calling this function is a best-effort attempt, because it is possible that the executor
 just crashes (or killed) before it can call abort.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html#abortTask-org.apache.hadoop.mapreduce.TaskAttemptContext-">abortTask</a></code>&nbsp;in class&nbsp;<code><a href="../../../../../org/apache/spark/internal/io/FileCommitProtocol.html" title="class in org.apache.spark.internal.io">FileCommitProtocol</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>taskContext</code> - (undocumented)</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-all.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../org/apache/spark/internal/io/HadoopMapRedCommitProtocol.html" title="class in org.apache.spark.internal.io"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../../org/apache/spark/internal/io/HadoopWriteConfigUtil.html" title="class in org.apache.spark.internal.io"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.html" target="_top">Frames</a></li>
<li><a href="HadoopMapReduceCommitProtocol.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.classes.inherited.from.class.org.apache.spark.internal.io.FileCommitProtocol">Nested</a>&nbsp;|&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li>Field&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../lib/api-javadocs.js"></script></body>
</html>
