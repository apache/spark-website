<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
     Spark Release 1.2.0 | Apache Spark
    
  </title>

  

  

  <!-- Bootstrap core CSS -->
  <link href="/css/cerulean.min.css" rel="stylesheet">
  <link href="/css/custom.css" rel="stylesheet">

  <!-- Code highlighter CSS -->
  <link href="/css/pygments-default.css" rel="stylesheet">

  <script type="text/javascript">
  <!-- Google Analytics initialization -->
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-32518208-2']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

  <!-- Adds slight delay to links to allow async reporting -->
  function trackOutboundLink(link, category, action) {
    try {
      _gaq.push(['_trackEvent', category , action]);
    } catch(err){}

    setTimeout(function() {
      document.location.href = link.href;
    }, 100);
  }
  </script>

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
  <![endif]-->
</head>

<body>

<script src="https://code.jquery.com/jquery.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script>
<script src="/js/lang-tabs.js"></script>
<script src="/js/downloads.js"></script>

<div class="container" style="max-width: 1200px;">

<div class="masthead">
  
    <p class="lead">
      <a href="/">
      <img src="/images/spark-logo-trademark.png"
        style="height:100px; width:auto; vertical-align: bottom; margin-top: 20px;"></a><span class="tagline">
          Lightning-fast unified analytics engine
      </span>
    </p>
  
</div>

<nav class="navbar navbar-default" role="navigation">
  <!-- Brand and toggle get grouped for better mobile display -->
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse"
            data-target="#navbar-collapse-1">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
  </div>

  <!-- Collect the nav links, forms, and other content for toggling -->
  <div class="collapse navbar-collapse" id="navbar-collapse-1">
    <ul class="nav navbar-nav">
      <li><a href="/downloads.html">Download</a></li>
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">
          Libraries <b class="caret"></b>
        </a>
        <ul class="dropdown-menu">
          <li><a href="/sql/">SQL and DataFrames</a></li>
          <li><a href="/streaming/">Spark Streaming</a></li>
          <li><a href="/mllib/">MLlib (machine learning)</a></li>
          <li><a href="/graphx/">GraphX (graph)</a></li>
          <li class="divider"></li>
          <li><a href="/third-party-projects.html">Third-Party Projects</a></li>
        </ul>
      </li>
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">
          Documentation <b class="caret"></b>
        </a>
        <ul class="dropdown-menu">
          <li><a href="/docs/latest/">Latest Release (Spark 2.3.1)</a></li>
          <li><a href="/documentation.html">Older Versions and Other Resources</a></li>
          <li><a href="/faq.html">Frequently Asked Questions</a></li>
        </ul>
      </li>
      <li><a href="/examples.html">Examples</a></li>
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">
          Community <b class="caret"></b>
        </a>
        <ul class="dropdown-menu">
          <li><a href="/community.html">Mailing Lists &amp; Resources</a></li>
          <li><a href="/contributing.html">Contributing to Spark</a></li>
          <li><a href="/improvement-proposals.html">Improvement Proposals (SPIP)</a></li>
          <li><a href="https://issues.apache.org/jira/browse/SPARK">Issue Tracker</a></li>
          <li><a href="/powered-by.html">Powered By</a></li>
          <li><a href="/committers.html">Project Committers</a></li>
          <li><a href="/history.html">Project History</a></li>
        </ul>
      </li>
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">
           Developers <b class="caret"></b>
        </a>
        <ul class="dropdown-menu">
          <li><a href="/developer-tools.html">Useful Developer Tools</a></li>
          <li><a href="/versioning-policy.html">Versioning Policy</a></li>
          <li><a href="/release-process.html">Release Process</a></li>
          <li><a href="/security.html">Security</a></li>
        </ul>
      </li>
    </ul>
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="https://www.apache.org/" class="dropdown-toggle" data-toggle="dropdown">
          Apache Software Foundation <b class="caret"></b></a>
        <ul class="dropdown-menu">
          <li><a href="https://www.apache.org/">Apache Homepage</a></li>
          <li><a href="https://www.apache.org/licenses/">License</a></li>
          <li><a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
          <li><a href="https://www.apache.org/foundation/thanks.html">Thanks</a></li>
          <li><a href="https://www.apache.org/security/">Security</a></li>
        </ul>
      </li>
    </ul>
  </div>
  <!-- /.navbar-collapse -->
</nav>


<div class="row">
  <div class="col-md-3 col-md-push-9">
    <div class="news" style="margin-bottom: 20px;">
      <h5>Latest News</h5>
      <ul class="list-unstyled">
        
          <li><a href="/news/spark-2-1-3-released.html">Spark 2.1.3 released</a>
          <span class="small">(Jun 29, 2018)</span></li>
        
          <li><a href="/news/spark-2-3-1-released.html">Spark 2.3.1 released</a>
          <span class="small">(Jun 08, 2018)</span></li>
        
          <li><a href="/news/spark-summit-june-2018-agenda-posted.html">Spark+AI Summit (June 4-6th, 2018, San Francisco) agenda posted</a>
          <span class="small">(Mar 01, 2018)</span></li>
        
          <li><a href="/news/spark-2-3-0-released.html">Spark 2.3.0 released</a>
          <span class="small">(Feb 28, 2018)</span></li>
        
      </ul>
      <p class="small" style="text-align: right;"><a href="/news/index.html">Archive</a></p>
    </div>
    <div style="text-align:center; margin-bottom: 20px;">
      <a href="https://www.apache.org/events/current-event.html">
        <img src="https://www.apache.org/events/current-event-234x60.png"/>
      </a>
    </div>
    <div class="hidden-xs hidden-sm">
      <a href="/downloads.html" class="btn btn-success btn-lg btn-block" style="margin-bottom: 30px;">
        Download Spark
      </a>
      <p style="font-size: 16px; font-weight: 500; color: #555;">
        Built-in Libraries:
      </p>
      <ul class="list-none">
        <li><a href="/sql/">SQL and DataFrames</a></li>
        <li><a href="/streaming/">Spark Streaming</a></li>
        <li><a href="/mllib/">MLlib (machine learning)</a></li>
        <li><a href="/graphx/">GraphX (graph)</a></li>
      </ul>
      <a href="/third-party-projects.html">Third-Party Projects</a>
    </div>
  </div>

  <div class="col-md-9 col-md-pull-3">
    <h2>Spark Release 1.2.0</h2>


<p>Spark 1.2.0 is the third release on the 1.X line. This release brings performance and usability improvements in Spark’s core engine, a major new API for MLlib, expanded ML support in Python, a fully H/A mode in Spark Streaming, and much more. GraphX has seen major performance and API improvements and graduates from an alpha component. Spark 1.2 represents the work of 172 contributors from more than 60 institutions in more than 1000 individual patches.</p>

<p>To download Spark 1.2 visit the <a href="/downloads.html">downloads</a> page.</p>

<h3 id="spark-core">Spark Core</h3>
<p>In 1.2 Spark core upgrades two major subsystems to improve the performance and stability of very large scale shuffles. The first is Spark’s communication manager used during bulk transfers, which upgrades to a <a href="https://issues.apache.org/jira/browse/SPARK-2468">netty-based implementation</a>. The second is Spark’s shuffle mechanism, which upgrades to the <a href="https://issues.apache.org/jira/browse/SPARK-3280">“sort based” shuffle initially released in Spark 1.1</a>. These both improve the performance and stability of very large scale shuffles. Spark also adds an <a href="https://issues.apache.org/jira/browse/SPARK-3174">elastic scaling mechanism</a> designed to improve cluster utilization during long running ETL-style jobs. This is currently supported on YARN and will make its way to other cluster managers in future versions. Finally, Spark 1.2 adds support for Scala 2.11. For instructions on building for Scala 2.11 see the <a href="/docs/1.2.0/building-spark.html#building-for-scala-211">build documentation</a>.</p>

<h3 id="spark-streaming">Spark Streaming</h3>
<p>This release includes two major feature additions to Spark’s streaming library, a Python API and a write ahead log for full driver H/A. The <a href="https://issues.apache.org/jira/browse/SPARK-2377">Python API</a> covers almost all the DStream transformations and output operations. Input sources based on text files and text over sockets are currently supported. Support for Kafka and Flume input streams in Python will be added in the next release. Second, Spark streaming now features H/A driver support through a <a href="https://issues.apache.org/jira/browse/SPARK-3129">write ahead log (WAL)</a>. In Spark 1.1 and earlier, some buffered (received but not yet processed) data can be lost during driver restarts. To prevent this Spark 1.2 adds an optional WAL, which buffers received data into a fault-tolerant file system (e.g. HDFS). See the <a href="/docs/1.2.0/streaming-programming-guide.html">streaming programming guide</a> for more details.</p>

<h3 id="mllib">MLLib</h3>
<p>Spark 1.2 previews a new set of machine learning API’s in a package called spark.ml that <a href="https://issues.apache.org/jira/browse/SPARK-3530">supports learning pipelines</a>, where multiple algorithms are run in sequence with varying parameters. This type of pipeline is common in practical machine learning deployments. The new ML package uses Spark’s SchemaRDD to represent <a href="https://issues.apache.org/jira/browse/SPARK-3573">ML datasets</a>, providing direct interoperability with Spark SQL. In addition to the new API, Spark 1.2 extends decision trees with two tree ensemble methods: <a href="https://issues.apache.org/jira/browse/SPARK-1545">random forests</a> and <a href="https://issues.apache.org/jira/browse/SPARK-1547">gradient-boosted trees</a>, among the most successful tree-based models for classification and regression. Finally, MLlib&#8217;s Python implementation receives a major update in 1.2 to simplify the process of adding Python APIs, along with better Python API coverage.</p>

<h3 id="spark-sql">Spark SQL</h3>
<p>In this release Spark SQL adds a <a href="https://issues.apache.org/jira/browse/SPARK-3247">new API for external data sources</a>. This API supports mounting external data sources as temporary tables, with support for optimizations such as predicate pushdown. Spark’s <a href="https://issues.apache.org/jira/browse/SPARK-4413">Parquet</a> and JSON bindings have been re-written to use this API and we expect a variety of community projects to integrate with other systems and formats during the 1.2 lifecycle.</p>

<p>Hive integration has been improved with support for the <a href="https://issues.apache.org/jira/browse/SPARK-3929">fixed-precision decimal type</a> and <a href="https://issues.apache.org/jira/browse/SPARK-2706">Hive 0.13</a>. Spark SQL also adds <a href="https://issues.apache.org/jira/browse/SPARK-3007">dynamically partitioned inserts</a>, a popular Hive feature. An internal re-architecting around caching improves the performance and semantics of <a href="https://issues.apache.org/jira/browse/SPARK-3212">caching SchemaRDD</a> instances and adds support for <a href="https://issues.apache.org/jira/browse/SPARK-2961">statistics-based partition pruning</a> for cached data.</p>

<h3 id="graphx">GraphX</h3>
<p>In 1.2 GraphX graduates from an alpha component and adds a stable API. This means applications written against GraphX are guaranteed to work with future Spark versions without code changes. A new core API, aggregateMessages, is introduced to replace the now deprecated mapReduceTriplet API. The new aggregateMessages API features a more imperative programming model and improves performance. Some early test users found 20% - 1X performance improvement by switching to the new API.</p>

<p>In addition, Spark now supports <a href="https://issues.apache.org/jira/browse/SPARK-3623">graph checkpointing</a> and <a href="https://issues.apache.org/jira/browse/SPARK-4672">lineage truncation</a> which are necessary to support large numbers of iterations in production jobs. Finally, a handful of performance improvements have been added for <a href="https://issues.apache.org/jira/browse/SPARK-3427">PageRank</a> and <a href="https://issues.apache.org/jira/browse/SPARK-4646">graph loading</a>.</p>

<h3 id="other-notes">Other Notes</h3>
<ul>
  <li>PySpark’s sort operator now supports external spilling for large datasets.</li>
  <li>PySpark now supports broadcast variables <a href="https://issues.apache.org/jira/browse/SPARK-3721">larger than 2GB</a> and performs <a href="https://issues.apache.org/jira/browse/SPARK-3073">external spilling during sorts</a>.</li>
  <li>Spark adds a <a href="https://issues.apache.org/jira/browse/SPARK-4145">job-level progress page in the Spark UI</a>, a <a href="https://issues.apache.org/jira/browse/SPARK-2321">stable API for progress reporting</a>, and <a href="https://issues.apache.org/jira/browse/SPARK-3179">dynamic updating of output metrics</a> as jobs complete.</li>
  <li>Spark now has support for <a href="https://issues.apache.org/jira/browse/SPARK-2759">reading binary files</a> for images and other binary formats.</li>
</ul>

<h3 id="upgrading-to-spark-12">Upgrading to Spark 1.2</h3>

<p>Spark 1.2 is binary compatible with Spark 1.0 and 1.1, so no code changes are necessary. This excludes APIs marked explicitly as unstable. Spark changes default configuration in a handful of cases for improved performance. Users who want to preserve identical configurations to Spark 1.1 can roll back these changes.</p>

<ol>
  <li><code>spark.shuffle.blockTransferService</code> has been changed from <code>nio</code> to <code>netty</code></li>
  <li><code>spark.shuffle.manager</code> has been changed from <code>hash</code> to <code>sort</code></li>
  <li>In PySpark, the default batch size has been changed to 0, which means the batch size is chosen based on the size of object.  Pre-1.2 behavior can be restored using <code>SparkContext([... args... ], batchSize=1024)</code>.</li>
  <li>Spark SQL has changed the following defaults:
    <ul>
      <li><code>spark.sql.parquet.cacheMetadata</code>: <code>false</code> -&gt; <code>true</code></li>
      <li><code>spark.sql.parquet.compression.codec</code>: <code>snappy</code> -&gt; <code>gzip</code></li>
      <li><code>spark.sql.hive.convertMetastoreParquet</code>: <code>false</code> -&gt; <code>true</code></li>
      <li><code>spark.sql.inMemoryColumnarStorage.compressed</code>: <code>false</code> -&gt; <code>true</code></li>
      <li><code>spark.sql.inMemoryColumnarStorage.batchSize</code>: <code>1000</code> -&gt; <code>10000</code></li>
      <li><code>spark.sql.autoBroadcastJoinThreshold</code>: <code>10000</code> -&gt; <code>10485760</code> (10 MB)</li>
    </ul>
  </li>
</ol>

<h4 id="known-issues">Known Issues</h4>
<p>A few smaller bugs did not make the release window. They will be fixed in Spark 1.2.1:</p>

<ul>
  <li>Netty shuffle does not respect secured port configuration. Work around - revert to nio shuffle: <a href="https://issues.apache.org/jira/browse/SPARK-4837">SPARK-4837</a></li>
  <li>java.io.FileNotFound exceptions when creating EXTERNAL hive tables. Work around - set hive.stats.autogather = false. <a href="https://issues.apache.org/jira/browse/SPARK-4892">SPARK-4892</a>.</li>
  <li>Exception PySpark zip function on textfile inputs: <a href="https://issues.apache.org/jira/browse/SPARK-4841">SPARK-4841</a></li>
  <li>MetricsServlet not properly initialized: <a href="https://issues.apache.org/jira/browse/SPARK-4841">SPARK-4595</a></li>
</ul>

<h3 id="credits">Credits</h3>
<ul>
  <li>Aaron Davidson &#8211; Improvements in Core; bug fixes in Core and Shuffle; improvement in Core and Shuffle</li>
  <li>Aaron Staple &#8211; Improvements in Core, MLlib, and Streaming; new features in PySpark; bug fixes in SQL</li>
  <li>Adam Pingel &#8211; Improvement in Core</li>
  <li>Ahir Reddy &#8211; Improvements in Core</li>
  <li>Akshat Aranya &#8211; Bug fixes in Core</li>
  <li>Alex Liu &#8211; Bug fixes in SQL</li>
  <li>Alexander Ulanov &#8211; New features in MLlib</li>
  <li>Allan Douglas R. De Oliveira &#8211; Improvements in Core</li>
  <li>Anand Avati &#8211; Improvement in Core</li>
  <li>Anant Asthana &#8211; Improvement in Core, MLlib, and SQL</li>
  <li>Andrew Ash &#8211; Documentation and bug fixes in Core</li>
  <li>Andrew Bullen &#8211; Bug fixes in MLlib</li>
  <li>Andrew Or &#8211; Improvements in Core and YARN; bug fixes in Windows, Core, and YARN; improvement in Core and YARN</li>
  <li>Andy Konwinski &#8211; Documentation in Core</li>
  <li>Aniket Bhatnagar &#8211; Bug fixes in Core and Streaming</li>
  <li>Ankur Dave &#8211; Improvements and bug fixes in GraphX</li>
  <li>Arun Ahuja &#8211; Documentation in Core</li>
  <li>Benoy Antony &#8211; Bug fixes in Web UI and YARN</li>
  <li>Bertrand Bossy &#8211; Bug fixes in Core</li>
  <li>Bill Bejeck &#8211; Bug fixes in Core</li>
  <li>Brenden Matthews &#8211; Bug fixes in Mesos</li>
  <li>Burak Yavuz &#8211; New features in MLlib</li>
  <li>Chao Chen &#8211; Improvements and documentation in Core</li>
  <li>Cheng Hao &#8211; Test, improvements, new features, bug fixes, and improvement in SQL</li>
  <li>Cheng Lian &#8211; Improvements in Core and SQL; test in SQL; new features in SQL; bug fixes in Core and SQL; documentation in Core</li>
  <li>Chester Chen &#8211; Bug fixes in YARN</li>
  <li>Chip Senkbeil &#8211; New features in Core</li>
  <li>Chirag Aggarwal &#8211; Bug fixes in SQL</li>
  <li>Chris Cope &#8211; Bug fixes in YARN</li>
  <li>Christoph Sawade &#8211; Improvements in MLlib and PySpark</li>
  <li>Cody Koeninger &#8211; Improvements in SQL</li>
  <li>Colin Patrick Mccabe &#8211; Improvements in Core</li>
  <li>DB Tsai &#8211; Improvements and improvement in MLlib</li>
  <li>Dale Richardson &#8211; Improvements in Core</li>
  <li>Dan McClary &#8211; New features in SQL</li>
  <li>Dan Osipov &#8211; New features in EC2</li>
  <li>Daoyuan Wang &#8211; Improvements in Core and SQL; new features in SQL; bug fixes in Core and SQL; documentation in Core</li>
  <li>Davies Liu &#8211; Improvements in Core, SQL, MLlib, and PySpark; new features in Core, Streaming, PySpark, and MLlib, and PySpark; bug fixes in Streaming, Core, SQL, MLlib, and PySpark; documentation in Core</li>
  <li>Derek Ma &#8211; Bug fixes in Core and Streaming</li>
  <li>DoingDone9 &#8211; Bug fixes in SQL</li>
  <li>Egor Pahomov &#8211; Bug fixes in Core</li>
  <li>Eric Eijkelenboom &#8211; Bug fixes in Core</li>
  <li>Eric Liang &#8211; Bug fixes in Core and SQL</li>
  <li>Erik Erlandson &#8211; Improvements and improvement in Core</li>
  <li>Eugen Cepoi &#8211; Improvements in Core</li>
  <li>Fairiz Azizi &#8211; Improvements in Core</li>
  <li>Felix Maximilian Moller &#8211; Documentation in Core</li>
  <li>Gankun Luo &#8211; Bug fixes in SQL</li>
  <li>Grega Kespret &#8211; Documentation in Core</li>
  <li>GuoQiang Li &#8211; Improvements in Core and MLlib; bug fixes in Core, Web UI, MLlib, and PySpark; improvement in YARN</li>
  <li>Hari Shreedharan &#8211; Bug fixes and improvement in Streaming</li>
  <li>Henry Cook &#8211; Documentation in Core</li>
  <li>Holden Karau &#8211; Documentation in Core; bug fixes in PySpark</li>
  <li>Hong Shen &#8211; Improvements in Core</li>
  <li>Hossein Falaki &#8211; Bug fixes in Web UI</li>
  <li>Ian Hummel &#8211; Improvements in Core</li>
  <li>Jacky Li &#8211; Bug fixes in Core</li>
  <li>Jakub Dubovsky &#8211; Bug fixes in Core</li>
  <li>Jascha Swisher &#8211; Bug fixes in Core</li>
  <li>Jay Vyas &#8211; Documentation in Core</li>
  <li>Jeremy Freeman &#8211; New features in Streaming and MLlib; bug fixes in Core and PySpark</li>
  <li>Jey Kottalam &#8211; Bug fixes in Core</li>
  <li>Jie Huang &#8211; Documentation and bug fixes in Core</li>
  <li>Jim Carroll &#8211; Improvements and bug fixes in SQL</li>
  <li>Jim Lim &#8211; Improvements in Core; bug fixes in YARN</li>
  <li>Jongyoul Lee &#8211; Bug fixes in Core and Mesos</li>
  <li>Joseph Bradley &#8211; Improvements in MLlib</li>
  <li>Joseph E. Gonzalez &#8211; Documentation in Core; bug fixes in GraphX and MLlib</li>
  <li>Joseph K. Bradley &#8211; Improvements in Core and MLlib; new features in MLlib and SQL; bug fixes in MLlib; documentation in Core and MLlib</li>
  <li>Josh Rosen &#8211; Improvements in Java API, Core, Web UI, and Shuffle; new features in Java API, Core, and Web UI; bug fixes in Core, PySpark, and Streaming; documentation in Core</li>
  <li>Kai Sasaki &#8211; Bug fixes in Core</li>
  <li>Kay Ousterhout &#8211; Improvements in Core and Web UI; bug fixes in Core and Web UI</li>
  <li>Ken Takagiwa &#8211; Documentation in Core</li>
  <li>Kenichi Maehashi &#8211; Improvements in Core</li>
  <li>Kevin Mader &#8211; Improvements in Java API and Core</li>
  <li>Kousuke Saruta &#8211; Improvements in Project Infra, Core, PySpark, YARN, SQL, and Web UI; bug fixes in Core, PySpark, MLlib, YARN, SQL, and Web UI; documentation in Core</li>
  <li>Larry Xiao &#8211; Improvements and bug fixes in GraphX</li>
  <li>Li Zhihui &#8211; Improvements in Core</li>
  <li>Liang-Chi Hsieh &#8211; Improvements in Core; bug fixes in Core and SQL</li>
  <li>Lianhui Wang &#8211; Bug fixes in GraphX</li>
  <li>Lijie Xu &#8211; Bug fixes in Core and GraphX</li>
  <li>Liquan Pei &#8211; Documentation in Core; new features in MLlib and PySpark</li>
  <li>Liu Hao &#8211; Bug fixes in Core</li>
  <li>Lu Lu &#8211; Improvements in GraphX</li>
  <li>Madhu Siddalingaiah &#8211; Documentation in Core</li>
  <li>Manish Amde &#8211; Improvements and new features in MLlib</li>
  <li>Marcelo Vanzin &#8211; Test in YARN; improvement in Core and YARN; new features in Core; bug fixes in Core and YARN; improvements in Core</li>
  <li>Mario Pastorelli &#8211; Documentation in Core</li>
  <li>Mark G. Whitney &#8211; Documentation in YARN</li>
  <li>Mark Hamstra &#8211; Bug fixes in Core</li>
  <li>Mark Mims &#8211; Improvements in Web UI</li>
  <li>Martin Weindel &#8211; Documentation in Core and Mesos</li>
  <li>Masayoshi TSUZUKI &#8211; Improvements in Windows, Core, and PySpark; bug fixes in Windows, Core, and PySpark</li>
  <li>Matei Zaharia &#8211; Improvement in Core and SQL; bug fixes in Core and SQL</li>
  <li>Matthew Cheah &#8211; Bug fixes in Core</li>
  <li>Matthew Farrellee &#8211; Improvements in Core; new features in PySpark; bug fixes in Core and PySpark</li>
  <li>Matthew Rocklin &#8211; Bug fixes in Core</li>
  <li>Matthew Taylor &#8211; Bug fixes in SQL</li>
  <li>Michael Armbrust &#8211; Improvements in SQL; new features in SQL; bug fixes in Core, PySpark, and SQL; documentation in Core</li>
  <li>Michael Griffiths &#8211; Bug fixes in PySpark</li>
  <li>Michelangelo D&#8217;Agostino &#8211; Improvements in MLlib and PySpark</li>
  <li>Mike Timper &#8211; Bug fixes in SQL</li>
  <li>Min Shen &#8211; Bug fixes in YARN</li>
  <li>Mingfei Shi &#8211; Bug fixes in Core</li>
  <li>Mubarak Seyed &#8211; Improvements in Streaming</li>
  <li>NamelessAnalyst &#8211; Improvements in GraphX</li>
  <li>Nan Zhu &#8211; Bug fixes and Improvements in Core</li>
  <li>Nathan Artz &#8211; Documentation in Core</li>
  <li>Nathan Howell &#8211; Bug fixes in SQL</li>
  <li>Nicholas Chammas &#8211; Improvement in Core; improvements in Project Infra, Core, and EC2; bug fixes in Project Infra, EC2, and SQL; documentation in Core</li>
  <li>Niklas Wilcke &#8211; Improvements in MLlib; bug fixes in Core</li>
  <li>Nishkam Ravi &#8211; Bug fixes in Core</li>
  <li>Oded Zimerman &#8211; Bug fixes in GraphX</li>
  <li>Patrick Wendell &#8211; Improvements in Core; bug fixes in Project Infra, Core, and Mesos</li>
  <li>Prashant Sharma &#8211; Improvements in Core; bug fixes in Streaming and Core; improvement in Core, YARN, and Streaming</li>
  <li>Praveen Seluka - New feature in Core</li>
  <li>Qiping Li &#8211; Improvements and new features in MLlib</li>
  <li>RJ Nowling &#8211; Improvements in MLlib; bug fixes in GraphX; documentation in Core</li>
  <li>Ravindra Pesala &#8211; Improvements, new features, and bug fixes in SQL</li>
  <li>Raymond Liu &#8211; Improvement in Core and Shuffle</li>
  <li>Renat Yusupov &#8211; Bug fixes in SQL</li>
  <li>Reno Zhang &#8211; Improvements in YARN</li>
  <li>Reynold Xin &#8211; Improvements in Core, Shuffle, EC2, and SQL; new features in Project Infra, Core, and EC2; bug fixes in Core and SQL; improvement in Core, Shuffle, and SQL</li>
  <li>Reza Zadeh &#8211; Improvements in Core; new features in MLlib; documentation in Core</li>
  <li>Rob O&#8217;Dwyer &#8211; Improvements in PySpark</li>
  <li>Rong Gu &#8211; Improvements in Core</li>
  <li>Rui Li &#8211; New features in Java API</li>
  <li>Saisai Shao &#8211; Improvements in Streaming; bug fixes in Streaming and Shuffle</li>
  <li>Sandy Ryza &#8211; Improvements in Core, MLlib, and YARN; new features in Core; bug fixes in Core and SQL</li>
  <li>Santiago M. Mola &#8211; Documentation in Core</li>
  <li>Sean Owen &#8211; Improvement in Streaming; improvements in Core and Streaming; new features in Core; bug fixes in Java API, Core, MLlib, and Streaming; documentation in Core</li>
  <li>Shane Knapp &#8211; Bug fixes in Core</li>
  <li>Shiti Saxena &#8211; Improvement in Core</li>
  <li>Shivaram Venkataraman &#8211; Improvements in Core; bug fixes in Core and EC2</li>
  <li>Shixiong Zhu &#8211; Test in Core; improvements in Core and Web UI; bug fixes in Core, Web UI, and YARN; documentation in Streaming and Core</li>
  <li>Bai Shou &#8211; Improvements and bug fixes in SQL</li>
  <li>Shuo Xiang &#8211; New features and bug fixes in MLlib</li>
  <li>Su Yan &#8211; Bug fixes in Core</li>
  <li>Sung Chung &#8211; Improvements in MLlib</li>
  <li>Surong Quan &#8211; Improvements in Streaming</li>
  <li>Takuya UESHIN &#8211; Test in SQL; documentation in Core; bug fixes in Core and SQL; improvements in SQL</li>
  <li>Tal Sliwowicz &#8211; Bug fixes in Core</li>
  <li>Tathagata Das &#8211; Improvements in Core and Streaming; bug fixes in Streaming and Core; improvement in Streaming</li>
  <li>Ted Yu &#8211; Bug fixes and improvement in Core</li>
  <li>Thomas Graves &#8211; Bug fixes in Core and YARN</li>
  <li>Tianshuo Deng &#8211; Bug fixes in Core and Shuffle</li>
  <li>Timothy Chen &#8211; Bug fixes in Mesos</li>
  <li>Tingjun Xu &#8211; Bug fixes in YARN</li>
  <li>Tomohiko K. &#8211; Bug fixes in Core and PySpark; improvement in PySpark</li>
  <li>Uncle Gen &#8211; Improvements in GraphX</li>
  <li>Uri Laserson &#8211; Improvements in PySpark</li>
  <li>Varadharajan Mukundan &#8211; Improvements in Core</li>
  <li>Venkata Ramana Gollamudi &#8211; New features and bug fixes in SQL</li>
  <li>Victor Tso &#8211; Bug fixes in Core</li>
  <li>Vida Ha &#8211; Improvements in SQL; bug fixes in EC2</li>
  <li>Viper Kun &#8211; Documentation in Core</li>
  <li>Wang Fei &#8211; Test in SQL; improvements in Core and SQL; bug fixes in Core and SQL; documentation in Core</li>
  <li>Wang Tao &#8211; Improvements in Core, YARN, and SQL; bug fixes in Core and YARN</li>
  <li>Ward Viaene &#8211; Bug fixes in PySpark</li>
  <li>Wenchen Fan &#8211; Bug fixes in SQL</li>
  <li>William Benton &#8211; Improvements and bug fixes in SQL</li>
  <li>Xiangrui Meng &#8211; Improvements in Core, PySpark, MLlib, SQL, Java API, and Web UI; documentation in Core; new features in SQL, MLlib, and PySpark; bug fixes in Core, MLlib, and PySpark; improvement in PySpark, MLlib, and SQL</li>
  <li>Xinyun Huang &#8211; Improvements in SQL</li>
  <li>Yadong Qi &#8211; Test in Core; improvements and bug fixes in Streaming</li>
  <li>Yanbo Liang &#8211; New features in MLlib</li>
  <li>Yantang Zhai &#8211; Improvements in Core; bug fixes in Core, Web UI, and SQL</li>
  <li>Yash Datta &#8211; Improvements in SQL</li>
  <li>Ye Xianjin &#8211; Improvements in Core</li>
  <li>Yin Huai &#8211; Documentation in Core; bug fixes in SQL</li>
  <li>Zdenek Farana &#8211; Bug fixes in SQL</li>
  <li>Zhan Zhang &#8211; Build fixes in SQL</li>
  <li>Zhang, Liye &#8211; Improvements and bug fixes in Core</li>
</ul>

<p><em>Thanks to everyone who contributed!</em></p>


<p>
<br/>
<a href="/news/">Spark News Archive</a>
</p>

  </div>
</div>



<footer class="small">
  <hr>
  Apache Spark, Spark, Apache, the Apache feather logo, and the Apache Spark project logo are either registered
  trademarks or trademarks of The Apache Software Foundation in the United States and other countries.
  See guidance on use of Apache Spark <a href="/trademarks.html">trademarks</a>.
  All other marks mentioned may be trademarks or registered trademarks of their respective owners.
  Copyright &copy; 2018 The Apache Software Foundation, Licensed under the
  <a href="https://www.apache.org/licenses/">Apache License, Version 2.0</a>.
</footer>

</div>

</body>
</html>
